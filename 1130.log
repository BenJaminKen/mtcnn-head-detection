Generate Data for pNet
[2016-11-30 21:20:47,817][INFO] loading WIDER
[2016-11-30 21:20:48,380][INFO] total images, train: 12797, val: 3196
[2016-11-30 21:20:48,382][INFO] total faces, train: 97311, val: 24101
[2016-11-30 21:20:48,382][INFO] writing train data, 12797 images
[2016-11-30 21:20:48,382][INFO] remove data/pnet_positive_train
[2016-11-30 21:20:48,458][INFO] remove data/pnet_negative_train
[2016-11-30 21:20:48,596][INFO] remove data/pnet_part_train
[2016-11-30 21:20:48,666][INFO] fill queues
[2016-11-30 21:20:49,191][INFO] writes 3233 positives, 3226 negatives, 3540 part
[2016-11-30 21:20:49,429][INFO] writes 7229 positives, 5760 negatives, 7010 part
[2016-11-30 21:20:49,653][INFO] writes 11150 positives, 7794 negatives, 11055 part
[2016-11-30 21:20:49,865][INFO] writes 14390 positives, 10496 negatives, 15113 part
[2016-11-30 21:20:50,043][INFO] writes 18281 positives, 12928 negatives, 18790 part
[2016-11-30 21:20:50,339][INFO] writes 21271 positives, 16318 negatives, 22410 part
[2016-11-30 21:20:50,540][INFO] writes 24595 positives, 19584 negatives, 25820 part
[2016-11-30 21:20:50,747][INFO] writes 28210 positives, 22215 negatives, 29574 part
[2016-11-30 21:20:51,059][INFO] writes 31591 positives, 25088 negatives, 33320 part
[2016-11-30 21:20:51,266][INFO] writes 35516 positives, 27417 negatives, 37066 part
[2016-11-30 21:20:51,586][INFO] writes 39033 positives, 30936 negatives, 40030 part
[2016-11-30 21:20:51,791][INFO] writes 42311 positives, 33281 negatives, 44407 part
[2016-11-30 21:20:52,015][INFO] writes 45247 positives, 37072 negatives, 47680 part
[2016-11-30 21:20:52,207][INFO] writes 48824 positives, 39936 negatives, 51239 part
[2016-11-30 21:20:52,463][INFO] writes 52439 positives, 42877 negatives, 54683 part
[2016-11-30 21:20:52,672][INFO] writes 56100 positives, 45312 negatives, 58587 part
[2016-11-30 21:20:52,897][INFO] writes 59544 positives, 48025 negatives, 62430 part
[2016-11-30 21:20:53,137][INFO] writes 62844 positives, 51065 negatives, 66090 part
[2016-11-30 21:20:53,312][INFO] writes 66197 positives, 53942 negatives, 69860 part
[2016-11-30 21:20:53,609][INFO] writes 68353 positives, 59266 negatives, 72380 part
[2016-11-30 21:20:53,884][INFO] writes 70601 positives, 64586 negatives, 74812 part
[2016-11-30 21:20:54,110][INFO] writes 73525 positives, 68224 negatives, 78250 part
[2016-11-30 21:20:54,326][INFO] writes 77879 positives, 71168 negatives, 80952 part
[2016-11-30 21:20:54,585][INFO] writes 80381 positives, 74238 negatives, 85380 part
[2016-11-30 21:20:54,807][INFO] writes 83889 positives, 76750 negatives, 89360 part
[2016-11-30 21:20:55,027][INFO] writes 87835 positives, 79944 negatives, 92220 part
[2016-11-30 21:20:55,283][INFO] writes 90758 positives, 82561 negatives, 96680 part
[2016-11-30 21:20:55,506][INFO] writes 93875 positives, 86272 negatives, 99852 part
[2016-11-30 21:20:55,748][INFO] writes 96925 positives, 89745 negatives, 103329 part
[2016-11-30 21:20:56,027][INFO] writes 100732 positives, 92288 negatives, 106979 part
[2016-11-30 21:20:56,290][INFO] writes 103455 positives, 96464 negatives, 110080 part
[2016-11-30 21:20:56,525][INFO] writes 106610 positives, 99609 negatives, 113780 part
[2016-11-30 21:20:56,751][INFO] writes 109649 positives, 103270 negatives, 117080 part
[2016-11-30 21:20:56,991][INFO] writes 112581 positives, 107468 negatives, 119950 part
[2016-11-30 21:20:57,256][INFO] writes 116400 positives, 110949 negatives, 122650 part
[2016-11-30 21:20:57,426][INFO] writes 119317 positives, 113332 negatives, 127350 part
[2016-11-30 21:20:57,692][INFO] writes 122395 positives, 117342 negatives, 130262 part
[2016-11-30 21:20:57,864][INFO] writes 125946 positives, 119808 negatives, 134245 part
[2016-11-30 21:20:58,127][INFO] writes 129347 positives, 122752 negatives, 137900 part
[2016-11-30 21:20:58,394][INFO] writes 132826 positives, 125568 negatives, 141605 part
[2016-11-30 21:20:58,668][INFO] writes 135805 positives, 129664 negatives, 144530 part
[2016-11-30 21:20:58,929][INFO] writes 139483 positives, 132608 negatives, 147908 part
[2016-11-30 21:20:59,204][INFO] writes 142899 positives, 134912 negatives, 152188 part
[2016-11-30 21:20:59,370][INFO] writes 148656 positives, 137041 negatives, 154302 part
[2016-11-30 21:20:59,579][INFO] writes 150899 positives, 138769 negatives, 160331 part
[2016-11-30 21:20:59,827][INFO] writes 153983 positives, 142396 negatives, 163620 part
[2016-11-30 21:21:00,038][INFO] writes 157451 positives, 145557 negatives, 166991 part
[2016-11-30 21:21:00,344][INFO] writes 161339 positives, 148736 negatives, 169924 part
[2016-11-30 21:21:00,584][INFO] writes 166599 positives, 150467 negatives, 172933 part
[2016-11-30 21:21:00,819][INFO] writes 168461 positives, 153088 negatives, 178450 part
[2016-11-30 21:21:01,082][INFO] writes 172211 positives, 155228 negatives, 182560 part
[2016-11-30 21:21:01,275][INFO] writes 175579 positives, 158470 negatives, 185950 part
[2016-11-30 21:21:01,492][INFO] writes 178725 positives, 162048 negatives, 189226 part
[2016-11-30 21:21:01,774][INFO] writes 181862 positives, 165701 negatives, 192436 part
[2016-11-30 21:21:01,969][INFO] writes 185044 positives, 169085 negatives, 195870 part
[2016-11-30 21:21:02,202][INFO] writes 187947 positives, 173117 negatives, 198935 part
[2016-11-30 21:21:02,482][INFO] writes 190694 positives, 177686 negatives, 201619 part
[2016-11-30 21:21:02,699][INFO] writes 193562 positives, 181651 negatives, 204786 part
[2016-11-30 21:21:03,002][INFO] writes 197422 positives, 184987 negatives, 207590 part
[2016-11-30 21:21:03,195][INFO] writes 199401 positives, 189568 negatives, 211030 part
[2016-11-30 21:21:03,457][INFO] writes 201729 positives, 194544 negatives, 213726 part
[2016-11-30 21:21:03,725][INFO] writes 204161 positives, 199458 negatives, 216380 part
[2016-11-30 21:21:03,997][INFO] writes 205881 positives, 206204 negatives, 217914 part
[2016-11-30 21:21:04,239][INFO] writes 207713 positives, 212096 negatives, 220190 part
[2016-11-30 21:21:04,480][INFO] writes 209459 positives, 218150 negatives, 222390 part
[2016-11-30 21:21:04,787][INFO] writes 210847 positives, 225212 negatives, 223940 part
[2016-11-30 21:21:05,044][INFO] writes 211957 positives, 232742 negatives, 225300 part
[2016-11-30 21:21:05,293][INFO] writes 213592 positives, 239177 negatives, 227230 part
[2016-11-30 21:21:05,579][INFO] writes 214855 positives, 246414 negatives, 228730 part
[2016-11-30 21:21:05,822][INFO] writes 216667 positives, 252544 negatives, 230788 part
[2016-11-30 21:21:06,075][INFO] writes 217875 positives, 259860 negatives, 232264 part
[2016-11-30 21:21:06,327][INFO] writes 219530 positives, 266419 negatives, 234050 part
[2016-11-30 21:21:06,584][INFO] writes 220927 positives, 273232 negatives, 235840 part
[2016-11-30 21:21:06,819][INFO] writes 222627 positives, 279552 negatives, 237820 part
[2016-11-30 21:21:07,092][INFO] writes 224103 positives, 286326 negatives, 239570 part
[2016-11-30 21:21:07,350][INFO] writes 226383 positives, 291456 negatives, 242160 part
[2016-11-30 21:21:07,618][INFO] writes 228275 positives, 297390 negatives, 244334 part
[2016-11-30 21:21:07,893][INFO] writes 230471 positives, 302788 negatives, 246740 part
[2016-11-30 21:21:08,134][INFO] writes 233439 positives, 306944 negatives, 249616 part
[2016-11-30 21:21:08,454][INFO] writes 235611 positives, 312338 negatives, 252050 part
[2016-11-30 21:21:08,665][INFO] writes 237878 positives, 317061 negatives, 255060 part
[2016-11-30 21:21:08,960][INFO] writes 239414 positives, 323545 negatives, 257040 part
[2016-11-30 21:21:09,199][INFO] writes 242205 positives, 328624 negatives, 259170 part
[2016-11-30 21:21:09,451][INFO] writes 244112 positives, 333417 negatives, 262470 part
[2016-11-30 21:21:09,714][INFO] writes 246233 positives, 339026 negatives, 264740 part
[2016-11-30 21:21:09,933][INFO] writes 249576 positives, 342493 negatives, 267930 part
[2016-11-30 21:21:10,310][INFO] writes 251837 positives, 347928 negatives, 270234 part
[2016-11-30 21:21:10,637][INFO] writes 253628 positives, 353461 negatives, 272910 part
[2016-11-30 21:21:10,795][INFO] writes 257230 positives, 355968 negatives, 276801 part
[2016-11-30 21:21:11,067][INFO] writes 260077 positives, 359982 negatives, 279940 part
[2016-11-30 21:21:11,413][INFO] writes 262668 positives, 364364 negatives, 282967 part
[2016-11-30 21:21:11,636][INFO] writes 265603 positives, 368086 negatives, 286310 part
[2016-11-30 21:21:11,899][INFO] writes 268887 positives, 371712 negatives, 289400 part
[2016-11-30 21:21:12,139][INFO] writes 272677 positives, 374311 negatives, 293011 part
[2016-11-30 21:21:12,366][INFO] writes 275153 positives, 378496 negatives, 296350 part
[2016-11-30 21:21:12,588][INFO] writes 278118 positives, 382011 negatives, 299870 part
[2016-11-30 21:21:12,820][INFO] writes 281361 positives, 385408 negatives, 303230 part
[2016-11-30 21:21:13,067][INFO] writes 284291 positives, 389248 negatives, 306460 part
[2016-11-30 21:21:13,311][INFO] writes 287984 positives, 392832 negatives, 309183 part
[2016-11-30 21:21:13,616][INFO] writes 290557 positives, 396239 negatives, 313203 part
[2016-11-30 21:21:13,773][INFO] writes 294293 positives, 398336 negatives, 317370 part
[2016-11-30 21:21:14,025][INFO] writes 298223 positives, 400568 negatives, 321208 part
[2016-11-30 21:21:14,274][INFO] writes 301897 positives, 403072 negatives, 325030 part
[2016-11-30 21:21:14,441][INFO] writes 305406 positives, 405261 negatives, 329332 part
[2016-11-30 21:21:14,676][INFO] writes 308887 positives, 408207 negatives, 332905 part
[2016-11-30 21:21:14,908][INFO] writes 312079 positives, 411520 negatives, 336400 part
[2016-11-30 21:21:15,194][INFO] writes 315176 positives, 414464 negatives, 340359 part
[2016-11-30 21:21:15,387][INFO] writes 318946 positives, 416543 negatives, 344510 part
[2016-11-30 21:21:15,744][INFO] writes 322157 positives, 420736 negatives, 347106 part
[2016-11-30 21:21:15,924][INFO] writes 327217 positives, 422016 negatives, 350766 part
[2016-11-30 21:21:16,090][INFO] writes 331001 positives, 423808 negatives, 355190 part
[2016-11-30 21:21:16,302][INFO] writes 333945 positives, 425800 negatives, 360254 part
[2016-11-30 21:21:16,503][INFO] writes 337005 positives, 428804 negatives, 364190 part
[2016-11-30 21:21:16,751][INFO] writes 340870 positives, 431311 negatives, 367818 part
[2016-11-30 21:21:16,920][INFO] writes 344410 positives, 433099 negatives, 372490 part
[2016-11-30 21:21:17,179][INFO] writes 347385 positives, 436864 negatives, 375750 part
[2016-11-30 21:21:17,481][INFO] writes 351584 positives, 439268 negatives, 379147 part
[2016-11-30 21:21:17,726][INFO] writes 354739 positives, 441514 negatives, 383746 part
[2016-11-30 21:21:18,014][INFO] writes 357940 positives, 445488 negatives, 386571 part
[2016-11-30 21:21:18,196][INFO] writes 363619 positives, 446720 negatives, 389660 part
[2016-11-30 21:21:18,380][INFO] writes 365823 positives, 448350 negatives, 395826 part
[2016-11-30 21:21:18,633][INFO] writes 368944 positives, 451625 negatives, 399430 part
[2016-11-30 21:21:18,943][INFO] writes 372624 positives, 454715 negatives, 402660 part
[2016-11-30 21:21:19,190][INFO] writes 375341 positives, 458496 negatives, 406162 part
[2016-11-30 21:21:19,449][INFO] writes 378745 positives, 461354 negatives, 409900 part
[2016-11-30 21:21:19,721][INFO] writes 382400 positives, 464159 negatives, 413440 part
[2016-11-30 21:21:19,959][INFO] writes 387174 positives, 466688 negatives, 416137 part
[2016-11-30 21:21:20,149][INFO] writes 389432 positives, 469370 negatives, 421197 part
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WAR[2016-11-30 21:21:20,403][INFO] writes 392684 positives, 472565 negatives, 424750 part
[2016-11-30 21:21:20,653][INFO] writes 395727 positives, 476170 negatives, 428102 part
[2016-11-30 21:21:20,868][INFO] writes 399265 positives, 478617 negatives, 432117 part
[2016-11-30 21:21:21,124][INFO] writes 402261 positives, 482341 negatives, 435397 part
[2016-11-30 21:21:21,355][INFO] writes 405557 positives, 485485 negatives, 438957 part
[2016-11-30 21:21:21,640][INFO] writes 409112 positives, 488064 negatives, 442823 part
[2016-11-30 21:21:21,827][INFO] writes 413265 positives, 489887 negatives, 446847 part
[2016-11-30 21:21:22,084][INFO] writes 416336 positives, 493486 negatives, 450177 part
[2016-11-30 21:21:22,339][INFO] writes 419926 positives, 496000 negatives, 454073 part
[2016-11-30 21:21:22,571][INFO] writes 423458 positives, 498944 negatives, 457597 part
[2016-11-30 21:21:22,802][INFO] writes 426999 positives, 501363 negatives, 461637 part
[2016-11-30 21:21:23,056][INFO] writes 430147 positives, 505472 negatives, 464380 part
[2016-11-30 21:21:23,308][INFO] writes 432859 positives, 509532 negatives, 467608 part
[2016-11-30 21:21:23,541][INFO] writes 435934 positives, 513148 negatives, 470917 part
[2016-11-30 21:21:23,792][INFO] writes 439088 positives, 516864 negatives, 474047 part
[2016-11-30 21:21:24,011][INFO] writes 442358 positives, 520817 negatives, 476824 part
[2016-11-30 21:21:24,323][INFO] writes 445215 positives, 524534 negatives, 480250 part
[2016-11-30 21:21:24,502][INFO] writes 448603 positives, 527069 negatives, 484327 part
[2016-11-30 21:21:24,779][INFO] writes 452051 positives, 529991 negatives, 487957 part
[2016-11-30 21:21:25,046][INFO] writes 455045 positives, 534144 negatives, 490810 part
[2016-11-30 21:21:25,255][INFO] writes 457890 positives, 538112 negatives, 493997 part
[2016-11-30 21:21:25,521][INFO] writes 460551 positives, 542761 negatives, 496687 part
[2016-11-30 21:21:25,736][INFO] writes 463934 positives, 545865 negatives, 500200 part
[2016-11-30 21:21:25,941][INFO] writes 466596 positives, 549896 negatives, 503507 part
[2016-11-30 21:21:26,148][INFO] writes 469232 positives, 554220 negatives, 506547 part
[2016-11-30 21:21:26,450][INFO] writes 471886 positives, 558976 negatives, 509137 part
[2016-11-30 21:21:26,748][INFO] writes 474081 positives, 564101 negatives, 511817 part
[2016-11-30 21:21:27,085][INFO] writes 476624 positives, 569023 negatives, 514352 part
[2016-11-30 21:21:27,339][INFO] writes 479685 positives, 573697 negatives, 516617 part
[2016-11-30 21:21:27,594][INFO] writes 482902 positives, 576886 negatives, 520211 part
[2016-11-30 21:21:27,827][INFO] writes 484346 positives, 582400 negatives, 523253 part
[2016-11-30 21:21:28,075][INFO] writes 486290 positives, 588672 negatives, 525037 part
[2016-11-30 21:21:28,293][INFO] writes 487855 positives, 594947 negatives, 527197 part
[2016-11-30 21:21:28,557][INFO] writes 489506 positives, 601407 negatives, 529086 part
[2016-11-30 21:21:28,832][INFO] writes 491879 positives, 606336 negatives, 531784 part
[2016-11-30 21:21:29,052][INFO] writes 493660 positives, 612402 negatives, 533937 part
[2016-11-30 21:21:29,286][INFO] writes 495283 positives, 618879 negatives, 535837 part
[2016-11-30 21:21:29,585][INFO] writes 496924 positives, 625298 negatives, 537777 part
[2016-11-30 21:21:29,878][INFO] writes 498890 positives, 631102 negatives, 540007 part
[2016-11-30 21:21:30,129][INFO] writes 500435 positives, 637725 negatives, 541839 part
[2016-11-30 21:21:30,385][INFO] writes 502286 positives, 643836 negatives, 543877 part
[2016-11-30 21:21:30,650][INFO] writes 504013 positives, 650229 negatives, 545757 part
[2016-11-30 21:21:30,854][INFO] writes 505652 positives, 656720 negatives, 547627 part
[2016-11-30 21:21:31,129][INFO] writes 507331 positives, 663061 negatives, 549607 part
[2016-11-30 21:21:31,438][INFO] writes 509715 positives, 668077 negatives, 552207 part
[2016-11-30 21:21:31,674][INFO] writes 513097 positives, 671232 negatives, 555670 part
[2016-11-30 21:21:31,989][INFO] writes 514690 positives, 677632 negatives, 557677 part
[2016-11-30 21:21:32,351][INFO] writes 517994 positives, 682368 negatives, 559637 part
[2016-11-30 21:21:32,627][INFO] writes 519700 positives, 687312 negatives, 562987 part
[2016-11-30 21:21:32,881][INFO] writes 522184 positives, 692008 negatives, 565807 part
[2016-11-30 21:21:33,123][INFO] writes 524057 positives, 697915 negatives, 568027 part
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WAR[2016-11-30 21:21:33,369][INFO] writes 526324 positives, 703232 negatives, 570443 part
[2016-11-30 21:21:33,579][INFO] writes 528683 positives, 708353 negatives, 572963 part
[2016-11-30 21:21:33,855][INFO] writes 530452 positives, 714560 negatives, 574987 part
[2016-11-30 21:21:34,096][INFO] writes 533053 positives, 719489 negatives, 577457 part
[2016-11-30 21:21:34,334][INFO] writes 535945 positives, 722947 negatives, 581107 part
[2016-11-30 21:21:34,620][INFO] writes 537918 positives, 728694 negatives, 583387 part
[2016-11-30 21:21:34,932][INFO] writes 540193 positives, 733885 negatives, 585921 part
[2016-11-30 21:21:35,161][INFO] writes 542254 positives, 739558 negatives, 588187 part
[2016-11-30 21:21:35,466][INFO] writes 544495 positives, 744857 negatives, 590647 part
[2016-11-30 21:21:35,750][INFO] writes 546430 positives, 750671 negatives, 592898 part
[2016-11-30 21:21:36,008][INFO] writes 547896 positives, 757516 negatives, 594587 part
[2016-11-30 21:21:36,372][INFO] writes 549845 positives, 763507 negatives, 596647 part
[2016-11-30 21:21:36,683][INFO] writes 551375 positives, 770157 negatives, 598467 part
[2016-11-30 21:21:36,982][INFO] writes 552815 positives, 777155 negatives, 600029 part
[2016-11-30 21:21:37,208][INFO] writes 555016 positives, 782590 negatives, 602393 part
[2016-11-30 21:21:37,439][INFO] writes 557289 positives, 787869 negatives, 604841 part
[2016-11-30 21:21:37,656][INFO] writes 559129 positives, 793783 negatives, 607087 part
[2016-11-30 21:21:37,922][INFO] writes 560491 positives, 800861 negatives, 608647 part
[2016-11-30 21:21:38,155][INFO] writes 562346 positives, 806912 negatives, 610741 part
[2016-11-30 21:21:38,419][INFO] writes 564463 positives, 813059 negatives, 612477 part
[2016-11-30 21:21:38,642][INFO] writes 566600 positives, 817812 negatives, 615587 part
[2016-11-30 21:21:38,864][INFO] writes 568462 positives, 823930 negatives, 617607 part
[2016-11-30 21:21:39,204][INFO] writes 570229 positives, 830362 negatives, 619408 part
[2016-11-30 21:21:39,454][INFO] writes 573496 positives, 834816 negatives, 621687 part
[2016-11-30 21:21:39,613][INFO] writes 575843 positives, 838419 negatives, 625737 part
[2016-11-30 21:21:39,913][INFO] writes 577767 positives, 844255 negatives, 627977 part
[2016-11-30 21:21:40,189][INFO] writes 580706 positives, 848384 negatives, 630909 part
[2016-11-30 21:21:40,439][INFO] writes 583633 positives, 851972 negatives, 634394 part
[2016-11-30 21:21:40,668][INFO] writes 585847 positives, 857085 negatives, 637067 part
[2016-11-30 21:21:40,909][INFO] writes 587703 positives, 863099 negatives, 639197 part
[2016-11-30 21:21:41,190][INFO] writes 590954 positives, 867080 negatives, 641965 part
[2016-11-30 21:21:41,378][INFO] writes 593721 positives, 870656 negatives, 645622 part
[2016-11-30 21:21:41,630][INFO] writes 596917 positives, 874510 negatives, 648572 part
[2016-11-30 21:21:41,838][INFO] writes 599692 positives, 878240 negatives, 652067 part
[2016-11-30 21:21:42,108][INFO] writes 601974 positives, 883448 negatives, 654577 part
[2016-11-30 21:21:42,406][INFO] writes 604114 positives, 888960 negatives, 656925 part
[2016-11-30 21:21:42,634][INFO] writes 606216 positives, 894476 negatives, 659307 part
[2016-11-30 21:21:42,905][INFO] writes 608575 positives, 899637 negatives, 661787 part
[2016-11-30 21:21:43,124][INFO] writes 611466 positives, 903595 negatives, 664938 part
[2016-11-30 21:21:43,349][INFO] writes 614574 positives, 907693 negatives, 667732 part
[2016-11-30 21:21:43,626][INFO] writes 616656 positives, 912686 negatives, 670657 part
[2016-11-30 21:21:43,831][INFO] writes 619130 positives, 917632 negatives, 673237 part
[2016-11-30 21:21:44,137][INFO] Process-6 reads 1000
[2016-11-30 21:21:44,176][INFO] writes 621321 positives, 922901 negatives, 675777 part
[2016-11-30 21:21:44,390][INFO] writes 622864 positives, 929708 negatives, 677427 part
[2016-11-30 21:21:44,680][INFO] writes 624556 positives, 936336 negatives, 679107 part
[2016-11-30 21:21:44,936][INFO] writes 626851 positives, 941467 negatives, 681681 part
[2016-11-30 21:21:45,200][INFO] writes 628308 positives, 948314 negatives, 683377 part
[2016-11-30 21:21:45,435][INFO] writes 630111 positives, 954631 negatives, 685257 part
[2016-11-30 21:21:45,683][INFO] writes 631944 positives, 960907 negatives, 687148 part
[2016-11-30 21:21:45,903][INFO] writes 633871 positives, 966784 negatives, 689344 part
[2016-11-30 21:21:46,202][INFO] writes 635691 positives, 973001 negatives, 691307 part
[2016-11-30 21:21:46,473][INFO] writes 637106 positives, 979996 negatives, 692897 part
[2016-11-30 21:21:46,652][INFO] writes 639775 positives, 984427 negatives, 695797 part
[2016-11-30 21:21:46,929][INFO] writes 641147 positives, 991525 negatives, 697327 part
[2016-11-30 21:21:47,236][INFO] writes 642850 positives, 997972 negatives, 699177 part
[2016-11-30 21:21:47,503][INFO] writes 644302 positives, 1004800 negatives, 700897 part
[2016-11-30 21:21:47,604][INFO] Process-4 reads 1000
[2016-11-30 21:21:47,654][INFO] Process-8 reads 1000
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WAR[2016-11-30 21:21:47,730][INFO] writes 646279 positives, 1010533 negatives, 703187 part
[2016-11-30 21:21:47,949][INFO] writes 648391 positives, 1016081 negatives, 705527 part
[2016-11-30 21:21:48,227][INFO] writes 650457 positives, 1022071 negatives, 707471 part
[2016-11-30 21:21:48,467][INFO] writes 652610 positives, 1027712 negatives, 709677 part
[2016-11-30 21:21:48,529][INFO] Process-7 reads 1000
[2016-11-30 21:21:48,557][INFO] Process-2 reads 1000
[2016-11-30 21:21:48,772][INFO] writes 654961 positives, 1032571 negatives, 712467 part
[2016-11-30 21:21:48,986][INFO] writes 657200 positives, 1037782 negatives, 715017 part
[2016-11-30 21:21:49,216][INFO] writes 658839 positives, 1044193 negatives, 716967 part
[2016-11-30 21:21:49,482][INFO] writes 660210 positives, 1051342 negatives, 718447 part
[2016-11-30 21:21:49,820][INFO] writes 661809 positives, 1058086 negatives, 720104 part
[2016-11-30 21:21:49,861][INFO] Process-3 reads 1000
[2016-11-30 21:21:49,989][INFO] Process-5 reads 1000
[2016-11-30 21:21:50,022][INFO] writes 663249 positives, 1064983 negatives, 721767 part
[2016-11-30 21:21:50,270][INFO] writes 664912 positives, 1071629 negatives, 723458 part
[2016-11-30 21:21:50,502][INFO] writes 666532 positives, 1078301 negatives, 725166 part
[2016-11-30 21:21:50,615][INFO] Process-1 reads 1000
[2016-11-30 21:21:50,719][INFO] writes 668551 positives, 1084001 negatives, 727447 part
[2016-11-30 21:21:50,991][INFO] writes 670234 positives, 1090368 negatives, 729397 part
[2016-11-30 21:21:51,240][INFO] writes 671614 positives, 1097528 negatives, 730857 part
[2016-11-30 21:21:51,481][INFO] writes 673510 positives, 1103498 negatives, 732991 part
[2016-11-30 21:21:51,685][INFO] writes 675330 positives, 1109742 negatives, 734927 part
[2016-11-30 21:21:51,914][INFO] writes 676923 positives, 1116309 negatives, 736767 part
[2016-11-30 21:21:52,226][INFO] writes 678474 positives, 1122958 negatives, 738567 part
[2016-11-30 21:21:52,488][INFO] writes 679900 positives, 1129922 negatives, 740177 part
[2016-11-30 21:21:52,759][INFO] writes 681559 positives, 1136423 negatives, 742017 part
[2016-11-30 21:21:53,066][INFO] writes 683342 positives, 1142660 negatives, 743997 part
[2016-11-30 21:21:53,316][INFO] writes 684703 positives, 1149729 negatives, 745567 part
[2016-11-30 21:21:53,587][INFO] writes 686421 positives, 1156071 negatives, 747507 part
[2016-11-30 21:21:53,845][INFO] writes 688004 positives, 1162688 negatives, 749307 part
[2016-11-30 21:21:54,115][INFO] writes 689914 positives, 1168688 negatives, 751397 part
[2016-11-30 21:21:54,477][INFO] writes 691598 positives, 1174974 negatives, 753427 part
[2016-11-30 21:21:54,727][INFO] writes 693304 positives, 1181374 negatives, 755321 part
[2016-11-30 21:21:55,007][INFO] writes 694911 positives, 1187971 negatives, 757117 part
[2016-11-30 21:21:55,291][INFO] writes 696750 positives, 1194122 negatives, 759127 part
[2016-11-30 21:21:55,584][INFO] writes 698616 positives, 1200166 negatives, 761217 part
[2016-11-30 21:21:55,857][INFO] writes 700170 positives, 1207192 negatives, 762637 part
[2016-11-30 21:21:56,113][INFO] writes 702869 positives, 1211652 negatives, 765478 part
[2016-11-30 21:21:56,354][INFO] writes 704910 positives, 1216982 negatives, 768107 part
[2016-11-30 21:21:56,591][INFO] writes 706570 positives, 1223552 negatives, 769877 part
[2016-11-30 21:21:56,911][INFO] writes 708264 positives, 1229868 negatives, 771867 part
[2016-11-30 21:21:57,180][INFO] writes 710125 positives, 1235997 negatives, 773877 part
[2016-11-30 21:21:57,445][INFO] writes 712500 positives, 1240732 negatives, 776767 part
[2016-11-30 21:21:57,694][INFO] writes 713768 positives, 1247874 negatives, 778357 part
[2016-11-30 21:21:57,974][INFO] writes 715794 positives, 1253499 negatives, 780706 part
[2016-11-30 21:21:58,220][INFO] writes 717670 positives, 1259552 negatives, 782777 part
[2016-11-30 21:21:58,584][INFO] writes 720004 positives, 1264588 negatives, 785407 part
[2016-11-30 21:21:58,798][INFO] writes 721797 positives, 1270732 negatives, 787470 part
[2016-11-30 21:21:59,046][INFO] writes 723934 positives, 1276048 negatives, 790017 part
[2016-11-30 21:21:59,310][INFO] writes 725804 positives, 1282075 negatives, 792120 part
[2016-11-30 21:21:59,577][INFO] writes 727176 positives, 1289056 negatives, 793767 part
[2016-11-30 21:21:59,846][INFO] writes 729352 positives, 1294593 negatives, 796054 part
[2016-11-30 21:22:00,160][INFO] writes 731766 positives, 1299476 negatives, 798757 part
[2016-11-30 21:22:00,432][INFO] writes 733619 positives, 1305669 negatives, 800711 part
[2016-11-30 21:22:00,684][INFO] writes 735440 positives, 1311925 negatives, 802634 part
[2016-11-30 21:22:00,918][INFO] writes 737023 positives, 1318439 negatives, 804537 part
[2016-11-30 21:22:01,157][INFO] writes 738665 positives, 1324907 negatives, 806427 part
[2016-11-30 21:22:01,431][INFO] writes 739928 positives, 1332224 negatives, 807847 part
[2016-11-30 21:22:01,755][INFO] writes 741825 positives, 1338167 negatives, 810007 part
[2016-11-30 21:22:01,978][INFO] writes 744212 positives, 1343150 negatives, 812637 part
[2016-11-30 21:22:02,181][INFO] writes 746282 positives, 1348670 negatives, 815047 part
[2016-11-30 21:22:02,434][INFO] writes 747670 positives, 1355652 negatives, 816677 part
[2016-11-30 21:22:02,740][INFO] writes 749345 positives, 1362067 negatives, 818587 part
[2016-11-30 21:22:03,046][INFO] writes 750840 positives, 1368872 negatives, 820287 part
[2016-11-30 21:22:03,393][INFO] writes 752662 positives, 1375040 negatives, 822297 part
N] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] r[2016-11-30 21:22:03,677][INFO] writes 754213 positives, 1381752 negatives, 824034 part
[2016-11-30 21:22:03,866][INFO] writes 757175 positives, 1386167 negatives, 826657 part
[2016-11-30 21:22:04,097][INFO] writes 758594 positives, 1392688 negatives, 828717 part
[2016-11-30 21:22:04,383][INFO] writes 760684 positives, 1398528 negatives, 830787 part
[2016-11-30 21:22:04,593][INFO] writes 762597 positives, 1404250 negatives, 833152 part
[2016-11-30 21:22:04,807][INFO] writes 764655 positives, 1409957 negatives, 835387 part
[2016-11-30 21:22:05,049][INFO] writes 766326 positives, 1416606 negatives, 837067 part
[2016-11-30 21:22:05,368][INFO] writes 768059 positives, 1422823 negatives, 839117 part
[2016-11-30 21:22:05,627][INFO] writes 770097 positives, 1428565 negatives, 841337 part
[2016-11-30 21:22:05,852][INFO] writes 772467 positives, 1433622 negatives, 843910 part
[2016-11-30 21:22:06,086][INFO] writes 774598 positives, 1439104 negatives, 846297 part
[2016-11-30 21:22:06,313][INFO] writes 776523 positives, 1444569 negatives, 848907 part
[2016-11-30 21:22:06,638][INFO] writes 778008 positives, 1451294 negatives, 850697 part
[2016-11-30 21:22:06,904][INFO] writes 779760 positives, 1457552 negatives, 852687 part
[2016-11-30 21:22:07,180][INFO] writes 781871 positives, 1463133 negatives, 854995 part
[2016-11-30 21:22:07,468][INFO] writes 784214 positives, 1468374 negatives, 857411 part
[2016-11-30 21:22:07,712][INFO] writes 787720 positives, 1471872 negatives, 860407 part
[2016-11-30 21:22:07,944][INFO] writes 789819 positives, 1476453 negatives, 863727 part
[2016-11-30 21:22:08,216][INFO] writes 792584 positives, 1480628 negatives, 866787 part
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WAR[2016-11-30 21:22:08,420][INFO] writes 796220 positives, 1484252 negatives, 869527 part
[2016-11-30 21:22:08,664][INFO] writes 798051 positives, 1489281 negatives, 872667 part
[2016-11-30 21:22:09,033][INFO] writes 800066 positives, 1495076 negatives, 874857 part
[2016-11-30 21:22:09,303][INFO] writes 802225 positives, 1500597 negatives, 877177 part
[2016-11-30 21:22:09,548][INFO] writes 804194 positives, 1506526 negatives, 879279 part
[2016-11-30 21:22:09,845][INFO] writes 805888 positives, 1512704 negatives, 881407 part
[2016-11-30 21:22:10,110][INFO] writes 808448 positives, 1517954 negatives, 883597 part
[2016-11-30 21:22:10,414][INFO] writes 811136 positives, 1522526 negatives, 886337 part
[2016-11-30 21:22:10,631][INFO] writes 813645 positives, 1526407 negatives, 889947 part
[2016-11-30 21:22:10,899][INFO] writes 816501 positives, 1530864 negatives, 892634 part
[2016-11-30 21:22:11,103][INFO] writes 820760 positives, 1534464 negatives, 894775 part
[2016-11-30 21:22:11,233][INFO] writes 824487 positives, 1536850 negatives, 898662 part
[2016-11-30 21:22:11,457][INFO] writes 826462 positives, 1540000 negatives, 903537 part
[2016-11-30 21:22:11,667][INFO] writes 828846 positives, 1545216 negatives, 905937 part
[2016-11-30 21:22:12,007][INFO] writes 831917 positives, 1549595 negatives, 908487 part
[2016-11-30 21:22:12,229][INFO] writes 835528 positives, 1551733 negatives, 912738 part
[2016-11-30 21:22:12,439][INFO] writes 838273 positives, 1555429 negatives, 916297 part
[2016-11-30 21:22:12,729][INFO] writes 841490 positives, 1558692 negatives, 919817 part
[2016-11-30 21:22:13,135][INFO] writes 843993 positives, 1563269 negatives, 922737 part
[2016-11-30 21:22:13,341][INFO] writes 846708 positives, 1567414 negatives, 925877 part
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WAR[2016-11-30 21:22:13,591][INFO] writes 849679 positives, 1572099 negatives, 928221 part
[2016-11-30 21:22:13,948][INFO] writes 851347 positives, 1577798 negatives, 930854 part
[2016-11-30 21:22:14,132][INFO] writes 855222 positives, 1580033 negatives, 934744 part
[2016-11-30 21:22:14,364][INFO] writes 858024 positives, 1583872 negatives, 938103 part
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:22:14,751][INFO] writes 862252 positives, 1587840 negatives, 939907 part
[2016-11-30 21:22:14,952][INFO] writes 864900 positives, 1589372 negatives, 945727 part
[2016-11-30 21:22:15,319][INFO] writes 867128 positives, 1594314 negatives, 948557 part
N] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:22:15,706][INFO] writes 870172 positives, 1598197 negatives, 951630 part
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WAR[2016-11-30 21:22:15,953][INFO] writes 873814 positives, 1600452 negatives, 955733 part
[2016-11-30 21:22:16,327][INFO] writes 876638 positives, 1604327 negatives, 959034 part
[2016-11-30 21:22:16,607][INFO] writes 879948 positives, 1608473 negatives, 961578 part
[2016-11-30 21:22:16,952][INFO] writes 881656 positives, 1613796 negatives, 964547 part
N] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:22:17,323][INFO] writes 883231 positives, 1620313 negatives, 966455 part
idiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:22:17,798][INFO] writes 885044 positives, 1626451 negatives, 968504 part
N] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:22:18,559][INFO] writes 887275 positives, 1632000 negatives, 970724 part
N] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
N] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:22:33,618][INFO] Finish
[2016-11-30 21:22:33,776][INFO] writing val data, 3196 images
[2016-11-30 21:22:33,777][INFO] remove data/pnet_positive_val
[2016-11-30 21:22:33,815][INFO] remove data/pnet_negative_val
[2016-11-30 21:22:33,869][INFO] remove data/pnet_part_val
[2016-11-30 21:22:33,897][INFO] fill queues
[2016-11-30 21:22:34,515][INFO] writes 3012 positives, 3840 negatives, 3147 part
[2016-11-30 21:22:34,776][INFO] writes 6486 positives, 6656 negatives, 6857 part
[2016-11-30 21:22:34,966][INFO] writes 9919 positives, 9779 negatives, 10301 part
[2016-11-30 21:22:35,246][INFO] writes 12919 positives, 13260 negatives, 13820 part
[2016-11-30 21:22:35,542][INFO] writes 16390 positives, 16139 negatives, 17470 part
[2016-11-30 21:22:35,790][INFO] writes 20484 positives, 19322 negatives, 20193 part
[2016-11-30 21:22:35,976][INFO] writes 23591 positives, 21632 negatives, 24776 part
[2016-11-30 21:22:36,222][INFO] writes 26619 positives, 24832 negatives, 28548 part
[2016-11-30 21:22:36,526][INFO] writes 30322 positives, 27648 negatives, 32029 part
[2016-11-30 21:22:36,816][INFO] writes 33286 positives, 31323 negatives, 35390 part
[2016-11-30 21:22:36,956][INFO] writes 36820 positives, 33699 negatives, 39480 part
[2016-11-30 21:22:37,210][INFO] writes 40725 positives, 37622 negatives, 41652 part
[2016-11-30 21:22:37,403][INFO] writes 43193 positives, 40346 negatives, 46460 part
[2016-11-30 21:22:37,557][INFO] writes 46504 positives, 43595 negatives, 49900 part
[2016-11-30 21:22:37,810][INFO] writes 48526 positives, 49383 negatives, 52090 part
[2016-11-30 21:22:38,095][INFO] writes 50906 positives, 54522 negatives, 54571 part
[2016-11-30 21:22:38,335][INFO] writes 53034 positives, 59835 negatives, 57130 part
[2016-11-30 21:22:38,537][INFO] writes 57305 positives, 62976 negatives, 59718 part
[2016-11-30 21:22:38,784][INFO] writes 58624 positives, 68065 negatives, 63310 part
[2016-11-30 21:22:39,146][INFO] writes 60762 positives, 73507 negatives, 65730 part
[2016-11-30 21:22:39,380][INFO] writes 63150 positives, 78598 negatives, 68251 part
[2016-11-30 21:22:39,665][INFO] writes 65455 positives, 83583 negatives, 70961 part
[2016-11-30 21:22:39,941][INFO] writes 68828 positives, 87072 negatives, 74099 part
[2016-11-30 21:22:40,189][INFO] writes 71908 positives, 91043 negatives, 77048 part
[2016-11-30 21:22:40,392][INFO] writes 74859 positives, 94050 negatives, 81090 part
[2016-11-30 21:22:40,601][INFO] writes 78642 positives, 97560 negatives, 83797 part
[2016-11-30 21:22:40,855][INFO] writes 81411 positives, 100608 negatives, 87980 part
[2016-11-30 21:22:41,066][INFO] writes 84321 positives, 103936 negatives, 91742 part
[2016-11-30 21:22:41,325][INFO] writes 87372 positives, 107357 negatives, 95270 part
[2016-11-30 21:22:41,594][INFO] writes 91465 positives, 109568 negatives, 98966 part
[2016-11-30 21:22:41,834][INFO] writes 95673 positives, 112128 negatives, 102198 part
[2016-11-30 21:22:42,027][INFO] writes 98605 positives, 114304 negatives, 107090 part
[2016-11-30 21:22:42,233][INFO] writes 102229 positives, 116480 negatives, 111290 part
[2016-11-30 21:22:42,427][INFO] writes 105316 positives, 119903 negatives, 114780 part
[2016-11-30 21:22:42,673][INFO] writes 108235 positives, 123904 negatives, 117860 part
[2016-11-30 21:22:42,976][INFO] writes 111164 positives, 127515 negatives, 121320 part
[2016-11-30 21:22:43,222][INFO] writes 113477 positives, 132592 negatives, 123930 part
[2016-11-30 21:22:43,438][INFO] writes 116081 positives, 137088 negatives, 126830 part
[2016-11-30 21:22:43,725][INFO] writes 118378 positives, 142591 negatives, 129030 part
[2016-11-30 21:22:44,004][INFO] writes 121092 positives, 146520 negatives, 132387 part
[2016-11-30 21:22:44,243][INFO] writes 123299 positives, 151808 negatives, 134892 part
[2016-11-30 21:22:44,520][INFO] writes 125089 positives, 158080 negatives, 136830 part
[2016-11-30 21:22:44,750][INFO] writes 127494 positives, 162663 negatives, 139842 part
[2016-11-30 21:22:45,032][INFO] writes 129544 positives, 168208 negatives, 142247 part
[2016-11-30 21:22:45,332][INFO] writes 131302 positives, 174427 negatives, 144270 part
[2016-11-30 21:22:45,605][INFO] writes 132758 positives, 181359 negatives, 145882 part
[2016-11-30 21:22:45,816][INFO] writes 135026 positives, 186783 negatives, 148190 part
[2016-11-30 21:22:46,084][INFO] writes 136607 positives, 192992 negatives, 150400 part
[2016-11-30 21:22:46,311][INFO] writes 138988 positives, 198478 negatives, 152533 part
[2016-11-30 21:22:46,608][INFO] writes 140713 positives, 204416 negatives, 154870 part
[2016-11-30 21:22:46,891][INFO] writes 142910 positives, 209859 negatives, 157230 part
[2016-11-30 21:22:47,128][INFO] writes 146399 positives, 213888 negatives, 159712 part
[2016-11-30 21:22:47,328][INFO] writes 150001 positives, 216704 negatives, 163294 part
[2016-11-30 21:22:47,627][INFO] writes 151537 positives, 222112 negatives, 166350 part
[2016-11-30 21:22:47,882][INFO] writes 153569 positives, 227840 negatives, 168590 part
[2016-11-30 21:22:48,129][INFO] writes 156842 positives, 232448 negatives, 170709 part
[2016-11-30 21:22:48,368][INFO] writes 158019 positives, 238592 negatives, 173388 part
[2016-11-30 21:22:48,625][INFO] writes 159629 positives, 245090 negatives, 175280 part
[2016-11-30 21:22:48,917][INFO] writes 161268 positives, 251681 negatives, 177050 part
[2016-11-30 21:22:49,155][INFO] writes 162733 positives, 258536 negatives, 178730 part
[2016-11-30 21:22:49,403][INFO] writes 164851 positives, 264083 negatives, 181065 part
[2016-11-30 21:22:49,656][INFO] writes 166302 positives, 271066 negatives, 182631 part
[2016-11-30 21:22:49,889][INFO] writes 168423 positives, 276566 negatives, 185010 part
[2016-11-30 21:22:50,164][INFO] writes 170542 positives, 282307 negatives, 187150 part
[2016-11-30 21:22:50,389][INFO] writes 172358 positives, 288261 negatives, 189380 part
[2016-11-30 21:22:50,688][INFO] writes 174155 positives, 294424 negatives, 191420 part
[2016-11-30 21:22:50,944][INFO] writes 175956 positives, 300683 negatives, 193360 part
[2016-11-30 21:22:51,164][INFO] writes 177481 positives, 307358 negatives, 195160 part
[2016-11-30 21:22:51,421][INFO] writes 179172 positives, 313798 negatives, 197029 part
[2016-11-30 21:22:51,701][INFO] writes 180764 positives, 320425 negatives, 198810 part
[2016-11-30 21:22:51,940][INFO] writes 182617 positives, 326332 negatives, 201050 part
[2016-11-30 21:22:52,194][INFO] writes 184286 positives, 332800 negatives, 202913 part
[2016-11-30 21:22:52,437][INFO] writes 186038 positives, 339041 negatives, 204920 part
[2016-11-30 21:22:52,681][INFO] writes 188094 positives, 344726 negatives, 207179 part
[2016-11-30 21:22:52,922][INFO] writes 189731 positives, 351232 negatives, 209036 part
[2016-11-30 21:22:53,273][INFO] writes 191768 positives, 356961 negatives, 211270 part
[2016-11-30 21:22:53,570][INFO] writes 194137 positives, 361992 negatives, 213870 part
[2016-11-30 21:22:53,809][INFO] writes 196319 positives, 367370 negatives, 216310 part
[2016-11-30 21:22:54,101][INFO] writes 198013 positives, 373666 negatives, 218320 part
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:22:54,481][INFO] writes 200234 positives, 379245 negatives, 220520 part
[2016-11-30 21:22:54,741][INFO] writes 203243 positives, 382805 negatives, 223951 part
[2016-11-30 21:22:54,998][INFO] writes 205740 positives, 387519 negatives, 226740 part
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:22:55,331][INFO] writes 208717 positives, 392196 negatives, 229086 part
[2016-11-30 21:22:55,650][INFO] writes 210905 positives, 396604 negatives, 232490 part
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:22:56,185][INFO] writes 212721 positives, 402718 negatives, 234560 part
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:22:56,825][INFO] writes 216096 positives, 405760 negatives, 238143 part
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:23:01,937][INFO] Finish
[2016-11-30 21:23:02,030][INFO] loading CelebA
[2016-11-30 21:23:08,400][INFO] total images, train: 162079, val: 40520
[2016-11-30 21:23:08,400][INFO] writing train data, 162079 images
[2016-11-30 21:23:08,400][INFO] remove data/pnet_landmark_train
[2016-11-30 21:23:08,553][INFO] fill queues
[2016-11-30 21:23:09,364][INFO] writes 1000 landmark faces
[2016-11-30 21:23:09,655][INFO] writes 2000 landmark faces
[2016-11-30 21:23:09,911][INFO] writes 3000 landmark faces
[2016-11-30 21:23:10,146][INFO] writes 4000 landmark faces
[2016-11-30 21:23:10,373][INFO] writes 5000 landmark faces
[2016-11-30 21:23:10,635][INFO] writes 6000 landmark faces
[2016-11-30 21:23:10,862][INFO] writes 7000 landmark faces
[2016-11-30 21:23:11,138][INFO] writes 8000 landmark faces
[2016-11-30 21:23:11,379][INFO] writes 9000 landmark faces
[2016-11-30 21:23:11,601][INFO] writes 10000 landmark faces
[2016-11-30 21:23:11,853][INFO] writes 11000 landmark faces
[2016-11-30 21:23:12,088][INFO] writes 12000 landmark faces
[2016-11-30 21:23:12,303][INFO] writes 13000 landmark faces
[2016-11-30 21:23:12,535][INFO] writes 14000 landmark faces
[2016-11-30 21:23:12,767][INFO] writes 15000 landmark faces
[2016-11-30 21:23:13,018][INFO] writes 16000 landmark faces
[2016-11-30 21:23:13,256][INFO] writes 17000 landmark faces
[2016-11-30 21:23:13,472][INFO] writes 18000 landmark faces
[2016-11-30 21:23:13,723][INFO] writes 19000 landmark faces
[2016-11-30 21:23:13,974][INFO] writes 20000 landmark faces
[2016-11-30 21:23:14,202][INFO] writes 21000 landmark faces
[2016-11-30 21:23:14,430][INFO] writes 22000 landmark faces
[2016-11-30 21:23:14,669][INFO] writes 23000 landmark faces
[2016-11-30 21:23:14,885][INFO] writes 24000 landmark faces
[2016-11-30 21:23:15,107][INFO] writes 25000 landmark faces
[2016-11-30 21:23:15,317][INFO] writes 26000 landmark faces
[2016-11-30 21:23:15,523][INFO] writes 27000 landmark faces
[2016-11-30 21:23:15,730][INFO] writes 28000 landmark faces
[2016-11-30 21:23:15,946][INFO] writes 29000 landmark faces
[2016-11-30 21:23:16,205][INFO] writes 30000 landmark faces
[2016-11-30 21:23:16,454][INFO] writes 31000 landmark faces
[2016-11-30 21:23:16,690][INFO] writes 32000 landmark faces
[2016-11-30 21:23:16,918][INFO] writes 33000 landmark faces
[2016-11-30 21:23:17,140][INFO] writes 34000 landmark faces
[2016-11-30 21:23:17,362][INFO] writes 35000 landmark faces
[2016-11-30 21:23:17,577][INFO] writes 36000 landmark faces
[2016-11-30 21:23:17,819][INFO] writes 37000 landmark faces
[2016-11-30 21:23:18,051][INFO] writes 38000 landmark faces
[2016-11-30 21:23:18,279][INFO] writes 39000 landmark faces
[2016-11-30 21:23:18,502][INFO] writes 40000 landmark faces
[2016-11-30 21:23:18,729][INFO] writes 41000 landmark faces
[2016-11-30 21:23:18,963][INFO] writes 42000 landmark faces
[2016-11-30 21:23:19,201][INFO] writes 43000 landmark faces
[2016-11-30 21:23:19,444][INFO] writes 44000 landmark faces
[2016-11-30 21:23:19,670][INFO] writes 45000 landmark faces
[2016-11-30 21:23:19,912][INFO] writes 46000 landmark faces
[2016-11-30 21:23:20,149][INFO] writes 47000 landmark faces
[2016-11-30 21:23:20,375][INFO] writes 48000 landmark faces
[2016-11-30 21:23:20,616][INFO] writes 49000 landmark faces
[2016-11-30 21:23:20,880][INFO] writes 50000 landmark faces
[2016-11-30 21:23:21,153][INFO] writes 51000 landmark faces
[2016-11-30 21:23:21,396][INFO] writes 52000 landmark faces
[2016-11-30 21:23:21,654][INFO] writes 53000 landmark faces
[2016-11-30 21:23:21,844][INFO] writes 54000 landmark faces
[2016-11-30 21:23:22,079][INFO] writes 55000 landmark faces
[2016-11-30 21:23:22,304][INFO] writes 56000 landmark faces
[2016-11-30 21:23:22,526][INFO] writes 57000 landmark faces
[2016-11-30 21:23:22,790][INFO] writes 58000 landmark faces
[2016-11-30 21:23:23,005][INFO] writes 59000 landmark faces
[2016-11-30 21:23:23,227][INFO] writes 60000 landmark faces
[2016-11-30 21:23:23,466][INFO] writes 61000 landmark faces
[2016-11-30 21:23:23,675][INFO] writes 62000 landmark faces
[2016-11-30 21:23:23,901][INFO] writes 63000 landmark faces
[2016-11-30 21:23:24,141][INFO] writes 64000 landmark faces
[2016-11-30 21:23:24,371][INFO] writes 65000 landmark faces
[2016-11-30 21:23:24,669][INFO] writes 66000 landmark faces
[2016-11-30 21:23:24,932][INFO] writes 67000 landmark faces
[2016-11-30 21:23:25,188][INFO] writes 68000 landmark faces
[2016-11-30 21:23:25,412][INFO] writes 69000 landmark faces
[2016-11-30 21:23:25,650][INFO] writes 70000 landmark faces
[2016-11-30 21:23:25,922][INFO] writes 71000 landmark faces
[2016-11-30 21:23:26,148][INFO] writes 72000 landmark faces
[2016-11-30 21:23:26,404][INFO] writes 73000 landmark faces
[2016-11-30 21:23:26,631][INFO] writes 74000 landmark faces
[2016-11-30 21:23:26,840][INFO] writes 75000 landmark faces
[2016-11-30 21:23:27,105][INFO] writes 76000 landmark faces
[2016-11-30 21:23:27,337][INFO] writes 77000 landmark faces
[2016-11-30 21:23:27,498][INFO] Process-25 reads 1000
[2016-11-30 21:23:27,567][INFO] writes 78000 landmark faces
[2016-11-30 21:23:27,715][INFO] Process-20 reads 1000
[2016-11-30 21:23:27,820][INFO] Process-19 reads 1000
[2016-11-30 21:23:27,831][INFO] Process-22 reads 1000
[2016-11-30 21:23:27,865][INFO] writes 79000 landmark faces
[2016-11-30 21:23:27,933][INFO] Process-23 reads 1000
[2016-11-30 21:23:28,089][INFO] writes 80000 landmark faces
[2016-11-30 21:23:28,152][INFO] Process-26 reads 1000
[2016-11-30 21:23:28,310][INFO] writes 81000 landmark faces
[2016-11-30 21:23:28,528][INFO] writes 82000 landmark faces
[2016-11-30 21:23:28,723][INFO] Process-24 reads 1000
[2016-11-30 21:23:28,773][INFO] writes 83000 landmark faces
[2016-11-30 21:23:28,775][INFO] Process-21 reads 1000
[2016-11-30 21:23:29,000][INFO] writes 84000 landmark faces
[2016-11-30 21:23:29,236][INFO] writes 85000 landmark faces
[2016-11-30 21:23:29,450][INFO] writes 86000 landmark faces
[2016-11-30 21:23:29,681][INFO] writes 87000 landmark faces
[2016-11-30 21:23:29,925][INFO] writes 88000 landmark faces
[2016-11-30 21:23:30,174][INFO] writes 89000 landmark faces
[2016-11-30 21:23:30,407][INFO] writes 90000 landmark faces
[2016-11-30 21:23:30,633][INFO] writes 91000 landmark faces
[2016-11-30 21:23:30,870][INFO] writes 92000 landmark faces
[2016-11-30 21:23:31,104][INFO] writes 93000 landmark faces
[2016-11-30 21:23:31,332][INFO] writes 94000 landmark faces
[2016-11-30 21:23:31,629][INFO] writes 95000 landmark faces
[2016-11-30 21:23:31,861][INFO] writes 96000 landmark faces
[2016-11-30 21:23:32,079][INFO] writes 97000 landmark faces
[2016-11-30 21:23:32,293][INFO] writes 98000 landmark faces
[2016-11-30 21:23:32,520][INFO] writes 99000 landmark faces
[2016-11-30 21:23:32,728][INFO] writes 100000 landmark faces
[2016-11-30 21:23:32,967][INFO] writes 101000 landmark faces
[2016-11-30 21:23:33,185][INFO] writes 102000 landmark faces
[2016-11-30 21:23:33,388][INFO] writes 103000 landmark faces
[2016-11-30 21:23:33,602][INFO] writes 104000 landmark faces
[2016-11-30 21:23:33,839][INFO] writes 105000 landmark faces
[2016-11-30 21:23:34,051][INFO] writes 106000 landmark faces
[2016-11-30 21:23:34,289][INFO] writes 107000 landmark faces
[2016-11-30 21:23:34,516][INFO] writes 108000 landmark faces
[2016-11-30 21:23:34,751][INFO] writes 109000 landmark faces
[2016-11-30 21:23:34,979][INFO] writes 110000 landmark faces
[2016-11-30 21:23:35,216][INFO] writes 111000 landmark faces
[2016-11-30 21:23:35,451][INFO] writes 112000 landmark faces
[2016-11-30 21:23:35,711][INFO] writes 113000 landmark faces
[2016-11-30 21:23:35,913][INFO] writes 114000 landmark faces
[2016-11-30 21:23:36,248][INFO] writes 115000 landmark faces
[2016-11-30 21:23:36,550][INFO] writes 116000 landmark faces
[2016-11-30 21:23:36,792][INFO] writes 117000 landmark faces
[2016-11-30 21:23:37,038][INFO] writes 118000 landmark faces
[2016-11-30 21:23:37,278][INFO] writes 119000 landmark faces
[2016-11-30 21:23:37,519][INFO] writes 120000 landmark faces
[2016-11-30 21:23:37,794][INFO] writes 121000 landmark faces
[2016-11-30 21:23:38,075][INFO] writes 122000 landmark faces
[2016-11-30 21:23:38,321][INFO] writes 123000 landmark faces
[2016-11-30 21:23:38,518][INFO] writes 124000 landmark faces
[2016-11-30 21:23:38,734][INFO] writes 125000 landmark faces
[2016-11-30 21:23:38,952][INFO] writes 126000 landmark faces
[2016-11-30 21:23:39,172][INFO] writes 127000 landmark faces
[2016-11-30 21:23:39,410][INFO] writes 128000 landmark faces
[2016-11-30 21:23:39,612][INFO] writes 129000 landmark faces
[2016-11-30 21:23:39,846][INFO] writes 130000 landmark faces
[2016-11-30 21:23:40,079][INFO] writes 131000 landmark faces
[2016-11-30 21:23:40,321][INFO] writes 132000 landmark faces
[2016-11-30 21:23:40,552][INFO] writes 133000 landmark faces
[2016-11-30 21:23:40,763][INFO] writes 134000 landmark faces
[2016-11-30 21:23:41,006][INFO] writes 135000 landmark faces
[2016-11-30 21:23:41,230][INFO] writes 136000 landmark faces
[2016-11-30 21:23:41,432][INFO] writes 137000 landmark faces
[2016-11-30 21:23:41,643][INFO] writes 138000 landmark faces
[2016-11-30 21:23:41,883][INFO] writes 139000 landmark faces
[2016-11-30 21:23:42,143][INFO] writes 140000 landmark faces
[2016-11-30 21:23:42,367][INFO] writes 141000 landmark faces
[2016-11-30 21:23:42,613][INFO] writes 142000 landmark faces
[2016-11-30 21:23:42,826][INFO] writes 143000 landmark faces
[2016-11-30 21:23:43,090][INFO] writes 144000 landmark faces
[2016-11-30 21:23:43,334][INFO] writes 145000 landmark faces
[2016-11-30 21:23:43,572][INFO] writes 146000 landmark faces
[2016-11-30 21:23:43,808][INFO] writes 147000 landmark faces
[2016-11-30 21:23:44,049][INFO] writes 148000 landmark faces
[2016-11-30 21:23:44,310][INFO] writes 149000 landmark faces
[2016-11-30 21:23:44,571][INFO] writes 150000 landmark faces
[2016-11-30 21:23:44,769][INFO] writes 151000 landmark faces
[2016-11-30 21:23:45,011][INFO] writes 152000 landmark faces
[2016-11-30 21:23:45,238][INFO] writes 153000 landmark faces
[2016-11-30 21:23:45,469][INFO] writes 154000 landmark faces
[2016-11-30 21:23:45,666][INFO] writes 155000 landmark faces
[2016-11-30 21:23:45,791][INFO] Process-20 reads 2000
[2016-11-30 21:23:45,880][INFO] writes 156000 landmark faces
[2016-11-30 21:23:46,119][INFO] writes 157000 landmark faces
[2016-11-30 21:23:46,356][INFO] writes 158000 landmark faces
[2016-11-30 21:23:46,589][INFO] Process-26 reads 2000
[2016-11-30 21:23:46,600][INFO] writes 159000 landmark faces
[2016-11-30 21:23:46,612][INFO] Process-22 reads 2000
[2016-11-30 21:23:46,722][INFO] Process-23 reads 2000
[2016-11-30 21:23:46,739][INFO] Process-19 reads 2000
[2016-11-30 21:23:46,797][INFO] writes 160000 landmark faces
[2016-11-30 21:23:47,020][INFO] writes 161000 landmark faces
[2016-11-30 21:23:47,064][INFO] Process-25 reads 2000
[2016-11-30 21:23:47,097][INFO] Process-24 reads 2000
[2016-11-30 21:23:47,240][INFO] writes 162000 landmark faces
[2016-11-30 21:23:47,455][INFO] writes 163000 landmark faces
[2016-11-30 21:23:47,660][INFO] writes 164000 landmark faces
[2016-11-30 21:23:47,768][INFO] Process-21 reads 2000
[2016-11-30 21:23:47,895][INFO] writes 165000 landmark faces
[2016-11-30 21:23:48,167][INFO] writes 166000 landmark faces
[2016-11-30 21:23:48,400][INFO] writes 167000 landmark faces
[2016-11-30 21:23:48,634][INFO] writes 168000 landmark faces
[2016-11-30 21:23:48,891][INFO] writes 169000 landmark faces
[2016-11-30 21:23:49,171][INFO] writes 170000 landmark faces
[2016-11-30 21:23:49,411][INFO] writes 171000 landmark faces
[2016-11-30 21:23:49,635][INFO] writes 172000 landmark faces
[2016-11-30 21:23:49,856][INFO] writes 173000 landmark faces
[2016-11-30 21:23:50,068][INFO] writes 174000 landmark faces
[2016-11-30 21:23:50,297][INFO] writes 175000 landmark faces
[2016-11-30 21:23:50,553][INFO] writes 176000 landmark faces
[2016-11-30 21:23:50,763][INFO] writes 177000 landmark faces
[2016-11-30 21:23:50,976][INFO] writes 178000 landmark faces
[2016-11-30 21:23:51,173][INFO] writes 179000 landmark faces
[2016-11-30 21:23:51,405][INFO] writes 180000 landmark faces
[2016-11-30 21:23:51,636][INFO] writes 181000 landmark faces
[2016-11-30 21:23:51,875][INFO] writes 182000 landmark faces
[2016-11-30 21:23:52,111][INFO] writes 183000 landmark faces
[2016-11-30 21:23:52,361][INFO] writes 184000 landmark faces
[2016-11-30 21:23:52,601][INFO] writes 185000 landmark faces
[2016-11-30 21:23:52,837][INFO] writes 186000 landmark faces
[2016-11-30 21:23:53,105][INFO] writes 187000 landmark faces
[2016-11-30 21:23:53,325][INFO] writes 188000 landmark faces
[2016-11-30 21:23:53,548][INFO] writes 189000 landmark faces
[2016-11-30 21:23:53,787][INFO] writes 190000 landmark faces
[2016-11-30 21:23:54,002][INFO] writes 191000 landmark faces
[2016-11-30 21:23:54,232][INFO] writes 192000 landmark faces
[2016-11-30 21:23:54,482][INFO] writes 193000 landmark faces
[2016-11-30 21:23:54,715][INFO] writes 194000 landmark faces
[2016-11-30 21:23:54,942][INFO] writes 195000 landmark faces
[2016-11-30 21:23:55,203][INFO] writes 196000 landmark faces
[2016-11-30 21:23:55,450][INFO] writes 197000 landmark faces
[2016-11-30 21:23:55,739][INFO] writes 198000 landmark faces
[2016-11-30 21:23:55,969][INFO] writes 199000 landmark faces
[2016-11-30 21:23:56,254][INFO] writes 200000 landmark faces
[2016-11-30 21:23:56,478][INFO] writes 201000 landmark faces
[2016-11-30 21:23:56,705][INFO] writes 202000 landmark faces
[2016-11-30 21:23:56,949][INFO] writes 203000 landmark faces
[2016-11-30 21:23:57,205][INFO] writes 204000 landmark faces
[2016-11-30 21:23:57,442][INFO] writes 205000 landmark faces
[2016-11-30 21:23:57,669][INFO] writes 206000 landmark faces
[2016-11-30 21:23:57,898][INFO] writes 207000 landmark faces
[2016-11-30 21:23:58,152][INFO] writes 208000 landmark faces
[2016-11-30 21:23:58,382][INFO] writes 209000 landmark faces
[2016-11-30 21:23:58,617][INFO] writes 210000 landmark faces
[2016-11-30 21:23:58,838][INFO] writes 211000 landmark faces
[2016-11-30 21:23:59,132][INFO] writes 212000 landmark faces
[2016-11-30 21:23:59,346][INFO] writes 213000 landmark faces
[2016-11-30 21:23:59,626][INFO] writes 214000 landmark faces
[2016-11-30 21:23:59,853][INFO] writes 215000 landmark faces
[2016-11-30 21:24:00,175][INFO] writes 216000 landmark faces
[2016-11-30 21:24:00,446][INFO] writes 217000 landmark faces
[2016-11-30 21:24:00,700][INFO] writes 218000 landmark faces
[2016-11-30 21:24:00,921][INFO] writes 219000 landmark faces
[2016-11-30 21:24:01,150][INFO] writes 220000 landmark faces
[2016-11-30 21:24:01,367][INFO] writes 221000 landmark faces
[2016-11-30 21:24:01,593][INFO] writes 222000 landmark faces
[2016-11-30 21:24:01,832][INFO] writes 223000 landmark faces
[2016-11-30 21:24:02,091][INFO] writes 224000 landmark faces
[2016-11-30 21:24:02,333][INFO] writes 225000 landmark faces
[2016-11-30 21:24:02,587][INFO] writes 226000 landmark faces
[2016-11-30 21:24:02,838][INFO] writes 227000 landmark faces
[2016-11-30 21:24:03,082][INFO] writes 228000 landmark faces
[2016-11-30 21:24:03,322][INFO] writes 229000 landmark faces
[2016-11-30 21:24:03,560][INFO] writes 230000 landmark faces
[2016-11-30 21:24:03,836][INFO] writes 231000 landmark faces
[2016-11-30 21:24:04,043][INFO] writes 232000 landmark faces
[2016-11-30 21:24:04,247][INFO] writes 233000 landmark faces
[2016-11-30 21:24:04,374][INFO] Process-20 reads 3000
[2016-11-30 21:24:04,497][INFO] writes 234000 landmark faces
[2016-11-30 21:24:04,718][INFO] writes 235000 landmark faces
[2016-11-30 21:24:04,919][INFO] writes 236000 landmark faces
[2016-11-30 21:24:05,122][INFO] writes 237000 landmark faces
[2016-11-30 21:24:05,225][INFO] Process-26 reads 3000
[2016-11-30 21:24:05,365][INFO] writes 238000 landmark faces
[2016-11-30 21:24:05,542][INFO] Process-19 reads 3000
[2016-11-30 21:24:05,571][INFO] writes 239000 landmark faces
[2016-11-30 21:24:05,803][INFO] writes 240000 landmark faces
[2016-11-30 21:24:05,945][INFO] Process-24 reads 3000
[2016-11-30 21:24:05,951][INFO] Process-21 reads 3000
[2016-11-30 21:24:05,967][INFO] Process-23 reads 3000
[2016-11-30 21:24:06,005][INFO] writes 241000 landmark faces
[2016-11-30 21:24:06,254][INFO] writes 242000 landmark faces
[2016-11-30 21:24:06,512][INFO] writes 243000 landmark faces
[2016-11-30 21:24:06,520][INFO] Process-22 reads 3000
[2016-11-30 21:24:06,764][INFO] writes 244000 landmark faces
[2016-11-30 21:24:06,882][INFO] Process-25 reads 3000
[2016-11-30 21:24:07,018][INFO] writes 245000 landmark faces
[2016-11-30 21:24:07,244][INFO] writes 246000 landmark faces
[2016-11-30 21:24:07,475][INFO] writes 247000 landmark faces
[2016-11-30 21:24:07,746][INFO] writes 248000 landmark faces
[2016-11-30 21:24:08,008][INFO] writes 249000 landmark faces
[2016-11-30 21:24:08,289][INFO] writes 250000 landmark faces
[2016-11-30 21:24:08,534][INFO] writes 251000 landmark faces
[2016-11-30 21:24:08,774][INFO] writes 252000 landmark faces
[2016-11-30 21:24:08,998][INFO] writes 253000 landmark faces
[2016-11-30 21:24:09,271][INFO] writes 254000 landmark faces
[2016-11-30 21:24:09,543][INFO] writes 255000 landmark faces
[2016-11-30 21:24:09,757][INFO] writes 256000 landmark faces
[2016-11-30 21:24:09,988][INFO] writes 257000 landmark faces
[2016-11-30 21:24:10,200][INFO] writes 258000 landmark faces
[2016-11-30 21:24:10,391][INFO] writes 259000 landmark faces
[2016-11-30 21:24:10,596][INFO] writes 260000 landmark faces
[2016-11-30 21:24:10,849][INFO] writes 261000 landmark faces
[2016-11-30 21:24:11,146][INFO] writes 262000 landmark faces
[2016-11-30 21:24:11,409][INFO] writes 263000 landmark faces
[2016-11-30 21:24:11,649][INFO] writes 264000 landmark faces
[2016-11-30 21:24:11,960][INFO] writes 265000 landmark faces
[2016-11-30 21:24:12,229][INFO] writes 266000 landmark faces
[2016-11-30 21:24:12,472][INFO] writes 267000 landmark faces
[2016-11-30 21:24:12,762][INFO] writes 268000 landmark faces
[2016-11-30 21:24:13,064][INFO] writes 269000 landmark faces
[2016-11-30 21:24:13,356][INFO] writes 270000 landmark faces
[2016-11-30 21:24:13,665][INFO] writes 271000 landmark faces
[2016-11-30 21:24:13,926][INFO] writes 272000 landmark faces
[2016-11-30 21:24:14,179][INFO] writes 273000 landmark faces
[2016-11-30 21:24:14,430][INFO] writes 274000 landmark faces
[2016-11-30 21:24:14,702][INFO] writes 275000 landmark faces
[2016-11-30 21:24:15,006][INFO] writes 276000 landmark faces
[2016-11-30 21:24:15,275][INFO] writes 277000 landmark faces
[2016-11-30 21:24:15,500][INFO] writes 278000 landmark faces
[2016-11-30 21:24:15,729][INFO] writes 279000 landmark faces
[2016-11-30 21:24:15,946][INFO] writes 280000 landmark faces
[2016-11-30 21:24:16,146][INFO] writes 281000 landmark faces
[2016-11-30 21:24:16,362][INFO] writes 282000 landmark faces
[2016-11-30 21:24:16,598][INFO] writes 283000 landmark faces
[2016-11-30 21:24:16,816][INFO] writes 284000 landmark faces
[2016-11-30 21:24:17,079][INFO] writes 285000 landmark faces
[2016-11-30 21:24:17,311][INFO] writes 286000 landmark faces
[2016-11-30 21:24:17,566][INFO] writes 287000 landmark faces
[2016-11-30 21:24:17,778][INFO] writes 288000 landmark faces
[2016-11-30 21:24:17,991][INFO] writes 289000 landmark faces
[2016-11-30 21:24:18,220][INFO] writes 290000 landmark faces
[2016-11-30 21:24:18,442][INFO] writes 291000 landmark faces
[2016-11-30 21:24:18,678][INFO] writes 292000 landmark faces
[2016-11-30 21:24:18,907][INFO] writes 293000 landmark faces
[2016-11-30 21:24:19,129][INFO] writes 294000 landmark faces
[2016-11-30 21:24:19,354][INFO] writes 295000 landmark faces
[2016-11-30 21:24:19,579][INFO] writes 296000 landmark faces
[2016-11-30 21:24:19,792][INFO] writes 297000 landmark faces
[2016-11-30 21:24:20,017][INFO] writes 298000 landmark faces
[2016-11-30 21:24:20,253][INFO] writes 299000 landmark faces
[2016-11-30 21:24:20,479][INFO] writes 300000 landmark faces
[2016-11-30 21:24:20,713][INFO] writes 301000 landmark faces
[2016-11-30 21:24:20,957][INFO] writes 302000 landmark faces
[2016-11-30 21:24:21,198][INFO] writes 303000 landmark faces
[2016-11-30 21:24:21,441][INFO] writes 304000 landmark faces
[2016-11-30 21:24:21,657][INFO] writes 305000 landmark faces
[2016-11-30 21:24:21,887][INFO] writes 306000 landmark faces
[2016-11-30 21:24:22,121][INFO] writes 307000 landmark faces
[2016-11-30 21:24:22,364][INFO] writes 308000 landmark faces
[2016-11-30 21:24:22,583][INFO] writes 309000 landmark faces
[2016-11-30 21:24:22,822][INFO] writes 310000 landmark faces
[2016-11-30 21:24:23,069][INFO] writes 311000 landmark faces
[2016-11-30 21:24:23,267][INFO] writes 312000 landmark faces
[2016-11-30 21:24:23,305][INFO] Process-26 reads 4000
[2016-11-30 21:24:23,472][INFO] writes 313000 landmark faces
[2016-11-30 21:24:23,744][INFO] writes 314000 landmark faces
[2016-11-30 21:24:23,921][INFO] Process-19 reads 4000
[2016-11-30 21:24:23,995][INFO] writes 315000 landmark faces
[2016-11-30 21:24:24,223][INFO] writes 316000 landmark faces
[2016-11-30 21:24:24,385][INFO] Process-20 reads 4000
[2016-11-30 21:24:24,437][INFO] writes 317000 landmark faces
[2016-11-30 21:24:24,664][INFO] writes 318000 landmark faces
[2016-11-30 21:24:24,779][INFO] Process-24 reads 4000
[2016-11-30 21:24:24,921][INFO] writes 319000 landmark faces
[2016-11-30 21:24:25,108][INFO] Process-22 reads 4000
[2016-11-30 21:24:25,148][INFO] writes 320000 landmark faces
[2016-11-30 21:24:25,373][INFO] writes 321000 landmark faces
[2016-11-30 21:24:25,643][INFO] writes 322000 landmark faces
[2016-11-30 21:24:25,868][INFO] writes 323000 landmark faces
[2016-11-30 21:24:26,039][INFO] Process-21 reads 4000
[2016-11-30 21:24:26,100][INFO] writes 324000 landmark faces
[2016-11-30 21:24:26,338][INFO] writes 325000 landmark faces
[2016-11-30 21:24:26,567][INFO] writes 326000 landmark faces
[2016-11-30 21:24:26,610][INFO] Process-23 reads 4000
[2016-11-30 21:24:26,789][INFO] writes 327000 landmark faces
[2016-11-30 21:24:26,970][INFO] Process-25 reads 4000
[2016-11-30 21:24:27,036][INFO] writes 328000 landmark faces
[2016-11-30 21:24:27,257][INFO] writes 329000 landmark faces
[2016-11-30 21:24:27,473][INFO] writes 330000 landmark faces
[2016-11-30 21:24:27,733][INFO] writes 331000 landmark faces
[2016-11-30 21:24:27,958][INFO] writes 332000 landmark faces
[2016-11-30 21:24:28,168][INFO] writes 333000 landmark faces
[2016-11-30 21:24:28,412][INFO] writes 334000 landmark faces
[2016-11-30 21:24:28,626][INFO] writes 335000 landmark faces
[2016-11-30 21:24:28,890][INFO] writes 336000 landmark faces
[2016-11-30 21:24:29,122][INFO] writes 337000 landmark faces
[2016-11-30 21:24:29,365][INFO] writes 338000 landmark faces
[2016-11-30 21:24:29,627][INFO] writes 339000 landmark faces
[2016-11-30 21:24:29,839][INFO] writes 340000 landmark faces
[2016-11-30 21:24:30,052][INFO] writes 341000 landmark faces
[2016-11-30 21:24:30,302][INFO] writes 342000 landmark faces
[2016-11-30 21:24:30,543][INFO] writes 343000 landmark faces
[2016-11-30 21:24:30,750][INFO] writes 344000 landmark faces
[2016-11-30 21:24:31,011][INFO] writes 345000 landmark faces
[2016-11-30 21:24:31,247][INFO] writes 346000 landmark faces
[2016-11-30 21:24:31,501][INFO] writes 347000 landmark faces
[2016-11-30 21:24:31,741][INFO] writes 348000 landmark faces
[2016-11-30 21:24:32,001][INFO] writes 349000 landmark faces
[2016-11-30 21:24:32,224][INFO] writes 350000 landmark faces
[2016-11-30 21:24:32,481][INFO] writes 351000 landmark faces
[2016-11-30 21:24:32,691][INFO] writes 352000 landmark faces
[2016-11-30 21:24:32,914][INFO] writes 353000 landmark faces
[2016-11-30 21:24:33,126][INFO] writes 354000 landmark faces
[2016-11-30 21:24:33,322][INFO] writes 355000 landmark faces
[2016-11-30 21:24:33,531][INFO] writes 356000 landmark faces
[2016-11-30 21:24:33,763][INFO] writes 357000 landmark faces
[2016-11-30 21:24:33,980][INFO] writes 358000 landmark faces
[2016-11-30 21:24:34,219][INFO] writes 359000 landmark faces
[2016-11-30 21:24:34,443][INFO] writes 360000 landmark faces
[2016-11-30 21:24:34,664][INFO] writes 361000 landmark faces
[2016-11-30 21:24:34,883][INFO] writes 362000 landmark faces
[2016-11-30 21:24:35,108][INFO] writes 363000 landmark faces
[2016-11-30 21:24:35,325][INFO] writes 364000 landmark faces
[2016-11-30 21:24:35,525][INFO] writes 365000 landmark faces
[2016-11-30 21:24:35,744][INFO] writes 366000 landmark faces
[2016-11-30 21:24:35,980][INFO] writes 367000 landmark faces
[2016-11-30 21:24:36,214][INFO] writes 368000 landmark faces
[2016-11-30 21:24:36,449][INFO] writes 369000 landmark faces
[2016-11-30 21:24:36,679][INFO] writes 370000 landmark faces
[2016-11-30 21:24:36,899][INFO] writes 371000 landmark faces
[2016-11-30 21:24:37,101][INFO] writes 372000 landmark faces
[2016-11-30 21:24:37,331][INFO] writes 373000 landmark faces
[2016-11-30 21:24:37,536][INFO] writes 374000 landmark faces
[2016-11-30 21:24:37,784][INFO] writes 375000 landmark faces
[2016-11-30 21:24:38,034][INFO] writes 376000 landmark faces
[2016-11-30 21:24:38,266][INFO] writes 377000 landmark faces
[2016-11-30 21:24:38,499][INFO] writes 378000 landmark faces
[2016-11-30 21:24:38,724][INFO] writes 379000 landmark faces
[2016-11-30 21:24:38,975][INFO] writes 380000 landmark faces
[2016-11-30 21:24:39,215][INFO] writes 381000 landmark faces
[2016-11-30 21:24:39,452][INFO] writes 382000 landmark faces
[2016-11-30 21:24:39,661][INFO] writes 383000 landmark faces
[2016-11-30 21:24:39,863][INFO] writes 384000 landmark faces
[2016-11-30 21:24:40,112][INFO] writes 385000 landmark faces
[2016-11-30 21:24:40,340][INFO] writes 386000 landmark faces
[2016-11-30 21:24:40,631][INFO] writes 387000 landmark faces
[2016-11-30 21:24:40,870][INFO] writes 388000 landmark faces
[2016-11-30 21:24:41,135][INFO] writes 389000 landmark faces
[2016-11-30 21:24:41,423][INFO] writes 390000 landmark faces
[2016-11-30 21:24:41,659][INFO] writes 391000 landmark faces
[2016-11-30 21:24:41,895][INFO] writes 392000 landmark faces
[2016-11-30 21:24:42,050][INFO] Process-26 reads 5000
[2016-11-30 21:24:42,134][INFO] writes 393000 landmark faces
[2016-11-30 21:24:42,420][INFO] writes 394000 landmark faces
[2016-11-30 21:24:42,651][INFO] writes 395000 landmark faces
[2016-11-30 21:24:42,728][INFO] Process-19 reads 5000
[2016-11-30 21:24:42,885][INFO] writes 396000 landmark faces
[2016-11-30 21:24:43,105][INFO] writes 397000 landmark faces
[2016-11-30 21:24:43,324][INFO] writes 398000 landmark faces
[2016-11-30 21:24:43,574][INFO] Process-24 reads 5000
[2016-11-30 21:24:43,584][INFO] writes 399000 landmark faces
[2016-11-30 21:24:43,652][INFO] Process-20 reads 5000
[2016-11-30 21:24:43,785][INFO] Process-21 reads 5000
[2016-11-30 21:24:43,826][INFO] writes 400000 landmark faces
[2016-11-30 21:24:44,054][INFO] writes 401000 landmark faces
[2016-11-30 21:24:44,299][INFO] writes 402000 landmark faces
[2016-11-30 21:24:44,344][INFO] Process-25 reads 5000
[2016-11-30 21:24:44,415][INFO] Process-22 reads 5000
[2016-11-30 21:24:44,519][INFO] writes 403000 landmark faces
[2016-11-30 21:24:44,752][INFO] writes 404000 landmark faces
[2016-11-30 21:24:45,025][INFO] writes 405000 landmark faces
[2016-11-30 21:24:45,252][INFO] writes 406000 landmark faces
[2016-11-30 21:24:45,481][INFO] writes 407000 landmark faces
[2016-11-30 21:24:45,695][INFO] writes 408000 landmark faces
[2016-11-30 21:24:45,936][INFO] writes 409000 landmark faces
[2016-11-30 21:24:45,991][INFO] Process-23 reads 5000
[2016-11-30 21:24:46,165][INFO] writes 410000 landmark faces
[2016-11-30 21:24:46,396][INFO] writes 411000 landmark faces
[2016-11-30 21:24:46,605][INFO] writes 412000 landmark faces
[2016-11-30 21:24:46,856][INFO] writes 413000 landmark faces
[2016-11-30 21:24:47,111][INFO] writes 414000 landmark faces
[2016-11-30 21:24:47,374][INFO] writes 415000 landmark faces
[2016-11-30 21:24:47,595][INFO] writes 416000 landmark faces
[2016-11-30 21:24:47,844][INFO] writes 417000 landmark faces
[2016-11-30 21:24:48,129][INFO] writes 418000 landmark faces
[2016-11-30 21:24:48,398][INFO] writes 419000 landmark faces
[2016-11-30 21:24:48,664][INFO] writes 420000 landmark faces
[2016-11-30 21:24:48,923][INFO] writes 421000 landmark faces
[2016-11-30 21:24:49,201][INFO] writes 422000 landmark faces
[2016-11-30 21:24:49,448][INFO] writes 423000 landmark faces
[2016-11-30 21:24:49,661][INFO] writes 424000 landmark faces
[2016-11-30 21:24:49,870][INFO] writes 425000 landmark faces
[2016-11-30 21:24:50,099][INFO] writes 426000 landmark faces
[2016-11-30 21:24:50,333][INFO] writes 427000 landmark faces
[2016-11-30 21:24:50,622][INFO] writes 428000 landmark faces
[2016-11-30 21:24:50,846][INFO] writes 429000 landmark faces
[2016-11-30 21:24:51,108][INFO] writes 430000 landmark faces
[2016-11-30 21:24:51,359][INFO] writes 431000 landmark faces
[2016-11-30 21:24:51,596][INFO] writes 432000 landmark faces
[2016-11-30 21:24:51,819][INFO] writes 433000 landmark faces
[2016-11-30 21:24:52,043][INFO] writes 434000 landmark faces
[2016-11-30 21:24:52,257][INFO] writes 435000 landmark faces
[2016-11-30 21:24:52,504][INFO] writes 436000 landmark faces
[2016-11-30 21:24:52,718][INFO] writes 437000 landmark faces
[2016-11-30 21:24:52,958][INFO] writes 438000 landmark faces
[2016-11-30 21:24:53,192][INFO] writes 439000 landmark faces
[2016-11-30 21:24:53,395][INFO] writes 440000 landmark faces
[2016-11-30 21:24:53,608][INFO] writes 441000 landmark faces
[2016-11-30 21:24:53,866][INFO] writes 442000 landmark faces
[2016-11-30 21:24:54,095][INFO] writes 443000 landmark faces
[2016-11-30 21:24:54,306][INFO] writes 444000 landmark faces
[2016-11-30 21:24:54,536][INFO] writes 445000 landmark faces
[2016-11-30 21:24:54,759][INFO] writes 446000 landmark faces
[2016-11-30 21:24:54,980][INFO] writes 447000 landmark faces
[2016-11-30 21:24:55,220][INFO] writes 448000 landmark faces
[2016-11-30 21:24:55,444][INFO] writes 449000 landmark faces
[2016-11-30 21:24:55,663][INFO] writes 450000 landmark faces
[2016-11-30 21:24:55,883][INFO] writes 451000 landmark faces
[2016-11-30 21:24:56,158][INFO] writes 452000 landmark faces
[2016-11-30 21:24:56,402][INFO] writes 453000 landmark faces
[2016-11-30 21:24:56,625][INFO] writes 454000 landmark faces
[2016-11-30 21:24:56,887][INFO] writes 455000 landmark faces
[2016-11-30 21:24:57,140][INFO] writes 456000 landmark faces
[2016-11-30 21:24:57,365][INFO] writes 457000 landmark faces
[2016-11-30 21:24:57,598][INFO] writes 458000 landmark faces
[2016-11-30 21:24:57,848][INFO] writes 459000 landmark faces
[2016-11-30 21:24:58,062][INFO] writes 460000 landmark faces
[2016-11-30 21:24:58,342][INFO] writes 461000 landmark faces
[2016-11-30 21:24:58,590][INFO] writes 462000 landmark faces
[2016-11-30 21:24:58,797][INFO] writes 463000 landmark faces
[2016-11-30 21:24:59,008][INFO] writes 464000 landmark faces
[2016-11-30 21:24:59,214][INFO] writes 465000 landmark faces
[2016-11-30 21:24:59,404][INFO] writes 466000 landmark faces
[2016-11-30 21:24:59,633][INFO] writes 467000 landmark faces
[2016-11-30 21:24:59,855][INFO] writes 468000 landmark faces
[2016-11-30 21:25:00,087][INFO] writes 469000 landmark faces
[2016-11-30 21:25:00,302][INFO] writes 470000 landmark faces
[2016-11-30 21:25:00,404][INFO] Process-26 reads 6000
[2016-11-30 21:25:00,606][INFO] writes 471000 landmark faces
[2016-11-30 21:25:00,857][INFO] writes 472000 landmark faces
[2016-11-30 21:25:01,098][INFO] writes 473000 landmark faces
[2016-11-30 21:25:01,309][INFO] writes 474000 landmark faces
[2016-11-30 21:25:01,529][INFO] writes 475000 landmark faces
[2016-11-30 21:25:01,580][INFO] Process-19 reads 6000
[2016-11-30 21:25:01,762][INFO] writes 476000 landmark faces
[2016-11-30 21:25:01,977][INFO] Process-24 reads 6000
[2016-11-30 21:25:01,978][INFO] writes 477000 landmark faces
[2016-11-30 21:25:02,235][INFO] writes 478000 landmark faces
[2016-11-30 21:25:02,306][INFO] Process-25 reads 6000
[2016-11-30 21:25:02,451][INFO] writes 479000 landmark faces
[2016-11-30 21:25:02,667][INFO] writes 480000 landmark faces
[2016-11-30 21:25:02,709][INFO] Process-20 reads 6000
[2016-11-30 21:25:02,852][INFO] Process-21 reads 6000
[2016-11-30 21:25:02,878][INFO] writes 481000 landmark faces
[2016-11-30 21:25:03,092][INFO] writes 482000 landmark faces
[2016-11-30 21:25:03,328][INFO] writes 483000 landmark faces
[2016-11-30 21:25:03,550][INFO] writes 484000 landmark faces
[2016-11-30 21:25:03,787][INFO] writes 485000 landmark faces
[2016-11-30 21:25:03,998][INFO] writes 486000 landmark faces
[2016-11-30 21:25:04,055][INFO] Process-22 reads 6000
[2016-11-30 21:25:04,211][INFO] writes 487000 landmark faces
[2016-11-30 21:25:04,425][INFO] writes 488000 landmark faces
[2016-11-30 21:25:04,683][INFO] writes 489000 landmark faces
[2016-11-30 21:25:04,719][INFO] Process-23 reads 6000
[2016-11-30 21:25:04,923][INFO] writes 490000 landmark faces
[2016-11-30 21:25:05,144][INFO] writes 491000 landmark faces
[2016-11-30 21:25:05,377][INFO] writes 492000 landmark faces
[2016-11-30 21:25:05,604][INFO] writes 493000 landmark faces
[2016-11-30 21:25:05,859][INFO] writes 494000 landmark faces
[2016-11-30 21:25:06,090][INFO] writes 495000 landmark faces
[2016-11-30 21:25:06,314][INFO] writes 496000 landmark faces
[2016-11-30 21:25:06,519][INFO] writes 497000 landmark faces
[2016-11-30 21:25:06,740][INFO] writes 498000 landmark faces
[2016-11-30 21:25:06,951][INFO] writes 499000 landmark faces
[2016-11-30 21:25:07,222][INFO] writes 500000 landmark faces
[2016-11-30 21:25:07,439][INFO] writes 501000 landmark faces
[2016-11-30 21:25:07,641][INFO] writes 502000 landmark faces
[2016-11-30 21:25:07,882][INFO] writes 503000 landmark faces
[2016-11-30 21:25:08,117][INFO] writes 504000 landmark faces
[2016-11-30 21:25:08,365][INFO] writes 505000 landmark faces
[2016-11-30 21:25:08,616][INFO] writes 506000 landmark faces
[2016-11-30 21:25:08,858][INFO] writes 507000 landmark faces
[2016-11-30 21:25:09,079][INFO] writes 508000 landmark faces
[2016-11-30 21:25:09,324][INFO] writes 509000 landmark faces
[2016-11-30 21:25:09,574][INFO] writes 510000 landmark faces
[2016-11-30 21:25:09,840][INFO] writes 511000 landmark faces
[2016-11-30 21:25:10,081][INFO] writes 512000 landmark faces
[2016-11-30 21:25:10,328][INFO] writes 513000 landmark faces
[2016-11-30 21:25:10,541][INFO] writes 514000 landmark faces
[2016-11-30 21:25:10,781][INFO] writes 515000 landmark faces
[2016-11-30 21:25:11,029][INFO] writes 516000 landmark faces
[2016-11-30 21:25:11,297][INFO] writes 517000 landmark faces
[2016-11-30 21:25:11,521][INFO] writes 518000 landmark faces
[2016-11-30 21:25:11,734][INFO] writes 519000 landmark faces
[2016-11-30 21:25:11,988][INFO] writes 520000 landmark faces
[2016-11-30 21:25:12,232][INFO] writes 521000 landmark faces
[2016-11-30 21:25:12,449][INFO] writes 522000 landmark faces
[2016-11-30 21:25:12,668][INFO] writes 523000 landmark faces
[2016-11-30 21:25:12,887][INFO] writes 524000 landmark faces
[2016-11-30 21:25:13,093][INFO] writes 525000 landmark faces
[2016-11-30 21:25:13,354][INFO] writes 526000 landmark faces
[2016-11-30 21:25:13,568][INFO] writes 527000 landmark faces
[2016-11-30 21:25:13,778][INFO] writes 528000 landmark faces
[2016-11-30 21:25:14,012][INFO] writes 529000 landmark faces
[2016-11-30 21:25:14,219][INFO] writes 530000 landmark faces
[2016-11-30 21:25:14,450][INFO] writes 531000 landmark faces
[2016-11-30 21:25:14,679][INFO] writes 532000 landmark faces
[2016-11-30 21:25:14,936][INFO] writes 533000 landmark faces
[2016-11-30 21:25:15,175][INFO] writes 534000 landmark faces
[2016-11-30 21:25:15,413][INFO] writes 535000 landmark faces
[2016-11-30 21:25:15,639][INFO] writes 536000 landmark faces
[2016-11-30 21:25:15,858][INFO] writes 537000 landmark faces
[2016-11-30 21:25:16,071][INFO] writes 538000 landmark faces
[2016-11-30 21:25:16,283][INFO] writes 539000 landmark faces
[2016-11-30 21:25:16,482][INFO] writes 540000 landmark faces
[2016-11-30 21:25:16,686][INFO] writes 541000 landmark faces
[2016-11-30 21:25:16,915][INFO] writes 542000 landmark faces
[2016-11-30 21:25:17,141][INFO] writes 543000 landmark faces
[2016-11-30 21:25:17,384][INFO] writes 544000 landmark faces
[2016-11-30 21:25:17,606][INFO] writes 545000 landmark faces
[2016-11-30 21:25:17,863][INFO] writes 546000 landmark faces
[2016-11-30 21:25:18,145][INFO] writes 547000 landmark faces
[2016-11-30 21:25:18,358][INFO] writes 548000 landmark faces
[2016-11-30 21:25:18,605][INFO] writes 549000 landmark faces
[2016-11-30 21:25:18,819][INFO] writes 550000 landmark faces
[2016-11-30 21:25:19,059][INFO] Process-26 reads 7000
[2016-11-30 21:25:19,064][INFO] writes 551000 landmark faces
[2016-11-30 21:25:19,302][INFO] writes 552000 landmark faces
[2016-11-30 21:25:19,561][INFO] writes 553000 landmark faces
[2016-11-30 21:25:19,793][INFO] writes 554000 landmark faces
[2016-11-30 21:25:20,006][INFO] writes 555000 landmark faces
[2016-11-30 21:25:20,097][INFO] Process-25 reads 7000
[2016-11-30 21:25:20,231][INFO] writes 556000 landmark faces
[2016-11-30 21:25:20,445][INFO] writes 557000 landmark faces
[2016-11-30 21:25:20,592][INFO] Process-24 reads 7000
[2016-11-30 21:25:20,689][INFO] writes 558000 landmark faces
[2016-11-30 21:25:20,742][INFO] Process-20 reads 7000
[2016-11-30 21:25:20,973][INFO] writes 559000 landmark faces
[2016-11-30 21:25:21,088][INFO] Process-19 reads 7000
[2016-11-30 21:25:21,273][INFO] writes 560000 landmark faces
[2016-11-30 21:25:21,525][INFO] writes 561000 landmark faces
[2016-11-30 21:25:21,792][INFO] writes 562000 landmark faces
[2016-11-30 21:25:21,800][INFO] Process-21 reads 7000
[2016-11-30 21:25:22,032][INFO] writes 563000 landmark faces
[2016-11-30 21:25:22,299][INFO] writes 564000 landmark faces
[2016-11-30 21:25:22,547][INFO] writes 565000 landmark faces
[2016-11-30 21:25:22,793][INFO] writes 566000 landmark faces
[2016-11-30 21:25:23,023][INFO] Process-22 reads 7000
[2016-11-30 21:25:23,045][INFO] writes 567000 landmark faces
[2016-11-30 21:25:23,256][INFO] writes 568000 landmark faces
[2016-11-30 21:25:23,506][INFO] writes 569000 landmark faces
[2016-11-30 21:25:23,653][INFO] Process-23 reads 7000
[2016-11-30 21:25:23,736][INFO] writes 570000 landmark faces
[2016-11-30 21:25:23,991][INFO] writes 571000 landmark faces
[2016-11-30 21:25:24,245][INFO] writes 572000 landmark faces
[2016-11-30 21:25:24,465][INFO] writes 573000 landmark faces
[2016-11-30 21:25:24,682][INFO] writes 574000 landmark faces
[2016-11-30 21:25:24,901][INFO] writes 575000 landmark faces
[2016-11-30 21:25:25,170][INFO] writes 576000 landmark faces
[2016-11-30 21:25:25,438][INFO] writes 577000 landmark faces
[2016-11-30 21:25:25,663][INFO] writes 578000 landmark faces
[2016-11-30 21:25:25,919][INFO] writes 579000 landmark faces
[2016-11-30 21:25:26,214][INFO] writes 580000 landmark faces
[2016-11-30 21:25:26,537][INFO] writes 581000 landmark faces
[2016-11-30 21:25:26,812][INFO] writes 582000 landmark faces
[2016-11-30 21:25:27,022][INFO] writes 583000 landmark faces
[2016-11-30 21:25:27,275][INFO] writes 584000 landmark faces
[2016-11-30 21:25:27,508][INFO] writes 585000 landmark faces
[2016-11-30 21:25:27,744][INFO] writes 586000 landmark faces
[2016-11-30 21:25:27,961][INFO] writes 587000 landmark faces
[2016-11-30 21:25:28,169][INFO] writes 588000 landmark faces
[2016-11-30 21:25:28,366][INFO] writes 589000 landmark faces
[2016-11-30 21:25:28,582][INFO] writes 590000 landmark faces
[2016-11-30 21:25:28,838][INFO] writes 591000 landmark faces
[2016-11-30 21:25:29,068][INFO] writes 592000 landmark faces
[2016-11-30 21:25:29,323][INFO] writes 593000 landmark faces
[2016-11-30 21:25:29,559][INFO] writes 594000 landmark faces
[2016-11-30 21:25:29,760][INFO] writes 595000 landmark faces
[2016-11-30 21:25:29,992][INFO] writes 596000 landmark faces
[2016-11-30 21:25:30,200][INFO] writes 597000 landmark faces
[2016-11-30 21:25:30,418][INFO] writes 598000 landmark faces
[2016-11-30 21:25:30,636][INFO] writes 599000 landmark faces
[2016-11-30 21:25:30,876][INFO] writes 600000 landmark faces
[2016-11-30 21:25:31,095][INFO] writes 601000 landmark faces
[2016-11-30 21:25:31,312][INFO] writes 602000 landmark faces
[2016-11-30 21:25:31,526][INFO] writes 603000 landmark faces
[2016-11-30 21:25:31,739][INFO] writes 604000 landmark faces
[2016-11-30 21:25:32,000][INFO] writes 605000 landmark faces
[2016-11-30 21:25:32,204][INFO] writes 606000 landmark faces
[2016-11-30 21:25:32,417][INFO] writes 607000 landmark faces
[2016-11-30 21:25:32,673][INFO] writes 608000 landmark faces
[2016-11-30 21:25:32,904][INFO] writes 609000 landmark faces
[2016-11-30 21:25:33,128][INFO] writes 610000 landmark faces
[2016-11-30 21:25:33,354][INFO] writes 611000 landmark faces
[2016-11-30 21:25:33,570][INFO] writes 612000 landmark faces
[2016-11-30 21:25:33,804][INFO] writes 613000 landmark faces
[2016-11-30 21:25:34,019][INFO] writes 614000 landmark faces
[2016-11-30 21:25:34,242][INFO] writes 615000 landmark faces
[2016-11-30 21:25:34,504][INFO] writes 616000 landmark faces
[2016-11-30 21:25:34,734][INFO] writes 617000 landmark faces
[2016-11-30 21:25:35,012][INFO] writes 618000 landmark faces
[2016-11-30 21:25:35,231][INFO] writes 619000 landmark faces
[2016-11-30 21:25:35,466][INFO] writes 620000 landmark faces
[2016-11-30 21:25:35,694][INFO] writes 621000 landmark faces
[2016-11-30 21:25:35,933][INFO] writes 622000 landmark faces
[2016-11-30 21:25:36,203][INFO] writes 623000 landmark faces
[2016-11-30 21:25:36,420][INFO] writes 624000 landmark faces
[2016-11-30 21:25:36,644][INFO] writes 625000 landmark faces
[2016-11-30 21:25:36,854][INFO] writes 626000 landmark faces
[2016-11-30 21:25:37,085][INFO] writes 627000 landmark faces
[2016-11-30 21:25:37,326][INFO] writes 628000 landmark faces
[2016-11-30 21:25:37,542][INFO] writes 629000 landmark faces
[2016-11-30 21:25:37,754][INFO] writes 630000 landmark faces
[2016-11-30 21:25:37,995][INFO] writes 631000 landmark faces
[2016-11-30 21:25:38,184][INFO] Process-26 reads 8000
[2016-11-30 21:25:38,226][INFO] writes 632000 landmark faces
[2016-11-30 21:25:38,470][INFO] writes 633000 landmark faces
[2016-11-30 21:25:38,703][INFO] writes 634000 landmark faces
[2016-11-30 21:25:38,906][INFO] Process-24 reads 8000
[2016-11-30 21:25:38,919][INFO] writes 635000 landmark faces
[2016-11-30 21:25:39,195][INFO] writes 636000 landmark faces
[2016-11-30 21:25:39,406][INFO] writes 637000 landmark faces
[2016-11-30 21:25:39,665][INFO] writes 638000 landmark faces
[2016-11-30 21:25:39,710][INFO] Process-25 reads 8000
[2016-11-30 21:25:39,895][INFO] writes 639000 landmark faces
[2016-11-30 21:25:39,930][INFO] Process-20 reads 8000
[2016-11-30 21:25:40,104][INFO] writes 640000 landmark faces
[2016-11-30 21:25:40,240][INFO] Process-21 reads 8000
[2016-11-30 21:25:40,325][INFO] writes 641000 landmark faces
[2016-11-30 21:25:40,541][INFO] writes 642000 landmark faces
[2016-11-30 21:25:40,827][INFO] writes 643000 landmark faces
[2016-11-30 21:25:41,069][INFO] writes 644000 landmark faces
[2016-11-30 21:25:41,197][INFO] Process-22 reads 8000
[2016-11-30 21:25:41,242][INFO] Process-19 reads 8000
[2016-11-30 21:25:41,334][INFO] writes 645000 landmark faces
[2016-11-30 21:25:41,546][INFO] writes 646000 landmark faces
[2016-11-30 21:25:41,782][INFO] writes 647000 landmark faces
[2016-11-30 21:25:41,946][INFO] Process-23 reads 8000
[2016-11-30 21:25:42,014][INFO] writes 648000 landmark faces
[2016-11-30 21:25:42,245][INFO] writes 649000 landmark faces
[2016-11-30 21:25:42,505][INFO] writes 650000 landmark faces
[2016-11-30 21:25:42,733][INFO] writes 651000 landmark faces
[2016-11-30 21:25:42,953][INFO] writes 652000 landmark faces
[2016-11-30 21:25:43,170][INFO] writes 653000 landmark faces
[2016-11-30 21:25:43,416][INFO] writes 654000 landmark faces
[2016-11-30 21:25:43,679][INFO] writes 655000 landmark faces
[2016-11-30 21:25:43,958][INFO] writes 656000 landmark faces
[2016-11-30 21:25:44,166][INFO] writes 657000 landmark faces
[2016-11-30 21:25:44,396][INFO] writes 658000 landmark faces
[2016-11-30 21:25:44,624][INFO] writes 659000 landmark faces
[2016-11-30 21:25:44,908][INFO] writes 660000 landmark faces
[2016-11-30 21:25:45,159][INFO] writes 661000 landmark faces
[2016-11-30 21:25:45,405][INFO] writes 662000 landmark faces
[2016-11-30 21:25:45,616][INFO] writes 663000 landmark faces
[2016-11-30 21:25:45,871][INFO] writes 664000 landmark faces
[2016-11-30 21:25:46,104][INFO] writes 665000 landmark faces
[2016-11-30 21:25:46,319][INFO] writes 666000 landmark faces
[2016-11-30 21:25:46,531][INFO] writes 667000 landmark faces
[2016-11-30 21:25:46,789][INFO] writes 668000 landmark faces
[2016-11-30 21:25:47,042][INFO] writes 669000 landmark faces
[2016-11-30 21:25:47,275][INFO] writes 670000 landmark faces
[2016-11-30 21:25:47,478][INFO] writes 671000 landmark faces
[2016-11-30 21:25:47,684][INFO] writes 672000 landmark faces
[2016-11-30 21:25:47,925][INFO] writes 673000 landmark faces
[2016-11-30 21:25:48,196][INFO] writes 674000 landmark faces
[2016-11-30 21:25:48,438][INFO] writes 675000 landmark faces
[2016-11-30 21:25:48,639][INFO] writes 676000 landmark faces
[2016-11-30 21:25:48,850][INFO] writes 677000 landmark faces
[2016-11-30 21:25:49,099][INFO] writes 678000 landmark faces
[2016-11-30 21:25:49,311][INFO] writes 679000 landmark faces
[2016-11-30 21:25:49,589][INFO] writes 680000 landmark faces
[2016-11-30 21:25:49,857][INFO] writes 681000 landmark faces
[2016-11-30 21:25:50,102][INFO] writes 682000 landmark faces
[2016-11-30 21:25:50,305][INFO] writes 683000 landmark faces
[2016-11-30 21:25:50,518][INFO] writes 684000 landmark faces
[2016-11-30 21:25:50,720][INFO] writes 685000 landmark faces
[2016-11-30 21:25:50,955][INFO] writes 686000 landmark faces
[2016-11-30 21:25:51,220][INFO] writes 687000 landmark faces
[2016-11-30 21:25:51,441][INFO] writes 688000 landmark faces
[2016-11-30 21:25:51,652][INFO] writes 689000 landmark faces
[2016-11-30 21:25:51,884][INFO] writes 690000 landmark faces
[2016-11-30 21:25:52,109][INFO] writes 691000 landmark faces
[2016-11-30 21:25:52,310][INFO] writes 692000 landmark faces
[2016-11-30 21:25:52,549][INFO] writes 693000 landmark faces
[2016-11-30 21:25:52,806][INFO] writes 694000 landmark faces
[2016-11-30 21:25:53,022][INFO] writes 695000 landmark faces
[2016-11-30 21:25:53,248][INFO] writes 696000 landmark faces
[2016-11-30 21:25:53,467][INFO] writes 697000 landmark faces
[2016-11-30 21:25:53,686][INFO] writes 698000 landmark faces
[2016-11-30 21:25:53,900][INFO] writes 699000 landmark faces
[2016-11-30 21:25:54,108][INFO] writes 700000 landmark faces
[2016-11-30 21:25:54,311][INFO] writes 701000 landmark faces
[2016-11-30 21:25:54,543][INFO] writes 702000 landmark faces
[2016-11-30 21:25:54,758][INFO] writes 703000 landmark faces
[2016-11-30 21:25:54,978][INFO] writes 704000 landmark faces
[2016-11-30 21:25:55,235][INFO] writes 705000 landmark faces
[2016-11-30 21:25:55,531][INFO] writes 706000 landmark faces
[2016-11-30 21:25:55,785][INFO] writes 707000 landmark faces
[2016-11-30 21:25:55,912][INFO] Process-26 reads 9000
[2016-11-30 21:25:56,030][INFO] writes 708000 landmark faces
[2016-11-30 21:25:56,277][INFO] writes 709000 landmark faces
[2016-11-30 21:25:56,530][INFO] writes 710000 landmark faces
[2016-11-30 21:25:56,740][INFO] writes 711000 landmark faces
[2016-11-30 21:25:56,959][INFO] writes 712000 landmark faces
[2016-11-30 21:25:57,188][INFO] writes 713000 landmark faces
[2016-11-30 21:25:57,234][INFO] Process-24 reads 9000
[2016-11-30 21:25:57,448][INFO] writes 714000 landmark faces
[2016-11-30 21:25:57,686][INFO] writes 715000 landmark faces
[2016-11-30 21:25:57,897][INFO] writes 716000 landmark faces
[2016-11-30 21:25:58,126][INFO] writes 717000 landmark faces
[2016-11-30 21:25:58,339][INFO] writes 718000 landmark faces
[2016-11-30 21:25:58,583][INFO] writes 719000 landmark faces
[2016-11-30 21:25:58,778][INFO] Process-25 reads 9000
[2016-11-30 21:25:58,875][INFO] writes 720000 landmark faces
[2016-11-30 21:25:59,107][INFO] writes 721000 landmark faces
[2016-11-30 21:25:59,255][INFO] Process-22 reads 9000
[2016-11-30 21:25:59,355][INFO] writes 722000 landmark faces
[2016-11-30 21:25:59,584][INFO] writes 723000 landmark faces
[2016-11-30 21:25:59,630][INFO] Process-20 reads 9000
[2016-11-30 21:25:59,693][INFO] Process-21 reads 9000
[2016-11-30 21:25:59,831][INFO] writes 724000 landmark faces
[2016-11-30 21:25:59,945][INFO] Process-19 reads 9000
[2016-11-30 21:26:00,066][INFO] writes 725000 landmark faces
[2016-11-30 21:26:00,319][INFO] writes 726000 landmark faces
[2016-11-30 21:26:00,337][INFO] Process-23 reads 9000
[2016-11-30 21:26:00,624][INFO] writes 727000 landmark faces
[2016-11-30 21:26:00,993][INFO] writes 728000 landmark faces
[2016-11-30 21:26:01,214][INFO] writes 729000 landmark faces
[2016-11-30 21:26:01,418][INFO] writes 730000 landmark faces
[2016-11-30 21:26:01,659][INFO] writes 731000 landmark faces
[2016-11-30 21:26:01,914][INFO] writes 732000 landmark faces
[2016-11-30 21:26:02,140][INFO] writes 733000 landmark faces
[2016-11-30 21:26:02,378][INFO] writes 734000 landmark faces
[2016-11-30 21:26:02,612][INFO] writes 735000 landmark faces
[2016-11-30 21:26:02,807][INFO] writes 736000 landmark faces
[2016-11-30 21:26:03,080][INFO] writes 737000 landmark faces
[2016-11-30 21:26:03,322][INFO] writes 738000 landmark faces
[2016-11-30 21:26:03,560][INFO] writes 739000 landmark faces
[2016-11-30 21:26:03,797][INFO] writes 740000 landmark faces
[2016-11-30 21:26:04,056][INFO] writes 741000 landmark faces
[2016-11-30 21:26:04,285][INFO] writes 742000 landmark faces
[2016-11-30 21:26:04,508][INFO] writes 743000 landmark faces
[2016-11-30 21:26:04,764][INFO] writes 744000 landmark faces
[2016-11-30 21:26:04,979][INFO] writes 745000 landmark faces
[2016-11-30 21:26:05,209][INFO] writes 746000 landmark faces
[2016-11-30 21:26:05,463][INFO] writes 747000 landmark faces
[2016-11-30 21:26:05,682][INFO] writes 748000 landmark faces
[2016-11-30 21:26:05,921][INFO] writes 749000 landmark faces
[2016-11-30 21:26:06,136][INFO] writes 750000 landmark faces
[2016-11-30 21:26:06,371][INFO] writes 751000 landmark faces
[2016-11-30 21:26:06,600][INFO] writes 752000 landmark faces
[2016-11-30 21:26:06,813][INFO] writes 753000 landmark faces
[2016-11-30 21:26:07,024][INFO] writes 754000 landmark faces
[2016-11-30 21:26:07,253][INFO] writes 755000 landmark faces
[2016-11-30 21:26:07,493][INFO] writes 756000 landmark faces
[2016-11-30 21:26:07,696][INFO] writes 757000 landmark faces
[2016-11-30 21:26:07,933][INFO] writes 758000 landmark faces
[2016-11-30 21:26:08,186][INFO] writes 759000 landmark faces
[2016-11-30 21:26:08,414][INFO] writes 760000 landmark faces
[2016-11-30 21:26:08,613][INFO] writes 761000 landmark faces
[2016-11-30 21:26:08,817][INFO] writes 762000 landmark faces
[2016-11-30 21:26:09,056][INFO] writes 763000 landmark faces
[2016-11-30 21:26:09,333][INFO] writes 764000 landmark faces
[2016-11-30 21:26:09,584][INFO] writes 765000 landmark faces
[2016-11-30 21:26:09,810][INFO] writes 766000 landmark faces
[2016-11-30 21:26:10,046][INFO] writes 767000 landmark faces
[2016-11-30 21:26:10,282][INFO] writes 768000 landmark faces
[2016-11-30 21:26:10,486][INFO] writes 769000 landmark faces
[2016-11-30 21:26:10,705][INFO] writes 770000 landmark faces
[2016-11-30 21:26:10,928][INFO] writes 771000 landmark faces
[2016-11-30 21:26:11,197][INFO] writes 772000 landmark faces
[2016-11-30 21:26:11,433][INFO] writes 773000 landmark faces
[2016-11-30 21:26:11,653][INFO] writes 774000 landmark faces
[2016-11-30 21:26:11,871][INFO] writes 775000 landmark faces
[2016-11-30 21:26:12,114][INFO] writes 776000 landmark faces
[2016-11-30 21:26:12,397][INFO] writes 777000 landmark faces
[2016-11-30 21:26:12,608][INFO] writes 778000 landmark faces
[2016-11-30 21:26:12,844][INFO] writes 779000 landmark faces
[2016-11-30 21:26:13,124][INFO] writes 780000 landmark faces
[2016-11-30 21:26:13,368][INFO] writes 781000 landmark faces
[2016-11-30 21:26:13,597][INFO] writes 782000 landmark faces
[2016-11-30 21:26:13,608][INFO] Process-26 reads 10000
[2016-11-30 21:26:13,811][INFO] writes 783000 landmark faces
[2016-11-30 21:26:14,042][INFO] writes 784000 landmark faces
[2016-11-30 21:26:14,257][INFO] writes 785000 landmark faces
[2016-11-30 21:26:14,472][INFO] writes 786000 landmark faces
[2016-11-30 21:26:14,686][INFO] writes 787000 landmark faces
[2016-11-30 21:26:14,903][INFO] writes 788000 landmark faces
[2016-11-30 21:26:15,125][INFO] writes 789000 landmark faces
[2016-11-30 21:26:15,358][INFO] writes 790000 landmark faces
[2016-11-30 21:26:15,613][INFO] writes 791000 landmark faces
[2016-11-30 21:26:15,841][INFO] writes 792000 landmark faces
[2016-11-30 21:26:16,034][INFO] writes 793000 landmark faces
[2016-11-30 21:26:16,264][INFO] writes 794000 landmark faces
[2016-11-30 21:26:16,284][INFO] Process-24 reads 10000
[2016-11-30 21:26:16,391][INFO] Process-25 reads 10000
[2016-11-30 21:26:16,476][INFO] writes 795000 landmark faces
[2016-11-30 21:26:16,742][INFO] writes 796000 landmark faces
[2016-11-30 21:26:16,798][INFO] Process-22 reads 10000
[2016-11-30 21:26:16,962][INFO] writes 797000 landmark faces
[2016-11-30 21:26:17,212][INFO] writes 798000 landmark faces
[2016-11-30 21:26:17,444][INFO] writes 799000 landmark faces
[2016-11-30 21:26:17,662][INFO] writes 800000 landmark faces
[2016-11-30 21:26:17,882][INFO] writes 801000 landmark faces
[2016-11-30 21:26:18,128][INFO] writes 802000 landmark faces
[2016-11-30 21:26:18,413][INFO] writes 803000 landmark faces
[2016-11-30 21:26:18,651][INFO] writes 804000 landmark faces
[2016-11-30 21:26:18,865][INFO] writes 805000 landmark faces
[2016-11-30 21:26:18,998][INFO] Process-23 reads 10000
[2016-11-30 21:26:19,093][INFO] writes 806000 landmark faces
[2016-11-30 21:26:19,338][INFO] writes 807000 landmark faces
[2016-11-30 21:26:19,420][INFO] Process-20 reads 10000
[2016-11-30 21:26:19,563][INFO] writes 808000 landmark faces
[2016-11-30 21:26:19,761][INFO] writes 809000 landmark faces
[2016-11-30 21:26:19,770][INFO] Process-19 reads 10000
[2016-11-30 21:26:19,962][INFO] writes 810000 landmark faces
[2016-11-30 21:26:20,041][INFO] Process-21 reads 10000
[2016-11-30 21:26:20,179][INFO] writes 811000 landmark faces
[2016-11-30 21:26:20,385][INFO] writes 812000 landmark faces
[2016-11-30 21:26:20,611][INFO] writes 813000 landmark faces
[2016-11-30 21:26:20,845][INFO] writes 814000 landmark faces
[2016-11-30 21:26:21,079][INFO] writes 815000 landmark faces
[2016-11-30 21:26:21,295][INFO] writes 816000 landmark faces
[2016-11-30 21:26:21,513][INFO] writes 817000 landmark faces
[2016-11-30 21:26:21,769][INFO] writes 818000 landmark faces
[2016-11-30 21:26:21,982][INFO] writes 819000 landmark faces
[2016-11-30 21:26:22,227][INFO] writes 820000 landmark faces
[2016-11-30 21:26:22,484][INFO] writes 821000 landmark faces
[2016-11-30 21:26:22,701][INFO] writes 822000 landmark faces
[2016-11-30 21:26:22,910][INFO] writes 823000 landmark faces
[2016-11-30 21:26:23,143][INFO] writes 824000 landmark faces
[2016-11-30 21:26:23,354][INFO] writes 825000 landmark faces
[2016-11-30 21:26:23,609][INFO] writes 826000 landmark faces
[2016-11-30 21:26:23,844][INFO] writes 827000 landmark faces
[2016-11-30 21:26:24,072][INFO] writes 828000 landmark faces
[2016-11-30 21:26:24,335][INFO] writes 829000 landmark faces
[2016-11-30 21:26:24,591][INFO] writes 830000 landmark faces
[2016-11-30 21:26:24,833][INFO] writes 831000 landmark faces
[2016-11-30 21:26:25,066][INFO] writes 832000 landmark faces
[2016-11-30 21:26:25,311][INFO] writes 833000 landmark faces
[2016-11-30 21:26:25,529][INFO] writes 834000 landmark faces
[2016-11-30 21:26:25,741][INFO] writes 835000 landmark faces
[2016-11-30 21:26:25,973][INFO] writes 836000 landmark faces
[2016-11-30 21:26:26,214][INFO] writes 837000 landmark faces
[2016-11-30 21:26:26,508][INFO] writes 838000 landmark faces
[2016-11-30 21:26:26,735][INFO] writes 839000 landmark faces
[2016-11-30 21:26:26,971][INFO] writes 840000 landmark faces
[2016-11-30 21:26:27,196][INFO] writes 841000 landmark faces
[2016-11-30 21:26:27,449][INFO] writes 842000 landmark faces
[2016-11-30 21:26:27,681][INFO] writes 843000 landmark faces
[2016-11-30 21:26:27,895][INFO] writes 844000 landmark faces
[2016-11-30 21:26:28,118][INFO] writes 845000 landmark faces
[2016-11-30 21:26:28,375][INFO] writes 846000 landmark faces
[2016-11-30 21:26:28,623][INFO] writes 847000 landmark faces
[2016-11-30 21:26:28,853][INFO] writes 848000 landmark faces
[2016-11-30 21:26:29,091][INFO] writes 849000 landmark faces
[2016-11-30 21:26:29,346][INFO] writes 850000 landmark faces
[2016-11-30 21:26:29,601][INFO] writes 851000 landmark faces
[2016-11-30 21:26:29,845][INFO] writes 852000 landmark faces
[2016-11-30 21:26:30,078][INFO] writes 853000 landmark faces
[2016-11-30 21:26:30,330][INFO] writes 854000 landmark faces
[2016-11-30 21:26:30,548][INFO] writes 855000 landmark faces
[2016-11-30 21:26:30,779][INFO] writes 856000 landmark faces
[2016-11-30 21:26:31,033][INFO] writes 857000 landmark faces
[2016-11-30 21:26:31,258][INFO] writes 858000 landmark faces
[2016-11-30 21:26:31,472][INFO] writes 859000 landmark faces
[2016-11-30 21:26:31,699][INFO] writes 860000 landmark faces
[2016-11-30 21:26:31,842][INFO] Process-26 reads 11000
[2016-11-30 21:26:31,935][INFO] writes 861000 landmark faces
[2016-11-30 21:26:32,174][INFO] writes 862000 landmark faces
[2016-11-30 21:26:32,398][INFO] writes 863000 landmark faces
[2016-11-30 21:26:32,638][INFO] writes 864000 landmark faces
[2016-11-30 21:26:32,909][INFO] writes 865000 landmark faces
[2016-11-30 21:26:33,157][INFO] writes 866000 landmark faces
[2016-11-30 21:26:33,416][INFO] writes 867000 landmark faces
[2016-11-30 21:26:33,650][INFO] writes 868000 landmark faces
[2016-11-30 21:26:33,898][INFO] writes 869000 landmark faces
[2016-11-30 21:26:34,211][INFO] writes 870000 landmark faces
[2016-11-30 21:26:34,475][INFO] writes 871000 landmark faces
[2016-11-30 21:26:34,735][INFO] writes 872000 landmark faces
[2016-11-30 21:26:34,970][INFO] writes 873000 landmark faces
[2016-11-30 21:26:35,224][INFO] writes 874000 landmark faces
[2016-11-30 21:26:35,455][INFO] writes 875000 landmark faces
[2016-11-30 21:26:35,713][INFO] writes 876000 landmark faces
[2016-11-30 21:26:35,764][INFO] Process-24 reads 11000
[2016-11-30 21:26:35,911][INFO] Process-22 reads 11000
[2016-11-30 21:26:35,973][INFO] writes 877000 landmark faces
[2016-11-30 21:26:36,232][INFO] writes 878000 landmark faces
[2016-11-30 21:26:36,472][INFO] writes 879000 landmark faces
[2016-11-30 21:26:36,599][INFO] Process-25 reads 11000
[2016-11-30 21:26:36,733][INFO] writes 880000 landmark faces
[2016-11-30 21:26:36,940][INFO] writes 881000 landmark faces
[2016-11-30 21:26:37,151][INFO] Process-23 reads 11000
[2016-11-30 21:26:37,165][INFO] writes 882000 landmark faces
[2016-11-30 21:26:37,424][INFO] writes 883000 landmark faces
[2016-11-30 21:26:37,701][INFO] writes 884000 landmark faces
[2016-11-30 21:26:37,939][INFO] writes 885000 landmark faces
[2016-11-30 21:26:38,160][INFO] writes 886000 landmark faces
[2016-11-30 21:26:38,373][INFO] writes 887000 landmark faces
[2016-11-30 21:26:38,432][INFO] Process-20 reads 11000
[2016-11-30 21:26:38,609][INFO] writes 888000 landmark faces
[2016-11-30 21:26:38,682][INFO] Process-19 reads 11000
[2016-11-30 21:26:38,843][INFO] writes 889000 landmark faces
[2016-11-30 21:26:39,059][INFO] writes 890000 landmark faces
[2016-11-30 21:26:39,273][INFO] writes 891000 landmark faces
[2016-11-30 21:26:39,287][INFO] Process-21 reads 11000
[2016-11-30 21:26:39,493][INFO] writes 892000 landmark faces
[2016-11-30 21:26:39,714][INFO] writes 893000 landmark faces
[2016-11-30 21:26:39,929][INFO] writes 894000 landmark faces
[2016-11-30 21:26:40,137][INFO] writes 895000 landmark faces
[2016-11-30 21:26:40,367][INFO] writes 896000 landmark faces
[2016-11-30 21:26:40,646][INFO] writes 897000 landmark faces
[2016-11-30 21:26:40,873][INFO] writes 898000 landmark faces
[2016-11-30 21:26:41,119][INFO] writes 899000 landmark faces
[2016-11-30 21:26:41,362][INFO] writes 900000 landmark faces
[2016-11-30 21:26:41,600][INFO] writes 901000 landmark faces
[2016-11-30 21:26:41,825][INFO] writes 902000 landmark faces
[2016-11-30 21:26:42,108][INFO] writes 903000 landmark faces
[2016-11-30 21:26:42,351][INFO] writes 904000 landmark faces
[2016-11-30 21:26:42,579][INFO] writes 905000 landmark faces
[2016-11-30 21:26:42,827][INFO] writes 906000 landmark faces
[2016-11-30 21:26:43,067][INFO] writes 907000 landmark faces
[2016-11-30 21:26:43,303][INFO] writes 908000 landmark faces
[2016-11-30 21:26:43,547][INFO] writes 909000 landmark faces
[2016-11-30 21:26:43,845][INFO] writes 910000 landmark faces
[2016-11-30 21:26:44,053][INFO] writes 911000 landmark faces
[2016-11-30 21:26:44,315][INFO] writes 912000 landmark faces
[2016-11-30 21:26:44,561][INFO] writes 913000 landmark faces
[2016-11-30 21:26:44,793][INFO] writes 914000 landmark faces
[2016-11-30 21:26:44,988][INFO] writes 915000 landmark faces
[2016-11-30 21:26:45,230][INFO] writes 916000 landmark faces
[2016-11-30 21:26:45,451][INFO] writes 917000 landmark faces
[2016-11-30 21:26:45,690][INFO] writes 918000 landmark faces
[2016-11-30 21:26:45,967][INFO] writes 919000 landmark faces
[2016-11-30 21:26:46,214][INFO] writes 920000 landmark faces
[2016-11-30 21:26:46,443][INFO] writes 921000 landmark faces
[2016-11-30 21:26:46,691][INFO] writes 922000 landmark faces
[2016-11-30 21:26:46,938][INFO] writes 923000 landmark faces
[2016-11-30 21:26:47,163][INFO] writes 924000 landmark faces
[2016-11-30 21:26:47,387][INFO] writes 925000 landmark faces
[2016-11-30 21:26:47,605][INFO] writes 926000 landmark faces
[2016-11-30 21:26:47,853][INFO] writes 927000 landmark faces
[2016-11-30 21:26:48,067][INFO] writes 928000 landmark faces
[2016-11-30 21:26:48,276][INFO] writes 929000 landmark faces
[2016-11-30 21:26:48,508][INFO] writes 930000 landmark faces
[2016-11-30 21:26:48,762][INFO] writes 931000 landmark faces
[2016-11-30 21:26:48,981][INFO] writes 932000 landmark faces
[2016-11-30 21:26:49,200][INFO] writes 933000 landmark faces
[2016-11-30 21:26:49,409][INFO] writes 934000 landmark faces
[2016-11-30 21:26:49,657][INFO] writes 935000 landmark faces
[2016-11-30 21:26:49,949][INFO] writes 936000 landmark faces
[2016-11-30 21:26:50,185][INFO] writes 937000 landmark faces
[2016-11-30 21:26:50,406][INFO] writes 938000 landmark faces
[2016-11-30 21:26:50,631][INFO] writes 939000 landmark faces
[2016-11-30 21:26:50,863][INFO] writes 940000 landmark faces
[2016-11-30 21:26:51,098][INFO] writes 941000 landmark faces
[2016-11-30 21:26:51,341][INFO] writes 942000 landmark faces
[2016-11-30 21:26:51,532][INFO] Process-26 reads 12000
[2016-11-30 21:26:51,561][INFO] writes 943000 landmark faces
[2016-11-30 21:26:51,780][INFO] writes 944000 landmark faces
[2016-11-30 21:26:52,002][INFO] writes 945000 landmark faces
[2016-11-30 21:26:52,237][INFO] writes 946000 landmark faces
[2016-11-30 21:26:52,489][INFO] writes 947000 landmark faces
[2016-11-30 21:26:52,717][INFO] writes 948000 landmark faces
[2016-11-30 21:26:52,988][INFO] writes 949000 landmark faces
[2016-11-30 21:26:53,238][INFO] writes 950000 landmark faces
[2016-11-30 21:26:53,463][INFO] writes 951000 landmark faces
[2016-11-30 21:26:53,687][INFO] writes 952000 landmark faces
[2016-11-30 21:26:53,916][INFO] writes 953000 landmark faces
[2016-11-30 21:26:53,953][INFO] Process-24 reads 12000
[2016-11-30 21:26:54,174][INFO] Process-22 reads 12000
[2016-11-30 21:26:54,182][INFO] writes 954000 landmark faces
[2016-11-30 21:26:54,401][INFO] writes 955000 landmark faces
[2016-11-30 21:26:54,641][INFO] writes 956000 landmark faces
[2016-11-30 21:26:54,877][INFO] writes 957000 landmark faces
[2016-11-30 21:26:55,036][INFO] Process-25 reads 12000
[2016-11-30 21:26:55,110][INFO] writes 958000 landmark faces
[2016-11-30 21:26:55,311][INFO] writes 959000 landmark faces
[2016-11-30 21:26:55,515][INFO] writes 960000 landmark faces
[2016-11-30 21:26:55,754][INFO] writes 961000 landmark faces
[2016-11-30 21:26:55,963][INFO] writes 962000 landmark faces
[2016-11-30 21:26:56,240][INFO] writes 963000 landmark faces
[2016-11-30 21:26:56,256][INFO] Process-23 reads 12000
[2016-11-30 21:26:56,452][INFO] writes 964000 landmark faces
[2016-11-30 21:26:56,680][INFO] writes 965000 landmark faces
[2016-11-30 21:26:56,893][INFO] writes 966000 landmark faces
[2016-11-30 21:26:57,179][INFO] writes 967000 landmark faces
[2016-11-30 21:26:57,407][INFO] writes 968000 landmark faces
[2016-11-30 21:26:57,713][INFO] writes 969000 landmark faces
[2016-11-30 21:26:57,918][INFO] Process-21 reads 12000
[2016-11-30 21:26:57,941][INFO] Process-19 reads 12000
[2016-11-30 21:26:57,989][INFO] writes 970000 landmark faces
[2016-11-30 21:26:58,247][INFO] writes 971000 landmark faces
[2016-11-30 21:26:58,288][INFO] Process-20 reads 12000
[2016-11-30 21:26:58,488][INFO] writes 972000 landmark faces
[2016-11-30 21:26:58,715][INFO] writes 973000 landmark faces
[2016-11-30 21:26:58,941][INFO] writes 974000 landmark faces
[2016-11-30 21:26:59,206][INFO] writes 975000 landmark faces
[2016-11-30 21:26:59,436][INFO] writes 976000 landmark faces
[2016-11-30 21:26:59,682][INFO] writes 977000 landmark faces
[2016-11-30 21:26:59,927][INFO] writes 978000 landmark faces
[2016-11-30 21:27:00,154][INFO] writes 979000 landmark faces
[2016-11-30 21:27:00,365][INFO] writes 980000 landmark faces
[2016-11-30 21:27:00,563][INFO] writes 981000 landmark faces
[2016-11-30 21:27:00,832][INFO] writes 982000 landmark faces
[2016-11-30 21:27:01,056][INFO] writes 983000 landmark faces
[2016-11-30 21:27:01,297][INFO] writes 984000 landmark faces
[2016-11-30 21:27:01,521][INFO] writes 985000 landmark faces
[2016-11-30 21:27:01,731][INFO] writes 986000 landmark faces
[2016-11-30 21:27:01,949][INFO] writes 987000 landmark faces
[2016-11-30 21:27:02,237][INFO] writes 988000 landmark faces
[2016-11-30 21:27:02,497][INFO] writes 989000 landmark faces
[2016-11-30 21:27:02,732][INFO] writes 990000 landmark faces
[2016-11-30 21:27:03,030][INFO] writes 991000 landmark faces
[2016-11-30 21:27:03,339][INFO] writes 992000 landmark faces
[2016-11-30 21:27:03,582][INFO] writes 993000 landmark faces
[2016-11-30 21:27:03,790][INFO] writes 994000 landmark faces
[2016-11-30 21:27:04,013][INFO] writes 995000 landmark faces
[2016-11-30 21:27:04,271][INFO] writes 996000 landmark faces
[2016-11-30 21:27:04,507][INFO] writes 997000 landmark faces
[2016-11-30 21:27:04,731][INFO] writes 998000 landmark faces
[2016-11-30 21:27:04,968][INFO] writes 999000 landmark faces
[2016-11-30 21:27:05,215][INFO] writes 1000000 landmark faces
[2016-11-30 21:27:05,458][INFO] writes 1001000 landmark faces
[2016-11-30 21:27:05,717][INFO] writes 1002000 landmark faces
[2016-11-30 21:27:05,943][INFO] writes 1003000 landmark faces
[2016-11-30 21:27:06,160][INFO] writes 1004000 landmark faces
[2016-11-30 21:27:06,383][INFO] writes 1005000 landmark faces
[2016-11-30 21:27:06,614][INFO] writes 1006000 landmark faces
[2016-11-30 21:27:06,850][INFO] writes 1007000 landmark faces
[2016-11-30 21:27:07,081][INFO] writes 1008000 landmark faces
[2016-11-30 21:27:07,285][INFO] writes 1009000 landmark faces
[2016-11-30 21:27:07,514][INFO] writes 1010000 landmark faces
[2016-11-30 21:27:07,776][INFO] writes 1011000 landmark faces
[2016-11-30 21:27:08,001][INFO] writes 1012000 landmark faces
[2016-11-30 21:27:08,218][INFO] writes 1013000 landmark faces
[2016-11-30 21:27:08,465][INFO] writes 1014000 landmark faces
[2016-11-30 21:27:08,700][INFO] writes 1015000 landmark faces
[2016-11-30 21:27:08,940][INFO] writes 1016000 landmark faces
[2016-11-30 21:27:09,182][INFO] writes 1017000 landmark faces
[2016-11-30 21:27:09,466][INFO] writes 1018000 landmark faces
[2016-11-30 21:27:09,735][INFO] writes 1019000 landmark faces
[2016-11-30 21:27:09,896][INFO] Process-26 reads 13000
[2016-11-30 21:27:09,985][INFO] writes 1020000 landmark faces
[2016-11-30 21:27:10,201][INFO] writes 1021000 landmark faces
[2016-11-30 21:27:10,452][INFO] writes 1022000 landmark faces
[2016-11-30 21:27:10,683][INFO] writes 1023000 landmark faces
[2016-11-30 21:27:10,965][INFO] writes 1024000 landmark faces
[2016-11-30 21:27:11,285][INFO] writes 1025000 landmark faces
[2016-11-30 21:27:11,419][INFO] writes 1026000 landmark faces
[2016-11-30 21:27:11,653][INFO] writes 1027000 landmark faces
[2016-11-30 21:27:11,955][INFO] writes 1028000 landmark faces
[2016-11-30 21:27:12,175][INFO] writes 1029000 landmark faces
[2016-11-30 21:27:12,422][INFO] writes 1030000 landmark faces
[2016-11-30 21:27:12,680][INFO] writes 1031000 landmark faces
[2016-11-30 21:27:12,758][INFO] Process-24 reads 13000
[2016-11-30 21:27:12,897][INFO] writes 1032000 landmark faces
[2016-11-30 21:27:13,123][INFO] writes 1033000 landmark faces
[2016-11-30 21:27:13,297][INFO] Process-22 reads 13000
[2016-11-30 21:27:13,407][INFO] writes 1034000 landmark faces
[2016-11-30 21:27:13,676][INFO] writes 1035000 landmark faces
[2016-11-30 21:27:13,697][INFO] Process-25 reads 13000
[2016-11-30 21:27:13,960][INFO] writes 1036000 landmark faces
[2016-11-30 21:27:14,243][INFO] writes 1037000 landmark faces
[2016-11-30 21:27:14,460][INFO] writes 1038000 landmark faces
[2016-11-30 21:27:14,703][INFO] writes 1039000 landmark faces
[2016-11-30 21:27:14,928][INFO] writes 1040000 landmark faces
[2016-11-30 21:27:15,171][INFO] writes 1041000 landmark faces
[2016-11-30 21:27:15,375][INFO] writes 1042000 landmark faces
[2016-11-30 21:27:15,577][INFO] writes 1043000 landmark faces
[2016-11-30 21:27:15,807][INFO] writes 1044000 landmark faces
[2016-11-30 21:27:16,070][INFO] writes 1045000 landmark faces
[2016-11-30 21:27:16,330][INFO] writes 1046000 landmark faces
[2016-11-30 21:27:16,554][INFO] writes 1047000 landmark faces
[2016-11-30 21:27:16,687][INFO] Process-19 reads 13000
[2016-11-30 21:27:16,752][INFO] writes 1048000 landmark faces
[2016-11-30 21:27:16,970][INFO] Process-23 reads 13000
[2016-11-30 21:27:16,990][INFO] writes 1049000 landmark faces
[2016-11-30 21:27:17,210][INFO] writes 1050000 landmark faces
[2016-11-30 21:27:17,440][INFO] writes 1051000 landmark faces
[2016-11-30 21:27:17,716][INFO] writes 1052000 landmark faces
[2016-11-30 21:27:17,932][INFO] writes 1053000 landmark faces
[2016-11-30 21:27:18,079][INFO] Process-21 reads 13000
[2016-11-30 21:27:18,145][INFO] writes 1054000 landmark faces
[2016-11-30 21:27:18,189][INFO] Process-20 reads 13000
[2016-11-30 21:27:18,379][INFO] writes 1055000 landmark faces
[2016-11-30 21:27:18,626][INFO] writes 1056000 landmark faces
[2016-11-30 21:27:18,866][INFO] writes 1057000 landmark faces
[2016-11-30 21:27:19,072][INFO] writes 1058000 landmark faces
[2016-11-30 21:27:19,300][INFO] writes 1059000 landmark faces
[2016-11-30 21:27:19,539][INFO] writes 1060000 landmark faces
[2016-11-30 21:27:19,756][INFO] writes 1061000 landmark faces
[2016-11-30 21:27:19,985][INFO] writes 1062000 landmark faces
[2016-11-30 21:27:20,215][INFO] writes 1063000 landmark faces
[2016-11-30 21:27:20,457][INFO] writes 1064000 landmark faces
[2016-11-30 21:27:20,684][INFO] writes 1065000 landmark faces
[2016-11-30 21:27:20,938][INFO] writes 1066000 landmark faces
[2016-11-30 21:27:21,137][INFO] writes 1067000 landmark faces
[2016-11-30 21:27:21,375][INFO] writes 1068000 landmark faces
[2016-11-30 21:27:21,596][INFO] writes 1069000 landmark faces
[2016-11-30 21:27:21,856][INFO] writes 1070000 landmark faces
[2016-11-30 21:27:22,120][INFO] writes 1071000 landmark faces
[2016-11-30 21:27:22,336][INFO] writes 1072000 landmark faces
[2016-11-30 21:27:22,568][INFO] writes 1073000 landmark faces
[2016-11-30 21:27:22,789][INFO] writes 1074000 landmark faces
[2016-11-30 21:27:23,029][INFO] writes 1075000 landmark faces
[2016-11-30 21:27:23,234][INFO] writes 1076000 landmark faces
[2016-11-30 21:27:23,455][INFO] writes 1077000 landmark faces
[2016-11-30 21:27:23,677][INFO] writes 1078000 landmark faces
[2016-11-30 21:27:23,902][INFO] writes 1079000 landmark faces
[2016-11-30 21:27:24,119][INFO] writes 1080000 landmark faces
[2016-11-30 21:27:24,313][INFO] writes 1081000 landmark faces
[2016-11-30 21:27:24,565][INFO] writes 1082000 landmark faces
[2016-11-30 21:27:24,773][INFO] writes 1083000 landmark faces
[2016-11-30 21:27:24,982][INFO] writes 1084000 landmark faces
[2016-11-30 21:27:25,230][INFO] writes 1085000 landmark faces
[2016-11-30 21:27:25,487][INFO] writes 1086000 landmark faces
[2016-11-30 21:27:25,709][INFO] writes 1087000 landmark faces
[2016-11-30 21:27:25,949][INFO] writes 1088000 landmark faces
[2016-11-30 21:27:26,169][INFO] writes 1089000 landmark faces
[2016-11-30 21:27:26,427][INFO] writes 1090000 landmark faces
[2016-11-30 21:27:26,673][INFO] writes 1091000 landmark faces
[2016-11-30 21:27:26,964][INFO] writes 1092000 landmark faces
[2016-11-30 21:27:27,193][INFO] writes 1093000 landmark faces
[2016-11-30 21:27:27,398][INFO] writes 1094000 landmark faces
[2016-11-30 21:27:27,603][INFO] writes 1095000 landmark faces
[2016-11-30 21:27:27,804][INFO] writes 1096000 landmark faces
[2016-11-30 21:27:28,018][INFO] writes 1097000 landmark faces
[2016-11-30 21:27:28,304][INFO] writes 1098000 landmark faces
[2016-11-30 21:27:28,558][INFO] writes 1099000 landmark faces
[2016-11-30 21:27:28,784][INFO] writes 1100000 landmark faces
[2016-11-30 21:27:29,020][INFO] writes 1101000 landmark faces
[2016-11-30 21:27:29,256][INFO] Process-26 reads 14000
[2016-11-30 21:27:29,260][INFO] writes 1102000 landmark faces
[2016-11-30 21:27:29,510][INFO] writes 1103000 landmark faces
[2016-11-30 21:27:29,743][INFO] writes 1104000 landmark faces
[2016-11-30 21:27:29,958][INFO] writes 1105000 landmark faces
[2016-11-30 21:27:30,186][INFO] writes 1106000 landmark faces
[2016-11-30 21:27:30,414][INFO] writes 1107000 landmark faces
[2016-11-30 21:27:30,635][INFO] writes 1108000 landmark faces
[2016-11-30 21:27:30,813][INFO] Process-24 reads 14000
[2016-11-30 21:27:30,840][INFO] writes 1109000 landmark faces
[2016-11-30 21:27:31,088][INFO] writes 1110000 landmark faces
[2016-11-30 21:27:31,330][INFO] writes 1111000 landmark faces
[2016-11-30 21:27:31,431][INFO] Process-22 reads 14000
[2016-11-30 21:27:31,548][INFO] writes 1112000 landmark faces
[2016-11-30 21:27:31,765][INFO] writes 1113000 landmark faces
[2016-11-30 21:27:31,988][INFO] writes 1114000 landmark faces
[2016-11-30 21:27:32,196][INFO] Process-25 reads 14000
[2016-11-30 21:27:32,212][INFO] writes 1115000 landmark faces
[2016-11-30 21:27:32,448][INFO] writes 1116000 landmark faces
[2016-11-30 21:27:32,664][INFO] writes 1117000 landmark faces
[2016-11-30 21:27:32,890][INFO] writes 1118000 landmark faces
[2016-11-30 21:27:33,138][INFO] writes 1119000 landmark faces
[2016-11-30 21:27:33,367][INFO] writes 1120000 landmark faces
[2016-11-30 21:27:33,649][INFO] writes 1121000 landmark faces
[2016-11-30 21:27:33,860][INFO] writes 1122000 landmark faces
[2016-11-30 21:27:34,088][INFO] writes 1123000 landmark faces
[2016-11-30 21:27:34,305][INFO] writes 1124000 landmark faces
[2016-11-30 21:27:34,527][INFO] writes 1125000 landmark faces
[2016-11-30 21:27:34,748][INFO] writes 1126000 landmark faces
[2016-11-30 21:27:34,920][INFO] Process-23 reads 14000
[2016-11-30 21:27:34,961][INFO] writes 1127000 landmark faces
[2016-11-30 21:27:35,176][INFO] writes 1128000 landmark faces
[2016-11-30 21:27:35,398][INFO] writes 1129000 landmark faces
[2016-11-30 21:27:35,497][INFO] Process-19 reads 14000
[2016-11-30 21:27:35,641][INFO] writes 1130000 landmark faces
[2016-11-30 21:27:35,876][INFO] writes 1131000 landmark faces
[2016-11-30 21:27:35,938][INFO] Process-21 reads 14000
[2016-11-30 21:27:36,073][INFO] writes 1132000 landmark faces
[2016-11-30 21:27:36,303][INFO] writes 1133000 landmark faces
[2016-11-30 21:27:36,535][INFO] writes 1134000 landmark faces
[2016-11-30 21:27:36,775][INFO] writes 1135000 landmark faces
[2016-11-30 21:27:37,027][INFO] writes 1136000 landmark faces
[2016-11-30 21:27:37,280][INFO] writes 1137000 landmark faces
[2016-11-30 21:27:37,408][INFO] Process-20 reads 14000
[2016-11-30 21:27:37,569][INFO] writes 1138000 landmark faces
[2016-11-30 21:27:37,874][INFO] writes 1139000 landmark faces
[2016-11-30 21:27:38,041][INFO] writes 1140000 landmark faces
[2016-11-30 21:27:38,288][INFO] writes 1141000 landmark faces
[2016-11-30 21:27:38,507][INFO] writes 1142000 landmark faces
[2016-11-30 21:27:38,754][INFO] writes 1143000 landmark faces
[2016-11-30 21:27:38,997][INFO] writes 1144000 landmark faces
[2016-11-30 21:27:39,258][INFO] writes 1145000 landmark faces
[2016-11-30 21:27:39,524][INFO] writes 1146000 landmark faces
[2016-11-30 21:27:39,817][INFO] writes 1147000 landmark faces
[2016-11-30 21:27:40,034][INFO] writes 1148000 landmark faces
[2016-11-30 21:27:40,268][INFO] writes 1149000 landmark faces
[2016-11-30 21:27:40,478][INFO] writes 1150000 landmark faces
[2016-11-30 21:27:40,699][INFO] writes 1151000 landmark faces
[2016-11-30 21:27:40,915][INFO] writes 1152000 landmark faces
[2016-11-30 21:27:41,139][INFO] writes 1153000 landmark faces
[2016-11-30 21:27:41,365][INFO] writes 1154000 landmark faces
[2016-11-30 21:27:41,598][INFO] writes 1155000 landmark faces
[2016-11-30 21:27:41,815][INFO] writes 1156000 landmark faces
[2016-11-30 21:27:42,053][INFO] writes 1157000 landmark faces
[2016-11-30 21:27:42,280][INFO] writes 1158000 landmark faces
[2016-11-30 21:27:42,514][INFO] writes 1159000 landmark faces
[2016-11-30 21:27:42,765][INFO] writes 1160000 landmark faces
[2016-11-30 21:27:43,013][INFO] writes 1161000 landmark faces
[2016-11-30 21:27:43,265][INFO] writes 1162000 landmark faces
[2016-11-30 21:27:43,475][INFO] writes 1163000 landmark faces
[2016-11-30 21:27:43,720][INFO] writes 1164000 landmark faces
[2016-11-30 21:27:44,015][INFO] writes 1165000 landmark faces
[2016-11-30 21:27:44,235][INFO] writes 1166000 landmark faces
[2016-11-30 21:27:44,440][INFO] writes 1167000 landmark faces
[2016-11-30 21:27:44,658][INFO] writes 1168000 landmark faces
[2016-11-30 21:27:44,895][INFO] writes 1169000 landmark faces
[2016-11-30 21:27:45,124][INFO] writes 1170000 landmark faces
[2016-11-30 21:27:45,351][INFO] writes 1171000 landmark faces
[2016-11-30 21:27:45,628][INFO] writes 1172000 landmark faces
[2016-11-30 21:27:45,863][INFO] writes 1173000 landmark faces
[2016-11-30 21:27:46,094][INFO] writes 1174000 landmark faces
[2016-11-30 21:27:46,304][INFO] writes 1175000 landmark faces
[2016-11-30 21:27:46,539][INFO] writes 1176000 landmark faces
[2016-11-30 21:27:46,743][INFO] writes 1177000 landmark faces
[2016-11-30 21:27:46,963][INFO] writes 1178000 landmark faces
[2016-11-30 21:27:47,199][INFO] writes 1179000 landmark faces
[2016-11-30 21:27:47,460][INFO] writes 1180000 landmark faces
[2016-11-30 21:27:47,674][INFO] writes 1181000 landmark faces
[2016-11-30 21:27:47,882][INFO] writes 1182000 landmark faces
[2016-11-30 21:27:48,090][INFO] writes 1183000 landmark faces
[2016-11-30 21:27:48,326][INFO] Process-24 reads 15000
[2016-11-30 21:27:48,355][INFO] writes 1184000 landmark faces
[2016-11-30 21:27:48,599][INFO] Process-26 reads 15000
[2016-11-30 21:27:48,606][INFO] writes 1185000 landmark faces
[2016-11-30 21:27:48,869][INFO] writes 1186000 landmark faces
[2016-11-30 21:27:49,086][INFO] writes 1187000 landmark faces
[2016-11-30 21:27:49,309][INFO] writes 1188000 landmark faces
[2016-11-30 21:27:49,533][INFO] writes 1189000 landmark faces
[2016-11-30 21:27:49,762][INFO] writes 1190000 landmark faces
[2016-11-30 21:27:49,968][INFO] writes 1191000 landmark faces
[2016-11-30 21:27:50,227][INFO] writes 1192000 landmark faces
[2016-11-30 21:27:50,318][INFO] Process-22 reads 15000
[2016-11-30 21:27:50,508][INFO] writes 1193000 landmark faces
[2016-11-30 21:27:50,737][INFO] writes 1194000 landmark faces
[2016-11-30 21:27:50,980][INFO] writes 1195000 landmark faces
[2016-11-30 21:27:51,009][INFO] Process-25 reads 15000
[2016-11-30 21:27:51,196][INFO] writes 1196000 landmark faces
[2016-11-30 21:27:51,422][INFO] writes 1197000 landmark faces
[2016-11-30 21:27:51,630][INFO] writes 1198000 landmark faces
[2016-11-30 21:27:51,845][INFO] writes 1199000 landmark faces
[2016-11-30 21:27:52,057][INFO] writes 1200000 landmark faces
[2016-11-30 21:27:52,293][INFO] writes 1201000 landmark faces
[2016-11-30 21:27:52,514][INFO] writes 1202000 landmark faces
[2016-11-30 21:27:52,755][INFO] writes 1203000 landmark faces
[2016-11-30 21:27:52,989][INFO] writes 1204000 landmark faces
[2016-11-30 21:27:53,205][INFO] writes 1205000 landmark faces
[2016-11-30 21:27:53,282][INFO] Process-19 reads 15000
[2016-11-30 21:27:53,404][INFO] writes 1206000 landmark faces
[2016-11-30 21:27:53,631][INFO] writes 1207000 landmark faces
[2016-11-30 21:27:53,730][INFO] Process-23 reads 15000
[2016-11-30 21:27:53,848][INFO] writes 1208000 landmark faces
[2016-11-30 21:27:54,075][INFO] writes 1209000 landmark faces
[2016-11-30 21:27:54,314][INFO] writes 1210000 landmark faces
[2016-11-30 21:27:54,545][INFO] writes 1211000 landmark faces
[2016-11-30 21:27:54,694][INFO] Process-21 reads 15000
[2016-11-30 21:27:54,802][INFO] writes 1212000 landmark faces
[2016-11-30 21:27:55,077][INFO] writes 1213000 landmark faces
[2016-11-30 21:27:55,330][INFO] writes 1214000 landmark faces
[2016-11-30 21:27:55,602][INFO] writes 1215000 landmark faces
[2016-11-30 21:27:55,842][INFO] writes 1216000 landmark faces
[2016-11-30 21:27:56,122][INFO] writes 1217000 landmark faces
[2016-11-30 21:27:56,345][INFO] writes 1218000 landmark faces
[2016-11-30 21:27:56,480][INFO] Process-20 reads 15000
[2016-11-30 21:27:56,552][INFO] writes 1219000 landmark faces
[2016-11-30 21:27:56,760][INFO] writes 1220000 landmark faces
[2016-11-30 21:27:56,995][INFO] writes 1221000 landmark faces
[2016-11-30 21:27:57,214][INFO] writes 1222000 landmark faces
[2016-11-30 21:27:57,421][INFO] writes 1223000 landmark faces
[2016-11-30 21:27:57,636][INFO] writes 1224000 landmark faces
[2016-11-30 21:27:57,846][INFO] writes 1225000 landmark faces
[2016-11-30 21:27:58,088][INFO] writes 1226000 landmark faces
[2016-11-30 21:27:58,347][INFO] writes 1227000 landmark faces
[2016-11-30 21:27:58,591][INFO] writes 1228000 landmark faces
[2016-11-30 21:27:58,869][INFO] writes 1229000 landmark faces
[2016-11-30 21:27:59,116][INFO] writes 1230000 landmark faces
[2016-11-30 21:27:59,360][INFO] writes 1231000 landmark faces
[2016-11-30 21:27:59,615][INFO] writes 1232000 landmark faces
[2016-11-30 21:27:59,832][INFO] writes 1233000 landmark faces
[2016-11-30 21:28:00,045][INFO] writes 1234000 landmark faces
[2016-11-30 21:28:00,272][INFO] writes 1235000 landmark faces
[2016-11-30 21:28:00,525][INFO] writes 1236000 landmark faces
[2016-11-30 21:28:00,777][INFO] writes 1237000 landmark faces
[2016-11-30 21:28:00,992][INFO] writes 1238000 landmark faces
[2016-11-30 21:28:01,222][INFO] writes 1239000 landmark faces
[2016-11-30 21:28:01,442][INFO] writes 1240000 landmark faces
[2016-11-30 21:28:01,689][INFO] writes 1241000 landmark faces
[2016-11-30 21:28:01,901][INFO] writes 1242000 landmark faces
[2016-11-30 21:28:02,159][INFO] writes 1243000 landmark faces
[2016-11-30 21:28:02,381][INFO] writes 1244000 landmark faces
[2016-11-30 21:28:02,592][INFO] writes 1245000 landmark faces
[2016-11-30 21:28:02,809][INFO] writes 1246000 landmark faces
[2016-11-30 21:28:03,036][INFO] writes 1247000 landmark faces
[2016-11-30 21:28:03,259][INFO] writes 1248000 landmark faces
[2016-11-30 21:28:03,475][INFO] writes 1249000 landmark faces
[2016-11-30 21:28:03,680][INFO] writes 1250000 landmark faces
[2016-11-30 21:28:03,919][INFO] writes 1251000 landmark faces
[2016-11-30 21:28:04,138][INFO] writes 1252000 landmark faces
[2016-11-30 21:28:04,388][INFO] writes 1253000 landmark faces
[2016-11-30 21:28:04,609][INFO] writes 1254000 landmark faces
[2016-11-30 21:28:04,824][INFO] writes 1255000 landmark faces
[2016-11-30 21:28:05,045][INFO] writes 1256000 landmark faces
[2016-11-30 21:28:05,276][INFO] writes 1257000 landmark faces
[2016-11-30 21:28:05,504][INFO] writes 1258000 landmark faces
[2016-11-30 21:28:05,714][INFO] writes 1259000 landmark faces
[2016-11-30 21:28:05,919][INFO] writes 1260000 landmark faces
[2016-11-30 21:28:06,141][INFO] writes 1261000 landmark faces
[2016-11-30 21:28:06,152][INFO] Process-24 reads 16000
[2016-11-30 21:28:06,366][INFO] writes 1262000 landmark faces
[2016-11-30 21:28:06,591][INFO] writes 1263000 landmark faces
[2016-11-30 21:28:06,829][INFO] writes 1264000 landmark faces
[2016-11-30 21:28:07,040][INFO] writes 1265000 landmark faces
[2016-11-30 21:28:07,269][INFO] writes 1266000 landmark faces
[2016-11-30 21:28:07,501][INFO] writes 1267000 landmark faces
[2016-11-30 21:28:07,719][INFO] writes 1268000 landmark faces
[2016-11-30 21:28:07,940][INFO] writes 1269000 landmark faces
[2016-11-30 21:28:08,000][INFO] Process-26 reads 16000
[2016-11-30 21:28:08,140][INFO] Process-25 reads 16000
[2016-11-30 21:28:08,173][INFO] writes 1270000 landmark faces
[2016-11-30 21:28:08,388][INFO] writes 1271000 landmark faces
[2016-11-30 21:28:08,639][INFO] writes 1272000 landmark faces
[2016-11-30 21:28:08,654][INFO] Process-22 reads 16000
[2016-11-30 21:28:08,858][INFO] writes 1273000 landmark faces
[2016-11-30 21:28:09,079][INFO] writes 1274000 landmark faces
[2016-11-30 21:28:09,316][INFO] writes 1275000 landmark faces
[2016-11-30 21:28:09,540][INFO] writes 1276000 landmark faces
[2016-11-30 21:28:09,739][INFO] writes 1277000 landmark faces
[2016-11-30 21:28:09,948][INFO] writes 1278000 landmark faces
[2016-11-30 21:28:10,165][INFO] writes 1279000 landmark faces
[2016-11-30 21:28:10,370][INFO] writes 1280000 landmark faces
[2016-11-30 21:28:10,594][INFO] writes 1281000 landmark faces
[2016-11-30 21:28:10,817][INFO] writes 1282000 landmark faces
[2016-11-30 21:28:11,075][INFO] writes 1283000 landmark faces
[2016-11-30 21:28:11,311][INFO] writes 1284000 landmark faces
[2016-11-30 21:28:11,522][INFO] writes 1285000 landmark faces
[2016-11-30 21:28:11,764][INFO] writes 1286000 landmark faces
[2016-11-30 21:28:11,856][INFO] Process-19 reads 16000
[2016-11-30 21:28:12,005][INFO] writes 1287000 landmark faces
[2016-11-30 21:28:12,223][INFO] writes 1288000 landmark faces
[2016-11-30 21:28:12,457][INFO] writes 1289000 landmark faces
[2016-11-30 21:28:12,670][INFO] writes 1290000 landmark faces
[2016-11-30 21:28:12,923][INFO] writes 1291000 landmark faces
[2016-11-30 21:28:13,121][INFO] Process-21 reads 16000
[2016-11-30 21:28:13,152][INFO] writes 1292000 landmark faces
[2016-11-30 21:28:13,397][INFO] writes 1293000 landmark faces
[2016-11-30 21:28:13,613][INFO] writes 1294000 landmark faces
[2016-11-30 21:28:13,707][INFO] Process-20 reads 16000
[2016-11-30 21:28:13,834][INFO] writes 1295000 landmark faces
[2016-11-30 21:28:14,036][INFO] writes 1296000 landmark faces
[2016-11-30 21:28:14,280][INFO] writes 1297000 landmark faces
[2016-11-30 21:28:14,345][INFO] Process-23 reads 16000
[2016-11-30 21:28:14,485][INFO] writes 1298000 landmark faces
[2016-11-30 21:28:14,683][INFO] writes 1299000 landmark faces
[2016-11-30 21:28:14,957][INFO] writes 1300000 landmark faces
[2016-11-30 21:28:15,195][INFO] writes 1301000 landmark faces
[2016-11-30 21:28:15,417][INFO] writes 1302000 landmark faces
[2016-11-30 21:28:15,623][INFO] writes 1303000 landmark faces
[2016-11-30 21:28:15,864][INFO] writes 1304000 landmark faces
[2016-11-30 21:28:16,107][INFO] writes 1305000 landmark faces
[2016-11-30 21:28:16,314][INFO] writes 1306000 landmark faces
[2016-11-30 21:28:16,523][INFO] writes 1307000 landmark faces
[2016-11-30 21:28:16,774][INFO] writes 1308000 landmark faces
[2016-11-30 21:28:17,023][INFO] writes 1309000 landmark faces
[2016-11-30 21:28:17,276][INFO] writes 1310000 landmark faces
[2016-11-30 21:28:17,509][INFO] writes 1311000 landmark faces
[2016-11-30 21:28:17,759][INFO] writes 1312000 landmark faces
[2016-11-30 21:28:18,009][INFO] writes 1313000 landmark faces
[2016-11-30 21:28:18,255][INFO] writes 1314000 landmark faces
[2016-11-30 21:28:18,496][INFO] writes 1315000 landmark faces
[2016-11-30 21:28:18,715][INFO] writes 1316000 landmark faces
[2016-11-30 21:28:18,959][INFO] writes 1317000 landmark faces
[2016-11-30 21:28:19,223][INFO] writes 1318000 landmark faces
[2016-11-30 21:28:19,440][INFO] writes 1319000 landmark faces
[2016-11-30 21:28:19,674][INFO] writes 1320000 landmark faces
[2016-11-30 21:28:19,884][INFO] writes 1321000 landmark faces
[2016-11-30 21:28:20,099][INFO] writes 1322000 landmark faces
[2016-11-30 21:28:20,353][INFO] writes 1323000 landmark faces
[2016-11-30 21:28:20,595][INFO] writes 1324000 landmark faces
[2016-11-30 21:28:20,849][INFO] writes 1325000 landmark faces
[2016-11-30 21:28:21,075][INFO] writes 1326000 landmark faces
[2016-11-30 21:28:21,301][INFO] writes 1327000 landmark faces
[2016-11-30 21:28:21,516][INFO] writes 1328000 landmark faces
[2016-11-30 21:28:21,774][INFO] writes 1329000 landmark faces
[2016-11-30 21:28:22,002][INFO] writes 1330000 landmark faces
[2016-11-30 21:28:22,214][INFO] writes 1331000 landmark faces
[2016-11-30 21:28:22,434][INFO] writes 1332000 landmark faces
[2016-11-30 21:28:22,654][INFO] writes 1333000 landmark faces
[2016-11-30 21:28:22,903][INFO] writes 1334000 landmark faces
[2016-11-30 21:28:23,150][INFO] writes 1335000 landmark faces
[2016-11-30 21:28:23,375][INFO] writes 1336000 landmark faces
[2016-11-30 21:28:23,413][INFO] Process-24 reads 17000
[2016-11-30 21:28:23,609][INFO] writes 1337000 landmark faces
[2016-11-30 21:28:23,867][INFO] writes 1338000 landmark faces
[2016-11-30 21:28:24,138][INFO] writes 1339000 landmark faces
[2016-11-30 21:28:24,365][INFO] writes 1340000 landmark faces
[2016-11-30 21:28:24,639][INFO] writes 1341000 landmark faces
[2016-11-30 21:28:24,886][INFO] writes 1342000 landmark faces
[2016-11-30 21:28:25,124][INFO] writes 1343000 landmark faces
[2016-11-30 21:28:25,341][INFO] writes 1344000 landmark faces
[2016-11-30 21:28:25,373][INFO] Process-25 reads 17000
[2016-11-30 21:28:25,557][INFO] writes 1345000 landmark faces
[2016-11-30 21:28:25,785][INFO] writes 1346000 landmark faces
[2016-11-30 21:28:26,045][INFO] writes 1347000 landmark faces
[2016-11-30 21:28:26,282][INFO] writes 1348000 landmark faces
[2016-11-30 21:28:26,555][INFO] writes 1349000 landmark faces
[2016-11-30 21:28:26,768][INFO] Process-26 reads 17000
[2016-11-30 21:28:26,833][INFO] writes 1350000 landmark faces
[2016-11-30 21:28:27,126][INFO] writes 1351000 landmark faces
[2016-11-30 21:28:27,331][INFO] writes 1352000 landmark faces
[2016-11-30 21:28:27,557][INFO] writes 1353000 landmark faces
[2016-11-30 21:28:27,765][INFO] Process-22 reads 17000
[2016-11-30 21:28:27,792][INFO] writes 1354000 landmark faces
[2016-11-30 21:28:28,032][INFO] writes 1355000 landmark faces
[2016-11-30 21:28:28,276][INFO] writes 1356000 landmark faces
[2016-11-30 21:28:28,522][INFO] writes 1357000 landmark faces
[2016-11-30 21:28:28,759][INFO] writes 1358000 landmark faces
[2016-11-30 21:28:28,978][INFO] writes 1359000 landmark faces
[2016-11-30 21:28:29,222][INFO] writes 1360000 landmark faces
[2016-11-30 21:28:29,437][INFO] writes 1361000 landmark faces
[2016-11-30 21:28:29,647][INFO] writes 1362000 landmark faces
[2016-11-30 21:28:29,874][INFO] writes 1363000 landmark faces
[2016-11-30 21:28:30,095][INFO] writes 1364000 landmark faces
[2016-11-30 21:28:30,332][INFO] writes 1365000 landmark faces
[2016-11-30 21:28:30,568][INFO] writes 1366000 landmark faces
[2016-11-30 21:28:30,801][INFO] writes 1367000 landmark faces
[2016-11-30 21:28:31,019][INFO] writes 1368000 landmark faces
[2016-11-30 21:28:31,244][INFO] writes 1369000 landmark faces
[2016-11-30 21:28:31,474][INFO] writes 1370000 landmark faces
[2016-11-30 21:28:31,628][INFO] Process-19 reads 17000
[2016-11-30 21:28:31,722][INFO] writes 1371000 landmark faces
[2016-11-30 21:28:31,970][INFO] writes 1372000 landmark faces
[2016-11-30 21:28:32,115][INFO] Process-21 reads 17000
[2016-11-30 21:28:32,175][INFO] Process-20 reads 17000
[2016-11-30 21:28:32,179][INFO] writes 1373000 landmark faces
[2016-11-30 21:28:32,410][INFO] writes 1374000 landmark faces
[2016-11-30 21:28:32,612][INFO] writes 1375000 landmark faces
[2016-11-30 21:28:32,887][INFO] writes 1376000 landmark faces
[2016-11-30 21:28:33,105][INFO] writes 1377000 landmark faces
[2016-11-30 21:28:33,321][INFO] writes 1378000 landmark faces
[2016-11-30 21:28:33,558][INFO] writes 1379000 landmark faces
[2016-11-30 21:28:33,760][INFO] writes 1380000 landmark faces
[2016-11-30 21:28:34,007][INFO] writes 1381000 landmark faces
[2016-11-30 21:28:34,040][INFO] Process-23 reads 17000
[2016-11-30 21:28:34,275][INFO] writes 1382000 landmark faces
[2016-11-30 21:28:34,505][INFO] writes 1383000 landmark faces
[2016-11-30 21:28:34,750][INFO] writes 1384000 landmark faces
[2016-11-30 21:28:35,035][INFO] writes 1385000 landmark faces
[2016-11-30 21:28:35,263][INFO] writes 1386000 landmark faces
[2016-11-30 21:28:35,501][INFO] writes 1387000 landmark faces
[2016-11-30 21:28:35,718][INFO] writes 1388000 landmark faces
[2016-11-30 21:28:35,940][INFO] writes 1389000 landmark faces
[2016-11-30 21:28:36,191][INFO] writes 1390000 landmark faces
[2016-11-30 21:28:36,438][INFO] writes 1391000 landmark faces
[2016-11-30 21:28:36,674][INFO] writes 1392000 landmark faces
[2016-11-30 21:28:36,884][INFO] writes 1393000 landmark faces
[2016-11-30 21:28:37,092][INFO] writes 1394000 landmark faces
[2016-11-30 21:28:37,337][INFO] writes 1395000 landmark faces
[2016-11-30 21:28:37,541][INFO] writes 1396000 landmark faces
[2016-11-30 21:28:37,775][INFO] writes 1397000 landmark faces
[2016-11-30 21:28:37,985][INFO] writes 1398000 landmark faces
[2016-11-30 21:28:38,223][INFO] writes 1399000 landmark faces
[2016-11-30 21:28:38,445][INFO] writes 1400000 landmark faces
[2016-11-30 21:28:38,688][INFO] writes 1401000 landmark faces
[2016-11-30 21:28:38,912][INFO] writes 1402000 landmark faces
[2016-11-30 21:28:39,133][INFO] writes 1403000 landmark faces
[2016-11-30 21:28:39,327][INFO] writes 1404000 landmark faces
[2016-11-30 21:28:39,536][INFO] writes 1405000 landmark faces
[2016-11-30 21:28:39,769][INFO] writes 1406000 landmark faces
[2016-11-30 21:28:39,993][INFO] writes 1407000 landmark faces
[2016-11-30 21:28:40,252][INFO] writes 1408000 landmark faces
[2016-11-30 21:28:40,506][INFO] writes 1409000 landmark faces
[2016-11-30 21:28:40,755][INFO] writes 1410000 landmark faces
[2016-11-30 21:28:40,987][INFO] writes 1411000 landmark faces
[2016-11-30 21:28:41,011][INFO] Process-24 reads 18000
[2016-11-30 21:28:41,230][INFO] writes 1412000 landmark faces
[2016-11-30 21:28:41,435][INFO] writes 1413000 landmark faces
[2016-11-30 21:28:41,672][INFO] writes 1414000 landmark faces
[2016-11-30 21:28:41,912][INFO] writes 1415000 landmark faces
[2016-11-30 21:28:42,182][INFO] writes 1416000 landmark faces
[2016-11-30 21:28:42,405][INFO] writes 1417000 landmark faces
[2016-11-30 21:28:42,650][INFO] writes 1418000 landmark faces
[2016-11-30 21:28:42,887][INFO] writes 1419000 landmark faces
[2016-11-30 21:28:43,112][INFO] writes 1420000 landmark faces
[2016-11-30 21:28:43,324][INFO] writes 1421000 landmark faces
[2016-11-30 21:28:43,535][INFO] writes 1422000 landmark faces
[2016-11-30 21:28:43,760][INFO] writes 1423000 landmark faces
[2016-11-30 21:28:43,995][INFO] writes 1424000 landmark faces
[2016-11-30 21:28:44,232][INFO] writes 1425000 landmark faces
[2016-11-30 21:28:44,519][INFO] writes 1426000 landmark faces
[2016-11-30 21:28:44,596][INFO] Process-25 reads 18000
[2016-11-30 21:28:44,743][INFO] writes 1427000 landmark faces
[2016-11-30 21:28:44,969][INFO] writes 1428000 landmark faces
[2016-11-30 21:28:45,195][INFO] writes 1429000 landmark faces
[2016-11-30 21:28:45,414][INFO] writes 1430000 landmark faces
[2016-11-30 21:28:45,621][INFO] writes 1431000 landmark faces
[2016-11-30 21:28:45,869][INFO] writes 1432000 landmark faces
[2016-11-30 21:28:46,057][INFO] Process-26 reads 18000
[2016-11-30 21:28:46,108][INFO] writes 1433000 landmark faces
[2016-11-30 21:28:46,281][INFO] Process-22 reads 18000
[2016-11-30 21:28:46,356][INFO] writes 1434000 landmark faces
[2016-11-30 21:28:46,574][INFO] writes 1435000 landmark faces
[2016-11-30 21:28:46,799][INFO] writes 1436000 landmark faces
[2016-11-30 21:28:47,050][INFO] writes 1437000 landmark faces
[2016-11-30 21:28:47,315][INFO] writes 1438000 landmark faces
[2016-11-30 21:28:47,568][INFO] writes 1439000 landmark faces
[2016-11-30 21:28:47,797][INFO] writes 1440000 landmark faces
[2016-11-30 21:28:48,032][INFO] writes 1441000 landmark faces
[2016-11-30 21:28:48,260][INFO] writes 1442000 landmark faces
[2016-11-30 21:28:48,488][INFO] writes 1443000 landmark faces
[2016-11-30 21:28:48,698][INFO] writes 1444000 landmark faces
[2016-11-30 21:28:48,923][INFO] writes 1445000 landmark faces
[2016-11-30 21:28:49,155][INFO] writes 1446000 landmark faces
[2016-11-30 21:28:49,391][INFO] writes 1447000 landmark faces
[2016-11-30 21:28:49,596][INFO] writes 1448000 landmark faces
[2016-11-30 21:28:49,876][INFO] writes 1449000 landmark faces
[2016-11-30 21:28:50,177][INFO] writes 1450000 landmark faces
[2016-11-30 21:28:50,483][INFO] writes 1451000 landmark faces
[2016-11-30 21:28:50,583][INFO] Process-19 reads 18000
[2016-11-30 21:28:50,604][INFO] Process-21 reads 18000
[2016-11-30 21:28:50,687][INFO] writes 1452000 landmark faces
[2016-11-30 21:28:50,796][INFO] Process-20 reads 18000
[2016-11-30 21:28:50,881][INFO] writes 1453000 landmark faces
[2016-11-30 21:28:51,098][INFO] writes 1454000 landmark faces
[2016-11-30 21:28:51,318][INFO] writes 1455000 landmark faces
[2016-11-30 21:28:51,526][INFO] writes 1456000 landmark faces
[2016-11-30 21:28:51,760][INFO] writes 1457000 landmark faces
[2016-11-30 21:28:51,982][INFO] writes 1458000 landmark faces
[2016-11-30 21:28:52,217][INFO] writes 1459000 landmark faces
[2016-11-30 21:28:52,427][INFO] writes 1460000 landmark faces
[2016-11-30 21:28:52,615][INFO] Process-23 reads 18000
[2016-11-30 21:28:52,651][INFO] writes 1461000 landmark faces
[2016-11-30 21:28:52,915][INFO] writes 1462000 landmark faces
[2016-11-30 21:28:53,113][INFO] writes 1463000 landmark faces
[2016-11-30 21:28:53,325][INFO] writes 1464000 landmark faces
[2016-11-30 21:28:53,570][INFO] writes 1465000 landmark faces
[2016-11-30 21:28:53,786][INFO] writes 1466000 landmark faces
[2016-11-30 21:28:54,050][INFO] writes 1467000 landmark faces
[2016-11-30 21:28:54,267][INFO] writes 1468000 landmark faces
[2016-11-30 21:28:54,489][INFO] writes 1469000 landmark faces
[2016-11-30 21:28:54,741][INFO] writes 1470000 landmark faces
[2016-11-30 21:28:54,969][INFO] writes 1471000 landmark faces
[2016-11-30 21:28:55,173][INFO] writes 1472000 landmark faces
[2016-11-30 21:28:55,376][INFO] writes 1473000 landmark faces
[2016-11-30 21:28:55,658][INFO] writes 1474000 landmark faces
[2016-11-30 21:28:55,861][INFO] writes 1475000 landmark faces
[2016-11-30 21:28:56,100][INFO] writes 1476000 landmark faces
[2016-11-30 21:28:56,371][INFO] writes 1477000 landmark faces
[2016-11-30 21:28:56,623][INFO] writes 1478000 landmark faces
[2016-11-30 21:28:56,863][INFO] writes 1479000 landmark faces
[2016-11-30 21:28:57,082][INFO] writes 1480000 landmark faces
[2016-11-30 21:28:57,310][INFO] writes 1481000 landmark faces
[2016-11-30 21:28:57,531][INFO] writes 1482000 landmark faces
[2016-11-30 21:28:57,754][INFO] writes 1483000 landmark faces
[2016-11-30 21:28:58,005][INFO] writes 1484000 landmark faces
[2016-11-30 21:28:58,211][INFO] writes 1485000 landmark faces
[2016-11-30 21:28:58,424][INFO] writes 1486000 landmark faces
[2016-11-30 21:28:58,652][INFO] writes 1487000 landmark faces
[2016-11-30 21:28:58,875][INFO] writes 1488000 landmark faces
[2016-11-30 21:28:59,122][INFO] writes 1489000 landmark faces
[2016-11-30 21:28:59,181][INFO] Process-24 reads 19000
[2016-11-30 21:28:59,378][INFO] writes 1490000 landmark faces
[2016-11-30 21:28:59,649][INFO] writes 1491000 landmark faces
[2016-11-30 21:28:59,863][INFO] writes 1492000 landmark faces
[2016-11-30 21:29:00,113][INFO] writes 1493000 landmark faces
[2016-11-30 21:29:00,345][INFO] writes 1494000 landmark faces
[2016-11-30 21:29:00,585][INFO] writes 1495000 landmark faces
[2016-11-30 21:29:00,835][INFO] writes 1496000 landmark faces
[2016-11-30 21:29:01,083][INFO] writes 1497000 landmark faces
[2016-11-30 21:29:01,325][INFO] writes 1498000 landmark faces
[2016-11-30 21:29:01,533][INFO] writes 1499000 landmark faces
[2016-11-30 21:29:01,752][INFO] writes 1500000 landmark faces
[2016-11-30 21:29:01,969][INFO] writes 1501000 landmark faces
[2016-11-30 21:29:02,232][INFO] writes 1502000 landmark faces
[2016-11-30 21:29:02,465][INFO] writes 1503000 landmark faces
[2016-11-30 21:29:02,690][INFO] writes 1504000 landmark faces
[2016-11-30 21:29:02,921][INFO] writes 1505000 landmark faces
[2016-11-30 21:29:03,178][INFO] writes 1506000 landmark faces
[2016-11-30 21:29:03,440][INFO] writes 1507000 landmark faces
[2016-11-30 21:29:03,636][INFO] Process-25 reads 19000
[2016-11-30 21:29:03,672][INFO] writes 1508000 landmark faces
[2016-11-30 21:29:03,893][INFO] writes 1509000 landmark faces
[2016-11-30 21:29:04,141][INFO] writes 1510000 landmark faces
[2016-11-30 21:29:04,383][INFO] writes 1511000 landmark faces
[2016-11-30 21:29:04,550][INFO] Process-22 reads 19000
[2016-11-30 21:29:04,619][INFO] writes 1512000 landmark faces
[2016-11-30 21:29:04,840][INFO] writes 1513000 landmark faces
[2016-11-30 21:29:05,093][INFO] writes 1514000 landmark faces
[2016-11-30 21:29:05,285][INFO] writes 1515000 landmark faces
[2016-11-30 21:29:05,506][INFO] writes 1516000 landmark faces
[2016-11-30 21:29:05,727][INFO] writes 1517000 landmark faces
[2016-11-30 21:29:05,985][INFO] writes 1518000 landmark faces
[2016-11-30 21:29:06,054][INFO] Process-26 reads 19000
[2016-11-30 21:29:06,193][INFO] writes 1519000 landmark faces
[2016-11-30 21:29:06,418][INFO] writes 1520000 landmark faces
[2016-11-30 21:29:06,683][INFO] writes 1521000 landmark faces
[2016-11-30 21:29:06,929][INFO] writes 1522000 landmark faces
[2016-11-30 21:29:07,145][INFO] writes 1523000 landmark faces
[2016-11-30 21:29:07,375][INFO] writes 1524000 landmark faces
[2016-11-30 21:29:07,620][INFO] writes 1525000 landmark faces
[2016-11-30 21:29:07,876][INFO] writes 1526000 landmark faces
[2016-11-30 21:29:08,098][INFO] writes 1527000 landmark faces
[2016-11-30 21:29:08,136][INFO] Process-20 reads 19000
[2016-11-30 21:29:08,340][INFO] writes 1528000 landmark faces
[2016-11-30 21:29:08,594][INFO] writes 1529000 landmark faces
[2016-11-30 21:29:08,833][INFO] Process-21 reads 19000
[2016-11-30 21:29:08,877][INFO] writes 1530000 landmark faces
[2016-11-30 21:29:09,114][INFO] writes 1531000 landmark faces
[2016-11-30 21:29:09,368][INFO] writes 1532000 landmark faces
[2016-11-30 21:29:09,621][INFO] writes 1533000 landmark faces
[2016-11-30 21:29:09,839][INFO] writes 1534000 landmark faces
[2016-11-30 21:29:10,080][INFO] writes 1535000 landmark faces
[2016-11-30 21:29:10,144][INFO] Process-19 reads 19000
[2016-11-30 21:29:10,359][INFO] writes 1536000 landmark faces
[2016-11-30 21:29:10,611][INFO] writes 1537000 landmark faces
[2016-11-30 21:29:10,846][INFO] writes 1538000 landmark faces
[2016-11-30 21:29:11,088][INFO] writes 1539000 landmark faces
[2016-11-30 21:29:11,345][INFO] writes 1540000 landmark faces
[2016-11-30 21:29:11,636][INFO] writes 1541000 landmark faces
[2016-11-30 21:29:11,882][INFO] writes 1542000 landmark faces
[2016-11-30 21:29:12,080][INFO] writes 1543000 landmark faces
[2016-11-30 21:29:12,297][INFO] writes 1544000 landmark faces
[2016-11-30 21:29:12,380][INFO] Process-23 reads 19000
[2016-11-30 21:29:12,544][INFO] writes 1545000 landmark faces
[2016-11-30 21:29:12,756][INFO] writes 1546000 landmark faces
[2016-11-30 21:29:12,993][INFO] writes 1547000 landmark faces
[2016-11-30 21:29:13,231][INFO] writes 1548000 landmark faces
[2016-11-30 21:29:13,458][INFO] writes 1549000 landmark faces
[2016-11-30 21:29:13,695][INFO] writes 1550000 landmark faces
[2016-11-30 21:29:13,913][INFO] writes 1551000 landmark faces
[2016-11-30 21:29:14,161][INFO] writes 1552000 landmark faces
[2016-11-30 21:29:14,383][INFO] writes 1553000 landmark faces
[2016-11-30 21:29:14,636][INFO] writes 1554000 landmark faces
[2016-11-30 21:29:14,881][INFO] writes 1555000 landmark faces
[2016-11-30 21:29:15,111][INFO] writes 1556000 landmark faces
[2016-11-30 21:29:15,334][INFO] writes 1557000 landmark faces
[2016-11-30 21:29:15,561][INFO] writes 1558000 landmark faces
[2016-11-30 21:29:15,819][INFO] writes 1559000 landmark faces
[2016-11-30 21:29:16,022][INFO] writes 1560000 landmark faces
[2016-11-30 21:29:16,259][INFO] writes 1561000 landmark faces
[2016-11-30 21:29:16,494][INFO] writes 1562000 landmark faces
[2016-11-30 21:29:16,725][INFO] writes 1563000 landmark faces
[2016-11-30 21:29:16,957][INFO] writes 1564000 landmark faces
[2016-11-30 21:29:17,164][INFO] writes 1565000 landmark faces
[2016-11-30 21:29:17,192][INFO] Process-24 reads 20000
[2016-11-30 21:29:17,419][INFO] writes 1566000 landmark faces
[2016-11-30 21:29:17,637][INFO] writes 1567000 landmark faces
[2016-11-30 21:29:17,850][INFO] writes 1568000 landmark faces
[2016-11-30 21:29:18,102][INFO] writes 1569000 landmark faces
[2016-11-30 21:29:18,330][INFO] writes 1570000 landmark faces
[2016-11-30 21:29:18,594][INFO] writes 1571000 landmark faces
[2016-11-30 21:29:18,802][INFO] writes 1572000 landmark faces
[2016-11-30 21:29:19,019][INFO] writes 1573000 landmark faces
[2016-11-30 21:29:19,251][INFO] writes 1574000 landmark faces
[2016-11-30 21:29:19,531][INFO] writes 1575000 landmark faces
[2016-11-30 21:29:19,742][INFO] writes 1576000 landmark faces
[2016-11-30 21:29:19,987][INFO] writes 1577000 landmark faces
[2016-11-30 21:29:20,203][INFO] writes 1578000 landmark faces
[2016-11-30 21:29:20,421][INFO] writes 1579000 landmark faces
[2016-11-30 21:29:20,648][INFO] writes 1580000 landmark faces
[2016-11-30 21:29:20,879][INFO] writes 1581000 landmark faces
[2016-11-30 21:29:21,112][INFO] writes 1582000 landmark faces
[2016-11-30 21:29:21,357][INFO] writes 1583000 landmark faces
[2016-11-30 21:29:21,461][INFO] Process-25 reads 20000
[2016-11-30 21:29:21,609][INFO] writes 1584000 landmark faces
[2016-11-30 21:29:21,828][INFO] writes 1585000 landmark faces
[2016-11-30 21:29:22,081][INFO] writes 1586000 landmark faces
[2016-11-30 21:29:22,319][INFO] writes 1587000 landmark faces
[2016-11-30 21:29:22,545][INFO] writes 1588000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:29:22,772][INFO] writes 1589000 landmark faces
[2016-11-30 21:29:23,114][INFO] writes 1590000 landmark faces
[2016-11-30 21:29:23,388][INFO] writes 1591000 landmark faces
[2016-11-30 21:29:23,680][INFO] writes 1592000 landmark faces
[2016-11-30 21:29:23,745][INFO] Process-22 reads 20000
[2016-11-30 21:29:23,941][INFO] writes 1593000 landmark faces
[2016-11-30 21:29:24,215][INFO] writes 1594000 landmark faces
[2016-11-30 21:29:24,487][INFO] writes 1595000 landmark faces
[2016-11-30 21:29:24,717][INFO] writes 1596000 landmark faces
[2016-11-30 21:29:24,879][INFO] Process-26 reads 20000
[2016-11-30 21:29:25,037][INFO] writes 1597000 landmark faces
[2016-11-30 21:29:25,309][INFO] writes 1598000 landmark faces
[2016-11-30 21:29:25,565][INFO] writes 1599000 landmark faces
[2016-11-30 21:29:25,840][INFO] writes 1600000 landmark faces
[2016-11-30 21:29:26,144][INFO] writes 1601000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:29:26,417][INFO] writes 1602000 landmark faces
[2016-11-30 21:29:26,725][INFO] writes 1603000 landmark faces
[2016-11-30 21:29:26,986][INFO] writes 1604000 landmark faces
[2016-11-30 21:29:27,090][INFO] Process-20 reads 20000
[2016-11-30 21:29:27,263][INFO] writes 1605000 landmark faces
[2016-11-30 21:29:27,545][INFO] writes 1606000 landmark faces
[2016-11-30 21:29:27,855][INFO] writes 1607000 landmark faces
[2016-11-30 21:29:28,159][INFO] writes 1608000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:29:28,454][INFO] Process-21 reads 20000
[2016-11-30 21:29:28,459][INFO] writes 1609000 landmark faces
[2016-11-30 21:29:28,564][INFO] Process-19 reads 20000
[2016-11-30 21:29:28,784][INFO] writes 1610000 landmark faces
[2016-11-30 21:29:29,097][INFO] writes 1611000 landmark faces
[2016-11-30 21:29:29,396][INFO] writes 1612000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:29:29,738][INFO] writes 1613000 landmark faces
[2016-11-30 21:29:30,179][INFO] writes 1614000 landmark faces
[2016-11-30 21:29:30,572][INFO] writes 1615000 landmark faces
[2016-11-30 21:29:30,792][INFO] Process-23 reads 20000
[2016-11-30 21:29:30,988][INFO] writes 1616000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:29:31,511][INFO] writes 1617000 landmark faces
[2016-11-30 21:29:32,109][INFO] writes 1618000 landmark faces
[2016-11-30 21:29:32,648][INFO] writes 1619000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:29:33,956][INFO] writes 1620000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:29:40,904][INFO] Finish
[2016-11-30 21:29:40,970][INFO] writing val data, 40520 images
[2016-11-30 21:29:40,975][INFO] remove data/pnet_landmark_val
[2016-11-30 21:29:41,050][INFO] fill queues
[2016-11-30 21:29:41,708][INFO] writes 1000 landmark faces
[2016-11-30 21:29:41,947][INFO] writes 2000 landmark faces
[2016-11-30 21:29:42,186][INFO] writes 3000 landmark faces
[2016-11-30 21:29:42,421][INFO] writes 4000 landmark faces
[2016-11-30 21:29:42,646][INFO] writes 5000 landmark faces
[2016-11-30 21:29:42,889][INFO] writes 6000 landmark faces
[2016-11-30 21:29:43,135][INFO] writes 7000 landmark faces
[2016-11-30 21:29:43,363][INFO] writes 8000 landmark faces
[2016-11-30 21:29:43,638][INFO] writes 9000 landmark faces
[2016-11-30 21:29:43,874][INFO] writes 10000 landmark faces
[2016-11-30 21:29:44,116][INFO] writes 11000 landmark faces
[2016-11-30 21:29:44,372][INFO] writes 12000 landmark faces
[2016-11-30 21:29:44,621][INFO] writes 13000 landmark faces
[2016-11-30 21:29:44,840][INFO] writes 14000 landmark faces
[2016-11-30 21:29:45,058][INFO] writes 15000 landmark faces
[2016-11-30 21:29:45,279][INFO] writes 16000 landmark faces
[2016-11-30 21:29:45,537][INFO] writes 17000 landmark faces
[2016-11-30 21:29:45,770][INFO] writes 18000 landmark faces
[2016-11-30 21:29:45,998][INFO] writes 19000 landmark faces
[2016-11-30 21:29:46,269][INFO] writes 20000 landmark faces
[2016-11-30 21:29:46,486][INFO] writes 21000 landmark faces
[2016-11-30 21:29:46,711][INFO] writes 22000 landmark faces
[2016-11-30 21:29:46,937][INFO] writes 23000 landmark faces
[2016-11-30 21:29:47,176][INFO] writes 24000 landmark faces
[2016-11-30 21:29:47,399][INFO] writes 25000 landmark faces
[2016-11-30 21:29:47,651][INFO] writes 26000 landmark faces
[2016-11-30 21:29:47,869][INFO] writes 27000 landmark faces
[2016-11-30 21:29:48,090][INFO] writes 28000 landmark faces
[2016-11-30 21:29:48,319][INFO] writes 29000 landmark faces
[2016-11-30 21:29:48,560][INFO] writes 30000 landmark faces
[2016-11-30 21:29:48,781][INFO] writes 31000 landmark faces
[2016-11-30 21:29:49,041][INFO] writes 32000 landmark faces
[2016-11-30 21:29:49,283][INFO] writes 33000 landmark faces
[2016-11-30 21:29:49,514][INFO] writes 34000 landmark faces
[2016-11-30 21:29:49,742][INFO] writes 35000 landmark faces
[2016-11-30 21:29:49,966][INFO] writes 36000 landmark faces
[2016-11-30 21:29:50,183][INFO] writes 37000 landmark faces
[2016-11-30 21:29:50,408][INFO] writes 38000 landmark faces
[2016-11-30 21:29:50,611][INFO] writes 39000 landmark faces
[2016-11-30 21:29:50,827][INFO] writes 40000 landmark faces
[2016-11-30 21:29:51,067][INFO] writes 41000 landmark faces
[2016-11-30 21:29:51,295][INFO] writes 42000 landmark faces
[2016-11-30 21:29:51,542][INFO] writes 43000 landmark faces
[2016-11-30 21:29:51,762][INFO] writes 44000 landmark faces
[2016-11-30 21:29:52,021][INFO] writes 45000 landmark faces
[2016-11-30 21:29:52,255][INFO] writes 46000 landmark faces
[2016-11-30 21:29:52,492][INFO] writes 47000 landmark faces
[2016-11-30 21:29:52,697][INFO] writes 48000 landmark faces
[2016-11-30 21:29:52,912][INFO] writes 49000 landmark faces
[2016-11-30 21:29:53,145][INFO] writes 50000 landmark faces
[2016-11-30 21:29:53,356][INFO] writes 51000 landmark faces
[2016-11-30 21:29:53,605][INFO] writes 52000 landmark faces
[2016-11-30 21:29:53,836][INFO] writes 53000 landmark faces
[2016-11-30 21:29:54,067][INFO] writes 54000 landmark faces
[2016-11-30 21:29:54,281][INFO] writes 55000 landmark faces
[2016-11-30 21:29:54,532][INFO] writes 56000 landmark faces
[2016-11-30 21:29:54,783][INFO] writes 57000 landmark faces
[2016-11-30 21:29:54,994][INFO] writes 58000 landmark faces
[2016-11-30 21:29:55,213][INFO] writes 59000 landmark faces
[2016-11-30 21:29:55,458][INFO] writes 60000 landmark faces
[2016-11-30 21:29:55,690][INFO] writes 61000 landmark faces
[2016-11-30 21:29:55,922][INFO] writes 62000 landmark faces
[2016-11-30 21:29:56,188][INFO] writes 63000 landmark faces
[2016-11-30 21:29:56,433][INFO] writes 64000 landmark faces
[2016-11-30 21:29:56,652][INFO] writes 65000 landmark faces
[2016-11-30 21:29:56,880][INFO] writes 66000 landmark faces
[2016-11-30 21:29:57,138][INFO] writes 67000 landmark faces
[2016-11-30 21:29:57,367][INFO] writes 68000 landmark faces
[2016-11-30 21:29:57,608][INFO] writes 69000 landmark faces
[2016-11-30 21:29:57,865][INFO] writes 70000 landmark faces
[2016-11-30 21:29:58,069][INFO] writes 71000 landmark faces
[2016-11-30 21:29:58,285][INFO] writes 72000 landmark faces
[2016-11-30 21:29:58,487][INFO] writes 73000 landmark faces
[2016-11-30 21:29:58,710][INFO] writes 74000 landmark faces
[2016-11-30 21:29:58,879][INFO] Process-33 reads 1000
[2016-11-30 21:29:58,922][INFO] writes 75000 landmark faces
[2016-11-30 21:29:59,152][INFO] writes 76000 landmark faces
[2016-11-30 21:29:59,333][INFO] Process-34 reads 1000
[2016-11-30 21:29:59,359][INFO] writes 77000 landmark faces
[2016-11-30 21:29:59,464][INFO] Process-28 reads 1000
[2016-11-30 21:29:59,593][INFO] writes 78000 landmark faces
[2016-11-30 21:29:59,754][INFO] Process-35 reads 1000
[2016-11-30 21:29:59,820][INFO] writes 79000 landmark faces
[2016-11-30 21:30:00,051][INFO] writes 80000 landmark faces
[2016-11-30 21:30:00,161][INFO] Process-31 reads 1000
[2016-11-30 21:30:00,272][INFO] writes 81000 landmark faces
[2016-11-30 21:30:00,527][INFO] writes 82000 landmark faces
[2016-11-30 21:30:00,593][INFO] Process-30 reads 1000
[2016-11-30 21:30:00,774][INFO] writes 83000 landmark faces
[2016-11-30 21:30:01,029][INFO] writes 84000 landmark faces
[2016-11-30 21:30:01,266][INFO] writes 85000 landmark faces
[2016-11-30 21:30:01,316][INFO] Process-32 reads 1000
[2016-11-30 21:30:01,413][INFO] Process-29 reads 1000
[2016-11-30 21:30:01,509][INFO] writes 86000 landmark faces
[2016-11-30 21:30:01,753][INFO] writes 87000 landmark faces
[2016-11-30 21:30:01,994][INFO] writes 88000 landmark faces
[2016-11-30 21:30:02,225][INFO] writes 89000 landmark faces
[2016-11-30 21:30:02,435][INFO] writes 90000 landmark faces
[2016-11-30 21:30:02,668][INFO] writes 91000 landmark faces
[2016-11-30 21:30:02,902][INFO] writes 92000 landmark faces
[2016-11-30 21:30:03,114][INFO] writes 93000 landmark faces
[2016-11-30 21:30:03,313][INFO] writes 94000 landmark faces
[2016-11-30 21:30:03,531][INFO] writes 95000 landmark faces
[2016-11-30 21:30:03,779][INFO] writes 96000 landmark faces
[2016-11-30 21:30:04,008][INFO] writes 97000 landmark faces
[2016-11-30 21:30:04,283][INFO] writes 98000 landmark faces
[2016-11-30 21:30:04,550][INFO] writes 99000 landmark faces
[2016-11-30 21:30:04,743][INFO] writes 100000 landmark faces
[2016-11-30 21:30:04,988][INFO] writes 101000 landmark faces
[2016-11-30 21:30:05,233][INFO] writes 102000 landmark faces
[2016-11-30 21:30:05,467][INFO] writes 103000 landmark faces
[2016-11-30 21:30:05,705][INFO] writes 104000 landmark faces
[2016-11-30 21:30:05,953][INFO] writes 105000 landmark faces
[2016-11-30 21:30:06,199][INFO] writes 106000 landmark faces
[2016-11-30 21:30:06,475][INFO] writes 107000 landmark faces
[2016-11-30 21:30:06,701][INFO] writes 108000 landmark faces
[2016-11-30 21:30:06,919][INFO] writes 109000 landmark faces
[2016-11-30 21:30:07,145][INFO] writes 110000 landmark faces
[2016-11-30 21:30:07,390][INFO] writes 111000 landmark faces
[2016-11-30 21:30:07,640][INFO] writes 112000 landmark faces
[2016-11-30 21:30:07,879][INFO] writes 113000 landmark faces
[2016-11-30 21:30:08,118][INFO] writes 114000 landmark faces
[2016-11-30 21:30:08,351][INFO] writes 115000 landmark faces
[2016-11-30 21:30:08,627][INFO] writes 116000 landmark faces
[2016-11-30 21:30:08,991][INFO] writes 117000 landmark faces
[2016-11-30 21:30:09,258][INFO] writes 118000 landmark faces
[2016-11-30 21:30:09,541][INFO] writes 119000 landmark faces
[2016-11-30 21:30:09,760][INFO] writes 120000 landmark faces
[2016-11-30 21:30:09,990][INFO] writes 121000 landmark faces
[2016-11-30 21:30:10,268][INFO] writes 122000 landmark faces
[2016-11-30 21:30:10,511][INFO] writes 123000 landmark faces
[2016-11-30 21:30:10,735][INFO] writes 124000 landmark faces
[2016-11-30 21:30:10,969][INFO] writes 125000 landmark faces
[2016-11-30 21:30:11,195][INFO] writes 126000 landmark faces
[2016-11-30 21:30:11,415][INFO] writes 127000 landmark faces
[2016-11-30 21:30:11,623][INFO] writes 128000 landmark faces
[2016-11-30 21:30:11,821][INFO] writes 129000 landmark faces
[2016-11-30 21:30:12,058][INFO] writes 130000 landmark faces
[2016-11-30 21:30:12,314][INFO] writes 131000 landmark faces
[2016-11-30 21:30:12,615][INFO] writes 132000 landmark faces
[2016-11-30 21:30:12,849][INFO] writes 133000 landmark faces
[2016-11-30 21:30:13,075][INFO] writes 134000 landmark faces
[2016-11-30 21:30:13,330][INFO] writes 135000 landmark faces
[2016-11-30 21:30:13,585][INFO] writes 136000 landmark faces
[2016-11-30 21:30:13,831][INFO] writes 137000 landmark faces
[2016-11-30 21:30:14,034][INFO] writes 138000 landmark faces
[2016-11-30 21:30:14,256][INFO] writes 139000 landmark faces
[2016-11-30 21:30:14,480][INFO] writes 140000 landmark faces
[2016-11-30 21:30:14,716][INFO] writes 141000 landmark faces
[2016-11-30 21:30:14,966][INFO] writes 142000 landmark faces
[2016-11-30 21:30:15,182][INFO] writes 143000 landmark faces
[2016-11-30 21:30:15,433][INFO] writes 144000 landmark faces
[2016-11-30 21:30:15,726][INFO] writes 145000 landmark faces
[2016-11-30 21:30:15,966][INFO] writes 146000 landmark faces
[2016-11-30 21:30:16,258][INFO] writes 147000 landmark faces
[2016-11-30 21:30:16,464][INFO] writes 148000 landmark faces
[2016-11-30 21:30:16,626][INFO] Process-33 reads 2000
[2016-11-30 21:30:16,700][INFO] writes 149000 landmark faces
[2016-11-30 21:30:16,918][INFO] writes 150000 landmark faces
[2016-11-30 21:30:17,169][INFO] writes 151000 landmark faces
[2016-11-30 21:30:17,403][INFO] writes 152000 landmark faces
[2016-11-30 21:30:17,638][INFO] writes 153000 landmark faces
[2016-11-30 21:30:17,863][INFO] writes 154000 landmark faces
[2016-11-30 21:30:17,984][INFO] Process-35 reads 2000
[2016-11-30 21:30:18,100][INFO] writes 155000 landmark faces
[2016-11-30 21:30:18,310][INFO] writes 156000 landmark faces
[2016-11-30 21:30:18,429][INFO] Process-28 reads 2000
[2016-11-30 21:30:18,537][INFO] writes 157000 landmark faces
[2016-11-30 21:30:18,758][INFO] writes 158000 landmark faces
[2016-11-30 21:30:18,993][INFO] writes 159000 landmark faces
[2016-11-30 21:30:19,237][INFO] writes 160000 landmark faces
[2016-11-30 21:30:19,450][INFO] writes 161000 landmark faces
[2016-11-30 21:30:19,706][INFO] Process-29 reads 2000
[2016-11-30 21:30:19,739][INFO] writes 162000 landmark faces
[2016-11-30 21:30:19,803][INFO] Process-34 reads 2000
[2016-11-30 21:30:19,846][INFO] Process-31 reads 2000
[2016-11-30 21:30:20,021][INFO] writes 163000 landmark faces
[2016-11-30 21:30:20,244][INFO] writes 164000 landmark faces
[2016-11-30 21:30:20,462][INFO] Process-32 reads 2000
[2016-11-30 21:30:20,477][INFO] writes 165000 landmark faces
[2016-11-30 21:30:20,696][INFO] writes 166000 landmark faces
[2016-11-30 21:30:20,927][INFO] Process-30 reads 2000
[2016-11-30 21:30:20,938][INFO] writes 167000 landmark faces
[2016-11-30 21:30:21,153][INFO] writes 168000 landmark faces
[2016-11-30 21:30:21,419][INFO] writes 169000 landmark faces
[2016-11-30 21:30:21,671][INFO] writes 170000 landmark faces
[2016-11-30 21:30:21,882][INFO] writes 171000 landmark faces
[2016-11-30 21:30:22,097][INFO] writes 172000 landmark faces
[2016-11-30 21:30:22,331][INFO] writes 173000 landmark faces
[2016-11-30 21:30:22,561][INFO] writes 174000 landmark faces
[2016-11-30 21:30:22,775][INFO] writes 175000 landmark faces
[2016-11-30 21:30:22,989][INFO] writes 176000 landmark faces
[2016-11-30 21:30:23,217][INFO] writes 177000 landmark faces
[2016-11-30 21:30:23,450][INFO] writes 178000 landmark faces
[2016-11-30 21:30:23,664][INFO] writes 179000 landmark faces
[2016-11-30 21:30:23,893][INFO] writes 180000 landmark faces
[2016-11-30 21:30:24,098][INFO] writes 181000 landmark faces
[2016-11-30 21:30:24,319][INFO] writes 182000 landmark faces
[2016-11-30 21:30:24,550][INFO] writes 183000 landmark faces
[2016-11-30 21:30:24,755][INFO] writes 184000 landmark faces
[2016-11-30 21:30:25,004][INFO] writes 185000 landmark faces
[2016-11-30 21:30:25,255][INFO] writes 186000 landmark faces
[2016-11-30 21:30:25,478][INFO] writes 187000 landmark faces
[2016-11-30 21:30:25,698][INFO] writes 188000 landmark faces
[2016-11-30 21:30:25,913][INFO] writes 189000 landmark faces
[2016-11-30 21:30:26,162][INFO] writes 190000 landmark faces
[2016-11-30 21:30:26,407][INFO] writes 191000 landmark faces
[2016-11-30 21:30:26,663][INFO] writes 192000 landmark faces
[2016-11-30 21:30:26,880][INFO] writes 193000 landmark faces
[2016-11-30 21:30:27,160][INFO] writes 194000 landmark faces
[2016-11-30 21:30:27,388][INFO] writes 195000 landmark faces
[2016-11-30 21:30:27,630][INFO] writes 196000 landmark faces
[2016-11-30 21:30:27,858][INFO] writes 197000 landmark faces
[2016-11-30 21:30:28,064][INFO] writes 198000 landmark faces
[2016-11-30 21:30:28,268][INFO] writes 199000 landmark faces
[2016-11-30 21:30:28,496][INFO] writes 200000 landmark faces
[2016-11-30 21:30:28,717][INFO] writes 201000 landmark faces
[2016-11-30 21:30:28,952][INFO] writes 202000 landmark faces
[2016-11-30 21:30:29,219][INFO] writes 203000 landmark faces
[2016-11-30 21:30:29,427][INFO] writes 204000 landmark faces
[2016-11-30 21:30:29,650][INFO] writes 205000 landmark faces
[2016-11-30 21:30:29,868][INFO] writes 206000 landmark faces
[2016-11-30 21:30:30,101][INFO] writes 207000 landmark faces
[2016-11-30 21:30:30,368][INFO] writes 208000 landmark faces
[2016-11-30 21:30:30,573][INFO] writes 209000 landmark faces
[2016-11-30 21:30:30,810][INFO] writes 210000 landmark faces
[2016-11-30 21:30:31,033][INFO] writes 211000 landmark faces
[2016-11-30 21:30:31,258][INFO] writes 212000 landmark faces
[2016-11-30 21:30:31,474][INFO] writes 213000 landmark faces
[2016-11-30 21:30:31,699][INFO] writes 214000 landmark faces
[2016-11-30 21:30:31,913][INFO] writes 215000 landmark faces
[2016-11-30 21:30:32,151][INFO] writes 216000 landmark faces
[2016-11-30 21:30:32,366][INFO] writes 217000 landmark faces
[2016-11-30 21:30:32,592][INFO] writes 218000 landmark faces
[2016-11-30 21:30:32,807][INFO] writes 219000 landmark faces
[2016-11-30 21:30:33,046][INFO] writes 220000 landmark faces
[2016-11-30 21:30:33,265][INFO] writes 221000 landmark faces
[2016-11-30 21:30:33,468][INFO] writes 222000 landmark faces
[2016-11-30 21:30:33,677][INFO] writes 223000 landmark faces
[2016-11-30 21:30:33,916][INFO] writes 224000 landmark faces
[2016-11-30 21:30:34,135][INFO] writes 225000 landmark faces
[2016-11-30 21:30:34,358][INFO] writes 226000 landmark faces
[2016-11-30 21:30:34,611][INFO] writes 227000 landmark faces
[2016-11-30 21:30:34,659][INFO] Process-33 reads 3000
[2016-11-30 21:30:34,820][INFO] writes 228000 landmark faces
[2016-11-30 21:30:35,048][INFO] writes 229000 landmark faces
[2016-11-30 21:30:35,275][INFO] writes 230000 landmark faces
[2016-11-30 21:30:35,498][INFO] writes 231000 landmark faces
[2016-11-30 21:30:35,743][INFO] writes 232000 landmark faces
[2016-11-30 21:30:35,948][INFO] writes 233000 landmark faces
[2016-11-30 21:30:36,013][INFO] Process-35 reads 3000
[2016-11-30 21:30:36,171][INFO] writes 234000 landmark faces
[2016-11-30 21:30:36,420][INFO] writes 235000 landmark faces
[2016-11-30 21:30:36,628][INFO] writes 236000 landmark faces
[2016-11-30 21:30:36,829][INFO] writes 237000 landmark faces
[2016-11-30 21:30:37,042][INFO] writes 238000 landmark faces
[2016-11-30 21:30:37,132][INFO] Process-29 reads 3000
[2016-11-30 21:30:37,254][INFO] writes 239000 landmark faces
[2016-11-30 21:30:37,485][INFO] writes 240000 landmark faces
[2016-11-30 21:30:37,692][INFO] Process-28 reads 3000
[2016-11-30 21:30:37,696][INFO] writes 241000 landmark faces
[2016-11-30 21:30:37,909][INFO] writes 242000 landmark faces
[2016-11-30 21:30:38,145][INFO] writes 243000 landmark faces
[2016-11-30 21:30:38,187][INFO] Process-32 reads 3000
[2016-11-30 21:30:38,227][INFO] Process-34 reads 3000
[2016-11-30 21:30:38,398][INFO] writes 244000 landmark faces
[2016-11-30 21:30:38,611][INFO] Process-31 reads 3000
[2016-11-30 21:30:38,611][INFO] writes 245000 landmark faces
[2016-11-30 21:30:38,814][INFO] writes 246000 landmark faces
[2016-11-30 21:30:38,834][INFO] Process-30 reads 3000
[2016-11-30 21:30:39,044][INFO] writes 247000 landmark faces
[2016-11-30 21:30:39,257][INFO] writes 248000 landmark faces
[2016-11-30 21:30:39,449][INFO] writes 249000 landmark faces
[2016-11-30 21:30:39,655][INFO] writes 250000 landmark faces
[2016-11-30 21:30:39,867][INFO] writes 251000 landmark faces
[2016-11-30 21:30:40,077][INFO] writes 252000 landmark faces
[2016-11-30 21:30:40,297][INFO] writes 253000 landmark faces
[2016-11-30 21:30:40,499][INFO] writes 254000 landmark faces
[2016-11-30 21:30:40,746][INFO] writes 255000 landmark faces
[2016-11-30 21:30:40,984][INFO] writes 256000 landmark faces
[2016-11-30 21:30:41,241][INFO] writes 257000 landmark faces
[2016-11-30 21:30:41,446][INFO] writes 258000 landmark faces
[2016-11-30 21:30:41,695][INFO] writes 259000 landmark faces
[2016-11-30 21:30:41,938][INFO] writes 260000 landmark faces
[2016-11-30 21:30:42,139][INFO] writes 261000 landmark faces
[2016-11-30 21:30:42,348][INFO] writes 262000 landmark faces
[2016-11-30 21:30:42,592][INFO] writes 263000 landmark faces
[2016-11-30 21:30:42,826][INFO] writes 264000 landmark faces
[2016-11-30 21:30:43,052][INFO] writes 265000 landmark faces
[2016-11-30 21:30:43,279][INFO] writes 266000 landmark faces
[2016-11-30 21:30:43,540][INFO] writes 267000 landmark faces
[2016-11-30 21:30:43,776][INFO] writes 268000 landmark faces
[2016-11-30 21:30:44,032][INFO] writes 269000 landmark faces
[2016-11-30 21:30:44,297][INFO] writes 270000 landmark faces
[2016-11-30 21:30:44,510][INFO] writes 271000 landmark faces
[2016-11-30 21:30:44,793][INFO] writes 272000 landmark faces
[2016-11-30 21:30:45,027][INFO] writes 273000 landmark faces
[2016-11-30 21:30:45,303][INFO] writes 274000 landmark faces
[2016-11-30 21:30:45,509][INFO] writes 275000 landmark faces
[2016-11-30 21:30:45,780][INFO] writes 276000 landmark faces
[2016-11-30 21:30:45,990][INFO] writes 277000 landmark faces
[2016-11-30 21:30:46,200][INFO] writes 278000 landmark faces
[2016-11-30 21:30:46,406][INFO] writes 279000 landmark faces
[2016-11-30 21:30:46,637][INFO] writes 280000 landmark faces
[2016-11-30 21:30:46,890][INFO] writes 281000 landmark faces
[2016-11-30 21:30:47,103][INFO] writes 282000 landmark faces
[2016-11-30 21:30:47,311][INFO] writes 283000 landmark faces
[2016-11-30 21:30:47,493][INFO] writes 284000 landmark faces
[2016-11-30 21:30:47,727][INFO] writes 285000 landmark faces
[2016-11-30 21:30:47,942][INFO] writes 286000 landmark faces
[2016-11-30 21:30:48,183][INFO] writes 287000 landmark faces
[2016-11-30 21:30:48,382][INFO] writes 288000 landmark faces
[2016-11-30 21:30:48,608][INFO] writes 289000 landmark faces
[2016-11-30 21:30:48,829][INFO] writes 290000 landmark faces
[2016-11-30 21:30:49,063][INFO] writes 291000 landmark faces
[2016-11-30 21:30:49,264][INFO] writes 292000 landmark faces
[2016-11-30 21:30:49,479][INFO] writes 293000 landmark faces
[2016-11-30 21:30:49,707][INFO] writes 294000 landmark faces
[2016-11-30 21:30:49,920][INFO] writes 295000 landmark faces
[2016-11-30 21:30:50,140][INFO] writes 296000 landmark faces
[2016-11-30 21:30:50,344][INFO] writes 297000 landmark faces
[2016-11-30 21:30:50,553][INFO] writes 298000 landmark faces
[2016-11-30 21:30:50,772][INFO] writes 299000 landmark faces
[2016-11-30 21:30:51,005][INFO] writes 300000 landmark faces
[2016-11-30 21:30:51,255][INFO] writes 301000 landmark faces
[2016-11-30 21:30:51,460][INFO] writes 302000 landmark faces
[2016-11-30 21:30:51,663][INFO] writes 303000 landmark faces
[2016-11-30 21:30:51,865][INFO] writes 304000 landmark faces
[2016-11-30 21:30:52,083][INFO] writes 305000 landmark faces
[2016-11-30 21:30:52,313][INFO] writes 306000 landmark faces
[2016-11-30 21:30:52,433][INFO] Process-33 reads 4000
[2016-11-30 21:30:52,536][INFO] writes 307000 landmark faces
[2016-11-30 21:30:52,784][INFO] writes 308000 landmark faces
[2016-11-30 21:30:53,001][INFO] writes 309000 landmark faces
[2016-11-30 21:30:53,006][INFO] Process-35 reads 4000
[2016-11-30 21:30:53,263][INFO] writes 310000 landmark faces
[2016-11-30 21:30:53,488][INFO] writes 311000 landmark faces
[2016-11-30 21:30:53,690][INFO] writes 312000 landmark faces
[2016-11-30 21:30:53,933][INFO] writes 313000 landmark faces
[2016-11-30 21:30:54,161][INFO] writes 314000 landmark faces
[2016-11-30 21:30:54,391][INFO] writes 315000 landmark faces
[2016-11-30 21:30:54,618][INFO] writes 316000 landmark faces
[2016-11-30 21:30:54,872][INFO] writes 317000 landmark faces
[2016-11-30 21:30:55,094][INFO] writes 318000 landmark faces
[2016-11-30 21:30:55,314][INFO] writes 319000 landmark faces
[2016-11-30 21:30:55,382][INFO] Process-29 reads 4000
[2016-11-30 21:30:55,553][INFO] writes 320000 landmark faces
[2016-11-30 21:30:55,781][INFO] writes 321000 landmark faces
[2016-11-30 21:30:55,990][INFO] writes 322000 landmark faces
[2016-11-30 21:30:56,207][INFO] Process-32 reads 4000
[2016-11-30 21:30:56,228][INFO] writes 323000 landmark faces
[2016-11-30 21:30:56,431][INFO] writes 324000 landmark faces
[2016-11-30 21:30:56,642][INFO] Process-28 reads 4000
[2016-11-30 21:30:56,648][INFO] writes 325000 landmark faces
[2016-11-30 21:30:56,665][INFO] Process-31 reads 4000
[2016-11-30 21:30:56,797][INFO] Process-30 reads 4000
[2016-11-30 21:30:56,860][INFO] writes 326000 landmark faces
[2016-11-30 21:30:57,004][INFO] Process-34 reads 4000
[2016-11-30 21:30:57,077][INFO] writes 327000 landmark faces
[2016-11-30 21:30:57,288][INFO] writes 328000 landmark faces
[2016-11-30 21:30:57,518][INFO] writes 329000 landmark faces
[2016-11-30 21:30:57,753][INFO] writes 330000 landmark faces
[2016-11-30 21:30:57,974][INFO] writes 331000 landmark faces
[2016-11-30 21:30:58,197][INFO] writes 332000 landmark faces
[2016-11-30 21:30:58,421][INFO] writes 333000 landmark faces
[2016-11-30 21:30:58,636][INFO] writes 334000 landmark faces
[2016-11-30 21:30:58,882][INFO] writes 335000 landmark faces
[2016-11-30 21:30:59,086][INFO] writes 336000 landmark faces
[2016-11-30 21:30:59,307][INFO] writes 337000 landmark faces
[2016-11-30 21:30:59,550][INFO] writes 338000 landmark faces
[2016-11-30 21:30:59,798][INFO] writes 339000 landmark faces
[2016-11-30 21:30:59,989][INFO] writes 340000 landmark faces
[2016-11-30 21:31:00,201][INFO] writes 341000 landmark faces
[2016-11-30 21:31:00,436][INFO] writes 342000 landmark faces
[2016-11-30 21:31:00,671][INFO] writes 343000 landmark faces
[2016-11-30 21:31:00,876][INFO] writes 344000 landmark faces
[2016-11-30 21:31:01,106][INFO] writes 345000 landmark faces
[2016-11-30 21:31:01,322][INFO] writes 346000 landmark faces
[2016-11-30 21:31:01,530][INFO] writes 347000 landmark faces
[2016-11-30 21:31:01,766][INFO] writes 348000 landmark faces
[2016-11-30 21:31:02,032][INFO] writes 349000 landmark faces
[2016-11-30 21:31:02,260][INFO] writes 350000 landmark faces
[2016-11-30 21:31:02,511][INFO] writes 351000 landmark faces
[2016-11-30 21:31:02,719][INFO] writes 352000 landmark faces
[2016-11-30 21:31:02,967][INFO] writes 353000 landmark faces
[2016-11-30 21:31:03,208][INFO] writes 354000 landmark faces
[2016-11-30 21:31:03,411][INFO] writes 355000 landmark faces
[2016-11-30 21:31:03,640][INFO] writes 356000 landmark faces
[2016-11-30 21:31:03,874][INFO] writes 357000 landmark faces
[2016-11-30 21:31:04,095][INFO] writes 358000 landmark faces
[2016-11-30 21:31:04,320][INFO] writes 359000 landmark faces
[2016-11-30 21:31:04,544][INFO] writes 360000 landmark faces
[2016-11-30 21:31:04,758][INFO] writes 361000 landmark faces
[2016-11-30 21:31:04,979][INFO] writes 362000 landmark faces
[2016-11-30 21:31:05,218][INFO] writes 363000 landmark faces
[2016-11-30 21:31:05,435][INFO] writes 364000 landmark faces
[2016-11-30 21:31:05,649][INFO] writes 365000 landmark faces
[2016-11-30 21:31:05,889][INFO] writes 366000 landmark faces
[2016-11-30 21:31:06,103][INFO] writes 367000 landmark faces
[2016-11-30 21:31:06,304][INFO] writes 368000 landmark faces
[2016-11-30 21:31:06,574][INFO] writes 369000 landmark faces
[2016-11-30 21:31:06,777][INFO] writes 370000 landmark faces
[2016-11-30 21:31:07,003][INFO] writes 371000 landmark faces
[2016-11-30 21:31:07,215][INFO] writes 372000 landmark faces
[2016-11-30 21:31:07,415][INFO] writes 373000 landmark faces
[2016-11-30 21:31:07,625][INFO] writes 374000 landmark faces
[2016-11-30 21:31:07,863][INFO] writes 375000 landmark faces
[2016-11-30 21:31:08,131][INFO] writes 376000 landmark faces
[2016-11-30 21:31:08,382][INFO] writes 377000 landmark faces
[2016-11-30 21:31:08,620][INFO] writes 378000 landmark faces
[2016-11-30 21:31:08,830][INFO] writes 379000 landmark faces
[2016-11-30 21:31:09,105][INFO] writes 380000 landmark faces
[2016-11-30 21:31:09,317][INFO] writes 381000 landmark faces
[2016-11-30 21:31:09,547][INFO] writes 382000 landmark faces
[2016-11-30 21:31:09,792][INFO] writes 383000 landmark faces
[2016-11-30 21:31:09,862][INFO] Process-35 reads 5000
[2016-11-30 21:31:10,045][INFO] writes 384000 landmark faces
[2016-11-30 21:31:10,280][INFO] writes 385000 landmark faces
[2016-11-30 21:31:10,488][INFO] writes 386000 landmark faces
[2016-11-30 21:31:10,728][INFO] writes 387000 landmark faces
[2016-11-30 21:31:10,950][INFO] writes 388000 landmark faces
[2016-11-30 21:31:11,214][INFO] writes 389000 landmark faces
[2016-11-30 21:31:11,489][INFO] writes 390000 landmark faces
[2016-11-30 21:31:11,728][INFO] writes 391000 landmark faces
[2016-11-30 21:31:12,013][INFO] writes 392000 landmark faces
[2016-11-30 21:31:12,206][INFO] Process-33 reads 5000
[2016-11-30 21:31:12,256][INFO] writes 393000 landmark faces
[2016-11-30 21:31:12,505][INFO] writes 394000 landmark faces
[2016-11-30 21:31:12,736][INFO] Process-32 reads 5000
[2016-11-30 21:31:12,747][INFO] writes 395000 landmark faces
[2016-11-30 21:31:12,967][INFO] writes 396000 landmark faces
[2016-11-30 21:31:13,263][INFO] writes 397000 landmark faces
[2016-11-30 21:31:13,549][INFO] writes 398000 landmark faces
[2016-11-30 21:31:13,826][INFO] writes 399000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:31:13,891][INFO] Process-29 reads 5000
[2016-11-30 21:31:14,184][INFO] writes 400000 landmark faces
[2016-11-30 21:31:14,356][INFO] Process-30 reads 5000
[2016-11-30 21:31:14,427][INFO] Process-31 reads 5000
[2016-11-30 21:31:14,554][INFO] writes 401000 landmark faces
[2016-11-30 21:31:14,938][INFO] writes 402000 landmark faces
[2016-11-30 21:31:15,232][INFO] Process-28 reads 5000
[2016-11-30 21:31:15,305][INFO] writes 403000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:31:15,911][INFO] writes 404000 landmark faces
[2016-11-30 21:31:16,466][INFO] Process-34 reads 5000
[2016-11-30 21:31:17,145][INFO] writes 405000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:31:19,058][INFO] Finish
Train pNet
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 21:31:21.937991 11185 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1557
test_interval: 6278
base_lr: 0.05
display: 500
max_iter: 125560
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 31390
snapshot: 6278
snapshot_prefix: "tmp/pnet"
solver_mode: GPU
net: "proto/p_train_val.prototxt"
test_initialization: false
average_loss: 500
I1130 21:31:21.938148 11185 solver.cpp:91] Creating training net from net file: proto/p_train_val.prototxt
I1130 21:31:21.938580 11185 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1130 21:31:21.938699 11185 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "bbox_target"
  top: "landmark_target"
  top: "label"
  include {
    phase: TRAIN
  }
  python_param {
    module: "layers.data_layer"
    layer: "FaceDataLayer"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "JfdaLoss"
  bottom: "score"
  bottom: "bbox_pred"
  bottom: "landmark_pred"
  bottom: "bbox_target"
  bottom: "landmark_target"
  bottom: "label"
  top: "face_cls_loss"
  top: "bbox_reg_loss"
  top: "landmark_reg_loss"
  top: "face_cls_neg_acc"
  top: "face_cls_pos_acc"
  loss_weight: 1
  loss_weight: 0.5
  loss_weight: 0.5
  loss_weight: 0
  loss_weight: 0
  jfda_loss_param {
    drop_loss_rate: 0.3
  }
}
I1130 21:31:21.938796 11185 layer_factory.hpp:77] Creating layer data
I1130 21:31:21.939307 11185 net.cpp:100] Creating Layer data
I1130 21:31:21.939329 11185 net.cpp:408] data -> data
I1130 21:31:21.939347 11185 net.cpp:408] data -> bbox_target
I1130 21:31:21.939354 11185 net.cpp:408] data -> landmark_target
I1130 21:31:21.939362 11185 net.cpp:408] data -> label
I1130 21:31:21.958135 11185 net.cpp:150] Setting up data
I1130 21:31:21.958159 11185 net.cpp:157] Top shape: 4 3 12 12 (1728)
I1130 21:31:21.958165 11185 net.cpp:157] Top shape: 4 4 (16)
I1130 21:31:21.958170 11185 net.cpp:157] Top shape: 4 10 (40)
I1130 21:31:21.958174 11185 net.cpp:157] Top shape: 4 (4)
I1130 21:31:21.958178 11185 net.cpp:165] Memory required for data: 7152
I1130 21:31:21.958183 11185 layer_factory.hpp:77] Creating layer conv1
I1130 21:31:21.958199 11185 net.cpp:100] Creating Layer conv1
I1130 21:31:21.958204 11185 net.cpp:434] conv1 <- data
I1130 21:31:21.958211 11185 net.cpp:408] conv1 -> conv1
I1130 21:31:22.218758 11185 net.cpp:150] Setting up conv1
I1130 21:31:22.218806 11185 net.cpp:157] Top shape: 4 10 10 10 (4000)
I1130 21:31:22.218809 11185 net.cpp:165] Memory required for data: 23152
I1130 21:31:22.218832 11185 layer_factory.hpp:77] Creating layer prelu1
I1130 21:31:22.218847 11185 net.cpp:100] Creating Layer prelu1
I1130 21:31:22.218852 11185 net.cpp:434] prelu1 <- conv1
I1130 21:31:22.218858 11185 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 21:31:22.218945 11185 net.cpp:150] Setting up prelu1
I1130 21:31:22.218950 11185 net.cpp:157] Top shape: 4 10 10 10 (4000)
I1130 21:31:22.218953 11185 net.cpp:165] Memory required for data: 39152
I1130 21:31:22.218960 11185 layer_factory.hpp:77] Creating layer pool1
I1130 21:31:22.218967 11185 net.cpp:100] Creating Layer pool1
I1130 21:31:22.218971 11185 net.cpp:434] pool1 <- conv1
I1130 21:31:22.218976 11185 net.cpp:408] pool1 -> pool1
I1130 21:31:22.219005 11185 net.cpp:150] Setting up pool1
I1130 21:31:22.219018 11185 net.cpp:157] Top shape: 4 10 5 5 (1000)
I1130 21:31:22.219022 11185 net.cpp:165] Memory required for data: 43152
I1130 21:31:22.219024 11185 layer_factory.hpp:77] Creating layer conv2
I1130 21:31:22.219035 11185 net.cpp:100] Creating Layer conv2
I1130 21:31:22.219038 11185 net.cpp:434] conv2 <- pool1
I1130 21:31:22.219043 11185 net.cpp:408] conv2 -> conv2
I1130 21:31:22.220912 11185 net.cpp:150] Setting up conv2
I1130 21:31:22.220927 11185 net.cpp:157] Top shape: 4 16 3 3 (576)
I1130 21:31:22.220932 11185 net.cpp:165] Memory required for data: 45456
I1130 21:31:22.220938 11185 layer_factory.hpp:77] Creating layer prelu2
I1130 21:31:22.220947 11185 net.cpp:100] Creating Layer prelu2
I1130 21:31:22.220950 11185 net.cpp:434] prelu2 <- conv2
I1130 21:31:22.220954 11185 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 21:31:22.221027 11185 net.cpp:150] Setting up prelu2
I1130 21:31:22.221034 11185 net.cpp:157] Top shape: 4 16 3 3 (576)
I1130 21:31:22.221035 11185 net.cpp:165] Memory required for data: 47760
I1130 21:31:22.221040 11185 layer_factory.hpp:77] Creating layer conv3
I1130 21:31:22.221050 11185 net.cpp:100] Creating Layer conv3
I1130 21:31:22.221052 11185 net.cpp:434] conv3 <- conv2
I1130 21:31:22.221060 11185 net.cpp:408] conv3 -> conv3
I1130 21:31:22.222937 11185 net.cpp:150] Setting up conv3
I1130 21:31:22.222952 11185 net.cpp:157] Top shape: 4 32 1 1 (128)
I1130 21:31:22.222956 11185 net.cpp:165] Memory required for data: 48272
I1130 21:31:22.222962 11185 layer_factory.hpp:77] Creating layer prelu3
I1130 21:31:22.222967 11185 net.cpp:100] Creating Layer prelu3
I1130 21:31:22.222973 11185 net.cpp:434] prelu3 <- conv3
I1130 21:31:22.222978 11185 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 21:31:22.223052 11185 net.cpp:150] Setting up prelu3
I1130 21:31:22.223057 11185 net.cpp:157] Top shape: 4 32 1 1 (128)
I1130 21:31:22.223060 11185 net.cpp:165] Memory required for data: 48784
I1130 21:31:22.223070 11185 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 21:31:22.223085 11185 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 21:31:22.223089 11185 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 21:31:22.223093 11185 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 21:31:22.223099 11185 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 21:31:22.223104 11185 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 21:31:22.223148 11185 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 21:31:22.223155 11185 net.cpp:157] Top shape: 4 32 1 1 (128)
I1130 21:31:22.223158 11185 net.cpp:157] Top shape: 4 32 1 1 (128)
I1130 21:31:22.223161 11185 net.cpp:157] Top shape: 4 32 1 1 (128)
I1130 21:31:22.223163 11185 net.cpp:165] Memory required for data: 50320
I1130 21:31:22.223166 11185 layer_factory.hpp:77] Creating layer score
I1130 21:31:22.223176 11185 net.cpp:100] Creating Layer score
I1130 21:31:22.223179 11185 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 21:31:22.223186 11185 net.cpp:408] score -> score
I1130 21:31:22.224031 11185 net.cpp:150] Setting up score
I1130 21:31:22.224042 11185 net.cpp:157] Top shape: 4 2 1 1 (8)
I1130 21:31:22.224047 11185 net.cpp:165] Memory required for data: 50352
I1130 21:31:22.224053 11185 layer_factory.hpp:77] Creating layer bbox_pred
I1130 21:31:22.224062 11185 net.cpp:100] Creating Layer bbox_pred
I1130 21:31:22.224066 11185 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 21:31:22.224081 11185 net.cpp:408] bbox_pred -> bbox_pred
I1130 21:31:22.224936 11185 net.cpp:150] Setting up bbox_pred
I1130 21:31:22.224947 11185 net.cpp:157] Top shape: 4 4 1 1 (16)
I1130 21:31:22.224951 11185 net.cpp:165] Memory required for data: 50416
I1130 21:31:22.224956 11185 layer_factory.hpp:77] Creating layer landmark_pred
I1130 21:31:22.224967 11185 net.cpp:100] Creating Layer landmark_pred
I1130 21:31:22.224972 11185 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 21:31:22.224978 11185 net.cpp:408] landmark_pred -> landmark_pred
I1130 21:31:22.225836 11185 net.cpp:150] Setting up landmark_pred
I1130 21:31:22.225853 11185 net.cpp:157] Top shape: 4 10 1 1 (40)
I1130 21:31:22.225857 11185 net.cpp:165] Memory required for data: 50576
I1130 21:31:22.225863 11185 layer_factory.hpp:77] Creating layer loss
I1130 21:31:22.225878 11185 net.cpp:100] Creating Layer loss
I1130 21:31:22.225881 11185 net.cpp:434] loss <- score
I1130 21:31:22.225885 11185 net.cpp:434] loss <- bbox_pred
I1130 21:31:22.225889 11185 net.cpp:434] loss <- landmark_pred
I1130 21:31:22.225893 11185 net.cpp:434] loss <- bbox_target
I1130 21:31:22.225894 11185 net.cpp:434] loss <- landmark_target
I1130 21:31:22.225898 11185 net.cpp:434] loss <- label
I1130 21:31:22.225904 11185 net.cpp:408] loss -> face_cls_loss
I1130 21:31:22.225911 11185 net.cpp:408] loss -> bbox_reg_loss
I1130 21:31:22.225917 11185 net.cpp:408] loss -> landmark_reg_loss
I1130 21:31:22.225924 11185 net.cpp:408] loss -> face_cls_neg_acc
I1130 21:31:22.225929 11185 net.cpp:408] loss -> face_cls_pos_acc
I1130 21:31:22.226012 11185 net.cpp:150] Setting up loss
I1130 21:31:22.226018 11185 net.cpp:157] Top shape: (1)
I1130 21:31:22.226022 11185 net.cpp:160]     with loss weight 1
I1130 21:31:22.226035 11185 net.cpp:157] Top shape: (1)
I1130 21:31:22.226038 11185 net.cpp:160]     with loss weight 0.5
I1130 21:31:22.226042 11185 net.cpp:157] Top shape: (1)
I1130 21:31:22.226045 11185 net.cpp:160]     with loss weight 0.5
I1130 21:31:22.226048 11185 net.cpp:157] Top shape: (1)
I1130 21:31:22.226052 11185 net.cpp:157] Top shape: (1)
I1130 21:31:22.226053 11185 net.cpp:165] Memory required for data: 50596
I1130 21:31:22.226056 11185 net.cpp:226] loss needs backward computation.
I1130 21:31:22.226060 11185 net.cpp:226] landmark_pred needs backward computation.
I1130 21:31:22.226063 11185 net.cpp:226] bbox_pred needs backward computation.
I1130 21:31:22.226071 11185 net.cpp:226] score needs backward computation.
I1130 21:31:22.226076 11185 net.cpp:226] conv3_prelu3_0_split needs backward computation.
I1130 21:31:22.226079 11185 net.cpp:226] prelu3 needs backward computation.
I1130 21:31:22.226083 11185 net.cpp:226] conv3 needs backward computation.
I1130 21:31:22.226084 11185 net.cpp:226] prelu2 needs backward computation.
I1130 21:31:22.226088 11185 net.cpp:226] conv2 needs backward computation.
I1130 21:31:22.226089 11185 net.cpp:226] pool1 needs backward computation.
I1130 21:31:22.226092 11185 net.cpp:226] prelu1 needs backward computation.
I1130 21:31:22.226094 11185 net.cpp:226] conv1 needs backward computation.
I1130 21:31:22.226099 11185 net.cpp:228] data does not need backward computation.
I1130 21:31:22.226100 11185 net.cpp:270] This network produces output bbox_reg_loss
I1130 21:31:22.226104 11185 net.cpp:270] This network produces output face_cls_loss
I1130 21:31:22.226106 11185 net.cpp:270] This network produces output face_cls_neg_acc
I1130 21:31:22.226109 11185 net.cpp:270] This network produces output face_cls_pos_acc
I1130 21:31:22.226111 11185 net.cpp:270] This network produces output landmark_reg_loss
I1130 21:31:22.226122 11185 net.cpp:283] Network initialization done.
I1130 21:31:22.226467 11185 solver.cpp:181] Creating test net (#0) specified by net file: proto/p_train_val.prototxt
I1130 21:31:22.226495 11185 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1130 21:31:22.226598 11185 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "bbox_target"
  top: "landmark_target"
  top: "label"
  include {
    phase: TEST
  }
  python_param {
    module: "layers.data_layer"
    layer: "FaceDataLayer"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "JfdaLoss"
  bottom: "score"
  bottom: "bbox_pred"
  bottom: "landmark_pred"
  bottom: "bbox_target"
  bottom: "landmark_target"
  bottom: "label"
  top: "face_cls_loss"
  top: "bbox_reg_loss"
  top: "landmark_reg_loss"
  top: "face_cls_neg_acc"
  top: "face_cls_pos_acc"
  loss_weight: 1
  loss_weight: 0.5
  loss_weight: 0.5
  loss_weight: 0
  loss_weight: 0
  jfda_loss_param {
    drop_loss_rate: 0.3
  }
}
I1130 21:31:22.226665 11185 layer_factory.hpp:77] Creating layer data
I1130 21:31:22.226730 11185 net.cpp:100] Creating Layer data
I1130 21:31:22.226737 11185 net.cpp:408] data -> data
I1130 21:31:22.226743 11185 net.cpp:408] data -> bbox_target
I1130 21:31:22.226748 11185 net.cpp:408] data -> landmark_target
I1130 21:31:22.226752 11185 net.cpp:408] data -> label
I1130 21:31:22.227053 11185 net.cpp:150] Setting up data
I1130 21:31:22.227062 11185 net.cpp:157] Top shape: 4 3 12 12 (1728)
I1130 21:31:22.227071 11185 net.cpp:157] Top shape: 4 4 (16)
I1130 21:31:22.227077 11185 net.cpp:157] Top shape: 4 10 (40)
I1130 21:31:22.227080 11185 net.cpp:157] Top shape: 4 (4)
I1130 21:31:22.227083 11185 net.cpp:165] Memory required for data: 7152
I1130 21:31:22.227087 11185 layer_factory.hpp:77] Creating layer conv1
I1130 21:31:22.227097 11185 net.cpp:100] Creating Layer conv1
I1130 21:31:22.227102 11185 net.cpp:434] conv1 <- data
I1130 21:31:22.227107 11185 net.cpp:408] conv1 -> conv1
I1130 21:31:22.227736 11185 net.cpp:150] Setting up conv1
I1130 21:31:22.227747 11185 net.cpp:157] Top shape: 4 10 10 10 (4000)
I1130 21:31:22.227751 11185 net.cpp:165] Memory required for data: 23152
I1130 21:31:22.227758 11185 layer_factory.hpp:77] Creating layer prelu1
I1130 21:31:22.227763 11185 net.cpp:100] Creating Layer prelu1
I1130 21:31:22.227766 11185 net.cpp:434] prelu1 <- conv1
I1130 21:31:22.227772 11185 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 21:31:22.227850 11185 net.cpp:150] Setting up prelu1
I1130 21:31:22.227857 11185 net.cpp:157] Top shape: 4 10 10 10 (4000)
I1130 21:31:22.227864 11185 net.cpp:165] Memory required for data: 39152
I1130 21:31:22.227869 11185 layer_factory.hpp:77] Creating layer pool1
I1130 21:31:22.227874 11185 net.cpp:100] Creating Layer pool1
I1130 21:31:22.227876 11185 net.cpp:434] pool1 <- conv1
I1130 21:31:22.227882 11185 net.cpp:408] pool1 -> pool1
I1130 21:31:22.227912 11185 net.cpp:150] Setting up pool1
I1130 21:31:22.227918 11185 net.cpp:157] Top shape: 4 10 5 5 (1000)
I1130 21:31:22.227921 11185 net.cpp:165] Memory required for data: 43152
I1130 21:31:22.227923 11185 layer_factory.hpp:77] Creating layer conv2
I1130 21:31:22.227933 11185 net.cpp:100] Creating Layer conv2
I1130 21:31:22.227936 11185 net.cpp:434] conv2 <- pool1
I1130 21:31:22.227941 11185 net.cpp:408] conv2 -> conv2
I1130 21:31:22.228792 11185 net.cpp:150] Setting up conv2
I1130 21:31:22.228808 11185 net.cpp:157] Top shape: 4 16 3 3 (576)
I1130 21:31:22.228812 11185 net.cpp:165] Memory required for data: 45456
I1130 21:31:22.228821 11185 layer_factory.hpp:77] Creating layer prelu2
I1130 21:31:22.228826 11185 net.cpp:100] Creating Layer prelu2
I1130 21:31:22.228828 11185 net.cpp:434] prelu2 <- conv2
I1130 21:31:22.228832 11185 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 21:31:22.228907 11185 net.cpp:150] Setting up prelu2
I1130 21:31:22.228915 11185 net.cpp:157] Top shape: 4 16 3 3 (576)
I1130 21:31:22.228919 11185 net.cpp:165] Memory required for data: 47760
I1130 21:31:22.228922 11185 layer_factory.hpp:77] Creating layer conv3
I1130 21:31:22.228930 11185 net.cpp:100] Creating Layer conv3
I1130 21:31:22.228934 11185 net.cpp:434] conv3 <- conv2
I1130 21:31:22.228938 11185 net.cpp:408] conv3 -> conv3
I1130 21:31:22.229809 11185 net.cpp:150] Setting up conv3
I1130 21:31:22.229822 11185 net.cpp:157] Top shape: 4 32 1 1 (128)
I1130 21:31:22.229826 11185 net.cpp:165] Memory required for data: 48272
I1130 21:31:22.229832 11185 layer_factory.hpp:77] Creating layer prelu3
I1130 21:31:22.229837 11185 net.cpp:100] Creating Layer prelu3
I1130 21:31:22.229840 11185 net.cpp:434] prelu3 <- conv3
I1130 21:31:22.229845 11185 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 21:31:22.229920 11185 net.cpp:150] Setting up prelu3
I1130 21:31:22.229926 11185 net.cpp:157] Top shape: 4 32 1 1 (128)
I1130 21:31:22.229929 11185 net.cpp:165] Memory required for data: 48784
I1130 21:31:22.229935 11185 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 21:31:22.229940 11185 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 21:31:22.229943 11185 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 21:31:22.229953 11185 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 21:31:22.229959 11185 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 21:31:22.229964 11185 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 21:31:22.230001 11185 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 21:31:22.230006 11185 net.cpp:157] Top shape: 4 32 1 1 (128)
I1130 21:31:22.230010 11185 net.cpp:157] Top shape: 4 32 1 1 (128)
I1130 21:31:22.230012 11185 net.cpp:157] Top shape: 4 32 1 1 (128)
I1130 21:31:22.230015 11185 net.cpp:165] Memory required for data: 50320
I1130 21:31:22.230017 11185 layer_factory.hpp:77] Creating layer score
I1130 21:31:22.230026 11185 net.cpp:100] Creating Layer score
I1130 21:31:22.230029 11185 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 21:31:22.230036 11185 net.cpp:408] score -> score
I1130 21:31:22.230885 11185 net.cpp:150] Setting up score
I1130 21:31:22.230900 11185 net.cpp:157] Top shape: 4 2 1 1 (8)
I1130 21:31:22.230903 11185 net.cpp:165] Memory required for data: 50352
I1130 21:31:22.230908 11185 layer_factory.hpp:77] Creating layer bbox_pred
I1130 21:31:22.230919 11185 net.cpp:100] Creating Layer bbox_pred
I1130 21:31:22.230924 11185 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 21:31:22.230929 11185 net.cpp:408] bbox_pred -> bbox_pred
I1130 21:31:22.231781 11185 net.cpp:150] Setting up bbox_pred
I1130 21:31:22.231796 11185 net.cpp:157] Top shape: 4 4 1 1 (16)
I1130 21:31:22.231798 11185 net.cpp:165] Memory required for data: 50416
I1130 21:31:22.231807 11185 layer_factory.hpp:77] Creating layer landmark_pred
I1130 21:31:22.231817 11185 net.cpp:100] Creating Layer landmark_pred
I1130 21:31:22.231822 11185 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 21:31:22.231828 11185 net.cpp:408] landmark_pred -> landmark_pred
I1130 21:31:22.232687 11185 net.cpp:150] Setting up landmark_pred
I1130 21:31:22.232702 11185 net.cpp:157] Top shape: 4 10 1 1 (40)
I1130 21:31:22.232705 11185 net.cpp:165] Memory required for data: 50576
I1130 21:31:22.232712 11185 layer_factory.hpp:77] Creating layer loss
I1130 21:31:22.232719 11185 net.cpp:100] Creating Layer loss
I1130 21:31:22.232723 11185 net.cpp:434] loss <- score
I1130 21:31:22.232728 11185 net.cpp:434] loss <- bbox_pred
I1130 21:31:22.232730 11185 net.cpp:434] loss <- landmark_pred
I1130 21:31:22.232733 11185 net.cpp:434] loss <- bbox_target
I1130 21:31:22.232736 11185 net.cpp:434] loss <- landmark_target
I1130 21:31:22.232738 11185 net.cpp:434] loss <- label
I1130 21:31:22.232744 11185 net.cpp:408] loss -> face_cls_loss
I1130 21:31:22.232753 11185 net.cpp:408] loss -> bbox_reg_loss
I1130 21:31:22.232758 11185 net.cpp:408] loss -> landmark_reg_loss
I1130 21:31:22.232764 11185 net.cpp:408] loss -> face_cls_neg_acc
I1130 21:31:22.232769 11185 net.cpp:408] loss -> face_cls_pos_acc
I1130 21:31:22.232847 11185 net.cpp:150] Setting up loss
I1130 21:31:22.232854 11185 net.cpp:157] Top shape: (1)
I1130 21:31:22.232857 11185 net.cpp:160]     with loss weight 1
I1130 21:31:22.232862 11185 net.cpp:157] Top shape: (1)
I1130 21:31:22.232866 11185 net.cpp:160]     with loss weight 0.5
I1130 21:31:22.232869 11185 net.cpp:157] Top shape: (1)
I1130 21:31:22.232872 11185 net.cpp:160]     with loss weight 0.5
I1130 21:31:22.232874 11185 net.cpp:157] Top shape: (1)
I1130 21:31:22.232877 11185 net.cpp:157] Top shape: (1)
I1130 21:31:22.232880 11185 net.cpp:165] Memory required for data: 50596
I1130 21:31:22.232882 11185 net.cpp:226] loss needs backward computation.
I1130 21:31:22.232887 11185 net.cpp:226] landmark_pred needs backward computation.
I1130 21:31:22.232889 11185 net.cpp:226] bbox_pred needs backward computation.
I1130 21:31:22.232892 11185 net.cpp:226] score needs backward computation.
I1130 21:31:22.232895 11185 net.cpp:226] conv3_prelu3_0_split needs backward computation.
I1130 21:31:22.232898 11185 net.cpp:226] prelu3 needs backward computation.
I1130 21:31:22.232900 11185 net.cpp:226] conv3 needs backward computation.
I1130 21:31:22.232903 11185 net.cpp:226] prelu2 needs backward computation.
I1130 21:31:22.232905 11185 net.cpp:226] conv2 needs backward computation.
I1130 21:31:22.232908 11185 net.cpp:226] pool1 needs backward computation.
I1130 21:31:22.232910 11185 net.cpp:226] prelu1 needs backward computation.
I1130 21:31:22.232913 11185 net.cpp:226] conv1 needs backward computation.
I1130 21:31:22.232916 11185 net.cpp:228] data does not need backward computation.
I1130 21:31:22.232918 11185 net.cpp:270] This network produces output bbox_reg_loss
I1130 21:31:22.232921 11185 net.cpp:270] This network produces output face_cls_loss
I1130 21:31:22.232924 11185 net.cpp:270] This network produces output face_cls_neg_acc
I1130 21:31:22.232928 11185 net.cpp:270] This network produces output face_cls_pos_acc
I1130 21:31:22.232929 11185 net.cpp:270] This network produces output landmark_reg_loss
I1130 21:31:22.232940 11185 net.cpp:283] Network initialization done.
I1130 21:31:22.232975 11185 solver.cpp:60] Solver scaffolding done.
Namespace(epoch=20, gpu=0, lr=0.05, lrp=5, lrw=0.1, net='p', size=128, snapshot=None)
I1130 21:31:22.249701 11185 solver.cpp:279] Solving pNet
I1130 21:31:22.249747 11185 solver.cpp:280] Learning Rate Policy: step
I1130 21:31:22.283428 11185 solver.cpp:228] Iteration 0, loss = 0.593411
I1130 21:31:22.283479 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0405373 (* 0.5 = 0.0202686 loss)
I1130 21:31:22.283486 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.366912 (* 1 = 0.366912 loss)
I1130 21:31:22.283490 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.921875
I1130 21:31:22.283501 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.0390625
I1130 21:31:22.283506 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.412462 (* 0.5 = 0.206231 loss)
I1130 21:31:22.283514 11185 sgd_solver.cpp:106] Iteration 0, lr = 0.05
I1130 21:31:26.248296 11185 solver.cpp:228] Iteration 500, loss = 0.224703
I1130 21:31:26.248359 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0168976 (* 0.5 = 0.00844882 loss)
I1130 21:31:26.248366 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.180251 (* 1 = 0.180251 loss)
I1130 21:31:26.248370 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:31:26.248374 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.546875
I1130 21:31:26.248379 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0113309 (* 0.5 = 0.00566547 loss)
I1130 21:31:26.248383 11185 sgd_solver.cpp:106] Iteration 500, lr = 0.05
I1130 21:31:30.218179 11185 solver.cpp:228] Iteration 1000, loss = 0.148481
I1130 21:31:30.218252 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.016686 (* 0.5 = 0.00834301 loss)
I1130 21:31:30.218260 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.132141 (* 1 = 0.132141 loss)
I1130 21:31:30.218263 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.953125
I1130 21:31:30.218267 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.773438
I1130 21:31:30.218271 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00921911 (* 0.5 = 0.00460955 loss)
I1130 21:31:30.218276 11185 sgd_solver.cpp:106] Iteration 1000, lr = 0.05
I1130 21:31:34.123747 11185 solver.cpp:228] Iteration 1500, loss = 0.127252
I1130 21:31:34.123806 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0130607 (* 0.5 = 0.00653034 loss)
I1130 21:31:34.123813 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0774364 (* 1 = 0.0774364 loss)
I1130 21:31:34.123817 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:31:34.123821 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.898438
I1130 21:31:34.123826 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00738402 (* 0.5 = 0.00369201 loss)
I1130 21:31:34.123831 11185 sgd_solver.cpp:106] Iteration 1500, lr = 0.05
I1130 21:31:38.019232 11185 solver.cpp:228] Iteration 2000, loss = 0.128845
I1130 21:31:38.019286 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.014381 (* 0.5 = 0.00719049 loss)
I1130 21:31:38.019294 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.103816 (* 1 = 0.103816 loss)
I1130 21:31:38.019297 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:31:38.019301 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:31:38.019306 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00889869 (* 0.5 = 0.00444935 loss)
I1130 21:31:38.019310 11185 sgd_solver.cpp:106] Iteration 2000, lr = 0.05
I1130 21:31:41.926326 11185 solver.cpp:228] Iteration 2500, loss = 0.128931
I1130 21:31:41.926400 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0152984 (* 0.5 = 0.00764919 loss)
I1130 21:31:41.926407 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.107673 (* 1 = 0.107673 loss)
I1130 21:31:41.926411 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.955729
I1130 21:31:41.926415 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 21:31:41.926420 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00577411 (* 0.5 = 0.00288706 loss)
I1130 21:31:41.926424 11185 sgd_solver.cpp:106] Iteration 2500, lr = 0.05
I1130 21:31:45.835391 11185 solver.cpp:228] Iteration 3000, loss = 0.11611
I1130 21:31:45.835445 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0150582 (* 0.5 = 0.00752911 loss)
I1130 21:31:45.835453 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0902727 (* 1 = 0.0902727 loss)
I1130 21:31:45.835474 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.971354
I1130 21:31:45.835479 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.867188
I1130 21:31:45.835482 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00592272 (* 0.5 = 0.00296136 loss)
I1130 21:31:45.835487 11185 sgd_solver.cpp:106] Iteration 3000, lr = 0.05
I1130 21:31:49.758929 11185 solver.cpp:228] Iteration 3500, loss = 0.118091
I1130 21:31:49.758985 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0157017 (* 0.5 = 0.00785087 loss)
I1130 21:31:49.758991 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.104884 (* 1 = 0.104884 loss)
I1130 21:31:49.758996 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.955729
I1130 21:31:49.758999 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 21:31:49.759004 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00468012 (* 0.5 = 0.00234006 loss)
I1130 21:31:49.759008 11185 sgd_solver.cpp:106] Iteration 3500, lr = 0.05
I1130 21:31:53.664474 11185 solver.cpp:228] Iteration 4000, loss = 0.130842
I1130 21:31:53.664532 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0146941 (* 0.5 = 0.00734704 loss)
I1130 21:31:53.664539 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.106845 (* 1 = 0.106845 loss)
I1130 21:31:53.664543 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:31:53.664547 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 21:31:53.664552 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0060041 (* 0.5 = 0.00300205 loss)
I1130 21:31:53.664556 11185 sgd_solver.cpp:106] Iteration 4000, lr = 0.05
I1130 21:31:57.555358 11185 solver.cpp:228] Iteration 4500, loss = 0.137435
I1130 21:31:57.555408 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0140208 (* 0.5 = 0.00701042 loss)
I1130 21:31:57.555413 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0871385 (* 1 = 0.0871385 loss)
I1130 21:31:57.555418 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.955729
I1130 21:31:57.555421 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.898438
I1130 21:31:57.555426 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00519652 (* 0.5 = 0.00259826 loss)
I1130 21:31:57.555430 11185 sgd_solver.cpp:106] Iteration 4500, lr = 0.05
I1130 21:32:01.393731 11185 solver.cpp:228] Iteration 5000, loss = 0.119722
I1130 21:32:01.393808 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0147812 (* 0.5 = 0.0073906 loss)
I1130 21:32:01.393816 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.14625 (* 1 = 0.14625 loss)
I1130 21:32:01.393821 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:32:01.393824 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.757812
I1130 21:32:01.393828 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00624316 (* 0.5 = 0.00312158 loss)
I1130 21:32:01.393833 11185 sgd_solver.cpp:106] Iteration 5000, lr = 0.05
I1130 21:32:05.233888 11185 solver.cpp:228] Iteration 5500, loss = 0.132387
I1130 21:32:05.233937 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0139245 (* 0.5 = 0.00696227 loss)
I1130 21:32:05.233942 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.136176 (* 1 = 0.136176 loss)
I1130 21:32:05.233947 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:32:05.233950 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.726562
I1130 21:32:05.233955 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00786491 (* 0.5 = 0.00393246 loss)
I1130 21:32:05.233960 11185 sgd_solver.cpp:106] Iteration 5500, lr = 0.05
I1130 21:32:09.086233 11185 solver.cpp:228] Iteration 6000, loss = 0.135071
I1130 21:32:09.086279 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0133946 (* 0.5 = 0.0066973 loss)
I1130 21:32:09.086295 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.116837 (* 1 = 0.116837 loss)
I1130 21:32:09.086300 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:32:09.086303 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.703125
I1130 21:32:09.086308 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00581693 (* 0.5 = 0.00290846 loss)
I1130 21:32:09.086313 11185 sgd_solver.cpp:106] Iteration 6000, lr = 0.05
I1130 21:32:11.210270 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_6278.caffemodel
I1130 21:32:11.213117 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_6278.solverstate
I1130 21:32:11.213318 11185 solver.cpp:337] Iteration 6278, Testing net (#0)
I1130 21:32:23.347553 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.01434 (* 0.5 = 0.00717001 loss)
I1130 21:32:23.347591 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.12858 (* 1 = 0.12858 loss)
I1130 21:32:23.347599 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.951282
I1130 21:32:23.347602 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.797853
I1130 21:32:23.347609 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00567269 (* 0.5 = 0.00283635 loss)
I1130 21:32:25.143172 11185 solver.cpp:228] Iteration 6500, loss = 0.114348
I1130 21:32:25.143225 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0137345 (* 0.5 = 0.00686725 loss)
I1130 21:32:25.143232 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.133775 (* 1 = 0.133775 loss)
I1130 21:32:25.143236 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.950521
I1130 21:32:25.143240 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:32:25.143244 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0062938 (* 0.5 = 0.0031469 loss)
I1130 21:32:25.143249 11185 sgd_solver.cpp:106] Iteration 6500, lr = 0.05
I1130 21:32:28.936156 11185 solver.cpp:228] Iteration 7000, loss = 0.117295
I1130 21:32:28.936205 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0146399 (* 0.5 = 0.00731994 loss)
I1130 21:32:28.936213 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.111606 (* 1 = 0.111606 loss)
I1130 21:32:28.936216 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 21:32:28.936220 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.726562
I1130 21:32:28.936224 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00653181 (* 0.5 = 0.00326591 loss)
I1130 21:32:28.936228 11185 sgd_solver.cpp:106] Iteration 7000, lr = 0.05
I1130 21:32:32.724460 11185 solver.cpp:228] Iteration 7500, loss = 0.102847
I1130 21:32:32.724509 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0127273 (* 0.5 = 0.00636363 loss)
I1130 21:32:32.724516 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0992378 (* 1 = 0.0992378 loss)
I1130 21:32:32.724520 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:32:32.724524 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.835938
I1130 21:32:32.724529 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00650629 (* 0.5 = 0.00325314 loss)
I1130 21:32:32.724532 11185 sgd_solver.cpp:106] Iteration 7500, lr = 0.05
I1130 21:32:36.505722 11185 solver.cpp:228] Iteration 8000, loss = 0.105859
I1130 21:32:36.505779 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0109372 (* 0.5 = 0.00546859 loss)
I1130 21:32:36.505785 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0849444 (* 1 = 0.0849444 loss)
I1130 21:32:36.505789 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:32:36.505794 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:32:36.505815 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00502332 (* 0.5 = 0.00251166 loss)
I1130 21:32:36.505820 11185 sgd_solver.cpp:106] Iteration 8000, lr = 0.05
I1130 21:32:40.271477 11185 solver.cpp:228] Iteration 8500, loss = 0.0857469
I1130 21:32:40.271525 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.013008 (* 0.5 = 0.00650398 loss)
I1130 21:32:40.271533 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.048135 (* 1 = 0.048135 loss)
I1130 21:32:40.271536 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.997396
I1130 21:32:40.271540 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 21:32:40.271545 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00561814 (* 0.5 = 0.00280907 loss)
I1130 21:32:40.271549 11185 sgd_solver.cpp:106] Iteration 8500, lr = 0.05
I1130 21:32:44.034873 11185 solver.cpp:228] Iteration 9000, loss = 0.117748
I1130 21:32:44.034915 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0147049 (* 0.5 = 0.00735246 loss)
I1130 21:32:44.034922 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0829986 (* 1 = 0.0829986 loss)
I1130 21:32:44.034926 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.971354
I1130 21:32:44.034929 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:32:44.034934 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00440126 (* 0.5 = 0.00220063 loss)
I1130 21:32:44.034939 11185 sgd_solver.cpp:106] Iteration 9000, lr = 0.05
I1130 21:32:47.789296 11185 solver.cpp:228] Iteration 9500, loss = 0.119541
I1130 21:32:47.789345 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0135139 (* 0.5 = 0.00675695 loss)
I1130 21:32:47.789352 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.128297 (* 1 = 0.128297 loss)
I1130 21:32:47.789356 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:32:47.789360 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.671875
I1130 21:32:47.789364 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00445057 (* 0.5 = 0.00222529 loss)
I1130 21:32:47.789368 11185 sgd_solver.cpp:106] Iteration 9500, lr = 0.05
I1130 21:32:51.553074 11185 solver.cpp:228] Iteration 10000, loss = 0.136107
I1130 21:32:51.553123 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0137789 (* 0.5 = 0.00688943 loss)
I1130 21:32:51.553130 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.125311 (* 1 = 0.125311 loss)
I1130 21:32:51.553134 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:32:51.553138 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:32:51.553143 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00699194 (* 0.5 = 0.00349597 loss)
I1130 21:32:51.553146 11185 sgd_solver.cpp:106] Iteration 10000, lr = 0.05
I1130 21:32:55.314149 11185 solver.cpp:228] Iteration 10500, loss = 0.110634
I1130 21:32:55.314198 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0138624 (* 0.5 = 0.00693119 loss)
I1130 21:32:55.314204 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0971787 (* 1 = 0.0971787 loss)
I1130 21:32:55.314208 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:32:55.314211 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:32:55.314216 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00540781 (* 0.5 = 0.0027039 loss)
I1130 21:32:55.314220 11185 sgd_solver.cpp:106] Iteration 10500, lr = 0.05
I1130 21:32:59.075345 11185 solver.cpp:228] Iteration 11000, loss = 0.115636
I1130 21:32:59.075397 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0134303 (* 0.5 = 0.00671516 loss)
I1130 21:32:59.075403 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0827854 (* 1 = 0.0827854 loss)
I1130 21:32:59.075407 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:32:59.075420 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:32:59.075425 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00551923 (* 0.5 = 0.00275961 loss)
I1130 21:32:59.075429 11185 sgd_solver.cpp:106] Iteration 11000, lr = 0.05
I1130 21:33:02.840936 11185 solver.cpp:228] Iteration 11500, loss = 0.110831
I1130 21:33:02.840986 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0151112 (* 0.5 = 0.00755561 loss)
I1130 21:33:02.840992 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0937926 (* 1 = 0.0937926 loss)
I1130 21:33:02.840996 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:33:02.840999 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:33:02.841004 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00539271 (* 0.5 = 0.00269636 loss)
I1130 21:33:02.841008 11185 sgd_solver.cpp:106] Iteration 11500, lr = 0.05
I1130 21:33:06.636307 11185 solver.cpp:228] Iteration 12000, loss = 0.11354
I1130 21:33:06.636356 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0138489 (* 0.5 = 0.00692443 loss)
I1130 21:33:06.636363 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.109646 (* 1 = 0.109646 loss)
I1130 21:33:06.636368 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.971354
I1130 21:33:06.636371 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.742188
I1130 21:33:06.636375 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00462664 (* 0.5 = 0.00231332 loss)
I1130 21:33:06.636380 11185 sgd_solver.cpp:106] Iteration 12000, lr = 0.05
I1130 21:33:10.407829 11185 solver.cpp:228] Iteration 12500, loss = 0.117833
I1130 21:33:10.407874 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0125513 (* 0.5 = 0.00627563 loss)
I1130 21:33:10.407881 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.111777 (* 1 = 0.111777 loss)
I1130 21:33:10.407886 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.945312
I1130 21:33:10.407888 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.820312
I1130 21:33:10.407893 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00608763 (* 0.5 = 0.00304381 loss)
I1130 21:33:10.407897 11185 sgd_solver.cpp:106] Iteration 12500, lr = 0.05
I1130 21:33:10.823403 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_12556.caffemodel
I1130 21:33:10.825666 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_12556.solverstate
I1130 21:33:10.825860 11185 solver.cpp:337] Iteration 12556, Testing net (#0)
I1130 21:33:23.044657 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0140024 (* 0.5 = 0.00700122 loss)
I1130 21:33:23.044694 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.119285 (* 1 = 0.119285 loss)
I1130 21:33:23.044698 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.97114
I1130 21:33:23.044703 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.764351
I1130 21:33:23.044708 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00526252 (* 0.5 = 0.00263126 loss)
I1130 21:33:26.468942 11185 solver.cpp:228] Iteration 13000, loss = 0.130639
I1130 21:33:26.468994 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0130848 (* 0.5 = 0.00654242 loss)
I1130 21:33:26.469002 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.113304 (* 1 = 0.113304 loss)
I1130 21:33:26.469005 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.953125
I1130 21:33:26.469009 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 21:33:26.469013 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00549149 (* 0.5 = 0.00274575 loss)
I1130 21:33:26.469017 11185 sgd_solver.cpp:106] Iteration 13000, lr = 0.05
I1130 21:33:30.240664 11185 solver.cpp:228] Iteration 13500, loss = 0.115028
I1130 21:33:30.240728 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0136864 (* 0.5 = 0.00684319 loss)
I1130 21:33:30.240736 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.119559 (* 1 = 0.119559 loss)
I1130 21:33:30.240741 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:33:30.240744 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.773438
I1130 21:33:30.240748 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00916627 (* 0.5 = 0.00458313 loss)
I1130 21:33:30.240752 11185 sgd_solver.cpp:106] Iteration 13500, lr = 0.05
I1130 21:33:34.006814 11185 solver.cpp:228] Iteration 14000, loss = 0.12778
I1130 21:33:34.006861 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0143993 (* 0.5 = 0.00719963 loss)
I1130 21:33:34.006868 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.111138 (* 1 = 0.111138 loss)
I1130 21:33:34.006872 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.986979
I1130 21:33:34.006875 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.773438
I1130 21:33:34.006880 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00516172 (* 0.5 = 0.00258086 loss)
I1130 21:33:34.006885 11185 sgd_solver.cpp:106] Iteration 14000, lr = 0.05
I1130 21:33:37.774175 11185 solver.cpp:228] Iteration 14500, loss = 0.111883
I1130 21:33:37.774231 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0130106 (* 0.5 = 0.00650528 loss)
I1130 21:33:37.774238 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0805766 (* 1 = 0.0805766 loss)
I1130 21:33:37.774242 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:33:37.774245 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:33:37.774250 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00440024 (* 0.5 = 0.00220012 loss)
I1130 21:33:37.774255 11185 sgd_solver.cpp:106] Iteration 14500, lr = 0.05
I1130 21:33:41.538419 11185 solver.cpp:228] Iteration 15000, loss = 0.0995419
I1130 21:33:41.538470 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0143457 (* 0.5 = 0.00717283 loss)
I1130 21:33:41.538476 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.076435 (* 1 = 0.076435 loss)
I1130 21:33:41.538480 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:33:41.538485 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.914062
I1130 21:33:41.538488 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0044847 (* 0.5 = 0.00224235 loss)
I1130 21:33:41.538492 11185 sgd_solver.cpp:106] Iteration 15000, lr = 0.05
I1130 21:33:45.314944 11185 solver.cpp:228] Iteration 15500, loss = 0.0784406
I1130 21:33:45.314988 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0130493 (* 0.5 = 0.00652463 loss)
I1130 21:33:45.314996 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0876775 (* 1 = 0.0876775 loss)
I1130 21:33:45.314998 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:33:45.315002 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.882812
I1130 21:33:45.315007 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00414147 (* 0.5 = 0.00207074 loss)
I1130 21:33:45.315011 11185 sgd_solver.cpp:106] Iteration 15500, lr = 0.05
I1130 21:33:49.096292 11185 solver.cpp:228] Iteration 16000, loss = 0.103723
I1130 21:33:49.096343 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0123769 (* 0.5 = 0.00618845 loss)
I1130 21:33:49.096349 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.122473 (* 1 = 0.122473 loss)
I1130 21:33:49.096354 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:33:49.096357 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 21:33:49.096361 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00534667 (* 0.5 = 0.00267334 loss)
I1130 21:33:49.096379 11185 sgd_solver.cpp:106] Iteration 16000, lr = 0.05
I1130 21:33:52.854545 11185 solver.cpp:228] Iteration 16500, loss = 0.117874
I1130 21:33:52.854594 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0128625 (* 0.5 = 0.00643125 loss)
I1130 21:33:52.854601 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0980051 (* 1 = 0.0980051 loss)
I1130 21:33:52.854605 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:33:52.854609 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:33:52.854614 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00362438 (* 0.5 = 0.00181219 loss)
I1130 21:33:52.854619 11185 sgd_solver.cpp:106] Iteration 16500, lr = 0.05
I1130 21:33:56.621258 11185 solver.cpp:228] Iteration 17000, loss = 0.112259
I1130 21:33:56.621310 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0129404 (* 0.5 = 0.0064702 loss)
I1130 21:33:56.621317 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0658031 (* 1 = 0.0658031 loss)
I1130 21:33:56.621321 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.986979
I1130 21:33:56.621325 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.867188
I1130 21:33:56.621330 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00418921 (* 0.5 = 0.0020946 loss)
I1130 21:33:56.621335 11185 sgd_solver.cpp:106] Iteration 17000, lr = 0.05
I1130 21:34:00.387307 11185 solver.cpp:228] Iteration 17500, loss = 0.116991
I1130 21:34:00.387352 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0143256 (* 0.5 = 0.00716278 loss)
I1130 21:34:00.387359 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.114697 (* 1 = 0.114697 loss)
I1130 21:34:00.387363 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:34:00.387367 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.867188
I1130 21:34:00.387372 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00534115 (* 0.5 = 0.00267058 loss)
I1130 21:34:00.387377 11185 sgd_solver.cpp:106] Iteration 17500, lr = 0.05
I1130 21:34:04.154125 11185 solver.cpp:228] Iteration 18000, loss = 0.118484
I1130 21:34:04.154186 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0154049 (* 0.5 = 0.00770246 loss)
I1130 21:34:04.154197 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.120506 (* 1 = 0.120506 loss)
I1130 21:34:04.154204 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:34:04.154209 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.757812
I1130 21:34:04.154217 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00428699 (* 0.5 = 0.00214349 loss)
I1130 21:34:04.154224 11185 sgd_solver.cpp:106] Iteration 18000, lr = 0.05
I1130 21:34:07.919978 11185 solver.cpp:228] Iteration 18500, loss = 0.126108
I1130 21:34:07.920029 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0147399 (* 0.5 = 0.00736996 loss)
I1130 21:34:07.920037 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.101299 (* 1 = 0.101299 loss)
I1130 21:34:07.920040 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:34:07.920043 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:34:07.920048 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00459907 (* 0.5 = 0.00229954 loss)
I1130 21:34:07.920053 11185 sgd_solver.cpp:106] Iteration 18500, lr = 0.05
I1130 21:34:10.427284 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_18834.caffemodel
I1130 21:34:10.429563 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_18834.solverstate
I1130 21:34:10.429750 11185 solver.cpp:337] Iteration 18834, Testing net (#0)
I1130 21:34:22.412438 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0139396 (* 0.5 = 0.00696978 loss)
I1130 21:34:22.412475 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.126591 (* 1 = 0.126591 loss)
I1130 21:34:22.412480 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.975087
I1130 21:34:22.412484 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.735223
I1130 21:34:22.412489 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00507339 (* 0.5 = 0.0025367 loss)
I1130 21:34:23.735231 11185 solver.cpp:228] Iteration 19000, loss = 0.115362
I1130 21:34:23.735286 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.01384 (* 0.5 = 0.00692001 loss)
I1130 21:34:23.735293 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.126056 (* 1 = 0.126056 loss)
I1130 21:34:23.735297 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:34:23.735301 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.75
I1130 21:34:23.735306 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00605483 (* 0.5 = 0.00302742 loss)
I1130 21:34:23.735309 11185 sgd_solver.cpp:106] Iteration 19000, lr = 0.05
I1130 21:34:27.504551 11185 solver.cpp:228] Iteration 19500, loss = 0.111312
I1130 21:34:27.504600 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0148013 (* 0.5 = 0.00740064 loss)
I1130 21:34:27.504606 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.100511 (* 1 = 0.100511 loss)
I1130 21:34:27.504611 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.947917
I1130 21:34:27.504613 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 21:34:27.504618 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00524457 (* 0.5 = 0.00262229 loss)
I1130 21:34:27.504622 11185 sgd_solver.cpp:106] Iteration 19500, lr = 0.05
I1130 21:34:31.274930 11185 solver.cpp:228] Iteration 20000, loss = 0.112243
I1130 21:34:31.274981 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0125427 (* 0.5 = 0.00627137 loss)
I1130 21:34:31.274988 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0565977 (* 1 = 0.0565977 loss)
I1130 21:34:31.274992 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 21:34:31.274996 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 21:34:31.275001 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00509694 (* 0.5 = 0.00254847 loss)
I1130 21:34:31.275004 11185 sgd_solver.cpp:106] Iteration 20000, lr = 0.05
I1130 21:34:35.052307 11185 solver.cpp:228] Iteration 20500, loss = 0.107835
I1130 21:34:35.052356 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0128838 (* 0.5 = 0.00644191 loss)
I1130 21:34:35.052363 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.104509 (* 1 = 0.104509 loss)
I1130 21:34:35.052366 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:34:35.052371 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.820312
I1130 21:34:35.052376 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00744061 (* 0.5 = 0.0037203 loss)
I1130 21:34:35.052379 11185 sgd_solver.cpp:106] Iteration 20500, lr = 0.05
I1130 21:34:38.826309 11185 solver.cpp:228] Iteration 21000, loss = 0.11376
I1130 21:34:38.826366 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0136337 (* 0.5 = 0.00681684 loss)
I1130 21:34:38.826373 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0801781 (* 1 = 0.0801781 loss)
I1130 21:34:38.826376 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:34:38.826380 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 21:34:38.826385 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00433766 (* 0.5 = 0.00216883 loss)
I1130 21:34:38.826390 11185 sgd_solver.cpp:106] Iteration 21000, lr = 0.05
I1130 21:34:42.586565 11185 solver.cpp:228] Iteration 21500, loss = 0.110976
I1130 21:34:42.586612 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0139062 (* 0.5 = 0.0069531 loss)
I1130 21:34:42.586632 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.115358 (* 1 = 0.115358 loss)
I1130 21:34:42.586635 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:34:42.586639 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.742188
I1130 21:34:42.586643 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00582453 (* 0.5 = 0.00291227 loss)
I1130 21:34:42.586648 11185 sgd_solver.cpp:106] Iteration 21500, lr = 0.05
I1130 21:34:46.355895 11185 solver.cpp:228] Iteration 22000, loss = 0.10055
I1130 21:34:46.355943 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0118528 (* 0.5 = 0.00592641 loss)
I1130 21:34:46.355950 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0889151 (* 1 = 0.0889151 loss)
I1130 21:34:46.355954 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:34:46.355958 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:34:46.355962 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00632992 (* 0.5 = 0.00316496 loss)
I1130 21:34:46.355967 11185 sgd_solver.cpp:106] Iteration 22000, lr = 0.05
I1130 21:34:50.126880 11185 solver.cpp:228] Iteration 22500, loss = 0.0890917
I1130 21:34:50.126927 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.014986 (* 0.5 = 0.00749298 loss)
I1130 21:34:50.126934 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.123775 (* 1 = 0.123775 loss)
I1130 21:34:50.126937 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 21:34:50.126941 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.734375
I1130 21:34:50.126945 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00652293 (* 0.5 = 0.00326147 loss)
I1130 21:34:50.126950 11185 sgd_solver.cpp:106] Iteration 22500, lr = 0.05
I1130 21:34:53.880455 11185 solver.cpp:228] Iteration 23000, loss = 0.117453
I1130 21:34:53.880506 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.012741 (* 0.5 = 0.00637052 loss)
I1130 21:34:53.880513 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.124771 (* 1 = 0.124771 loss)
I1130 21:34:53.880517 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.950521
I1130 21:34:53.880522 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.78125
I1130 21:34:53.880527 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00483696 (* 0.5 = 0.00241848 loss)
I1130 21:34:53.880530 11185 sgd_solver.cpp:106] Iteration 23000, lr = 0.05
I1130 21:34:57.642930 11185 solver.cpp:228] Iteration 23500, loss = 0.114765
I1130 21:34:57.642983 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0150208 (* 0.5 = 0.00751042 loss)
I1130 21:34:57.642992 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.10973 (* 1 = 0.10973 loss)
I1130 21:34:57.642995 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:34:57.642999 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.710938
I1130 21:34:57.643004 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00503381 (* 0.5 = 0.00251691 loss)
I1130 21:34:57.643009 11185 sgd_solver.cpp:106] Iteration 23500, lr = 0.05
I1130 21:35:01.410939 11185 solver.cpp:228] Iteration 24000, loss = 0.102955
I1130 21:35:01.410990 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0127872 (* 0.5 = 0.00639358 loss)
I1130 21:35:01.410997 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0833963 (* 1 = 0.0833963 loss)
I1130 21:35:01.411001 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:35:01.411005 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:35:01.411010 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00401311 (* 0.5 = 0.00200655 loss)
I1130 21:35:01.411015 11185 sgd_solver.cpp:106] Iteration 24000, lr = 0.05
I1130 21:35:05.181669 11185 solver.cpp:228] Iteration 24500, loss = 0.0975332
I1130 21:35:05.181720 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0124419 (* 0.5 = 0.00622093 loss)
I1130 21:35:05.181726 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0766336 (* 1 = 0.0766336 loss)
I1130 21:35:05.181730 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 21:35:05.181735 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.867188
I1130 21:35:05.181738 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00369306 (* 0.5 = 0.00184653 loss)
I1130 21:35:05.181743 11185 sgd_solver.cpp:106] Iteration 24500, lr = 0.05
I1130 21:35:08.952904 11185 solver.cpp:228] Iteration 25000, loss = 0.119015
I1130 21:35:08.952955 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.012873 (* 0.5 = 0.00643648 loss)
I1130 21:35:08.952961 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.120419 (* 1 = 0.120419 loss)
I1130 21:35:08.952965 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:35:08.952968 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.734375
I1130 21:35:08.952973 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00602021 (* 0.5 = 0.00301011 loss)
I1130 21:35:08.952977 11185 sgd_solver.cpp:106] Iteration 25000, lr = 0.05
I1130 21:35:09.796062 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_25112.caffemodel
I1130 21:35:09.798271 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_25112.solverstate
I1130 21:35:09.798447 11185 solver.cpp:337] Iteration 25112, Testing net (#0)
I1130 21:35:21.506458 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0138777 (* 0.5 = 0.00693886 loss)
I1130 21:35:21.506487 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.122631 (* 1 = 0.122631 loss)
I1130 21:35:21.506492 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.980132
I1130 21:35:21.506495 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.726542
I1130 21:35:21.506500 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00490651 (* 0.5 = 0.00245325 loss)
I1130 21:35:24.518699 11185 solver.cpp:228] Iteration 25500, loss = 0.114696
I1130 21:35:24.518754 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0152311 (* 0.5 = 0.00761556 loss)
I1130 21:35:24.518761 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0898159 (* 1 = 0.0898159 loss)
I1130 21:35:24.518765 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:35:24.518769 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:35:24.518774 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00646819 (* 0.5 = 0.00323409 loss)
I1130 21:35:24.518779 11185 sgd_solver.cpp:106] Iteration 25500, lr = 0.05
I1130 21:35:28.412369 11185 solver.cpp:228] Iteration 26000, loss = 0.118852
I1130 21:35:28.412439 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0128081 (* 0.5 = 0.00640406 loss)
I1130 21:35:28.412447 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.112735 (* 1 = 0.112735 loss)
I1130 21:35:28.412451 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.953125
I1130 21:35:28.412454 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:35:28.412459 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00516455 (* 0.5 = 0.00258228 loss)
I1130 21:35:28.412464 11185 sgd_solver.cpp:106] Iteration 26000, lr = 0.05
I1130 21:35:32.561396 11185 solver.cpp:228] Iteration 26500, loss = 0.114894
I1130 21:35:32.561465 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0129521 (* 0.5 = 0.00647607 loss)
I1130 21:35:32.561471 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.125985 (* 1 = 0.125985 loss)
I1130 21:35:32.561475 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:35:32.561494 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.757812
I1130 21:35:32.561499 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00558323 (* 0.5 = 0.00279162 loss)
I1130 21:35:32.561504 11185 sgd_solver.cpp:106] Iteration 26500, lr = 0.05
I1130 21:35:36.691490 11185 solver.cpp:228] Iteration 27000, loss = 0.131624
I1130 21:35:36.691583 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0141316 (* 0.5 = 0.00706581 loss)
I1130 21:35:36.691592 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0876007 (* 1 = 0.0876007 loss)
I1130 21:35:36.691596 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:35:36.691601 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:35:36.691606 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00474663 (* 0.5 = 0.00237332 loss)
I1130 21:35:36.691609 11185 sgd_solver.cpp:106] Iteration 27000, lr = 0.05
I1130 21:35:40.778393 11185 solver.cpp:228] Iteration 27500, loss = 0.113678
I1130 21:35:40.778462 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0134628 (* 0.5 = 0.00673141 loss)
I1130 21:35:40.778470 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0984434 (* 1 = 0.0984434 loss)
I1130 21:35:40.778475 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:35:40.778478 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:35:40.778483 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00489506 (* 0.5 = 0.00244753 loss)
I1130 21:35:40.778488 11185 sgd_solver.cpp:106] Iteration 27500, lr = 0.05
I1130 21:35:44.853628 11185 solver.cpp:228] Iteration 28000, loss = 0.109828
I1130 21:35:44.853696 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.01286 (* 0.5 = 0.00643001 loss)
I1130 21:35:44.853703 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0914726 (* 1 = 0.0914726 loss)
I1130 21:35:44.853708 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.945312
I1130 21:35:44.853711 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 21:35:44.853716 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00348019 (* 0.5 = 0.00174009 loss)
I1130 21:35:44.853721 11185 sgd_solver.cpp:106] Iteration 28000, lr = 0.05
I1130 21:35:48.882678 11185 solver.cpp:228] Iteration 28500, loss = 0.0950579
I1130 21:35:48.882746 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0130241 (* 0.5 = 0.00651206 loss)
I1130 21:35:48.882755 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0676226 (* 1 = 0.0676226 loss)
I1130 21:35:48.882758 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 21:35:48.882762 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.835938
I1130 21:35:48.882767 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00897249 (* 0.5 = 0.00448625 loss)
I1130 21:35:48.882771 11185 sgd_solver.cpp:106] Iteration 28500, lr = 0.05
I1130 21:35:52.908643 11185 solver.cpp:228] Iteration 29000, loss = 0.0908466
I1130 21:35:52.908710 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.011381 (* 0.5 = 0.00569048 loss)
I1130 21:35:52.908716 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0637815 (* 1 = 0.0637815 loss)
I1130 21:35:52.908720 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 21:35:52.908725 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.882812
I1130 21:35:52.908730 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00414528 (* 0.5 = 0.00207264 loss)
I1130 21:35:52.908735 11185 sgd_solver.cpp:106] Iteration 29000, lr = 0.05
I1130 21:35:56.939604 11185 solver.cpp:228] Iteration 29500, loss = 0.0872182
I1130 21:35:56.939677 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0128711 (* 0.5 = 0.00643556 loss)
I1130 21:35:56.939702 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0989604 (* 1 = 0.0989604 loss)
I1130 21:35:56.939705 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.955729
I1130 21:35:56.939709 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:35:56.939714 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00631217 (* 0.5 = 0.00315609 loss)
I1130 21:35:56.939719 11185 sgd_solver.cpp:106] Iteration 29500, lr = 0.05
I1130 21:36:01.019585 11185 solver.cpp:228] Iteration 30000, loss = 0.116251
I1130 21:36:01.019654 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0144395 (* 0.5 = 0.00721974 loss)
I1130 21:36:01.019661 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.151118 (* 1 = 0.151118 loss)
I1130 21:36:01.019665 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.945312
I1130 21:36:01.019670 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.679688
I1130 21:36:01.019675 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00394192 (* 0.5 = 0.00197096 loss)
I1130 21:36:01.019678 11185 sgd_solver.cpp:106] Iteration 30000, lr = 0.05
I1130 21:36:05.065204 11185 solver.cpp:228] Iteration 30500, loss = 0.122784
I1130 21:36:05.065270 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0135814 (* 0.5 = 0.00679072 loss)
I1130 21:36:05.065279 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0733767 (* 1 = 0.0733767 loss)
I1130 21:36:05.065282 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 21:36:05.065286 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:36:05.065291 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00502985 (* 0.5 = 0.00251493 loss)
I1130 21:36:05.065295 11185 sgd_solver.cpp:106] Iteration 30500, lr = 0.05
I1130 21:36:09.072562 11185 solver.cpp:228] Iteration 31000, loss = 0.116
I1130 21:36:09.072629 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0150359 (* 0.5 = 0.00751797 loss)
I1130 21:36:09.072636 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.135206 (* 1 = 0.135206 loss)
I1130 21:36:09.072640 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:36:09.072644 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.703125
I1130 21:36:09.072649 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00506505 (* 0.5 = 0.00253252 loss)
I1130 21:36:09.072654 11185 sgd_solver.cpp:106] Iteration 31000, lr = 0.05
I1130 21:36:12.259243 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_31390.caffemodel
I1130 21:36:12.261591 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_31390.solverstate
I1130 21:36:12.261785 11185 solver.cpp:337] Iteration 31390, Testing net (#0)
I1130 21:36:24.540629 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0138199 (* 0.5 = 0.00690996 loss)
I1130 21:36:24.540674 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.123639 (* 1 = 0.123639 loss)
I1130 21:36:24.540680 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.956386
I1130 21:36:24.540684 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.792695
I1130 21:36:24.540691 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00489381 (* 0.5 = 0.00244691 loss)
I1130 21:36:25.407733 11185 solver.cpp:228] Iteration 31500, loss = 0.112608
I1130 21:36:25.407776 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0128321 (* 0.5 = 0.00641607 loss)
I1130 21:36:25.407783 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0899428 (* 1 = 0.0899428 loss)
I1130 21:36:25.407788 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:36:25.407791 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 21:36:25.407796 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00527083 (* 0.5 = 0.00263542 loss)
I1130 21:36:25.407814 11185 sgd_solver.cpp:106] Iteration 31500, lr = 0.005
I1130 21:36:29.255880 11185 solver.cpp:228] Iteration 32000, loss = 0.120654
I1130 21:36:29.255936 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0115111 (* 0.5 = 0.00575557 loss)
I1130 21:36:29.255944 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.111604 (* 1 = 0.111604 loss)
I1130 21:36:29.255947 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:36:29.255950 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:36:29.255955 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00505719 (* 0.5 = 0.00252859 loss)
I1130 21:36:29.255960 11185 sgd_solver.cpp:106] Iteration 32000, lr = 0.005
I1130 21:36:33.114584 11185 solver.cpp:228] Iteration 32500, loss = 0.103943
I1130 21:36:33.114634 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0145976 (* 0.5 = 0.00729881 loss)
I1130 21:36:33.114640 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.10578 (* 1 = 0.10578 loss)
I1130 21:36:33.114645 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:36:33.114648 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.835938
I1130 21:36:33.114653 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00352006 (* 0.5 = 0.00176003 loss)
I1130 21:36:33.114657 11185 sgd_solver.cpp:106] Iteration 32500, lr = 0.005
I1130 21:36:36.998453 11185 solver.cpp:228] Iteration 33000, loss = 0.103805
I1130 21:36:36.998522 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0157041 (* 0.5 = 0.00785204 loss)
I1130 21:36:36.998529 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.103919 (* 1 = 0.103919 loss)
I1130 21:36:36.998533 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:36:36.998538 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 21:36:36.998541 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00497301 (* 0.5 = 0.0024865 loss)
I1130 21:36:36.998546 11185 sgd_solver.cpp:106] Iteration 33000, lr = 0.005
I1130 21:36:40.832612 11185 solver.cpp:228] Iteration 33500, loss = 0.111119
I1130 21:36:40.832671 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0124981 (* 0.5 = 0.00624905 loss)
I1130 21:36:40.832679 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0911367 (* 1 = 0.0911367 loss)
I1130 21:36:40.832684 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:36:40.832686 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.835938
I1130 21:36:40.832691 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00503657 (* 0.5 = 0.00251829 loss)
I1130 21:36:40.832696 11185 sgd_solver.cpp:106] Iteration 33500, lr = 0.005
I1130 21:36:44.676846 11185 solver.cpp:228] Iteration 34000, loss = 0.112488
I1130 21:36:44.676898 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0134405 (* 0.5 = 0.00672026 loss)
I1130 21:36:44.676904 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0854824 (* 1 = 0.0854824 loss)
I1130 21:36:44.676908 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:36:44.676913 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:36:44.676916 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00410439 (* 0.5 = 0.00205219 loss)
I1130 21:36:44.676920 11185 sgd_solver.cpp:106] Iteration 34000, lr = 0.005
I1130 21:36:48.547947 11185 solver.cpp:228] Iteration 34500, loss = 0.11853
I1130 21:36:48.548005 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.013394 (* 0.5 = 0.006697 loss)
I1130 21:36:48.548012 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.100666 (* 1 = 0.100666 loss)
I1130 21:36:48.548017 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:36:48.548032 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:36:48.548038 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00449979 (* 0.5 = 0.0022499 loss)
I1130 21:36:48.548043 11185 sgd_solver.cpp:106] Iteration 34500, lr = 0.005
I1130 21:36:52.336964 11185 solver.cpp:228] Iteration 35000, loss = 0.108032
I1130 21:36:52.337018 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0126895 (* 0.5 = 0.00634475 loss)
I1130 21:36:52.337024 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0754631 (* 1 = 0.0754631 loss)
I1130 21:36:52.337028 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:36:52.337033 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.867188
I1130 21:36:52.337036 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00571526 (* 0.5 = 0.00285763 loss)
I1130 21:36:52.337040 11185 sgd_solver.cpp:106] Iteration 35000, lr = 0.005
I1130 21:36:56.122189 11185 solver.cpp:228] Iteration 35500, loss = 0.115585
I1130 21:36:56.122242 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0125214 (* 0.5 = 0.00626068 loss)
I1130 21:36:56.122249 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0975996 (* 1 = 0.0975996 loss)
I1130 21:36:56.122253 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.971354
I1130 21:36:56.122257 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:36:56.122262 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00394797 (* 0.5 = 0.00197398 loss)
I1130 21:36:56.122267 11185 sgd_solver.cpp:106] Iteration 35500, lr = 0.005
I1130 21:36:59.964141 11185 solver.cpp:228] Iteration 36000, loss = 0.090256
I1130 21:36:59.964184 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0131596 (* 0.5 = 0.0065798 loss)
I1130 21:36:59.964190 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.062375 (* 1 = 0.062375 loss)
I1130 21:36:59.964195 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.986979
I1130 21:36:59.964198 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.882812
I1130 21:36:59.964202 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00534637 (* 0.5 = 0.00267319 loss)
I1130 21:36:59.964206 11185 sgd_solver.cpp:106] Iteration 36000, lr = 0.005
I1130 21:37:03.902487 11185 solver.cpp:228] Iteration 36500, loss = 0.0855161
I1130 21:37:03.902549 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0124376 (* 0.5 = 0.00621878 loss)
I1130 21:37:03.902559 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0770867 (* 1 = 0.0770867 loss)
I1130 21:37:03.902565 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:37:03.902570 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.835938
I1130 21:37:03.902576 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00844212 (* 0.5 = 0.00422106 loss)
I1130 21:37:03.902582 11185 sgd_solver.cpp:106] Iteration 36500, lr = 0.005
I1130 21:37:08.211038 11185 solver.cpp:228] Iteration 37000, loss = 0.0975892
I1130 21:37:08.211110 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0142095 (* 0.5 = 0.00710475 loss)
I1130 21:37:08.211127 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0972055 (* 1 = 0.0972055 loss)
I1130 21:37:08.211130 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:37:08.211134 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 21:37:08.211139 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00384156 (* 0.5 = 0.00192078 loss)
I1130 21:37:08.211144 11185 sgd_solver.cpp:106] Iteration 37000, lr = 0.005
I1130 21:37:12.485901 11185 solver.cpp:228] Iteration 37500, loss = 0.104116
I1130 21:37:12.485975 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.012587 (* 0.5 = 0.00629351 loss)
I1130 21:37:12.485982 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.105629 (* 1 = 0.105629 loss)
I1130 21:37:12.486002 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.971354
I1130 21:37:12.486006 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.796875
I1130 21:37:12.486011 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0042536 (* 0.5 = 0.0021268 loss)
I1130 21:37:12.486016 11185 sgd_solver.cpp:106] Iteration 37500, lr = 0.005
I1130 21:37:13.884707 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_37668.caffemodel
I1130 21:37:13.887395 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_37668.solverstate
I1130 21:37:13.887773 11185 solver.cpp:337] Iteration 37668, Testing net (#0)
I1130 21:37:26.536588 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0133411 (* 0.5 = 0.00667054 loss)
I1130 21:37:26.536662 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.110058 (* 1 = 0.110058 loss)
I1130 21:37:26.536669 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.970472
I1130 21:37:26.536672 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.795756
I1130 21:37:26.536679 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00470843 (* 0.5 = 0.00235422 loss)
I1130 21:37:29.441138 11185 solver.cpp:228] Iteration 38000, loss = 0.100053
I1130 21:37:29.441205 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.014197 (* 0.5 = 0.00709849 loss)
I1130 21:37:29.441213 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.107537 (* 1 = 0.107537 loss)
I1130 21:37:29.441217 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:37:29.441229 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.820312
I1130 21:37:29.441234 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00456455 (* 0.5 = 0.00228227 loss)
I1130 21:37:29.441238 11185 sgd_solver.cpp:106] Iteration 38000, lr = 0.005
I1130 21:37:33.610743 11185 solver.cpp:228] Iteration 38500, loss = 0.103903
I1130 21:37:33.610797 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0129708 (* 0.5 = 0.00648542 loss)
I1130 21:37:33.610805 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.129625 (* 1 = 0.129625 loss)
I1130 21:37:33.610808 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:37:33.610812 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.773438
I1130 21:37:33.610817 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00456613 (* 0.5 = 0.00228306 loss)
I1130 21:37:33.610821 11185 sgd_solver.cpp:106] Iteration 38500, lr = 0.005
I1130 21:37:37.665462 11185 solver.cpp:228] Iteration 39000, loss = 0.12527
I1130 21:37:37.665518 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0138905 (* 0.5 = 0.00694524 loss)
I1130 21:37:37.665524 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.115111 (* 1 = 0.115111 loss)
I1130 21:37:37.665529 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:37:37.665532 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:37:37.665536 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00490994 (* 0.5 = 0.00245497 loss)
I1130 21:37:37.665540 11185 sgd_solver.cpp:106] Iteration 39000, lr = 0.005
I1130 21:37:41.725033 11185 solver.cpp:228] Iteration 39500, loss = 0.109357
I1130 21:37:41.725095 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0103861 (* 0.5 = 0.00519307 loss)
I1130 21:37:41.725102 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.113052 (* 1 = 0.113052 loss)
I1130 21:37:41.725106 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:37:41.725111 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:37:41.725116 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00622535 (* 0.5 = 0.00311268 loss)
I1130 21:37:41.725119 11185 sgd_solver.cpp:106] Iteration 39500, lr = 0.005
I1130 21:37:45.829357 11185 solver.cpp:228] Iteration 40000, loss = 0.114892
I1130 21:37:45.829424 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0139395 (* 0.5 = 0.00696976 loss)
I1130 21:37:45.829440 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0955599 (* 1 = 0.0955599 loss)
I1130 21:37:45.829444 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:37:45.829448 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:37:45.829453 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00388627 (* 0.5 = 0.00194314 loss)
I1130 21:37:45.829458 11185 sgd_solver.cpp:106] Iteration 40000, lr = 0.005
I1130 21:37:49.848875 11185 solver.cpp:228] Iteration 40500, loss = 0.110227
I1130 21:37:49.848932 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0148269 (* 0.5 = 0.00741347 loss)
I1130 21:37:49.848937 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.123085 (* 1 = 0.123085 loss)
I1130 21:37:49.848942 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:37:49.848945 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.71875
I1130 21:37:49.848950 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00323302 (* 0.5 = 0.00161651 loss)
I1130 21:37:49.848954 11185 sgd_solver.cpp:106] Iteration 40500, lr = 0.005
I1130 21:37:53.897758 11185 solver.cpp:228] Iteration 41000, loss = 0.103188
I1130 21:37:53.897822 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0133901 (* 0.5 = 0.00669506 loss)
I1130 21:37:53.897830 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0768709 (* 1 = 0.0768709 loss)
I1130 21:37:53.897833 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.986979
I1130 21:37:53.897845 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 21:37:53.897850 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00337468 (* 0.5 = 0.00168734 loss)
I1130 21:37:53.897855 11185 sgd_solver.cpp:106] Iteration 41000, lr = 0.005
I1130 21:37:58.229218 11185 solver.cpp:228] Iteration 41500, loss = 0.101466
I1130 21:37:58.229284 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0125393 (* 0.5 = 0.00626966 loss)
I1130 21:37:58.229291 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.109246 (* 1 = 0.109246 loss)
I1130 21:37:58.229295 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:37:58.229300 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.765625
I1130 21:37:58.229305 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00370583 (* 0.5 = 0.00185292 loss)
I1130 21:37:58.229308 11185 sgd_solver.cpp:106] Iteration 41500, lr = 0.005
I1130 21:38:02.566285 11185 solver.cpp:228] Iteration 42000, loss = 0.103223
I1130 21:38:02.566339 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0129272 (* 0.5 = 0.0064636 loss)
I1130 21:38:02.566345 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0820068 (* 1 = 0.0820068 loss)
I1130 21:38:02.566350 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:38:02.566354 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.882812
I1130 21:38:02.566359 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00548602 (* 0.5 = 0.00274301 loss)
I1130 21:38:02.566364 11185 sgd_solver.cpp:106] Iteration 42000, lr = 0.005
I1130 21:38:07.142961 11185 solver.cpp:228] Iteration 42500, loss = 0.0996865
I1130 21:38:07.143023 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0140877 (* 0.5 = 0.00704385 loss)
I1130 21:38:07.143031 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.105596 (* 1 = 0.105596 loss)
I1130 21:38:07.143036 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.950521
I1130 21:38:07.143041 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:38:07.143061 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00412534 (* 0.5 = 0.00206267 loss)
I1130 21:38:07.143072 11185 sgd_solver.cpp:106] Iteration 42500, lr = 0.005
I1130 21:38:11.757464 11185 solver.cpp:228] Iteration 43000, loss = 0.0909265
I1130 21:38:11.757519 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0111405 (* 0.5 = 0.00557025 loss)
I1130 21:38:11.757525 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0940815 (* 1 = 0.0940815 loss)
I1130 21:38:11.757529 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:38:11.757534 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:38:11.757539 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00353918 (* 0.5 = 0.00176959 loss)
I1130 21:38:11.757542 11185 sgd_solver.cpp:106] Iteration 43000, lr = 0.005
I1130 21:38:15.812366 11185 solver.cpp:228] Iteration 43500, loss = 0.0904839
I1130 21:38:15.812419 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.011496 (* 0.5 = 0.005748 loss)
I1130 21:38:15.812427 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0955678 (* 1 = 0.0955678 loss)
I1130 21:38:15.812430 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 21:38:15.812434 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.765625
I1130 21:38:15.812439 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00419073 (* 0.5 = 0.00209537 loss)
I1130 21:38:15.812443 11185 sgd_solver.cpp:106] Iteration 43500, lr = 0.005
I1130 21:38:19.421062 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_43946.caffemodel
I1130 21:38:19.423559 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_43946.solverstate
I1130 21:38:19.423735 11185 solver.cpp:337] Iteration 43946, Testing net (#0)
I1130 21:38:31.978837 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0132717 (* 0.5 = 0.00663584 loss)
I1130 21:38:31.978883 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.107226 (* 1 = 0.107226 loss)
I1130 21:38:31.978888 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.974146
I1130 21:38:31.978891 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.792013
I1130 21:38:31.978898 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00470306 (* 0.5 = 0.00235153 loss)
I1130 21:38:32.301499 11185 solver.cpp:228] Iteration 44000, loss = 0.125429
I1130 21:38:32.301549 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0140334 (* 0.5 = 0.00701668 loss)
I1130 21:38:32.301558 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.128613 (* 1 = 0.128613 loss)
I1130 21:38:32.301564 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:38:32.301568 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.757812
I1130 21:38:32.301574 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00603958 (* 0.5 = 0.00301979 loss)
I1130 21:38:32.301579 11185 sgd_solver.cpp:106] Iteration 44000, lr = 0.005
I1130 21:38:36.283958 11185 solver.cpp:228] Iteration 44500, loss = 0.10921
I1130 21:38:36.283982 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0137429 (* 0.5 = 0.00687147 loss)
I1130 21:38:36.283988 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0906314 (* 1 = 0.0906314 loss)
I1130 21:38:36.283992 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.971354
I1130 21:38:36.283995 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:38:36.284000 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00582326 (* 0.5 = 0.00291163 loss)
I1130 21:38:36.284004 11185 sgd_solver.cpp:106] Iteration 44500, lr = 0.005
I1130 21:38:40.064301 11185 solver.cpp:228] Iteration 45000, loss = 0.0976039
I1130 21:38:40.064328 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.013384 (* 0.5 = 0.00669202 loss)
I1130 21:38:40.064345 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0818732 (* 1 = 0.0818732 loss)
I1130 21:38:40.064349 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:38:40.064353 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.867188
I1130 21:38:40.064357 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00473849 (* 0.5 = 0.00236925 loss)
I1130 21:38:40.064362 11185 sgd_solver.cpp:106] Iteration 45000, lr = 0.005
I1130 21:38:43.851847 11185 solver.cpp:228] Iteration 45500, loss = 0.0941396
I1130 21:38:43.851871 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0140374 (* 0.5 = 0.00701872 loss)
I1130 21:38:43.851876 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.103729 (* 1 = 0.103729 loss)
I1130 21:38:43.851881 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:38:43.851884 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:38:43.851888 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00589575 (* 0.5 = 0.00294788 loss)
I1130 21:38:43.851892 11185 sgd_solver.cpp:106] Iteration 45500, lr = 0.005
I1130 21:38:47.646663 11185 solver.cpp:228] Iteration 46000, loss = 0.11486
I1130 21:38:47.646684 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0135563 (* 0.5 = 0.00677816 loss)
I1130 21:38:47.646690 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.113316 (* 1 = 0.113316 loss)
I1130 21:38:47.646694 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:38:47.646697 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:38:47.646703 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00483808 (* 0.5 = 0.00241904 loss)
I1130 21:38:47.646705 11185 sgd_solver.cpp:106] Iteration 46000, lr = 0.005
I1130 21:38:51.429205 11185 solver.cpp:228] Iteration 46500, loss = 0.102473
I1130 21:38:51.429227 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0107687 (* 0.5 = 0.00538437 loss)
I1130 21:38:51.429234 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0905847 (* 1 = 0.0905847 loss)
I1130 21:38:51.429237 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:38:51.429241 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 21:38:51.429245 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00461339 (* 0.5 = 0.0023067 loss)
I1130 21:38:51.429250 11185 sgd_solver.cpp:106] Iteration 46500, lr = 0.005
I1130 21:38:55.206312 11185 solver.cpp:228] Iteration 47000, loss = 0.108311
I1130 21:38:55.206334 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0109888 (* 0.5 = 0.00549439 loss)
I1130 21:38:55.206341 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.1111 (* 1 = 0.1111 loss)
I1130 21:38:55.206344 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:38:55.206347 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:38:55.206352 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00350918 (* 0.5 = 0.00175459 loss)
I1130 21:38:55.206357 11185 sgd_solver.cpp:106] Iteration 47000, lr = 0.005
I1130 21:38:59.240458 11185 solver.cpp:228] Iteration 47500, loss = 0.118112
I1130 21:38:59.240525 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0133825 (* 0.5 = 0.00669127 loss)
I1130 21:38:59.240533 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0821581 (* 1 = 0.0821581 loss)
I1130 21:38:59.240537 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:38:59.240541 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.882812
I1130 21:38:59.240552 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00357958 (* 0.5 = 0.00178979 loss)
I1130 21:38:59.240556 11185 sgd_solver.cpp:106] Iteration 47500, lr = 0.005
I1130 21:39:03.416038 11185 solver.cpp:228] Iteration 48000, loss = 0.108804
I1130 21:39:03.416110 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0160562 (* 0.5 = 0.0080281 loss)
I1130 21:39:03.416121 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.122981 (* 1 = 0.122981 loss)
I1130 21:39:03.416126 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:39:03.416131 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.726562
I1130 21:39:03.416136 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00550605 (* 0.5 = 0.00275302 loss)
I1130 21:39:03.416151 11185 sgd_solver.cpp:106] Iteration 48000, lr = 0.005
I1130 21:39:07.483626 11185 solver.cpp:228] Iteration 48500, loss = 0.12443
I1130 21:39:07.483676 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0151288 (* 0.5 = 0.00756441 loss)
I1130 21:39:07.483683 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.116631 (* 1 = 0.116631 loss)
I1130 21:39:07.483687 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:39:07.483691 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.765625
I1130 21:39:07.483695 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00466327 (* 0.5 = 0.00233164 loss)
I1130 21:39:07.483700 11185 sgd_solver.cpp:106] Iteration 48500, lr = 0.005
I1130 21:39:11.500787 11185 solver.cpp:228] Iteration 49000, loss = 0.101264
I1130 21:39:11.500838 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0133809 (* 0.5 = 0.00669045 loss)
I1130 21:39:11.500844 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0799256 (* 1 = 0.0799256 loss)
I1130 21:39:11.500847 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:39:11.500851 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:39:11.500855 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00430114 (* 0.5 = 0.00215057 loss)
I1130 21:39:11.500859 11185 sgd_solver.cpp:106] Iteration 49000, lr = 0.005
I1130 21:39:15.550869 11185 solver.cpp:228] Iteration 49500, loss = 0.0925694
I1130 21:39:15.550922 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0119789 (* 0.5 = 0.00598943 loss)
I1130 21:39:15.550930 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0549471 (* 1 = 0.0549471 loss)
I1130 21:39:15.550933 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:39:15.550937 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 21:39:15.550942 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00430241 (* 0.5 = 0.00215121 loss)
I1130 21:39:15.550947 11185 sgd_solver.cpp:106] Iteration 49500, lr = 0.005
I1130 21:39:19.713326 11185 solver.cpp:228] Iteration 50000, loss = 0.0779492
I1130 21:39:19.713395 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0120614 (* 0.5 = 0.00603071 loss)
I1130 21:39:19.713403 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0508284 (* 1 = 0.0508284 loss)
I1130 21:39:19.713407 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 21:39:19.713412 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.929688
I1130 21:39:19.713416 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00480292 (* 0.5 = 0.00240146 loss)
I1130 21:39:19.713420 11185 sgd_solver.cpp:106] Iteration 50000, lr = 0.005
I1130 21:39:21.636634 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_50224.caffemodel
I1130 21:39:21.639051 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_50224.solverstate
I1130 21:39:21.639242 11185 solver.cpp:337] Iteration 50224, Testing net (#0)
I1130 21:39:34.038497 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0134155 (* 0.5 = 0.00670777 loss)
I1130 21:39:34.038540 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.114046 (* 1 = 0.114046 loss)
I1130 21:39:34.038563 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.980087
I1130 21:39:34.038568 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.750973
I1130 21:39:34.038573 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00464945 (* 0.5 = 0.00232473 loss)
I1130 21:39:36.375488 11185 solver.cpp:228] Iteration 50500, loss = 0.0901178
I1130 21:39:36.375550 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0133198 (* 0.5 = 0.00665991 loss)
I1130 21:39:36.375558 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0726443 (* 1 = 0.0726443 loss)
I1130 21:39:36.375562 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 21:39:36.375566 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:39:36.375571 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00438167 (* 0.5 = 0.00219083 loss)
I1130 21:39:36.375576 11185 sgd_solver.cpp:106] Iteration 50500, lr = 0.005
I1130 21:39:40.597781 11185 solver.cpp:228] Iteration 51000, loss = 0.108672
I1130 21:39:40.597843 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0121723 (* 0.5 = 0.00608615 loss)
I1130 21:39:40.597851 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0922932 (* 1 = 0.0922932 loss)
I1130 21:39:40.597856 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:39:40.597859 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:39:40.597864 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00463349 (* 0.5 = 0.00231674 loss)
I1130 21:39:40.597868 11185 sgd_solver.cpp:106] Iteration 51000, lr = 0.005
I1130 21:39:44.753356 11185 solver.cpp:228] Iteration 51500, loss = 0.115639
I1130 21:39:44.753418 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0139287 (* 0.5 = 0.00696435 loss)
I1130 21:39:44.753425 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0957417 (* 1 = 0.0957417 loss)
I1130 21:39:44.753429 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.971354
I1130 21:39:44.753433 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:39:44.753438 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0040008 (* 0.5 = 0.0020004 loss)
I1130 21:39:44.753443 11185 sgd_solver.cpp:106] Iteration 51500, lr = 0.005
I1130 21:39:48.918790 11185 solver.cpp:228] Iteration 52000, loss = 0.0963577
I1130 21:39:48.918843 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.012338 (* 0.5 = 0.00616901 loss)
I1130 21:39:48.918849 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0737903 (* 1 = 0.0737903 loss)
I1130 21:39:48.918853 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:39:48.918858 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.867188
I1130 21:39:48.918861 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00528125 (* 0.5 = 0.00264062 loss)
I1130 21:39:48.918866 11185 sgd_solver.cpp:106] Iteration 52000, lr = 0.005
I1130 21:39:53.071012 11185 solver.cpp:228] Iteration 52500, loss = 0.120875
I1130 21:39:53.071071 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0130851 (* 0.5 = 0.00654257 loss)
I1130 21:39:53.071081 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.10129 (* 1 = 0.10129 loss)
I1130 21:39:53.071086 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:39:53.071090 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.75
I1130 21:39:53.071095 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00465046 (* 0.5 = 0.00232523 loss)
I1130 21:39:53.071099 11185 sgd_solver.cpp:106] Iteration 52500, lr = 0.005
I1130 21:39:57.233242 11185 solver.cpp:228] Iteration 53000, loss = 0.119931
I1130 21:39:57.233292 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0121343 (* 0.5 = 0.00606717 loss)
I1130 21:39:57.233299 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.127641 (* 1 = 0.127641 loss)
I1130 21:39:57.233314 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:39:57.233317 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.742188
I1130 21:39:57.233322 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00429109 (* 0.5 = 0.00214555 loss)
I1130 21:39:57.233327 11185 sgd_solver.cpp:106] Iteration 53000, lr = 0.005
I1130 21:40:01.390616 11185 solver.cpp:228] Iteration 53500, loss = 0.100864
I1130 21:40:01.390684 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0116868 (* 0.5 = 0.00584341 loss)
I1130 21:40:01.390691 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0919433 (* 1 = 0.0919433 loss)
I1130 21:40:01.390696 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:40:01.390699 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.820312
I1130 21:40:01.390713 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00375177 (* 0.5 = 0.00187588 loss)
I1130 21:40:01.390718 11185 sgd_solver.cpp:106] Iteration 53500, lr = 0.005
I1130 21:40:05.565495 11185 solver.cpp:228] Iteration 54000, loss = 0.100166
I1130 21:40:05.565547 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0128985 (* 0.5 = 0.00644924 loss)
I1130 21:40:05.565554 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0855387 (* 1 = 0.0855387 loss)
I1130 21:40:05.565558 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.971354
I1130 21:40:05.565562 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.882812
I1130 21:40:05.565567 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00521875 (* 0.5 = 0.00260938 loss)
I1130 21:40:05.565578 11185 sgd_solver.cpp:106] Iteration 54000, lr = 0.005
I1130 21:40:09.786247 11185 solver.cpp:228] Iteration 54500, loss = 0.107602
I1130 21:40:09.786304 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.012754 (* 0.5 = 0.00637701 loss)
I1130 21:40:09.786314 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.110847 (* 1 = 0.110847 loss)
I1130 21:40:09.786319 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.955729
I1130 21:40:09.786324 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.820312
I1130 21:40:09.786336 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00396066 (* 0.5 = 0.00198033 loss)
I1130 21:40:09.786341 11185 sgd_solver.cpp:106] Iteration 54500, lr = 0.005
I1130 21:40:13.949178 11185 solver.cpp:228] Iteration 55000, loss = 0.101928
I1130 21:40:13.949239 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0127896 (* 0.5 = 0.00639479 loss)
I1130 21:40:13.949247 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.116476 (* 1 = 0.116476 loss)
I1130 21:40:13.949251 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:40:13.949254 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.820312
I1130 21:40:13.949259 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00385928 (* 0.5 = 0.00192964 loss)
I1130 21:40:13.949265 11185 sgd_solver.cpp:106] Iteration 55000, lr = 0.005
I1130 21:40:18.112416 11185 solver.cpp:228] Iteration 55500, loss = 0.113853
I1130 21:40:18.112481 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0134794 (* 0.5 = 0.0067397 loss)
I1130 21:40:18.112489 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.10488 (* 1 = 0.10488 loss)
I1130 21:40:18.112493 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.955729
I1130 21:40:18.112498 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:40:18.112503 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0046259 (* 0.5 = 0.00231295 loss)
I1130 21:40:18.112506 11185 sgd_solver.cpp:106] Iteration 55500, lr = 0.005
I1130 21:40:22.304373 11185 solver.cpp:228] Iteration 56000, loss = 0.108783
I1130 21:40:22.304442 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0145401 (* 0.5 = 0.00727007 loss)
I1130 21:40:22.304450 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.120759 (* 1 = 0.120759 loss)
I1130 21:40:22.304461 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:40:22.304464 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 21:40:22.304469 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00414717 (* 0.5 = 0.00207358 loss)
I1130 21:40:22.304474 11185 sgd_solver.cpp:106] Iteration 56000, lr = 0.005
I1130 21:40:26.518648 11185 solver.cpp:228] Iteration 56500, loss = 0.0977106
I1130 21:40:26.518713 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0128389 (* 0.5 = 0.00641944 loss)
I1130 21:40:26.518720 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.107272 (* 1 = 0.107272 loss)
I1130 21:40:26.518724 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:40:26.518738 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.78125
I1130 21:40:26.518743 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00334778 (* 0.5 = 0.00167389 loss)
I1130 21:40:26.518746 11185 sgd_solver.cpp:106] Iteration 56500, lr = 0.005
I1130 21:40:26.527128 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_56502.caffemodel
I1130 21:40:26.529400 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_56502.solverstate
I1130 21:40:26.529584 11185 solver.cpp:337] Iteration 56502, Testing net (#0)
I1130 21:40:39.071580 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0134245 (* 0.5 = 0.00671223 loss)
I1130 21:40:39.071625 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.123619 (* 1 = 0.123619 loss)
I1130 21:40:39.071631 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.983949
I1130 21:40:39.071635 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.717169
I1130 21:40:39.071641 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00470022 (* 0.5 = 0.00235011 loss)
I1130 21:40:43.269332 11185 solver.cpp:228] Iteration 57000, loss = 0.090985
I1130 21:40:43.269393 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0141051 (* 0.5 = 0.00705256 loss)
I1130 21:40:43.269400 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0858696 (* 1 = 0.0858696 loss)
I1130 21:40:43.269404 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:40:43.269408 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.835938
I1130 21:40:43.269413 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00447838 (* 0.5 = 0.00223919 loss)
I1130 21:40:43.269418 11185 sgd_solver.cpp:106] Iteration 57000, lr = 0.005
I1130 21:40:47.444901 11185 solver.cpp:228] Iteration 57500, loss = 0.0932599
I1130 21:40:47.444953 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.01425 (* 0.5 = 0.00712502 loss)
I1130 21:40:47.444960 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0871513 (* 1 = 0.0871513 loss)
I1130 21:40:47.444964 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:40:47.444968 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.882812
I1130 21:40:47.444973 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00404893 (* 0.5 = 0.00202446 loss)
I1130 21:40:47.444977 11185 sgd_solver.cpp:106] Iteration 57500, lr = 0.005
I1130 21:40:51.609092 11185 solver.cpp:228] Iteration 58000, loss = 0.102786
I1130 21:40:51.609155 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0122384 (* 0.5 = 0.00611921 loss)
I1130 21:40:51.609163 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0894529 (* 1 = 0.0894529 loss)
I1130 21:40:51.609166 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:40:51.609170 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:40:51.609189 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00429766 (* 0.5 = 0.00214883 loss)
I1130 21:40:51.609194 11185 sgd_solver.cpp:106] Iteration 58000, lr = 0.005
I1130 21:40:55.767240 11185 solver.cpp:228] Iteration 58500, loss = 0.0945334
I1130 21:40:55.767290 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0132252 (* 0.5 = 0.0066126 loss)
I1130 21:40:55.767298 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.082166 (* 1 = 0.082166 loss)
I1130 21:40:55.767302 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:40:55.767307 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.867188
I1130 21:40:55.767312 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00427195 (* 0.5 = 0.00213598 loss)
I1130 21:40:55.767315 11185 sgd_solver.cpp:106] Iteration 58500, lr = 0.005
I1130 21:40:59.928344 11185 solver.cpp:228] Iteration 59000, loss = 0.0951572
I1130 21:40:59.928409 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0131628 (* 0.5 = 0.00658138 loss)
I1130 21:40:59.928416 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.12446 (* 1 = 0.12446 loss)
I1130 21:40:59.928421 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:40:59.928424 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.742188
I1130 21:40:59.928429 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00562091 (* 0.5 = 0.00281046 loss)
I1130 21:40:59.928434 11185 sgd_solver.cpp:106] Iteration 59000, lr = 0.005
I1130 21:41:04.103834 11185 solver.cpp:228] Iteration 59500, loss = 0.110211
I1130 21:41:04.103905 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0116591 (* 0.5 = 0.00582957 loss)
I1130 21:41:04.103912 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.112969 (* 1 = 0.112969 loss)
I1130 21:41:04.103917 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:41:04.103920 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 21:41:04.103925 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00381409 (* 0.5 = 0.00190705 loss)
I1130 21:41:04.103930 11185 sgd_solver.cpp:106] Iteration 59500, lr = 0.005
I1130 21:41:08.278687 11185 solver.cpp:228] Iteration 60000, loss = 0.119955
I1130 21:41:08.278739 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0128774 (* 0.5 = 0.00643872 loss)
I1130 21:41:08.278746 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0847389 (* 1 = 0.0847389 loss)
I1130 21:41:08.278750 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:41:08.278754 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 21:41:08.278759 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00480784 (* 0.5 = 0.00240392 loss)
I1130 21:41:08.278764 11185 sgd_solver.cpp:106] Iteration 60000, lr = 0.005
I1130 21:41:12.426684 11185 solver.cpp:228] Iteration 60500, loss = 0.102321
I1130 21:41:12.426736 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.01231 (* 0.5 = 0.006155 loss)
I1130 21:41:12.426743 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0866132 (* 1 = 0.0866132 loss)
I1130 21:41:12.426748 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.971354
I1130 21:41:12.426753 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.820312
I1130 21:41:12.426756 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00554856 (* 0.5 = 0.00277428 loss)
I1130 21:41:12.426761 11185 sgd_solver.cpp:106] Iteration 60500, lr = 0.005
I1130 21:41:16.575275 11185 solver.cpp:228] Iteration 61000, loss = 0.117631
I1130 21:41:16.575327 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.012797 (* 0.5 = 0.00639851 loss)
I1130 21:41:16.575342 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.117573 (* 1 = 0.117573 loss)
I1130 21:41:16.575361 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.953125
I1130 21:41:16.575366 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:41:16.575371 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00408904 (* 0.5 = 0.00204452 loss)
I1130 21:41:16.575381 11185 sgd_solver.cpp:106] Iteration 61000, lr = 0.005
I1130 21:41:20.708757 11185 solver.cpp:228] Iteration 61500, loss = 0.116794
I1130 21:41:20.708811 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0125494 (* 0.5 = 0.00627469 loss)
I1130 21:41:20.708819 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0951922 (* 1 = 0.0951922 loss)
I1130 21:41:20.708823 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:41:20.708827 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 21:41:20.708832 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00360225 (* 0.5 = 0.00180113 loss)
I1130 21:41:20.708837 11185 sgd_solver.cpp:106] Iteration 61500, lr = 0.005
I1130 21:41:24.943249 11185 solver.cpp:228] Iteration 62000, loss = 0.0989609
I1130 21:41:24.943311 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0101395 (* 0.5 = 0.00506974 loss)
I1130 21:41:24.943317 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.100432 (* 1 = 0.100432 loss)
I1130 21:41:24.943321 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:41:24.943334 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.835938
I1130 21:41:24.943339 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00537977 (* 0.5 = 0.00268989 loss)
I1130 21:41:24.943344 11185 sgd_solver.cpp:106] Iteration 62000, lr = 0.005
I1130 21:41:29.166435 11185 solver.cpp:228] Iteration 62500, loss = 0.10375
I1130 21:41:29.166491 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0142789 (* 0.5 = 0.00713943 loss)
I1130 21:41:29.166497 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.116559 (* 1 = 0.116559 loss)
I1130 21:41:29.166502 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:41:29.166507 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.796875
I1130 21:41:29.166510 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00411444 (* 0.5 = 0.00205722 loss)
I1130 21:41:29.166515 11185 sgd_solver.cpp:106] Iteration 62500, lr = 0.005
I1130 21:41:31.487752 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_62780.caffemodel
I1130 21:41:31.490191 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_62780.solverstate
I1130 21:41:31.490373 11185 solver.cpp:337] Iteration 62780, Testing net (#0)
I1130 21:41:44.060147 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0132673 (* 0.5 = 0.00663364 loss)
I1130 21:41:44.060189 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.118896 (* 1 = 0.118896 loss)
I1130 21:41:44.060194 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.973957
I1130 21:41:44.060199 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.766809
I1130 21:41:44.060204 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00465783 (* 0.5 = 0.00232892 loss)
I1130 21:41:45.910193 11185 solver.cpp:228] Iteration 63000, loss = 0.0949905
I1130 21:41:45.910264 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0133649 (* 0.5 = 0.00668247 loss)
I1130 21:41:45.910271 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0856721 (* 1 = 0.0856721 loss)
I1130 21:41:45.910275 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:41:45.910279 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 21:41:45.910284 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00394254 (* 0.5 = 0.00197127 loss)
I1130 21:41:45.910290 11185 sgd_solver.cpp:106] Iteration 63000, lr = 0.0005
I1130 21:41:50.073220 11185 solver.cpp:228] Iteration 63500, loss = 0.0962835
I1130 21:41:50.073282 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0129154 (* 0.5 = 0.00645772 loss)
I1130 21:41:50.073288 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0841738 (* 1 = 0.0841738 loss)
I1130 21:41:50.073292 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:41:50.073297 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 21:41:50.073300 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0048794 (* 0.5 = 0.0024397 loss)
I1130 21:41:50.073314 11185 sgd_solver.cpp:106] Iteration 63500, lr = 0.0005
I1130 21:41:54.216439 11185 solver.cpp:228] Iteration 64000, loss = 0.0824183
I1130 21:41:54.216500 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0119409 (* 0.5 = 0.00597044 loss)
I1130 21:41:54.216507 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0787578 (* 1 = 0.0787578 loss)
I1130 21:41:54.216511 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 21:41:54.216514 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:41:54.216519 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00520733 (* 0.5 = 0.00260366 loss)
I1130 21:41:54.216524 11185 sgd_solver.cpp:106] Iteration 64000, lr = 0.0005
I1130 21:41:58.363335 11185 solver.cpp:228] Iteration 64500, loss = 0.108944
I1130 21:41:58.363405 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0144464 (* 0.5 = 0.00722322 loss)
I1130 21:41:58.363415 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.103994 (* 1 = 0.103994 loss)
I1130 21:41:58.363425 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:41:58.363430 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.773438
I1130 21:41:58.363435 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00492295 (* 0.5 = 0.00246147 loss)
I1130 21:41:58.363441 11185 sgd_solver.cpp:106] Iteration 64500, lr = 0.0005
I1130 21:42:02.514394 11185 solver.cpp:228] Iteration 65000, loss = 0.113698
I1130 21:42:02.514461 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0143321 (* 0.5 = 0.00716604 loss)
I1130 21:42:02.514467 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.13684 (* 1 = 0.13684 loss)
I1130 21:42:02.514472 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:42:02.514477 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.710938
I1130 21:42:02.514482 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00499829 (* 0.5 = 0.00249914 loss)
I1130 21:42:02.514487 11185 sgd_solver.cpp:106] Iteration 65000, lr = 0.0005
I1130 21:42:06.691149 11185 solver.cpp:228] Iteration 65500, loss = 0.123806
I1130 21:42:06.691203 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.012252 (* 0.5 = 0.006126 loss)
I1130 21:42:06.691210 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0792347 (* 1 = 0.0792347 loss)
I1130 21:42:06.691215 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:42:06.691220 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:42:06.691232 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00456637 (* 0.5 = 0.00228318 loss)
I1130 21:42:06.691237 11185 sgd_solver.cpp:106] Iteration 65500, lr = 0.0005
I1130 21:42:10.877873 11185 solver.cpp:228] Iteration 66000, loss = 0.0999662
I1130 21:42:10.877945 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0132609 (* 0.5 = 0.00663046 loss)
I1130 21:42:10.877952 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0818366 (* 1 = 0.0818366 loss)
I1130 21:42:10.877956 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:42:10.877960 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:42:10.877982 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00482925 (* 0.5 = 0.00241463 loss)
I1130 21:42:10.877988 11185 sgd_solver.cpp:106] Iteration 66000, lr = 0.0005
I1130 21:42:15.082247 11185 solver.cpp:228] Iteration 66500, loss = 0.107822
I1130 21:42:15.082334 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.011989 (* 0.5 = 0.00599451 loss)
I1130 21:42:15.082346 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0883487 (* 1 = 0.0883487 loss)
I1130 21:42:15.082355 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:42:15.082361 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:42:15.082370 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0047498 (* 0.5 = 0.0023749 loss)
I1130 21:42:15.082378 11185 sgd_solver.cpp:106] Iteration 66500, lr = 0.0005
I1130 21:42:19.323650 11185 solver.cpp:228] Iteration 67000, loss = 0.104449
I1130 21:42:19.323711 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.013212 (* 0.5 = 0.00660601 loss)
I1130 21:42:19.323719 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.085656 (* 1 = 0.085656 loss)
I1130 21:42:19.323724 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:42:19.323729 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:42:19.323740 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00515623 (* 0.5 = 0.00257811 loss)
I1130 21:42:19.323745 11185 sgd_solver.cpp:106] Iteration 67000, lr = 0.0005
I1130 21:42:23.510757 11185 solver.cpp:228] Iteration 67500, loss = 0.104156
I1130 21:42:23.510813 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0128468 (* 0.5 = 0.00642338 loss)
I1130 21:42:23.510821 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.105802 (* 1 = 0.105802 loss)
I1130 21:42:23.510834 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:42:23.510838 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.796875
I1130 21:42:23.510843 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00418788 (* 0.5 = 0.00209394 loss)
I1130 21:42:23.510848 11185 sgd_solver.cpp:106] Iteration 67500, lr = 0.0005
I1130 21:42:27.495748 11185 solver.cpp:228] Iteration 68000, loss = 0.110351
I1130 21:42:27.495796 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.01424 (* 0.5 = 0.00711999 loss)
I1130 21:42:27.495805 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.115637 (* 1 = 0.115637 loss)
I1130 21:42:27.495808 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:42:27.495812 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.78125
I1130 21:42:27.495816 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00439691 (* 0.5 = 0.00219845 loss)
I1130 21:42:27.495821 11185 sgd_solver.cpp:106] Iteration 68000, lr = 0.0005
I1130 21:42:31.271772 11185 solver.cpp:228] Iteration 68500, loss = 0.12293
I1130 21:42:31.271801 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.012124 (* 0.5 = 0.00606198 loss)
I1130 21:42:31.271808 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.108991 (* 1 = 0.108991 loss)
I1130 21:42:31.271812 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.953125
I1130 21:42:31.271816 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 21:42:31.271821 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00456393 (* 0.5 = 0.00228196 loss)
I1130 21:42:31.271824 11185 sgd_solver.cpp:106] Iteration 68500, lr = 0.0005
I1130 21:42:35.044327 11185 solver.cpp:228] Iteration 69000, loss = 0.104323
I1130 21:42:35.044353 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0126103 (* 0.5 = 0.00630515 loss)
I1130 21:42:35.044359 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.10469 (* 1 = 0.10469 loss)
I1130 21:42:35.044363 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:42:35.044378 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 21:42:35.044384 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00361108 (* 0.5 = 0.00180554 loss)
I1130 21:42:35.044387 11185 sgd_solver.cpp:106] Iteration 69000, lr = 0.0005
I1130 21:42:35.474274 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_69058.caffemodel
I1130 21:42:35.476492 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_69058.solverstate
I1130 21:42:35.476652 11185 solver.cpp:337] Iteration 69058, Testing net (#0)
I1130 21:42:47.591168 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0133936 (* 0.5 = 0.00669681 loss)
I1130 21:42:47.591210 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.106217 (* 1 = 0.106217 loss)
I1130 21:42:47.591215 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.966099
I1130 21:42:47.591219 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.816118
I1130 21:42:47.591225 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00465923 (* 0.5 = 0.00232961 loss)
I1130 21:42:51.097685 11185 solver.cpp:228] Iteration 69500, loss = 0.126324
I1130 21:42:51.097726 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.011243 (* 0.5 = 0.00562149 loss)
I1130 21:42:51.097733 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0999808 (* 1 = 0.0999808 loss)
I1130 21:42:51.097738 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:42:51.097741 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.867188
I1130 21:42:51.097745 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00570964 (* 0.5 = 0.00285482 loss)
I1130 21:42:51.097750 11185 sgd_solver.cpp:106] Iteration 69500, lr = 0.0005
I1130 21:42:54.863284 11185 solver.cpp:228] Iteration 70000, loss = 0.10354
I1130 21:42:54.863307 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0134131 (* 0.5 = 0.00670657 loss)
I1130 21:42:54.863314 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0950915 (* 1 = 0.0950915 loss)
I1130 21:42:54.863317 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.947917
I1130 21:42:54.863322 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:42:54.863325 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00690365 (* 0.5 = 0.00345183 loss)
I1130 21:42:54.863329 11185 sgd_solver.cpp:106] Iteration 70000, lr = 0.0005
I1130 21:42:58.631391 11185 solver.cpp:228] Iteration 70500, loss = 0.0951142
I1130 21:42:58.631419 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0128386 (* 0.5 = 0.0064193 loss)
I1130 21:42:58.631427 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0589521 (* 1 = 0.0589521 loss)
I1130 21:42:58.631430 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 21:42:58.631434 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 21:42:58.631438 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00285906 (* 0.5 = 0.00142953 loss)
I1130 21:42:58.631443 11185 sgd_solver.cpp:106] Iteration 70500, lr = 0.0005
I1130 21:43:02.404016 11185 solver.cpp:228] Iteration 71000, loss = 0.0743474
I1130 21:43:02.404037 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0141291 (* 0.5 = 0.00706456 loss)
I1130 21:43:02.404043 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0711088 (* 1 = 0.0711088 loss)
I1130 21:43:02.404047 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:43:02.404052 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.882812
I1130 21:43:02.404055 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00435753 (* 0.5 = 0.00217877 loss)
I1130 21:43:02.404059 11185 sgd_solver.cpp:106] Iteration 71000, lr = 0.0005
I1130 21:43:06.184214 11185 solver.cpp:228] Iteration 71500, loss = 0.0972315
I1130 21:43:06.184245 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0139569 (* 0.5 = 0.00697844 loss)
I1130 21:43:06.184252 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.106639 (* 1 = 0.106639 loss)
I1130 21:43:06.184257 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:43:06.184260 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:43:06.184264 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00420724 (* 0.5 = 0.00210362 loss)
I1130 21:43:06.184268 11185 sgd_solver.cpp:106] Iteration 71500, lr = 0.0005
I1130 21:43:09.963985 11185 solver.cpp:228] Iteration 72000, loss = 0.11025
I1130 21:43:09.964010 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0129759 (* 0.5 = 0.00648797 loss)
I1130 21:43:09.964015 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.107629 (* 1 = 0.107629 loss)
I1130 21:43:09.964020 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:43:09.964022 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:43:09.964026 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00417773 (* 0.5 = 0.00208886 loss)
I1130 21:43:09.964030 11185 sgd_solver.cpp:106] Iteration 72000, lr = 0.0005
I1130 21:43:13.733507 11185 solver.cpp:228] Iteration 72500, loss = 0.105388
I1130 21:43:13.733530 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0141893 (* 0.5 = 0.00709463 loss)
I1130 21:43:13.733536 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.123734 (* 1 = 0.123734 loss)
I1130 21:43:13.733541 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:43:13.733543 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.796875
I1130 21:43:13.733548 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00381944 (* 0.5 = 0.00190972 loss)
I1130 21:43:13.733551 11185 sgd_solver.cpp:106] Iteration 72500, lr = 0.0005
I1130 21:43:17.508455 11185 solver.cpp:228] Iteration 73000, loss = 0.112094
I1130 21:43:17.508476 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0132466 (* 0.5 = 0.00662329 loss)
I1130 21:43:17.508483 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.11375 (* 1 = 0.11375 loss)
I1130 21:43:17.508486 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:43:17.508491 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.796875
I1130 21:43:17.508494 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00504825 (* 0.5 = 0.00252412 loss)
I1130 21:43:17.508498 11185 sgd_solver.cpp:106] Iteration 73000, lr = 0.0005
I1130 21:43:21.287971 11185 solver.cpp:228] Iteration 73500, loss = 0.113431
I1130 21:43:21.288038 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0121442 (* 0.5 = 0.00607212 loss)
I1130 21:43:21.288046 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.123438 (* 1 = 0.123438 loss)
I1130 21:43:21.288050 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:43:21.288053 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.773438
I1130 21:43:21.288058 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00362238 (* 0.5 = 0.00181119 loss)
I1130 21:43:21.288063 11185 sgd_solver.cpp:106] Iteration 73500, lr = 0.0005
I1130 21:43:25.048331 11185 solver.cpp:228] Iteration 74000, loss = 0.1231
I1130 21:43:25.048355 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0138876 (* 0.5 = 0.00694378 loss)
I1130 21:43:25.048362 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0944954 (* 1 = 0.0944954 loss)
I1130 21:43:25.048365 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:43:25.048369 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:43:25.048373 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00483444 (* 0.5 = 0.00241722 loss)
I1130 21:43:25.048384 11185 sgd_solver.cpp:106] Iteration 74000, lr = 0.0005
I1130 21:43:28.809232 11185 solver.cpp:228] Iteration 74500, loss = 0.108035
I1130 21:43:28.809258 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.011786 (* 0.5 = 0.005893 loss)
I1130 21:43:28.809264 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.103513 (* 1 = 0.103513 loss)
I1130 21:43:28.809268 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:43:28.809273 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.820312
I1130 21:43:28.809276 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00560754 (* 0.5 = 0.00280377 loss)
I1130 21:43:28.809280 11185 sgd_solver.cpp:106] Iteration 74500, lr = 0.0005
I1130 21:43:32.575706 11185 solver.cpp:228] Iteration 75000, loss = 0.105695
I1130 21:43:32.575729 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0124315 (* 0.5 = 0.00621576 loss)
I1130 21:43:32.575736 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0865406 (* 1 = 0.0865406 loss)
I1130 21:43:32.575740 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:43:32.575743 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:43:32.575747 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00429743 (* 0.5 = 0.00214872 loss)
I1130 21:43:32.575752 11185 sgd_solver.cpp:106] Iteration 75000, lr = 0.0005
I1130 21:43:35.099143 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_75336.caffemodel
I1130 21:43:35.101418 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_75336.solverstate
I1130 21:43:35.101578 11185 solver.cpp:337] Iteration 75336, Testing net (#0)
I1130 21:43:47.298513 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.013184 (* 0.5 = 0.00659198 loss)
I1130 21:43:47.298564 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.110994 (* 1 = 0.110994 loss)
I1130 21:43:47.298569 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.955177
I1130 21:43:47.298573 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.834824
I1130 21:43:47.298578 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00466644 (* 0.5 = 0.00233322 loss)
I1130 21:43:48.637060 11185 solver.cpp:228] Iteration 75500, loss = 0.106354
I1130 21:43:48.637091 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0143492 (* 0.5 = 0.0071746 loss)
I1130 21:43:48.637099 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.107063 (* 1 = 0.107063 loss)
I1130 21:43:48.637102 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.950521
I1130 21:43:48.637106 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:43:48.637110 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00515373 (* 0.5 = 0.00257687 loss)
I1130 21:43:48.637115 11185 sgd_solver.cpp:106] Iteration 75500, lr = 0.0005
I1130 21:43:52.474858 11185 solver.cpp:228] Iteration 76000, loss = 0.100072
I1130 21:43:52.474880 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.014331 (* 0.5 = 0.00716552 loss)
I1130 21:43:52.474887 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.107532 (* 1 = 0.107532 loss)
I1130 21:43:52.474891 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:43:52.474895 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.773438
I1130 21:43:52.474900 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00543913 (* 0.5 = 0.00271957 loss)
I1130 21:43:52.474903 11185 sgd_solver.cpp:106] Iteration 76000, lr = 0.0005
I1130 21:43:56.258935 11185 solver.cpp:228] Iteration 76500, loss = 0.110936
I1130 21:43:56.258965 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0116856 (* 0.5 = 0.00584282 loss)
I1130 21:43:56.258971 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.107301 (* 1 = 0.107301 loss)
I1130 21:43:56.258982 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:43:56.258986 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:43:56.258991 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00449411 (* 0.5 = 0.00224706 loss)
I1130 21:43:56.258994 11185 sgd_solver.cpp:106] Iteration 76500, lr = 0.0005
I1130 21:44:00.047281 11185 solver.cpp:228] Iteration 77000, loss = 0.108955
I1130 21:44:00.047304 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0122594 (* 0.5 = 0.00612969 loss)
I1130 21:44:00.047310 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.110601 (* 1 = 0.110601 loss)
I1130 21:44:00.047314 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.955729
I1130 21:44:00.047317 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:44:00.047322 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00425113 (* 0.5 = 0.00212556 loss)
I1130 21:44:00.047325 11185 sgd_solver.cpp:106] Iteration 77000, lr = 0.0005
I1130 21:44:03.835166 11185 solver.cpp:228] Iteration 77500, loss = 0.0949037
I1130 21:44:03.835187 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0116533 (* 0.5 = 0.00582665 loss)
I1130 21:44:03.835193 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.053334 (* 1 = 0.053334 loss)
I1130 21:44:03.835197 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 21:44:03.835201 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 21:44:03.835206 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00429103 (* 0.5 = 0.00214551 loss)
I1130 21:44:03.835209 11185 sgd_solver.cpp:106] Iteration 77500, lr = 0.0005
I1130 21:44:07.613409 11185 solver.cpp:228] Iteration 78000, loss = 0.0891023
I1130 21:44:07.613430 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0138002 (* 0.5 = 0.00690008 loss)
I1130 21:44:07.613437 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.124085 (* 1 = 0.124085 loss)
I1130 21:44:07.613440 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:44:07.613445 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.773438
I1130 21:44:07.613448 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0044789 (* 0.5 = 0.00223945 loss)
I1130 21:44:07.613452 11185 sgd_solver.cpp:106] Iteration 78000, lr = 0.0005
I1130 21:44:11.392339 11185 solver.cpp:228] Iteration 78500, loss = 0.110834
I1130 21:44:11.392365 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0152857 (* 0.5 = 0.00764283 loss)
I1130 21:44:11.392372 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.113893 (* 1 = 0.113893 loss)
I1130 21:44:11.392375 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.955729
I1130 21:44:11.392379 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.765625
I1130 21:44:11.392383 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.004681 (* 0.5 = 0.0023405 loss)
I1130 21:44:11.392387 11185 sgd_solver.cpp:106] Iteration 78500, lr = 0.0005
I1130 21:44:15.178426 11185 solver.cpp:228] Iteration 79000, loss = 0.108689
I1130 21:44:15.178455 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0140905 (* 0.5 = 0.00704524 loss)
I1130 21:44:15.178464 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.11157 (* 1 = 0.11157 loss)
I1130 21:44:15.178469 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:44:15.178474 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:44:15.178479 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00455139 (* 0.5 = 0.0022757 loss)
I1130 21:44:15.178485 11185 sgd_solver.cpp:106] Iteration 79000, lr = 0.0005
I1130 21:44:18.964929 11185 solver.cpp:228] Iteration 79500, loss = 0.0970563
I1130 21:44:18.964957 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0117871 (* 0.5 = 0.00589353 loss)
I1130 21:44:18.964963 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0590118 (* 1 = 0.0590118 loss)
I1130 21:44:18.964967 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.986979
I1130 21:44:18.964972 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 21:44:18.964975 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00441123 (* 0.5 = 0.00220562 loss)
I1130 21:44:18.964979 11185 sgd_solver.cpp:106] Iteration 79500, lr = 0.0005
I1130 21:44:22.756583 11185 solver.cpp:228] Iteration 80000, loss = 0.0950834
I1130 21:44:22.756606 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0137917 (* 0.5 = 0.00689584 loss)
I1130 21:44:22.756613 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0762447 (* 1 = 0.0762447 loss)
I1130 21:44:22.756616 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:44:22.756619 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:44:22.756624 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00393215 (* 0.5 = 0.00196608 loss)
I1130 21:44:22.756628 11185 sgd_solver.cpp:106] Iteration 80000, lr = 0.0005
I1130 21:44:26.540815 11185 solver.cpp:228] Iteration 80500, loss = 0.113374
I1130 21:44:26.540841 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0136029 (* 0.5 = 0.00680147 loss)
I1130 21:44:26.540848 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.110825 (* 1 = 0.110825 loss)
I1130 21:44:26.540853 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:44:26.540855 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:44:26.540860 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00517492 (* 0.5 = 0.00258746 loss)
I1130 21:44:26.540863 11185 sgd_solver.cpp:106] Iteration 80500, lr = 0.0005
I1130 21:44:30.446667 11185 solver.cpp:228] Iteration 81000, loss = 0.109643
I1130 21:44:30.446717 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0135386 (* 0.5 = 0.00676929 loss)
I1130 21:44:30.446732 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0785434 (* 1 = 0.0785434 loss)
I1130 21:44:30.446737 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:44:30.446740 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.882812
I1130 21:44:30.446745 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00504806 (* 0.5 = 0.00252403 loss)
I1130 21:44:30.446750 11185 sgd_solver.cpp:106] Iteration 81000, lr = 0.0005
I1130 21:44:34.610004 11185 solver.cpp:228] Iteration 81500, loss = 0.115437
I1130 21:44:34.610072 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0140939 (* 0.5 = 0.00704693 loss)
I1130 21:44:34.610082 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.106739 (* 1 = 0.106739 loss)
I1130 21:44:34.610086 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.971354
I1130 21:44:34.610090 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.820312
I1130 21:44:34.610102 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00438163 (* 0.5 = 0.00219082 loss)
I1130 21:44:34.610107 11185 sgd_solver.cpp:106] Iteration 81500, lr = 0.0005
I1130 21:44:35.546169 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_81614.caffemodel
I1130 21:44:35.548542 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_81614.solverstate
I1130 21:44:35.548717 11185 solver.cpp:337] Iteration 81614, Testing net (#0)
I1130 21:44:48.093454 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0133369 (* 0.5 = 0.00666843 loss)
I1130 21:44:48.093493 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.106992 (* 1 = 0.106992 loss)
I1130 21:44:48.093499 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.966094
I1130 21:44:48.093514 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.814552
I1130 21:44:48.093519 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.0046688 (* 0.5 = 0.0023344 loss)
I1130 21:44:51.094682 11185 solver.cpp:228] Iteration 82000, loss = 0.109734
I1130 21:44:51.094723 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0134009 (* 0.5 = 0.00670047 loss)
I1130 21:44:51.094730 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.136353 (* 1 = 0.136353 loss)
I1130 21:44:51.094734 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.955729
I1130 21:44:51.094738 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.765625
I1130 21:44:51.094743 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00465044 (* 0.5 = 0.00232522 loss)
I1130 21:44:51.094746 11185 sgd_solver.cpp:106] Iteration 82000, lr = 0.0005
I1130 21:44:54.870849 11185 solver.cpp:228] Iteration 82500, loss = 0.128595
I1130 21:44:54.870872 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0119767 (* 0.5 = 0.00598835 loss)
I1130 21:44:54.870879 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0931384 (* 1 = 0.0931384 loss)
I1130 21:44:54.870882 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:44:54.870887 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:44:54.870890 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00527608 (* 0.5 = 0.00263804 loss)
I1130 21:44:54.870894 11185 sgd_solver.cpp:106] Iteration 82500, lr = 0.0005
I1130 21:44:58.648370 11185 solver.cpp:228] Iteration 83000, loss = 0.107268
I1130 21:44:58.648398 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0123555 (* 0.5 = 0.00617777 loss)
I1130 21:44:58.648406 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0793216 (* 1 = 0.0793216 loss)
I1130 21:44:58.648409 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 21:44:58.648412 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.867188
I1130 21:44:58.648416 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00433102 (* 0.5 = 0.00216551 loss)
I1130 21:44:58.648422 11185 sgd_solver.cpp:106] Iteration 83000, lr = 0.0005
I1130 21:45:02.426730 11185 solver.cpp:228] Iteration 83500, loss = 0.106102
I1130 21:45:02.426753 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.013065 (* 0.5 = 0.00653249 loss)
I1130 21:45:02.426759 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0737923 (* 1 = 0.0737923 loss)
I1130 21:45:02.426762 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:45:02.426766 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:45:02.426770 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0050214 (* 0.5 = 0.0025107 loss)
I1130 21:45:02.426774 11185 sgd_solver.cpp:106] Iteration 83500, lr = 0.0005
I1130 21:45:06.205355 11185 solver.cpp:228] Iteration 84000, loss = 0.091109
I1130 21:45:06.205377 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0154308 (* 0.5 = 0.00771541 loss)
I1130 21:45:06.205384 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0880251 (* 1 = 0.0880251 loss)
I1130 21:45:06.205387 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:45:06.205391 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:45:06.205395 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00456665 (* 0.5 = 0.00228332 loss)
I1130 21:45:06.205399 11185 sgd_solver.cpp:106] Iteration 84000, lr = 0.0005
I1130 21:45:09.989331 11185 solver.cpp:228] Iteration 84500, loss = 0.0884353
I1130 21:45:09.989352 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0131547 (* 0.5 = 0.00657735 loss)
I1130 21:45:09.989359 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0756572 (* 1 = 0.0756572 loss)
I1130 21:45:09.989368 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:45:09.989372 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.882812
I1130 21:45:09.989377 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00426814 (* 0.5 = 0.00213407 loss)
I1130 21:45:09.989382 11185 sgd_solver.cpp:106] Iteration 84500, lr = 0.0005
I1130 21:45:13.757510 11185 solver.cpp:228] Iteration 85000, loss = 0.0822727
I1130 21:45:13.757531 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0118465 (* 0.5 = 0.00592326 loss)
I1130 21:45:13.757537 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0998454 (* 1 = 0.0998454 loss)
I1130 21:45:13.757541 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:45:13.757544 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:45:13.757550 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00464288 (* 0.5 = 0.00232144 loss)
I1130 21:45:13.757553 11185 sgd_solver.cpp:106] Iteration 85000, lr = 0.0005
I1130 21:45:17.522835 11185 solver.cpp:228] Iteration 85500, loss = 0.113244
I1130 21:45:17.522861 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0163243 (* 0.5 = 0.00816214 loss)
I1130 21:45:17.522867 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.117229 (* 1 = 0.117229 loss)
I1130 21:45:17.522871 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:45:17.522874 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.796875
I1130 21:45:17.522878 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00311735 (* 0.5 = 0.00155868 loss)
I1130 21:45:17.522882 11185 sgd_solver.cpp:106] Iteration 85500, lr = 0.0005
I1130 21:45:21.290837 11185 solver.cpp:228] Iteration 86000, loss = 0.113878
I1130 21:45:21.290858 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0142295 (* 0.5 = 0.00711475 loss)
I1130 21:45:21.290864 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0897424 (* 1 = 0.0897424 loss)
I1130 21:45:21.290868 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:45:21.290871 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.867188
I1130 21:45:21.290875 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00454527 (* 0.5 = 0.00227264 loss)
I1130 21:45:21.290879 11185 sgd_solver.cpp:106] Iteration 86000, lr = 0.0005
I1130 21:45:25.063103 11185 solver.cpp:228] Iteration 86500, loss = 0.114306
I1130 21:45:25.063125 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0144463 (* 0.5 = 0.00722314 loss)
I1130 21:45:25.063132 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.10392 (* 1 = 0.10392 loss)
I1130 21:45:25.063135 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:45:25.063138 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.796875
I1130 21:45:25.063143 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00610702 (* 0.5 = 0.00305351 loss)
I1130 21:45:25.063146 11185 sgd_solver.cpp:106] Iteration 86500, lr = 0.0005
I1130 21:45:28.828836 11185 solver.cpp:228] Iteration 87000, loss = 0.107539
I1130 21:45:28.828866 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0125891 (* 0.5 = 0.00629454 loss)
I1130 21:45:28.828872 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0928442 (* 1 = 0.0928442 loss)
I1130 21:45:28.828876 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:45:28.828879 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:45:28.828883 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00472837 (* 0.5 = 0.00236418 loss)
I1130 21:45:28.828887 11185 sgd_solver.cpp:106] Iteration 87000, lr = 0.0005
I1130 21:45:32.604409 11185 solver.cpp:228] Iteration 87500, loss = 0.114853
I1130 21:45:32.604432 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0126436 (* 0.5 = 0.00632179 loss)
I1130 21:45:32.604444 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.118461 (* 1 = 0.118461 loss)
I1130 21:45:32.604449 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.971354
I1130 21:45:32.604452 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.78125
I1130 21:45:32.604456 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00413747 (* 0.5 = 0.00206873 loss)
I1130 21:45:32.604460 11185 sgd_solver.cpp:106] Iteration 87500, lr = 0.0005
I1130 21:45:35.555971 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_87892.caffemodel
I1130 21:45:35.558188 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_87892.solverstate
I1130 21:45:35.558346 11185 solver.cpp:337] Iteration 87892, Testing net (#0)
I1130 21:45:47.336446 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0132941 (* 0.5 = 0.00664706 loss)
I1130 21:45:47.336483 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.108032 (* 1 = 0.108032 loss)
I1130 21:45:47.336488 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.963553
I1130 21:45:47.336493 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.820503
I1130 21:45:47.336498 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00462082 (* 0.5 = 0.00231041 loss)
I1130 21:45:47.986057 11185 solver.cpp:228] Iteration 88000, loss = 0.102556
I1130 21:45:47.986085 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0118619 (* 0.5 = 0.00593094 loss)
I1130 21:45:47.986093 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0987977 (* 1 = 0.0987977 loss)
I1130 21:45:47.986109 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:45:47.986111 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:45:47.986116 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00472223 (* 0.5 = 0.00236112 loss)
I1130 21:45:47.986121 11185 sgd_solver.cpp:106] Iteration 88000, lr = 0.0005
I1130 21:45:51.792871 11185 solver.cpp:228] Iteration 88500, loss = 0.10276
I1130 21:45:51.792893 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0136481 (* 0.5 = 0.00682405 loss)
I1130 21:45:51.792901 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.115098 (* 1 = 0.115098 loss)
I1130 21:45:51.792904 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:45:51.792907 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.773438
I1130 21:45:51.792912 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00396701 (* 0.5 = 0.0019835 loss)
I1130 21:45:51.792917 11185 sgd_solver.cpp:106] Iteration 88500, lr = 0.0005
I1130 21:45:55.582789 11185 solver.cpp:228] Iteration 89000, loss = 0.108806
I1130 21:45:55.582811 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.012044 (* 0.5 = 0.00602201 loss)
I1130 21:45:55.582818 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.10101 (* 1 = 0.10101 loss)
I1130 21:45:55.582821 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:45:55.582825 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:45:55.582829 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00628069 (* 0.5 = 0.00314035 loss)
I1130 21:45:55.582834 11185 sgd_solver.cpp:106] Iteration 89000, lr = 0.0005
I1130 21:45:59.363319 11185 solver.cpp:228] Iteration 89500, loss = 0.111462
I1130 21:45:59.363346 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0133524 (* 0.5 = 0.00667622 loss)
I1130 21:45:59.363353 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0699992 (* 1 = 0.0699992 loss)
I1130 21:45:59.363356 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.986979
I1130 21:45:59.363359 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 21:45:59.363370 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0046573 (* 0.5 = 0.00232865 loss)
I1130 21:45:59.363374 11185 sgd_solver.cpp:106] Iteration 89500, lr = 0.0005
I1130 21:46:03.148999 11185 solver.cpp:228] Iteration 90000, loss = 0.117146
I1130 21:46:03.149020 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0123591 (* 0.5 = 0.00617956 loss)
I1130 21:46:03.149027 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.106356 (* 1 = 0.106356 loss)
I1130 21:46:03.149030 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:46:03.149034 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 21:46:03.149039 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00573944 (* 0.5 = 0.00286972 loss)
I1130 21:46:03.149042 11185 sgd_solver.cpp:106] Iteration 90000, lr = 0.0005
I1130 21:46:06.933544 11185 solver.cpp:228] Iteration 90500, loss = 0.108801
I1130 21:46:06.933567 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0133709 (* 0.5 = 0.00668544 loss)
I1130 21:46:06.933573 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0887141 (* 1 = 0.0887141 loss)
I1130 21:46:06.933576 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:46:06.933579 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.835938
I1130 21:46:06.933584 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00338107 (* 0.5 = 0.00169053 loss)
I1130 21:46:06.933588 11185 sgd_solver.cpp:106] Iteration 90500, lr = 0.0005
I1130 21:46:10.714540 11185 solver.cpp:228] Iteration 91000, loss = 0.115523
I1130 21:46:10.714561 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.013737 (* 0.5 = 0.00686849 loss)
I1130 21:46:10.714568 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.10997 (* 1 = 0.10997 loss)
I1130 21:46:10.714571 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:46:10.714576 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:46:10.714579 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00375925 (* 0.5 = 0.00187962 loss)
I1130 21:46:10.714583 11185 sgd_solver.cpp:106] Iteration 91000, lr = 0.0005
I1130 21:46:14.495383 11185 solver.cpp:228] Iteration 91500, loss = 0.0912959
I1130 21:46:14.495406 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0126012 (* 0.5 = 0.00630058 loss)
I1130 21:46:14.495414 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0659639 (* 1 = 0.0659639 loss)
I1130 21:46:14.495416 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:46:14.495420 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:46:14.495424 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00651556 (* 0.5 = 0.00325778 loss)
I1130 21:46:14.495429 11185 sgd_solver.cpp:106] Iteration 91500, lr = 0.0005
I1130 21:46:18.276562 11185 solver.cpp:228] Iteration 92000, loss = 0.0831495
I1130 21:46:18.276590 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0104495 (* 0.5 = 0.00522477 loss)
I1130 21:46:18.276597 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.073656 (* 1 = 0.073656 loss)
I1130 21:46:18.276600 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:46:18.276604 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.882812
I1130 21:46:18.276608 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00499209 (* 0.5 = 0.00249605 loss)
I1130 21:46:18.276612 11185 sgd_solver.cpp:106] Iteration 92000, lr = 0.0005
I1130 21:46:22.061019 11185 solver.cpp:228] Iteration 92500, loss = 0.0972018
I1130 21:46:22.061043 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0113991 (* 0.5 = 0.00569956 loss)
I1130 21:46:22.061049 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0796379 (* 1 = 0.0796379 loss)
I1130 21:46:22.061053 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:46:22.061072 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:46:22.061080 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00433661 (* 0.5 = 0.00216831 loss)
I1130 21:46:22.061084 11185 sgd_solver.cpp:106] Iteration 92500, lr = 0.0005
I1130 21:46:25.846678 11185 solver.cpp:228] Iteration 93000, loss = 0.105046
I1130 21:46:25.846699 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0145013 (* 0.5 = 0.00725067 loss)
I1130 21:46:25.846706 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0887119 (* 1 = 0.0887119 loss)
I1130 21:46:25.846709 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:46:25.846714 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:46:25.846717 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00469406 (* 0.5 = 0.00234703 loss)
I1130 21:46:25.846721 11185 sgd_solver.cpp:106] Iteration 93000, lr = 0.0005
I1130 21:46:29.630276 11185 solver.cpp:228] Iteration 93500, loss = 0.10067
I1130 21:46:29.630305 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0125349 (* 0.5 = 0.00626743 loss)
I1130 21:46:29.630311 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0750396 (* 1 = 0.0750396 loss)
I1130 21:46:29.630314 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 21:46:29.630318 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:46:29.630322 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00523213 (* 0.5 = 0.00261606 loss)
I1130 21:46:29.630326 11185 sgd_solver.cpp:106] Iteration 93500, lr = 0.0005
I1130 21:46:33.404836 11185 solver.cpp:228] Iteration 94000, loss = 0.106533
I1130 21:46:33.404860 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0129872 (* 0.5 = 0.00649362 loss)
I1130 21:46:33.404865 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.119944 (* 1 = 0.119944 loss)
I1130 21:46:33.404868 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:46:33.404872 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.773438
I1130 21:46:33.404876 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00568828 (* 0.5 = 0.00284414 loss)
I1130 21:46:33.404881 11185 sgd_solver.cpp:106] Iteration 94000, lr = 0.0005
I1130 21:46:34.683761 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_94170.caffemodel
I1130 21:46:34.685976 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_94170.solverstate
I1130 21:46:34.686143 11185 solver.cpp:337] Iteration 94170, Testing net (#0)
I1130 21:46:46.430028 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0133049 (* 0.5 = 0.00665247 loss)
I1130 21:46:46.430053 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.106389 (* 1 = 0.106389 loss)
I1130 21:46:46.430058 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.970393
I1130 21:46:46.430063 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.806409
I1130 21:46:46.430070 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00467561 (* 0.5 = 0.0023378 loss)
I1130 21:46:49.055440 11185 solver.cpp:228] Iteration 94500, loss = 0.126213
I1130 21:46:49.055465 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0129301 (* 0.5 = 0.00646503 loss)
I1130 21:46:49.055471 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.113906 (* 1 = 0.113906 loss)
I1130 21:46:49.055475 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:46:49.055480 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:46:49.055483 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00395433 (* 0.5 = 0.00197716 loss)
I1130 21:46:49.055487 11185 sgd_solver.cpp:106] Iteration 94500, lr = 5e-05
I1130 21:46:52.830709 11185 solver.cpp:228] Iteration 95000, loss = 0.118175
I1130 21:46:52.830731 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0130716 (* 0.5 = 0.0065358 loss)
I1130 21:46:52.830737 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.131709 (* 1 = 0.131709 loss)
I1130 21:46:52.830741 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:46:52.830744 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:46:52.830749 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0049735 (* 0.5 = 0.00248675 loss)
I1130 21:46:52.830754 11185 sgd_solver.cpp:106] Iteration 95000, lr = 5e-05
I1130 21:46:56.597041 11185 solver.cpp:228] Iteration 95500, loss = 0.119
I1130 21:46:56.597084 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0140446 (* 0.5 = 0.00702232 loss)
I1130 21:46:56.597091 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.138497 (* 1 = 0.138497 loss)
I1130 21:46:56.597095 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:46:56.597100 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.75
I1130 21:46:56.597103 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00627258 (* 0.5 = 0.00313629 loss)
I1130 21:46:56.597107 11185 sgd_solver.cpp:106] Iteration 95500, lr = 5e-05
I1130 21:47:00.369772 11185 solver.cpp:228] Iteration 96000, loss = 0.110042
I1130 21:47:00.369796 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0148665 (* 0.5 = 0.00743325 loss)
I1130 21:47:00.369802 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.105478 (* 1 = 0.105478 loss)
I1130 21:47:00.369806 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:47:00.369809 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:47:00.369813 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0047979 (* 0.5 = 0.00239895 loss)
I1130 21:47:00.369817 11185 sgd_solver.cpp:106] Iteration 96000, lr = 5e-05
I1130 21:47:04.143956 11185 solver.cpp:228] Iteration 96500, loss = 0.104509
I1130 21:47:04.143978 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0132032 (* 0.5 = 0.0066016 loss)
I1130 21:47:04.143985 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0907596 (* 1 = 0.0907596 loss)
I1130 21:47:04.143988 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:47:04.143992 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:47:04.143996 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00392351 (* 0.5 = 0.00196176 loss)
I1130 21:47:04.144001 11185 sgd_solver.cpp:106] Iteration 96500, lr = 5e-05
I1130 21:47:07.926718 11185 solver.cpp:228] Iteration 97000, loss = 0.103693
I1130 21:47:07.926741 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0139272 (* 0.5 = 0.00696359 loss)
I1130 21:47:07.926748 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0980811 (* 1 = 0.0980811 loss)
I1130 21:47:07.926753 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:47:07.926755 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:47:07.926760 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0040974 (* 0.5 = 0.0020487 loss)
I1130 21:47:07.926764 11185 sgd_solver.cpp:106] Iteration 97000, lr = 5e-05
I1130 21:47:11.880158 11185 solver.cpp:228] Iteration 97500, loss = 0.107965
I1130 21:47:11.880204 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0126188 (* 0.5 = 0.00630941 loss)
I1130 21:47:11.880211 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0659781 (* 1 = 0.0659781 loss)
I1130 21:47:11.880215 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:47:11.880218 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.929688
I1130 21:47:11.880223 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0036724 (* 0.5 = 0.0018362 loss)
I1130 21:47:11.880239 11185 sgd_solver.cpp:106] Iteration 97500, lr = 5e-05
I1130 21:47:15.652658 11185 solver.cpp:228] Iteration 98000, loss = 0.102447
I1130 21:47:15.652683 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0161176 (* 0.5 = 0.00805881 loss)
I1130 21:47:15.652688 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.104464 (* 1 = 0.104464 loss)
I1130 21:47:15.652691 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:47:15.652695 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:47:15.652699 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00364005 (* 0.5 = 0.00182002 loss)
I1130 21:47:15.652704 11185 sgd_solver.cpp:106] Iteration 98000, lr = 5e-05
I1130 21:47:19.421537 11185 solver.cpp:228] Iteration 98500, loss = 0.09673
I1130 21:47:19.421566 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.013219 (* 0.5 = 0.0066095 loss)
I1130 21:47:19.421573 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0923707 (* 1 = 0.0923707 loss)
I1130 21:47:19.421577 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.971354
I1130 21:47:19.421581 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:47:19.421586 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00570308 (* 0.5 = 0.00285154 loss)
I1130 21:47:19.421589 11185 sgd_solver.cpp:106] Iteration 98500, lr = 5e-05
I1130 21:47:23.192579 11185 solver.cpp:228] Iteration 99000, loss = 0.0901439
I1130 21:47:23.192600 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0134535 (* 0.5 = 0.00672673 loss)
I1130 21:47:23.192606 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0987735 (* 1 = 0.0987735 loss)
I1130 21:47:23.192610 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:47:23.192613 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.867188
I1130 21:47:23.192617 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00375839 (* 0.5 = 0.00187919 loss)
I1130 21:47:23.192622 11185 sgd_solver.cpp:106] Iteration 99000, lr = 5e-05
I1130 21:47:26.958128 11185 solver.cpp:228] Iteration 99500, loss = 0.128458
I1130 21:47:26.958149 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.012896 (* 0.5 = 0.006448 loss)
I1130 21:47:26.958155 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.115479 (* 1 = 0.115479 loss)
I1130 21:47:26.958159 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.955729
I1130 21:47:26.958163 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:47:26.958168 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00537703 (* 0.5 = 0.00268852 loss)
I1130 21:47:26.958171 11185 sgd_solver.cpp:106] Iteration 99500, lr = 5e-05
I1130 21:47:30.726380 11185 solver.cpp:228] Iteration 100000, loss = 0.114021
I1130 21:47:30.726408 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00990683 (* 0.5 = 0.00495341 loss)
I1130 21:47:30.726415 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0931857 (* 1 = 0.0931857 loss)
I1130 21:47:30.726418 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 21:47:30.726423 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:47:30.726426 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00450629 (* 0.5 = 0.00225314 loss)
I1130 21:47:30.726430 11185 sgd_solver.cpp:106] Iteration 100000, lr = 5e-05
I1130 21:47:34.103070 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_100448.caffemodel
I1130 21:47:34.105334 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_100448.solverstate
I1130 21:47:34.105525 11185 solver.cpp:337] Iteration 100448, Testing net (#0)
I1130 21:47:46.337539 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0130919 (* 0.5 = 0.00654595 loss)
I1130 21:47:46.337590 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.104319 (* 1 = 0.104319 loss)
I1130 21:47:46.337596 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.967779
I1130 21:47:46.337599 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.816825
I1130 21:47:46.337604 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00464461 (* 0.5 = 0.0023223 loss)
I1130 21:47:46.650557 11185 solver.cpp:228] Iteration 100500, loss = 0.0982492
I1130 21:47:46.650576 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0130041 (* 0.5 = 0.00650205 loss)
I1130 21:47:46.650583 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0711494 (* 1 = 0.0711494 loss)
I1130 21:47:46.650588 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 21:47:46.650590 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.867188
I1130 21:47:46.650595 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00477884 (* 0.5 = 0.00238942 loss)
I1130 21:47:46.650599 11185 sgd_solver.cpp:106] Iteration 100500, lr = 5e-05
I1130 21:47:50.622442 11185 solver.cpp:228] Iteration 101000, loss = 0.0974199
I1130 21:47:50.622465 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0140665 (* 0.5 = 0.00703326 loss)
I1130 21:47:50.622473 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.122448 (* 1 = 0.122448 loss)
I1130 21:47:50.622476 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:47:50.622479 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.726562
I1130 21:47:50.622484 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00419549 (* 0.5 = 0.00209774 loss)
I1130 21:47:50.622488 11185 sgd_solver.cpp:106] Iteration 101000, lr = 5e-05
I1130 21:47:54.676852 11185 solver.cpp:228] Iteration 101500, loss = 0.118467
I1130 21:47:54.676909 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0140484 (* 0.5 = 0.00702418 loss)
I1130 21:47:54.676918 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0732671 (* 1 = 0.0732671 loss)
I1130 21:47:54.676921 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.986979
I1130 21:47:54.676926 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.835938
I1130 21:47:54.676930 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00315367 (* 0.5 = 0.00157683 loss)
I1130 21:47:54.676935 11185 sgd_solver.cpp:106] Iteration 101500, lr = 5e-05
I1130 21:47:58.823240 11185 solver.cpp:228] Iteration 102000, loss = 0.107542
I1130 21:47:58.823302 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0141559 (* 0.5 = 0.00707797 loss)
I1130 21:47:58.823310 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.10726 (* 1 = 0.10726 loss)
I1130 21:47:58.823314 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:47:58.823328 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:47:58.823333 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00494551 (* 0.5 = 0.00247275 loss)
I1130 21:47:58.823338 11185 sgd_solver.cpp:106] Iteration 102000, lr = 5e-05
I1130 21:48:02.982084 11185 solver.cpp:228] Iteration 102500, loss = 0.11562
I1130 21:48:02.982177 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.013492 (* 0.5 = 0.00674598 loss)
I1130 21:48:02.982184 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.112727 (* 1 = 0.112727 loss)
I1130 21:48:02.982189 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:48:02.982193 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:48:02.982198 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00569283 (* 0.5 = 0.00284641 loss)
I1130 21:48:02.982203 11185 sgd_solver.cpp:106] Iteration 102500, lr = 5e-05
I1130 21:48:07.145489 11185 solver.cpp:228] Iteration 103000, loss = 0.118341
I1130 21:48:07.145584 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0135269 (* 0.5 = 0.00676345 loss)
I1130 21:48:07.145592 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.105765 (* 1 = 0.105765 loss)
I1130 21:48:07.145597 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 21:48:07.145601 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.765625
I1130 21:48:07.145606 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00431911 (* 0.5 = 0.00215955 loss)
I1130 21:48:07.145611 11185 sgd_solver.cpp:106] Iteration 103000, lr = 5e-05
I1130 21:48:11.377742 11185 solver.cpp:228] Iteration 103500, loss = 0.114925
I1130 21:48:11.377800 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0120478 (* 0.5 = 0.0060239 loss)
I1130 21:48:11.377809 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.10583 (* 1 = 0.10583 loss)
I1130 21:48:11.377813 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:48:11.377817 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.820312
I1130 21:48:11.377830 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00382346 (* 0.5 = 0.00191173 loss)
I1130 21:48:11.377835 11185 sgd_solver.cpp:106] Iteration 103500, lr = 5e-05
I1130 21:48:15.541527 11185 solver.cpp:228] Iteration 104000, loss = 0.122793
I1130 21:48:15.541594 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0134164 (* 0.5 = 0.00670818 loss)
I1130 21:48:15.541601 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.104489 (* 1 = 0.104489 loss)
I1130 21:48:15.541605 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:48:15.541610 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:48:15.541615 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00573315 (* 0.5 = 0.00286658 loss)
I1130 21:48:15.541627 11185 sgd_solver.cpp:106] Iteration 104000, lr = 5e-05
I1130 21:48:19.766480 11185 solver.cpp:228] Iteration 104500, loss = 0.105014
I1130 21:48:19.766551 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0124923 (* 0.5 = 0.00624613 loss)
I1130 21:48:19.766564 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0723414 (* 1 = 0.0723414 loss)
I1130 21:48:19.766569 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:48:19.766573 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 21:48:19.766578 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00453054 (* 0.5 = 0.00226527 loss)
I1130 21:48:19.766583 11185 sgd_solver.cpp:106] Iteration 104500, lr = 5e-05
I1130 21:48:23.937630 11185 solver.cpp:228] Iteration 105000, loss = 0.0957962
I1130 21:48:23.937710 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0130708 (* 0.5 = 0.00653541 loss)
I1130 21:48:23.937716 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0803568 (* 1 = 0.0803568 loss)
I1130 21:48:23.937721 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:48:23.937724 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.898438
I1130 21:48:23.937729 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00349531 (* 0.5 = 0.00174765 loss)
I1130 21:48:23.937734 11185 sgd_solver.cpp:106] Iteration 105000, lr = 5e-05
I1130 21:48:28.090382 11185 solver.cpp:228] Iteration 105500, loss = 0.0810117
I1130 21:48:28.090469 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0118189 (* 0.5 = 0.00590947 loss)
I1130 21:48:28.090478 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0674206 (* 1 = 0.0674206 loss)
I1130 21:48:28.090483 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 21:48:28.090488 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 21:48:28.090494 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00704521 (* 0.5 = 0.0035226 loss)
I1130 21:48:28.090531 11185 sgd_solver.cpp:106] Iteration 105500, lr = 5e-05
I1130 21:48:32.257313 11185 solver.cpp:228] Iteration 106000, loss = 0.0921636
I1130 21:48:32.257387 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0134888 (* 0.5 = 0.0067444 loss)
I1130 21:48:32.257395 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0846906 (* 1 = 0.0846906 loss)
I1130 21:48:32.257398 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.971354
I1130 21:48:32.257402 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:48:32.257407 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00413082 (* 0.5 = 0.00206541 loss)
I1130 21:48:32.257412 11185 sgd_solver.cpp:106] Iteration 106000, lr = 5e-05
I1130 21:48:36.417734 11185 solver.cpp:228] Iteration 106500, loss = 0.112116
I1130 21:48:36.417785 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0144824 (* 0.5 = 0.00724121 loss)
I1130 21:48:36.417793 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.113173 (* 1 = 0.113173 loss)
I1130 21:48:36.417798 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:48:36.417800 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:48:36.417805 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00540749 (* 0.5 = 0.00270374 loss)
I1130 21:48:36.417819 11185 sgd_solver.cpp:106] Iteration 106500, lr = 5e-05
I1130 21:48:38.273480 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_106726.caffemodel
I1130 21:48:38.275835 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_106726.solverstate
I1130 21:48:38.276000 11185 solver.cpp:337] Iteration 106726, Testing net (#0)
I1130 21:48:51.483453 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0133838 (* 0.5 = 0.00669188 loss)
I1130 21:48:51.483484 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.100976 (* 1 = 0.100976 loss)
I1130 21:48:51.483489 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.974416
I1130 21:48:51.483492 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.805119
I1130 21:48:51.483499 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00463186 (* 0.5 = 0.00231593 loss)
I1130 21:48:53.790505 11185 solver.cpp:228] Iteration 107000, loss = 0.121172
I1130 21:48:53.790567 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0128144 (* 0.5 = 0.00640722 loss)
I1130 21:48:53.790575 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.081953 (* 1 = 0.081953 loss)
I1130 21:48:53.790580 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:48:53.790583 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 21:48:53.790587 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00334472 (* 0.5 = 0.00167236 loss)
I1130 21:48:53.790601 11185 sgd_solver.cpp:106] Iteration 107000, lr = 5e-05
I1130 21:48:57.907922 11185 solver.cpp:228] Iteration 107500, loss = 0.0978764
I1130 21:48:57.907985 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0122998 (* 0.5 = 0.00614988 loss)
I1130 21:48:57.907992 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0512159 (* 1 = 0.0512159 loss)
I1130 21:48:57.908005 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 21:48:57.908010 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 21:48:57.908013 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00434527 (* 0.5 = 0.00217263 loss)
I1130 21:48:57.908018 11185 sgd_solver.cpp:106] Iteration 107500, lr = 5e-05
I1130 21:49:02.060680 11185 solver.cpp:228] Iteration 108000, loss = 0.128596
I1130 21:49:02.060739 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0127112 (* 0.5 = 0.00635559 loss)
I1130 21:49:02.060747 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.139875 (* 1 = 0.139875 loss)
I1130 21:49:02.060775 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.947917
I1130 21:49:02.060780 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.75
I1130 21:49:02.060784 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00534344 (* 0.5 = 0.00267172 loss)
I1130 21:49:02.060788 11185 sgd_solver.cpp:106] Iteration 108000, lr = 5e-05
I1130 21:49:06.206420 11185 solver.cpp:228] Iteration 108500, loss = 0.122377
I1130 21:49:06.206475 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0126616 (* 0.5 = 0.0063308 loss)
I1130 21:49:06.206490 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.112212 (* 1 = 0.112212 loss)
I1130 21:49:06.206495 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:49:06.206498 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.789062
I1130 21:49:06.206503 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00552017 (* 0.5 = 0.00276009 loss)
I1130 21:49:06.206508 11185 sgd_solver.cpp:106] Iteration 108500, lr = 5e-05
I1130 21:49:10.376718 11185 solver.cpp:228] Iteration 109000, loss = 0.106162
I1130 21:49:10.376770 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0142803 (* 0.5 = 0.00714013 loss)
I1130 21:49:10.376786 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0820451 (* 1 = 0.0820451 loss)
I1130 21:49:10.376791 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.986979
I1130 21:49:10.376796 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:49:10.376801 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0041231 (* 0.5 = 0.00206155 loss)
I1130 21:49:10.376804 11185 sgd_solver.cpp:106] Iteration 109000, lr = 5e-05
I1130 21:49:14.514086 11185 solver.cpp:228] Iteration 109500, loss = 0.102048
I1130 21:49:14.514143 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0141687 (* 0.5 = 0.00708435 loss)
I1130 21:49:14.514150 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0823531 (* 1 = 0.0823531 loss)
I1130 21:49:14.514154 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 21:49:14.514158 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:49:14.514163 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00428756 (* 0.5 = 0.00214378 loss)
I1130 21:49:14.514168 11185 sgd_solver.cpp:106] Iteration 109500, lr = 5e-05
I1130 21:49:18.654603 11185 solver.cpp:228] Iteration 110000, loss = 0.110641
I1130 21:49:18.654664 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0133136 (* 0.5 = 0.00665681 loss)
I1130 21:49:18.654671 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0929389 (* 1 = 0.0929389 loss)
I1130 21:49:18.654675 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.958333
I1130 21:49:18.654680 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 21:49:18.654685 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00441641 (* 0.5 = 0.0022082 loss)
I1130 21:49:18.654695 11185 sgd_solver.cpp:106] Iteration 110000, lr = 5e-05
I1130 21:49:22.817833 11185 solver.cpp:228] Iteration 110500, loss = 0.10461
I1130 21:49:22.817905 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0137784 (* 0.5 = 0.00688918 loss)
I1130 21:49:22.817914 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0982491 (* 1 = 0.0982491 loss)
I1130 21:49:22.817919 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:49:22.817924 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.773438
I1130 21:49:22.817930 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00352167 (* 0.5 = 0.00176084 loss)
I1130 21:49:22.817936 11185 sgd_solver.cpp:106] Iteration 110500, lr = 5e-05
I1130 21:49:26.963341 11185 solver.cpp:228] Iteration 111000, loss = 0.118813
I1130 21:49:26.963412 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0113832 (* 0.5 = 0.00569159 loss)
I1130 21:49:26.963419 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.14448 (* 1 = 0.14448 loss)
I1130 21:49:26.963423 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.955729
I1130 21:49:26.963428 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.742188
I1130 21:49:26.963433 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00915049 (* 0.5 = 0.00457525 loss)
I1130 21:49:26.963436 11185 sgd_solver.cpp:106] Iteration 111000, lr = 5e-05
I1130 21:49:31.111049 11185 solver.cpp:228] Iteration 111500, loss = 0.110096
I1130 21:49:31.111115 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0130263 (* 0.5 = 0.00651313 loss)
I1130 21:49:31.111124 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0916499 (* 1 = 0.0916499 loss)
I1130 21:49:31.111127 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.986979
I1130 21:49:31.111131 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:49:31.111135 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00508836 (* 0.5 = 0.00254418 loss)
I1130 21:49:31.111140 11185 sgd_solver.cpp:106] Iteration 111500, lr = 5e-05
I1130 21:49:35.253974 11185 solver.cpp:228] Iteration 112000, loss = 0.105889
I1130 21:49:35.254040 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0118971 (* 0.5 = 0.00594853 loss)
I1130 21:49:35.254047 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0868068 (* 1 = 0.0868068 loss)
I1130 21:49:35.254051 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:49:35.254055 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 21:49:35.254060 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00444015 (* 0.5 = 0.00222007 loss)
I1130 21:49:35.254081 11185 sgd_solver.cpp:106] Iteration 112000, lr = 5e-05
I1130 21:49:39.414635 11185 solver.cpp:228] Iteration 112500, loss = 0.0946447
I1130 21:49:39.414688 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0117692 (* 0.5 = 0.0058846 loss)
I1130 21:49:39.414695 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0720255 (* 1 = 0.0720255 loss)
I1130 21:49:39.414700 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.981771
I1130 21:49:39.414703 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.898438
I1130 21:49:39.414708 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00462372 (* 0.5 = 0.00231186 loss)
I1130 21:49:39.414713 11185 sgd_solver.cpp:106] Iteration 112500, lr = 5e-05
I1130 21:49:43.584481 11185 solver.cpp:228] Iteration 113000, loss = 0.0938881
I1130 21:49:43.584543 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0148412 (* 0.5 = 0.00742062 loss)
I1130 21:49:43.584550 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0825815 (* 1 = 0.0825815 loss)
I1130 21:49:43.584554 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:49:43.584558 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 21:49:43.584563 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00551987 (* 0.5 = 0.00275994 loss)
I1130 21:49:43.584568 11185 sgd_solver.cpp:106] Iteration 113000, lr = 5e-05
I1130 21:49:43.609760 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_113004.caffemodel
I1130 21:49:43.612259 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_113004.solverstate
I1130 21:49:43.612423 11185 solver.cpp:337] Iteration 113004, Testing net (#0)
I1130 21:49:56.178453 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0131292 (* 0.5 = 0.00656461 loss)
I1130 21:49:56.178496 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.105354 (* 1 = 0.105354 loss)
I1130 21:49:56.178503 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.963331
I1130 21:49:56.178521 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.829003
I1130 21:49:56.178527 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00463638 (* 0.5 = 0.00231819 loss)
I1130 21:50:00.639320 11185 solver.cpp:228] Iteration 113500, loss = 0.106794
I1130 21:50:00.639359 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0146493 (* 0.5 = 0.00732467 loss)
I1130 21:50:00.639366 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0965018 (* 1 = 0.0965018 loss)
I1130 21:50:00.639370 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:50:00.639374 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.851562
I1130 21:50:00.639379 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00402293 (* 0.5 = 0.00201146 loss)
I1130 21:50:00.639384 11185 sgd_solver.cpp:106] Iteration 113500, lr = 5e-05
I1130 21:50:04.732079 11185 solver.cpp:228] Iteration 114000, loss = 0.101534
I1130 21:50:04.732098 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0130451 (* 0.5 = 0.00652255 loss)
I1130 21:50:04.732105 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0687733 (* 1 = 0.0687733 loss)
I1130 21:50:04.732110 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 21:50:04.732113 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:50:04.732117 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00487109 (* 0.5 = 0.00243554 loss)
I1130 21:50:04.732121 11185 sgd_solver.cpp:106] Iteration 114000, lr = 5e-05
I1130 21:50:09.062399 11185 solver.cpp:228] Iteration 114500, loss = 0.0970418
I1130 21:50:09.062464 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0133101 (* 0.5 = 0.00665505 loss)
I1130 21:50:09.062471 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.140422 (* 1 = 0.140422 loss)
I1130 21:50:09.062476 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:50:09.062480 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.6875
I1130 21:50:09.062485 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00388607 (* 0.5 = 0.00194304 loss)
I1130 21:50:09.062490 11185 sgd_solver.cpp:106] Iteration 114500, lr = 5e-05
I1130 21:50:13.440603 11185 solver.cpp:228] Iteration 115000, loss = 0.115872
I1130 21:50:13.440677 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0121969 (* 0.5 = 0.00609845 loss)
I1130 21:50:13.440686 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.131237 (* 1 = 0.131237 loss)
I1130 21:50:13.440690 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.947917
I1130 21:50:13.440695 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.757812
I1130 21:50:13.440699 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00501837 (* 0.5 = 0.00250919 loss)
I1130 21:50:13.440704 11185 sgd_solver.cpp:106] Iteration 115000, lr = 5e-05
I1130 21:50:17.734064 11185 solver.cpp:228] Iteration 115500, loss = 0.125942
I1130 21:50:17.734138 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.012548 (* 0.5 = 0.00627402 loss)
I1130 21:50:17.734148 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.102712 (* 1 = 0.102712 loss)
I1130 21:50:17.734151 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:50:17.734156 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.820312
I1130 21:50:17.734160 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0036438 (* 0.5 = 0.0018219 loss)
I1130 21:50:17.734166 11185 sgd_solver.cpp:106] Iteration 115500, lr = 5e-05
I1130 21:50:21.804025 11185 solver.cpp:228] Iteration 116000, loss = 0.106454
I1130 21:50:21.804100 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0143425 (* 0.5 = 0.00717125 loss)
I1130 21:50:21.804108 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.103649 (* 1 = 0.103649 loss)
I1130 21:50:21.804128 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 21:50:21.804133 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.796875
I1130 21:50:21.804138 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00437804 (* 0.5 = 0.00218902 loss)
I1130 21:50:21.804143 11185 sgd_solver.cpp:106] Iteration 116000, lr = 5e-05
I1130 21:50:25.903774 11185 solver.cpp:228] Iteration 116500, loss = 0.125774
I1130 21:50:25.903851 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0145233 (* 0.5 = 0.00726164 loss)
I1130 21:50:25.903861 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0926154 (* 1 = 0.0926154 loss)
I1130 21:50:25.903867 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 21:50:25.903872 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:50:25.903878 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00842595 (* 0.5 = 0.00421297 loss)
I1130 21:50:25.903885 11185 sgd_solver.cpp:106] Iteration 116500, lr = 5e-05
I1130 21:50:29.953712 11185 solver.cpp:228] Iteration 117000, loss = 0.119109
I1130 21:50:29.953754 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0129625 (* 0.5 = 0.00648123 loss)
I1130 21:50:29.953763 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.113395 (* 1 = 0.113395 loss)
I1130 21:50:29.953768 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:50:29.953773 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.804688
I1130 21:50:29.953778 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00500298 (* 0.5 = 0.00250149 loss)
I1130 21:50:29.953784 11185 sgd_solver.cpp:106] Iteration 117000, lr = 5e-05
I1130 21:50:33.762697 11185 solver.cpp:228] Iteration 117500, loss = 0.102021
I1130 21:50:33.762720 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0134757 (* 0.5 = 0.00673787 loss)
I1130 21:50:33.762727 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0782454 (* 1 = 0.0782454 loss)
I1130 21:50:33.762730 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:50:33.762734 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:50:33.762738 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00483457 (* 0.5 = 0.00241728 loss)
I1130 21:50:33.762743 11185 sgd_solver.cpp:106] Iteration 117500, lr = 5e-05
I1130 21:50:37.571691 11185 solver.cpp:228] Iteration 118000, loss = 0.107139
I1130 21:50:37.571712 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0131599 (* 0.5 = 0.00657995 loss)
I1130 21:50:37.571718 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0988065 (* 1 = 0.0988065 loss)
I1130 21:50:37.571722 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:50:37.571727 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.835938
I1130 21:50:37.571730 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00399539 (* 0.5 = 0.0019977 loss)
I1130 21:50:37.571735 11185 sgd_solver.cpp:106] Iteration 118000, lr = 5e-05
I1130 21:50:41.534754 11185 solver.cpp:228] Iteration 118500, loss = 0.0989475
I1130 21:50:41.534775 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0128379 (* 0.5 = 0.00641896 loss)
I1130 21:50:41.534780 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.103442 (* 1 = 0.103442 loss)
I1130 21:50:41.534785 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:50:41.534788 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 21:50:41.534793 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00321439 (* 0.5 = 0.00160719 loss)
I1130 21:50:41.534797 11185 sgd_solver.cpp:106] Iteration 118500, lr = 5e-05
I1130 21:50:45.353893 11185 solver.cpp:228] Iteration 119000, loss = 0.0968194
I1130 21:50:45.353914 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0104203 (* 0.5 = 0.00521015 loss)
I1130 21:50:45.353926 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.101299 (* 1 = 0.101299 loss)
I1130 21:50:45.353931 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:50:45.353935 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.835938
I1130 21:50:45.353940 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00348398 (* 0.5 = 0.00174199 loss)
I1130 21:50:45.353943 11185 sgd_solver.cpp:106] Iteration 119000, lr = 5e-05
I1130 21:50:47.501344 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_119282.caffemodel
I1130 21:50:47.503633 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_119282.solverstate
I1130 21:50:47.503795 11185 solver.cpp:337] Iteration 119282, Testing net (#0)
I1130 21:51:00.276235 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0132669 (* 0.5 = 0.00663346 loss)
I1130 21:51:00.276276 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.106662 (* 1 = 0.106662 loss)
I1130 21:51:00.276283 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.980121
I1130 21:51:00.276285 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.771872
I1130 21:51:00.276293 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00463828 (* 0.5 = 0.00231914 loss)
I1130 21:51:02.017738 11185 solver.cpp:228] Iteration 119500, loss = 0.0858444
I1130 21:51:02.017762 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0119839 (* 0.5 = 0.00599193 loss)
I1130 21:51:02.017768 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0799473 (* 1 = 0.0799473 loss)
I1130 21:51:02.017772 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:51:02.017776 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 21:51:02.017781 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00478184 (* 0.5 = 0.00239092 loss)
I1130 21:51:02.017786 11185 sgd_solver.cpp:106] Iteration 119500, lr = 5e-05
I1130 21:51:05.826434 11185 solver.cpp:228] Iteration 120000, loss = 0.106309
I1130 21:51:05.826457 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0137173 (* 0.5 = 0.00685866 loss)
I1130 21:51:05.826464 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0962963 (* 1 = 0.0962963 loss)
I1130 21:51:05.826468 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:51:05.826472 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.796875
I1130 21:51:05.826477 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00413759 (* 0.5 = 0.00206879 loss)
I1130 21:51:05.826480 11185 sgd_solver.cpp:106] Iteration 120000, lr = 5e-05
I1130 21:51:09.629550 11185 solver.cpp:228] Iteration 120500, loss = 0.117812
I1130 21:51:09.629571 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0130439 (* 0.5 = 0.00652197 loss)
I1130 21:51:09.629578 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.110655 (* 1 = 0.110655 loss)
I1130 21:51:09.629582 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.947917
I1130 21:51:09.629585 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 21:51:09.629590 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00637737 (* 0.5 = 0.00318869 loss)
I1130 21:51:09.629595 11185 sgd_solver.cpp:106] Iteration 120500, lr = 5e-05
I1130 21:51:13.441319 11185 solver.cpp:228] Iteration 121000, loss = 0.122712
I1130 21:51:13.441344 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0134108 (* 0.5 = 0.00670542 loss)
I1130 21:51:13.441351 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.104522 (* 1 = 0.104522 loss)
I1130 21:51:13.441354 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:51:13.441359 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.75
I1130 21:51:13.441370 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00757882 (* 0.5 = 0.00378941 loss)
I1130 21:51:13.441375 11185 sgd_solver.cpp:106] Iteration 121000, lr = 5e-05
I1130 21:51:17.455943 11185 solver.cpp:228] Iteration 121500, loss = 0.100546
I1130 21:51:17.456001 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0125019 (* 0.5 = 0.00625096 loss)
I1130 21:51:17.456009 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0883257 (* 1 = 0.0883257 loss)
I1130 21:51:17.456013 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.963542
I1130 21:51:17.456017 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 21:51:17.456022 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00388243 (* 0.5 = 0.00194122 loss)
I1130 21:51:17.456027 11185 sgd_solver.cpp:106] Iteration 121500, lr = 5e-05
I1130 21:51:21.542479 11185 solver.cpp:228] Iteration 122000, loss = 0.108531
I1130 21:51:21.542554 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0117801 (* 0.5 = 0.00589003 loss)
I1130 21:51:21.542563 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0898092 (* 1 = 0.0898092 loss)
I1130 21:51:21.542568 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.966146
I1130 21:51:21.542573 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:51:21.542579 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00541869 (* 0.5 = 0.00270934 loss)
I1130 21:51:21.542585 11185 sgd_solver.cpp:106] Iteration 122000, lr = 5e-05
I1130 21:51:25.604982 11185 solver.cpp:228] Iteration 122500, loss = 0.107476
I1130 21:51:25.605054 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0109849 (* 0.5 = 0.00549244 loss)
I1130 21:51:25.605062 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0794835 (* 1 = 0.0794835 loss)
I1130 21:51:25.605065 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 21:51:25.605075 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.914062
I1130 21:51:25.605082 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00493908 (* 0.5 = 0.00246954 loss)
I1130 21:51:25.605087 11185 sgd_solver.cpp:106] Iteration 122500, lr = 5e-05
I1130 21:51:29.646440 11185 solver.cpp:228] Iteration 123000, loss = 0.104985
I1130 21:51:29.646512 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.012476 (* 0.5 = 0.00623802 loss)
I1130 21:51:29.646519 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0790968 (* 1 = 0.0790968 loss)
I1130 21:51:29.646523 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.986979
I1130 21:51:29.646528 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 21:51:29.646533 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00427098 (* 0.5 = 0.00213549 loss)
I1130 21:51:29.646538 11185 sgd_solver.cpp:106] Iteration 123000, lr = 5e-05
I1130 21:51:33.756695 11185 solver.cpp:228] Iteration 123500, loss = 0.112371
I1130 21:51:33.756773 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0145737 (* 0.5 = 0.00728684 loss)
I1130 21:51:33.756781 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.119647 (* 1 = 0.119647 loss)
I1130 21:51:33.756785 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 21:51:33.756789 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.773438
I1130 21:51:33.756794 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00411213 (* 0.5 = 0.00205606 loss)
I1130 21:51:33.756800 11185 sgd_solver.cpp:106] Iteration 123500, lr = 5e-05
I1130 21:51:37.848793 11185 solver.cpp:228] Iteration 124000, loss = 0.123816
I1130 21:51:37.848860 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0148799 (* 0.5 = 0.00743997 loss)
I1130 21:51:37.848867 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.125169 (* 1 = 0.125169 loss)
I1130 21:51:37.848886 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:51:37.848891 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.710938
I1130 21:51:37.848896 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00382336 (* 0.5 = 0.00191168 loss)
I1130 21:51:37.848901 11185 sgd_solver.cpp:106] Iteration 124000, lr = 5e-05
I1130 21:51:42.020298 11185 solver.cpp:228] Iteration 124500, loss = 0.105041
I1130 21:51:42.020372 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0130347 (* 0.5 = 0.00651737 loss)
I1130 21:51:42.020380 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.132447 (* 1 = 0.132447 loss)
I1130 21:51:42.020385 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 21:51:42.020388 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.765625
I1130 21:51:42.020393 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00389907 (* 0.5 = 0.00194953 loss)
I1130 21:51:42.020400 11185 sgd_solver.cpp:106] Iteration 124500, lr = 5e-05
I1130 21:51:46.145828 11185 solver.cpp:228] Iteration 125000, loss = 0.131145
I1130 21:51:46.145897 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0132563 (* 0.5 = 0.00662815 loss)
I1130 21:51:46.145905 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.118959 (* 1 = 0.118959 loss)
I1130 21:51:46.145910 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:51:46.145913 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.75
I1130 21:51:46.145918 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00364238 (* 0.5 = 0.00182119 loss)
I1130 21:51:46.145923 11185 sgd_solver.cpp:106] Iteration 125000, lr = 5e-05
I1130 21:51:50.232897 11185 solver.cpp:228] Iteration 125500, loss = 0.10654
I1130 21:51:50.232970 11185 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0131956 (* 0.5 = 0.00659779 loss)
I1130 21:51:50.232977 11185 solver.cpp:244]     Train net output #1: face_cls_loss = 0.108714 (* 1 = 0.108714 loss)
I1130 21:51:50.232982 11185 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 21:51:50.232986 11185 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.773438
I1130 21:51:50.232991 11185 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00464664 (* 0.5 = 0.00232332 loss)
I1130 21:51:50.232996 11185 sgd_solver.cpp:106] Iteration 125500, lr = 5e-05
I1130 21:51:50.717375 11185 solver.cpp:454] Snapshotting to binary proto file tmp/pnet_iter_125560.caffemodel
I1130 21:51:50.719650 11185 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/pnet_iter_125560.solverstate
I1130 21:51:50.719760 11185 solver.cpp:337] Iteration 125560, Testing net (#0)
I1130 21:52:02.954237 11185 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0132568 (* 0.5 = 0.00662839 loss)
I1130 21:52:02.954282 11185 solver.cpp:404]     Test net output #1: face_cls_loss = 0.105307 (* 1 = 0.105307 loss)
I1130 21:52:02.954288 11185 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.969522
I1130 21:52:02.954290 11185 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.807543
I1130 21:52:02.954295 11185 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.0046395 (* 0.5 = 0.00231975 loss)
I1130 21:52:02.954299 11185 solver.cpp:322] Optimization Done.
Generate Data for rNet
[2016-11-30 21:52:04,720][INFO] loading CelebA
[2016-11-30 21:52:10,958][INFO] total images, train: 162079, val: 40520
[2016-11-30 21:52:10,959][INFO] writing train data, 162079 images
[2016-11-30 21:52:10,959][INFO] remove data/rnet_landmark_train
[2016-11-30 21:52:10,959][INFO] fill queues
[2016-11-30 21:52:11,745][INFO] writes 1000 landmark faces
[2016-11-30 21:52:12,027][INFO] writes 2000 landmark faces
[2016-11-30 21:52:12,264][INFO] writes 3000 landmark faces
[2016-11-30 21:52:12,503][INFO] writes 4000 landmark faces
[2016-11-30 21:52:12,735][INFO] writes 5000 landmark faces
[2016-11-30 21:52:12,973][INFO] writes 6000 landmark faces
[2016-11-30 21:52:13,201][INFO] writes 7000 landmark faces
[2016-11-30 21:52:13,464][INFO] writes 8000 landmark faces
[2016-11-30 21:52:13,702][INFO] writes 9000 landmark faces
[2016-11-30 21:52:13,919][INFO] writes 10000 landmark faces
[2016-11-30 21:52:14,172][INFO] writes 11000 landmark faces
[2016-11-30 21:52:14,398][INFO] writes 12000 landmark faces
[2016-11-30 21:52:14,602][INFO] writes 13000 landmark faces
[2016-11-30 21:52:14,844][INFO] writes 14000 landmark faces
[2016-11-30 21:52:15,070][INFO] writes 15000 landmark faces
[2016-11-30 21:52:15,331][INFO] writes 16000 landmark faces
[2016-11-30 21:52:15,568][INFO] writes 17000 landmark faces
[2016-11-30 21:52:15,793][INFO] writes 18000 landmark faces
[2016-11-30 21:52:16,016][INFO] writes 19000 landmark faces
[2016-11-30 21:52:16,268][INFO] writes 20000 landmark faces
[2016-11-30 21:52:16,502][INFO] writes 21000 landmark faces
[2016-11-30 21:52:16,737][INFO] writes 22000 landmark faces
[2016-11-30 21:52:16,950][INFO] writes 23000 landmark faces
[2016-11-30 21:52:17,168][INFO] writes 24000 landmark faces
[2016-11-30 21:52:17,382][INFO] writes 25000 landmark faces
[2016-11-30 21:52:17,602][INFO] writes 26000 landmark faces
[2016-11-30 21:52:17,805][INFO] writes 27000 landmark faces
[2016-11-30 21:52:18,013][INFO] writes 28000 landmark faces
[2016-11-30 21:52:18,225][INFO] writes 29000 landmark faces
[2016-11-30 21:52:18,475][INFO] writes 30000 landmark faces
[2016-11-30 21:52:18,720][INFO] writes 31000 landmark faces
[2016-11-30 21:52:18,937][INFO] writes 32000 landmark faces
[2016-11-30 21:52:19,187][INFO] writes 33000 landmark faces
[2016-11-30 21:52:19,399][INFO] writes 34000 landmark faces
[2016-11-30 21:52:19,629][INFO] writes 35000 landmark faces
[2016-11-30 21:52:19,842][INFO] writes 36000 landmark faces
[2016-11-30 21:52:20,066][INFO] writes 37000 landmark faces
[2016-11-30 21:52:20,293][INFO] writes 38000 landmark faces
[2016-11-30 21:52:20,547][INFO] writes 39000 landmark faces
[2016-11-30 21:52:20,782][INFO] writes 40000 landmark faces
[2016-11-30 21:52:20,998][INFO] writes 41000 landmark faces
[2016-11-30 21:52:21,223][INFO] writes 42000 landmark faces
[2016-11-30 21:52:21,477][INFO] writes 43000 landmark faces
[2016-11-30 21:52:21,710][INFO] writes 44000 landmark faces
[2016-11-30 21:52:21,935][INFO] writes 45000 landmark faces
[2016-11-30 21:52:22,199][INFO] writes 46000 landmark faces
[2016-11-30 21:52:22,413][INFO] writes 47000 landmark faces
[2016-11-30 21:52:22,659][INFO] writes 48000 landmark faces
[2016-11-30 21:52:22,898][INFO] writes 49000 landmark faces
[2016-11-30 21:52:23,114][INFO] writes 50000 landmark faces
[2016-11-30 21:52:23,365][INFO] writes 51000 landmark faces
[2016-11-30 21:52:23,608][INFO] writes 52000 landmark faces
[2016-11-30 21:52:23,866][INFO] writes 53000 landmark faces
[2016-11-30 21:52:24,074][INFO] writes 54000 landmark faces
[2016-11-30 21:52:24,298][INFO] writes 55000 landmark faces
[2016-11-30 21:52:24,505][INFO] writes 56000 landmark faces
[2016-11-30 21:52:24,744][INFO] writes 57000 landmark faces
[2016-11-30 21:52:24,962][INFO] writes 58000 landmark faces
[2016-11-30 21:52:25,226][INFO] writes 59000 landmark faces
[2016-11-30 21:52:25,464][INFO] writes 60000 landmark faces
[2016-11-30 21:52:25,666][INFO] writes 61000 landmark faces
[2016-11-30 21:52:25,907][INFO] writes 62000 landmark faces
[2016-11-30 21:52:26,111][INFO] writes 63000 landmark faces
[2016-11-30 21:52:26,360][INFO] writes 64000 landmark faces
[2016-11-30 21:52:26,589][INFO] writes 65000 landmark faces
[2016-11-30 21:52:26,869][INFO] writes 66000 landmark faces
[2016-11-30 21:52:27,133][INFO] writes 67000 landmark faces
[2016-11-30 21:52:27,422][INFO] writes 68000 landmark faces
[2016-11-30 21:52:27,647][INFO] writes 69000 landmark faces
[2016-11-30 21:52:27,871][INFO] writes 70000 landmark faces
[2016-11-30 21:52:28,110][INFO] writes 71000 landmark faces
[2016-11-30 21:52:28,350][INFO] writes 72000 landmark faces
[2016-11-30 21:52:28,583][INFO] writes 73000 landmark faces
[2016-11-30 21:52:28,800][INFO] writes 74000 landmark faces
[2016-11-30 21:52:29,062][INFO] writes 75000 landmark faces
[2016-11-30 21:52:29,298][INFO] writes 76000 landmark faces
[2016-11-30 21:52:29,522][INFO] writes 77000 landmark faces
[2016-11-30 21:52:29,551][INFO] Process-7 reads 1000
[2016-11-30 21:52:29,702][INFO] Process-4 reads 1000
[2016-11-30 21:52:29,775][INFO] writes 78000 landmark faces
[2016-11-30 21:52:30,010][INFO] Process-1 reads 1000
[2016-11-30 21:52:30,070][INFO] writes 79000 landmark faces
[2016-11-30 21:52:30,118][INFO] Process-2 reads 1000
[2016-11-30 21:52:30,284][INFO] Process-8 reads 1000
[2016-11-30 21:52:30,298][INFO] writes 80000 landmark faces
[2016-11-30 21:52:30,321][INFO] Process-5 reads 1000
[2016-11-30 21:52:30,499][INFO] writes 81000 landmark faces
[2016-11-30 21:52:30,707][INFO] writes 82000 landmark faces
[2016-11-30 21:52:30,872][INFO] Process-3 reads 1000
[2016-11-30 21:52:30,949][INFO] writes 83000 landmark faces
[2016-11-30 21:52:31,190][INFO] writes 84000 landmark faces
[2016-11-30 21:52:31,292][INFO] Process-6 reads 1000
[2016-11-30 21:52:31,427][INFO] writes 85000 landmark faces
[2016-11-30 21:52:31,633][INFO] writes 86000 landmark faces
[2016-11-30 21:52:31,849][INFO] writes 87000 landmark faces
[2016-11-30 21:52:32,086][INFO] writes 88000 landmark faces
[2016-11-30 21:52:32,339][INFO] writes 89000 landmark faces
[2016-11-30 21:52:32,551][INFO] writes 90000 landmark faces
[2016-11-30 21:52:32,790][INFO] writes 91000 landmark faces
[2016-11-30 21:52:33,011][INFO] writes 92000 landmark faces
[2016-11-30 21:52:33,272][INFO] writes 93000 landmark faces
[2016-11-30 21:52:33,515][INFO] writes 94000 landmark faces
[2016-11-30 21:52:33,757][INFO] writes 95000 landmark faces
[2016-11-30 21:52:33,971][INFO] writes 96000 landmark faces
[2016-11-30 21:52:34,215][INFO] writes 97000 landmark faces
[2016-11-30 21:52:34,460][INFO] writes 98000 landmark faces
[2016-11-30 21:52:34,683][INFO] writes 99000 landmark faces
[2016-11-30 21:52:34,892][INFO] writes 100000 landmark faces
[2016-11-30 21:52:35,116][INFO] writes 101000 landmark faces
[2016-11-30 21:52:35,348][INFO] writes 102000 landmark faces
[2016-11-30 21:52:35,559][INFO] writes 103000 landmark faces
[2016-11-30 21:52:35,775][INFO] writes 104000 landmark faces
[2016-11-30 21:52:36,004][INFO] writes 105000 landmark faces
[2016-11-30 21:52:36,212][INFO] writes 106000 landmark faces
[2016-11-30 21:52:36,451][INFO] writes 107000 landmark faces
[2016-11-30 21:52:36,671][INFO] writes 108000 landmark faces
[2016-11-30 21:52:36,918][INFO] writes 109000 landmark faces
[2016-11-30 21:52:37,121][INFO] writes 110000 landmark faces
[2016-11-30 21:52:37,333][INFO] writes 111000 landmark faces
[2016-11-30 21:52:37,544][INFO] writes 112000 landmark faces
[2016-11-30 21:52:37,754][INFO] writes 113000 landmark faces
[2016-11-30 21:52:38,001][INFO] writes 114000 landmark faces
[2016-11-30 21:52:38,262][INFO] writes 115000 landmark faces
[2016-11-30 21:52:38,483][INFO] writes 116000 landmark faces
[2016-11-30 21:52:38,704][INFO] writes 117000 landmark faces
[2016-11-30 21:52:38,920][INFO] writes 118000 landmark faces
[2016-11-30 21:52:39,174][INFO] writes 119000 landmark faces
[2016-11-30 21:52:39,403][INFO] writes 120000 landmark faces
[2016-11-30 21:52:39,623][INFO] writes 121000 landmark faces
[2016-11-30 21:52:39,908][INFO] writes 122000 landmark faces
[2016-11-30 21:52:40,122][INFO] writes 123000 landmark faces
[2016-11-30 21:52:40,348][INFO] writes 124000 landmark faces
[2016-11-30 21:52:40,570][INFO] writes 125000 landmark faces
[2016-11-30 21:52:40,779][INFO] writes 126000 landmark faces
[2016-11-30 21:52:40,987][INFO] writes 127000 landmark faces
[2016-11-30 21:52:41,201][INFO] writes 128000 landmark faces
[2016-11-30 21:52:41,434][INFO] writes 129000 landmark faces
[2016-11-30 21:52:41,679][INFO] writes 130000 landmark faces
[2016-11-30 21:52:41,911][INFO] writes 131000 landmark faces
[2016-11-30 21:52:42,135][INFO] writes 132000 landmark faces
[2016-11-30 21:52:42,373][INFO] writes 133000 landmark faces
[2016-11-30 21:52:42,592][INFO] writes 134000 landmark faces
[2016-11-30 21:52:42,823][INFO] writes 135000 landmark faces
[2016-11-30 21:52:43,025][INFO] writes 136000 landmark faces
[2016-11-30 21:52:43,233][INFO] writes 137000 landmark faces
[2016-11-30 21:52:43,460][INFO] writes 138000 landmark faces
[2016-11-30 21:52:43,710][INFO] writes 139000 landmark faces
[2016-11-30 21:52:43,981][INFO] writes 140000 landmark faces
[2016-11-30 21:52:44,241][INFO] writes 141000 landmark faces
[2016-11-30 21:52:44,519][INFO] writes 142000 landmark faces
[2016-11-30 21:52:44,844][INFO] writes 143000 landmark faces
[2016-11-30 21:52:45,133][INFO] writes 144000 landmark faces
[2016-11-30 21:52:45,430][INFO] writes 145000 landmark faces
[2016-11-30 21:52:45,699][INFO] writes 146000 landmark faces
[2016-11-30 21:52:45,979][INFO] writes 147000 landmark faces
[2016-11-30 21:52:46,201][INFO] writes 148000 landmark faces
[2016-11-30 21:52:46,441][INFO] writes 149000 landmark faces
[2016-11-30 21:52:46,686][INFO] writes 150000 landmark faces
[2016-11-30 21:52:46,879][INFO] writes 151000 landmark faces
[2016-11-30 21:52:47,107][INFO] writes 152000 landmark faces
[2016-11-30 21:52:47,324][INFO] writes 153000 landmark faces
[2016-11-30 21:52:47,581][INFO] writes 154000 landmark faces
[2016-11-30 21:52:47,806][INFO] writes 155000 landmark faces
[2016-11-30 21:52:48,051][INFO] writes 156000 landmark faces
[2016-11-30 21:52:48,155][INFO] Process-2 reads 2000
[2016-11-30 21:52:48,166][INFO] Process-4 reads 2000
[2016-11-30 21:52:48,266][INFO] writes 157000 landmark faces
[2016-11-30 21:52:48,486][INFO] writes 158000 landmark faces
[2016-11-30 21:52:48,549][INFO] Process-7 reads 2000
[2016-11-30 21:52:48,582][INFO] Process-1 reads 2000
[2016-11-30 21:52:48,687][INFO] writes 159000 landmark faces
[2016-11-30 21:52:48,918][INFO] writes 160000 landmark faces
[2016-11-30 21:52:49,131][INFO] writes 161000 landmark faces
[2016-11-30 21:52:49,143][INFO] Process-8 reads 2000
[2016-11-30 21:52:49,345][INFO] writes 162000 landmark faces
[2016-11-30 21:52:49,391][INFO] Process-5 reads 2000
[2016-11-30 21:52:49,560][INFO] writes 163000 landmark faces
[2016-11-30 21:52:49,588][INFO] Process-3 reads 2000
[2016-11-30 21:52:49,627][INFO] Process-6 reads 2000
[2016-11-30 21:52:49,784][INFO] writes 164000 landmark faces
[2016-11-30 21:52:50,028][INFO] writes 165000 landmark faces
[2016-11-30 21:52:50,276][INFO] writes 166000 landmark faces
[2016-11-30 21:52:50,500][INFO] writes 167000 landmark faces
[2016-11-30 21:52:50,755][INFO] writes 168000 landmark faces
[2016-11-30 21:52:51,008][INFO] writes 169000 landmark faces
[2016-11-30 21:52:51,219][INFO] writes 170000 landmark faces
[2016-11-30 21:52:51,433][INFO] writes 171000 landmark faces
[2016-11-30 21:52:51,656][INFO] writes 172000 landmark faces
[2016-11-30 21:52:51,920][INFO] writes 173000 landmark faces
[2016-11-30 21:52:52,122][INFO] writes 174000 landmark faces
[2016-11-30 21:52:52,349][INFO] writes 175000 landmark faces
[2016-11-30 21:52:52,571][INFO] writes 176000 landmark faces
[2016-11-30 21:52:52,789][INFO] writes 177000 landmark faces
[2016-11-30 21:52:53,041][INFO] writes 178000 landmark faces
[2016-11-30 21:52:53,281][INFO] writes 179000 landmark faces
[2016-11-30 21:52:53,498][INFO] writes 180000 landmark faces
[2016-11-30 21:52:53,732][INFO] writes 181000 landmark faces
[2016-11-30 21:52:53,939][INFO] writes 182000 landmark faces
[2016-11-30 21:52:54,192][INFO] writes 183000 landmark faces
[2016-11-30 21:52:54,432][INFO] writes 184000 landmark faces
[2016-11-30 21:52:54,659][INFO] writes 185000 landmark faces
[2016-11-30 21:52:54,873][INFO] writes 186000 landmark faces
[2016-11-30 21:52:55,140][INFO] writes 187000 landmark faces
[2016-11-30 21:52:55,356][INFO] writes 188000 landmark faces
[2016-11-30 21:52:55,575][INFO] writes 189000 landmark faces
[2016-11-30 21:52:55,846][INFO] writes 190000 landmark faces
[2016-11-30 21:52:56,065][INFO] writes 191000 landmark faces
[2016-11-30 21:52:56,283][INFO] writes 192000 landmark faces
[2016-11-30 21:52:56,549][INFO] writes 193000 landmark faces
[2016-11-30 21:52:56,774][INFO] writes 194000 landmark faces
[2016-11-30 21:52:56,998][INFO] writes 195000 landmark faces
[2016-11-30 21:52:57,247][INFO] writes 196000 landmark faces
[2016-11-30 21:52:57,466][INFO] writes 197000 landmark faces
[2016-11-30 21:52:57,727][INFO] writes 198000 landmark faces
[2016-11-30 21:52:57,994][INFO] writes 199000 landmark faces
[2016-11-30 21:52:58,211][INFO] writes 200000 landmark faces
[2016-11-30 21:52:58,439][INFO] writes 201000 landmark faces
[2016-11-30 21:52:58,694][INFO] writes 202000 landmark faces
[2016-11-30 21:52:58,917][INFO] writes 203000 landmark faces
[2016-11-30 21:52:59,130][INFO] writes 204000 landmark faces
[2016-11-30 21:52:59,354][INFO] writes 205000 landmark faces
[2016-11-30 21:52:59,572][INFO] writes 206000 landmark faces
[2016-11-30 21:52:59,819][INFO] writes 207000 landmark faces
[2016-11-30 21:53:00,098][INFO] writes 208000 landmark faces
[2016-11-30 21:53:00,311][INFO] writes 209000 landmark faces
[2016-11-30 21:53:00,551][INFO] writes 210000 landmark faces
[2016-11-30 21:53:00,808][INFO] writes 211000 landmark faces
[2016-11-30 21:53:01,067][INFO] writes 212000 landmark faces
[2016-11-30 21:53:01,285][INFO] writes 213000 landmark faces
[2016-11-30 21:53:01,544][INFO] writes 214000 landmark faces
[2016-11-30 21:53:01,787][INFO] writes 215000 landmark faces
[2016-11-30 21:53:02,051][INFO] writes 216000 landmark faces
[2016-11-30 21:53:02,272][INFO] writes 217000 landmark faces
[2016-11-30 21:53:02,564][INFO] writes 218000 landmark faces
[2016-11-30 21:53:02,805][INFO] writes 219000 landmark faces
[2016-11-30 21:53:03,025][INFO] writes 220000 landmark faces
[2016-11-30 21:53:03,268][INFO] writes 221000 landmark faces
[2016-11-30 21:53:03,519][INFO] writes 222000 landmark faces
[2016-11-30 21:53:03,739][INFO] writes 223000 landmark faces
[2016-11-30 21:53:03,982][INFO] writes 224000 landmark faces
[2016-11-30 21:53:04,204][INFO] writes 225000 landmark faces
[2016-11-30 21:53:04,436][INFO] writes 226000 landmark faces
[2016-11-30 21:53:04,697][INFO] writes 227000 landmark faces
[2016-11-30 21:53:04,941][INFO] writes 228000 landmark faces
[2016-11-30 21:53:05,162][INFO] writes 229000 landmark faces
[2016-11-30 21:53:05,409][INFO] writes 230000 landmark faces
[2016-11-30 21:53:05,637][INFO] writes 231000 landmark faces
[2016-11-30 21:53:05,853][INFO] writes 232000 landmark faces
[2016-11-30 21:53:06,093][INFO] writes 233000 landmark faces
[2016-11-30 21:53:06,353][INFO] writes 234000 landmark faces
[2016-11-30 21:53:06,353][INFO] Process-2 reads 3000
[2016-11-30 21:53:06,563][INFO] writes 235000 landmark faces
[2016-11-30 21:53:06,800][INFO] writes 236000 landmark faces
[2016-11-30 21:53:07,014][INFO] writes 237000 landmark faces
[2016-11-30 21:53:07,220][INFO] writes 238000 landmark faces
[2016-11-30 21:53:07,414][INFO] Process-1 reads 3000
[2016-11-30 21:53:07,431][INFO] writes 239000 landmark faces
[2016-11-30 21:53:07,471][INFO] Process-7 reads 3000
[2016-11-30 21:53:07,532][INFO] Process-8 reads 3000
[2016-11-30 21:53:07,573][INFO] Process-4 reads 3000
[2016-11-30 21:53:07,632][INFO] writes 240000 landmark faces
[2016-11-30 21:53:07,816][INFO] Process-3 reads 3000
[2016-11-30 21:53:07,854][INFO] writes 241000 landmark faces
[2016-11-30 21:53:08,070][INFO] writes 242000 landmark faces
[2016-11-30 21:53:08,318][INFO] writes 243000 landmark faces
[2016-11-30 21:53:08,349][INFO] Process-6 reads 3000
[2016-11-30 21:53:08,393][INFO] Process-5 reads 3000
[2016-11-30 21:53:08,584][INFO] writes 244000 landmark faces
[2016-11-30 21:53:08,861][INFO] writes 245000 landmark faces
[2016-11-30 21:53:09,073][INFO] writes 246000 landmark faces
[2016-11-30 21:53:09,264][INFO] writes 247000 landmark faces
[2016-11-30 21:53:09,476][INFO] writes 248000 landmark faces
[2016-11-30 21:53:09,694][INFO] writes 249000 landmark faces
[2016-11-30 21:53:09,977][INFO] writes 250000 landmark faces
[2016-11-30 21:53:10,184][INFO] writes 251000 landmark faces
[2016-11-30 21:53:10,422][INFO] writes 252000 landmark faces
[2016-11-30 21:53:10,649][INFO] writes 253000 landmark faces
[2016-11-30 21:53:10,869][INFO] writes 254000 landmark faces
[2016-11-30 21:53:11,111][INFO] writes 255000 landmark faces
[2016-11-30 21:53:11,332][INFO] writes 256000 landmark faces
[2016-11-30 21:53:11,594][INFO] writes 257000 landmark faces
[2016-11-30 21:53:11,805][INFO] writes 258000 landmark faces
[2016-11-30 21:53:12,000][INFO] writes 259000 landmark faces
[2016-11-30 21:53:12,204][INFO] writes 260000 landmark faces
[2016-11-30 21:53:12,432][INFO] writes 261000 landmark faces
[2016-11-30 21:53:12,658][INFO] writes 262000 landmark faces
[2016-11-30 21:53:12,880][INFO] writes 263000 landmark faces
[2016-11-30 21:53:13,099][INFO] writes 264000 landmark faces
[2016-11-30 21:53:13,376][INFO] writes 265000 landmark faces
[2016-11-30 21:53:13,581][INFO] writes 266000 landmark faces
[2016-11-30 21:53:13,809][INFO] writes 267000 landmark faces
[2016-11-30 21:53:14,028][INFO] writes 268000 landmark faces
[2016-11-30 21:53:14,266][INFO] writes 269000 landmark faces
[2016-11-30 21:53:14,493][INFO] writes 270000 landmark faces
[2016-11-30 21:53:14,697][INFO] writes 271000 landmark faces
[2016-11-30 21:53:14,902][INFO] writes 272000 landmark faces
[2016-11-30 21:53:15,116][INFO] writes 273000 landmark faces
[2016-11-30 21:53:15,338][INFO] writes 274000 landmark faces
[2016-11-30 21:53:15,572][INFO] writes 275000 landmark faces
[2016-11-30 21:53:15,831][INFO] writes 276000 landmark faces
[2016-11-30 21:53:16,086][INFO] writes 277000 landmark faces
[2016-11-30 21:53:16,297][INFO] writes 278000 landmark faces
[2016-11-30 21:53:16,510][INFO] writes 279000 landmark faces
[2016-11-30 21:53:16,720][INFO] writes 280000 landmark faces
[2016-11-30 21:53:16,956][INFO] writes 281000 landmark faces
[2016-11-30 21:53:17,184][INFO] writes 282000 landmark faces
[2016-11-30 21:53:17,426][INFO] writes 283000 landmark faces
[2016-11-30 21:53:17,660][INFO] writes 284000 landmark faces
[2016-11-30 21:53:17,886][INFO] writes 285000 landmark faces
[2016-11-30 21:53:18,108][INFO] writes 286000 landmark faces
[2016-11-30 21:53:18,321][INFO] writes 287000 landmark faces
[2016-11-30 21:53:18,541][INFO] writes 288000 landmark faces
[2016-11-30 21:53:18,745][INFO] writes 289000 landmark faces
[2016-11-30 21:53:19,060][INFO] writes 290000 landmark faces
[2016-11-30 21:53:19,276][INFO] writes 291000 landmark faces
[2016-11-30 21:53:19,509][INFO] writes 292000 landmark faces
[2016-11-30 21:53:19,831][INFO] writes 293000 landmark faces
[2016-11-30 21:53:20,015][INFO] writes 294000 landmark faces
[2016-11-30 21:53:20,254][INFO] writes 295000 landmark faces
[2016-11-30 21:53:20,520][INFO] writes 296000 landmark faces
[2016-11-30 21:53:20,736][INFO] writes 297000 landmark faces
[2016-11-30 21:53:20,989][INFO] writes 298000 landmark faces
[2016-11-30 21:53:21,212][INFO] writes 299000 landmark faces
[2016-11-30 21:53:21,435][INFO] writes 300000 landmark faces
[2016-11-30 21:53:21,667][INFO] writes 301000 landmark faces
[2016-11-30 21:53:21,900][INFO] writes 302000 landmark faces
[2016-11-30 21:53:22,116][INFO] writes 303000 landmark faces
[2016-11-30 21:53:22,340][INFO] writes 304000 landmark faces
[2016-11-30 21:53:22,593][INFO] writes 305000 landmark faces
[2016-11-30 21:53:22,810][INFO] writes 306000 landmark faces
[2016-11-30 21:53:23,081][INFO] writes 307000 landmark faces
[2016-11-30 21:53:23,309][INFO] writes 308000 landmark faces
[2016-11-30 21:53:23,546][INFO] writes 309000 landmark faces
[2016-11-30 21:53:23,780][INFO] writes 310000 landmark faces
[2016-11-30 21:53:23,994][INFO] writes 311000 landmark faces
[2016-11-30 21:53:24,205][INFO] writes 312000 landmark faces
[2016-11-30 21:53:24,445][INFO] writes 313000 landmark faces
[2016-11-30 21:53:24,728][INFO] writes 314000 landmark faces
[2016-11-30 21:53:24,996][INFO] writes 315000 landmark faces
[2016-11-30 21:53:25,217][INFO] writes 316000 landmark faces
[2016-11-30 21:53:25,356][INFO] Process-1 reads 4000
[2016-11-30 21:53:25,384][INFO] Process-2 reads 4000
[2016-11-30 21:53:25,426][INFO] writes 317000 landmark faces
[2016-11-30 21:53:25,570][INFO] Process-8 reads 4000
[2016-11-30 21:53:25,667][INFO] writes 318000 landmark faces
[2016-11-30 21:53:25,803][INFO] Process-7 reads 4000
[2016-11-30 21:53:25,875][INFO] writes 319000 landmark faces
[2016-11-30 21:53:26,122][INFO] writes 320000 landmark faces
[2016-11-30 21:53:26,322][INFO] writes 321000 landmark faces
[2016-11-30 21:53:26,363][INFO] Process-4 reads 4000
[2016-11-30 21:53:26,533][INFO] writes 322000 landmark faces
[2016-11-30 21:53:26,583][INFO] Process-5 reads 4000
[2016-11-30 21:53:26,728][INFO] Process-3 reads 4000
[2016-11-30 21:53:26,822][INFO] Process-6 reads 4000
[2016-11-30 21:53:26,823][INFO] writes 323000 landmark faces
[2016-11-30 21:53:27,045][INFO] writes 324000 landmark faces
[2016-11-30 21:53:27,249][INFO] writes 325000 landmark faces
[2016-11-30 21:53:27,462][INFO] writes 326000 landmark faces
[2016-11-30 21:53:27,742][INFO] writes 327000 landmark faces
[2016-11-30 21:53:27,957][INFO] writes 328000 landmark faces
[2016-11-30 21:53:28,154][INFO] writes 329000 landmark faces
[2016-11-30 21:53:28,390][INFO] writes 330000 landmark faces
[2016-11-30 21:53:28,602][INFO] writes 331000 landmark faces
[2016-11-30 21:53:28,842][INFO] writes 332000 landmark faces
[2016-11-30 21:53:29,093][INFO] writes 333000 landmark faces
[2016-11-30 21:53:29,317][INFO] writes 334000 landmark faces
[2016-11-30 21:53:29,555][INFO] writes 335000 landmark faces
[2016-11-30 21:53:29,773][INFO] writes 336000 landmark faces
[2016-11-30 21:53:29,992][INFO] writes 337000 landmark faces
[2016-11-30 21:53:30,233][INFO] writes 338000 landmark faces
[2016-11-30 21:53:30,449][INFO] writes 339000 landmark faces
[2016-11-30 21:53:30,678][INFO] writes 340000 landmark faces
[2016-11-30 21:53:30,942][INFO] writes 341000 landmark faces
[2016-11-30 21:53:31,213][INFO] writes 342000 landmark faces
[2016-11-30 21:53:31,483][INFO] writes 343000 landmark faces
[2016-11-30 21:53:31,732][INFO] writes 344000 landmark faces
[2016-11-30 21:53:31,934][INFO] writes 345000 landmark faces
[2016-11-30 21:53:32,165][INFO] writes 346000 landmark faces
[2016-11-30 21:53:32,377][INFO] writes 347000 landmark faces
[2016-11-30 21:53:32,607][INFO] writes 348000 landmark faces
[2016-11-30 21:53:32,836][INFO] writes 349000 landmark faces
[2016-11-30 21:53:33,071][INFO] writes 350000 landmark faces
[2016-11-30 21:53:33,282][INFO] writes 351000 landmark faces
[2016-11-30 21:53:33,505][INFO] writes 352000 landmark faces
[2016-11-30 21:53:33,757][INFO] writes 353000 landmark faces
[2016-11-30 21:53:33,971][INFO] writes 354000 landmark faces
[2016-11-30 21:53:34,195][INFO] writes 355000 landmark faces
[2016-11-30 21:53:34,398][INFO] writes 356000 landmark faces
[2016-11-30 21:53:34,604][INFO] writes 357000 landmark faces
[2016-11-30 21:53:34,853][INFO] writes 358000 landmark faces
[2016-11-30 21:53:35,032][INFO] writes 359000 landmark faces
[2016-11-30 21:53:35,248][INFO] writes 360000 landmark faces
[2016-11-30 21:53:35,493][INFO] writes 361000 landmark faces
[2016-11-30 21:53:35,744][INFO] writes 362000 landmark faces
[2016-11-30 21:53:35,987][INFO] writes 363000 landmark faces
[2016-11-30 21:53:36,191][INFO] writes 364000 landmark faces
[2016-11-30 21:53:36,438][INFO] writes 365000 landmark faces
[2016-11-30 21:53:36,652][INFO] writes 366000 landmark faces
[2016-11-30 21:53:36,870][INFO] writes 367000 landmark faces
[2016-11-30 21:53:37,098][INFO] writes 368000 landmark faces
[2016-11-30 21:53:37,313][INFO] writes 369000 landmark faces
[2016-11-30 21:53:37,546][INFO] writes 370000 landmark faces
[2016-11-30 21:53:37,741][INFO] writes 371000 landmark faces
[2016-11-30 21:53:38,008][INFO] writes 372000 landmark faces
[2016-11-30 21:53:38,243][INFO] writes 373000 landmark faces
[2016-11-30 21:53:38,499][INFO] writes 374000 landmark faces
[2016-11-30 21:53:38,713][INFO] writes 375000 landmark faces
[2016-11-30 21:53:38,950][INFO] writes 376000 landmark faces
[2016-11-30 21:53:39,162][INFO] writes 377000 landmark faces
[2016-11-30 21:53:39,413][INFO] writes 378000 landmark faces
[2016-11-30 21:53:39,622][INFO] writes 379000 landmark faces
[2016-11-30 21:53:39,874][INFO] writes 380000 landmark faces
[2016-11-30 21:53:40,086][INFO] writes 381000 landmark faces
[2016-11-30 21:53:40,303][INFO] writes 382000 landmark faces
[2016-11-30 21:53:40,534][INFO] writes 383000 landmark faces
[2016-11-30 21:53:40,798][INFO] writes 384000 landmark faces
[2016-11-30 21:53:41,027][INFO] writes 385000 landmark faces
[2016-11-30 21:53:41,266][INFO] writes 386000 landmark faces
[2016-11-30 21:53:41,532][INFO] writes 387000 landmark faces
[2016-11-30 21:53:41,796][INFO] writes 388000 landmark faces
[2016-11-30 21:53:42,034][INFO] writes 389000 landmark faces
[2016-11-30 21:53:42,301][INFO] writes 390000 landmark faces
[2016-11-30 21:53:42,582][INFO] writes 391000 landmark faces
[2016-11-30 21:53:42,841][INFO] writes 392000 landmark faces
[2016-11-30 21:53:43,074][INFO] writes 393000 landmark faces
[2016-11-30 21:53:43,310][INFO] writes 394000 landmark faces
[2016-11-30 21:53:43,461][INFO] Process-7 reads 5000
[2016-11-30 21:53:43,558][INFO] writes 395000 landmark faces
[2016-11-30 21:53:43,765][INFO] writes 396000 landmark faces
[2016-11-30 21:53:44,022][INFO] writes 397000 landmark faces
[2016-11-30 21:53:44,050][INFO] Process-2 reads 5000
[2016-11-30 21:53:44,273][INFO] writes 398000 landmark faces
[2016-11-30 21:53:44,474][INFO] writes 399000 landmark faces
[2016-11-30 21:53:44,563][INFO] Process-3 reads 5000
[2016-11-30 21:53:44,677][INFO] Process-1 reads 5000
[2016-11-30 21:53:44,696][INFO] writes 400000 landmark faces
[2016-11-30 21:53:44,747][INFO] Process-8 reads 5000
[2016-11-30 21:53:44,919][INFO] writes 401000 landmark faces
[2016-11-30 21:53:45,017][INFO] Process-6 reads 5000
[2016-11-30 21:53:45,151][INFO] writes 402000 landmark faces
[2016-11-30 21:53:45,241][INFO] Process-5 reads 5000
[2016-11-30 21:53:45,405][INFO] writes 403000 landmark faces
[2016-11-30 21:53:45,635][INFO] writes 404000 landmark faces
[2016-11-30 21:53:45,854][INFO] writes 405000 landmark faces
[2016-11-30 21:53:45,954][INFO] Process-4 reads 5000
[2016-11-30 21:53:46,071][INFO] writes 406000 landmark faces
[2016-11-30 21:53:46,311][INFO] writes 407000 landmark faces
[2016-11-30 21:53:46,591][INFO] writes 408000 landmark faces
[2016-11-30 21:53:46,822][INFO] writes 409000 landmark faces
[2016-11-30 21:53:47,020][INFO] writes 410000 landmark faces
[2016-11-30 21:53:47,232][INFO] writes 411000 landmark faces
[2016-11-30 21:53:47,448][INFO] writes 412000 landmark faces
[2016-11-30 21:53:47,695][INFO] writes 413000 landmark faces
[2016-11-30 21:53:47,924][INFO] writes 414000 landmark faces
[2016-11-30 21:53:48,162][INFO] writes 415000 landmark faces
[2016-11-30 21:53:48,413][INFO] writes 416000 landmark faces
[2016-11-30 21:53:48,685][INFO] writes 417000 landmark faces
[2016-11-30 21:53:48,898][INFO] writes 418000 landmark faces
[2016-11-30 21:53:49,135][INFO] writes 419000 landmark faces
[2016-11-30 21:53:49,378][INFO] writes 420000 landmark faces
[2016-11-30 21:53:49,631][INFO] writes 421000 landmark faces
[2016-11-30 21:53:49,852][INFO] writes 422000 landmark faces
[2016-11-30 21:53:50,060][INFO] writes 423000 landmark faces
[2016-11-30 21:53:50,280][INFO] writes 424000 landmark faces
[2016-11-30 21:53:50,511][INFO] writes 425000 landmark faces
[2016-11-30 21:53:50,708][INFO] writes 426000 landmark faces
[2016-11-30 21:53:50,916][INFO] writes 427000 landmark faces
[2016-11-30 21:53:51,130][INFO] writes 428000 landmark faces
[2016-11-30 21:53:51,359][INFO] writes 429000 landmark faces
[2016-11-30 21:53:51,647][INFO] writes 430000 landmark faces
[2016-11-30 21:53:51,874][INFO] writes 431000 landmark faces
[2016-11-30 21:53:52,083][INFO] writes 432000 landmark faces
[2016-11-30 21:53:52,318][INFO] writes 433000 landmark faces
[2016-11-30 21:53:52,557][INFO] writes 434000 landmark faces
[2016-11-30 21:53:52,794][INFO] writes 435000 landmark faces
[2016-11-30 21:53:53,001][INFO] writes 436000 landmark faces
[2016-11-30 21:53:53,233][INFO] writes 437000 landmark faces
[2016-11-30 21:53:53,469][INFO] writes 438000 landmark faces
[2016-11-30 21:53:53,694][INFO] writes 439000 landmark faces
[2016-11-30 21:53:53,929][INFO] writes 440000 landmark faces
[2016-11-30 21:53:54,169][INFO] writes 441000 landmark faces
[2016-11-30 21:53:54,400][INFO] writes 442000 landmark faces
[2016-11-30 21:53:54,631][INFO] writes 443000 landmark faces
[2016-11-30 21:53:54,897][INFO] writes 444000 landmark faces
[2016-11-30 21:53:55,136][INFO] writes 445000 landmark faces
[2016-11-30 21:53:55,414][INFO] writes 446000 landmark faces
[2016-11-30 21:53:55,791][INFO] writes 447000 landmark faces
[2016-11-30 21:53:56,106][INFO] writes 448000 landmark faces
[2016-11-30 21:53:56,484][INFO] writes 449000 landmark faces
[2016-11-30 21:53:56,775][INFO] writes 450000 landmark faces
[2016-11-30 21:53:56,988][INFO] writes 451000 landmark faces
[2016-11-30 21:53:57,213][INFO] writes 452000 landmark faces
[2016-11-30 21:53:57,442][INFO] writes 453000 landmark faces
[2016-11-30 21:53:57,663][INFO] writes 454000 landmark faces
[2016-11-30 21:53:57,869][INFO] writes 455000 landmark faces
[2016-11-30 21:53:58,088][INFO] writes 456000 landmark faces
[2016-11-30 21:53:58,310][INFO] writes 457000 landmark faces
[2016-11-30 21:53:58,523][INFO] writes 458000 landmark faces
[2016-11-30 21:53:58,767][INFO] writes 459000 landmark faces
[2016-11-30 21:53:59,015][INFO] writes 460000 landmark faces
[2016-11-30 21:53:59,250][INFO] writes 461000 landmark faces
[2016-11-30 21:53:59,500][INFO] writes 462000 landmark faces
[2016-11-30 21:53:59,728][INFO] writes 463000 landmark faces
[2016-11-30 21:53:59,955][INFO] writes 464000 landmark faces
[2016-11-30 21:54:00,166][INFO] writes 465000 landmark faces
[2016-11-30 21:54:00,398][INFO] writes 466000 landmark faces
[2016-11-30 21:54:00,639][INFO] writes 467000 landmark faces
[2016-11-30 21:54:00,855][INFO] writes 468000 landmark faces
[2016-11-30 21:54:01,081][INFO] writes 469000 landmark faces
[2016-11-30 21:54:01,317][INFO] writes 470000 landmark faces
[2016-11-30 21:54:01,381][INFO] Process-7 reads 6000
[2016-11-30 21:54:01,539][INFO] writes 471000 landmark faces
[2016-11-30 21:54:01,758][INFO] writes 472000 landmark faces
[2016-11-30 21:54:01,951][INFO] writes 473000 landmark faces
[2016-11-30 21:54:02,203][INFO] writes 474000 landmark faces
[2016-11-30 21:54:02,427][INFO] writes 475000 landmark faces
[2016-11-30 21:54:02,605][INFO] Process-2 reads 6000
[2016-11-30 21:54:02,654][INFO] writes 476000 landmark faces
[2016-11-30 21:54:02,716][INFO] Process-8 reads 6000
[2016-11-30 21:54:02,869][INFO] writes 477000 landmark faces
[2016-11-30 21:54:03,079][INFO] writes 478000 landmark faces
[2016-11-30 21:54:03,319][INFO] writes 479000 landmark faces
[2016-11-30 21:54:03,510][INFO] Process-3 reads 6000
[2016-11-30 21:54:03,540][INFO] writes 480000 landmark faces
[2016-11-30 21:54:03,736][INFO] writes 481000 landmark faces
[2016-11-30 21:54:03,978][INFO] writes 482000 landmark faces
[2016-11-30 21:54:04,039][INFO] Process-6 reads 6000
[2016-11-30 21:54:04,197][INFO] writes 483000 landmark faces
[2016-11-30 21:54:04,251][INFO] Process-5 reads 6000
[2016-11-30 21:54:04,278][INFO] Process-1 reads 6000
[2016-11-30 21:54:04,412][INFO] writes 484000 landmark faces
[2016-11-30 21:54:04,624][INFO] writes 485000 landmark faces
[2016-11-30 21:54:04,882][INFO] writes 486000 landmark faces
[2016-11-30 21:54:05,145][INFO] writes 487000 landmark faces
[2016-11-30 21:54:05,230][INFO] Process-4 reads 6000
[2016-11-30 21:54:05,358][INFO] writes 488000 landmark faces
[2016-11-30 21:54:05,601][INFO] writes 489000 landmark faces
[2016-11-30 21:54:05,837][INFO] writes 490000 landmark faces
[2016-11-30 21:54:06,055][INFO] writes 491000 landmark faces
[2016-11-30 21:54:06,273][INFO] writes 492000 landmark faces
[2016-11-30 21:54:06,506][INFO] writes 493000 landmark faces
[2016-11-30 21:54:06,750][INFO] writes 494000 landmark faces
[2016-11-30 21:54:06,975][INFO] writes 495000 landmark faces
[2016-11-30 21:54:07,192][INFO] writes 496000 landmark faces
[2016-11-30 21:54:07,432][INFO] writes 497000 landmark faces
[2016-11-30 21:54:07,640][INFO] writes 498000 landmark faces
[2016-11-30 21:54:07,884][INFO] writes 499000 landmark faces
[2016-11-30 21:54:08,120][INFO] writes 500000 landmark faces
[2016-11-30 21:54:08,371][INFO] writes 501000 landmark faces
[2016-11-30 21:54:08,599][INFO] writes 502000 landmark faces
[2016-11-30 21:54:08,809][INFO] writes 503000 landmark faces
[2016-11-30 21:54:09,029][INFO] writes 504000 landmark faces
[2016-11-30 21:54:09,282][INFO] writes 505000 landmark faces
[2016-11-30 21:54:09,503][INFO] writes 506000 landmark faces
[2016-11-30 21:54:09,758][INFO] writes 507000 landmark faces
[2016-11-30 21:54:10,005][INFO] writes 508000 landmark faces
[2016-11-30 21:54:10,214][INFO] writes 509000 landmark faces
[2016-11-30 21:54:10,416][INFO] writes 510000 landmark faces
[2016-11-30 21:54:10,635][INFO] writes 511000 landmark faces
[2016-11-30 21:54:10,883][INFO] writes 512000 landmark faces
[2016-11-30 21:54:11,122][INFO] writes 513000 landmark faces
[2016-11-30 21:54:11,374][INFO] writes 514000 landmark faces
[2016-11-30 21:54:11,620][INFO] writes 515000 landmark faces
[2016-11-30 21:54:11,847][INFO] writes 516000 landmark faces
[2016-11-30 21:54:12,125][INFO] writes 517000 landmark faces
[2016-11-30 21:54:12,400][INFO] writes 518000 landmark faces
[2016-11-30 21:54:12,650][INFO] writes 519000 landmark faces
[2016-11-30 21:54:12,869][INFO] writes 520000 landmark faces
[2016-11-30 21:54:13,088][INFO] writes 521000 landmark faces
[2016-11-30 21:54:13,328][INFO] writes 522000 landmark faces
[2016-11-30 21:54:13,533][INFO] writes 523000 landmark faces
[2016-11-30 21:54:13,773][INFO] writes 524000 landmark faces
[2016-11-30 21:54:14,021][INFO] writes 525000 landmark faces
[2016-11-30 21:54:14,229][INFO] writes 526000 landmark faces
[2016-11-30 21:54:14,462][INFO] writes 527000 landmark faces
[2016-11-30 21:54:14,673][INFO] writes 528000 landmark faces
[2016-11-30 21:54:14,886][INFO] writes 529000 landmark faces
[2016-11-30 21:54:15,129][INFO] writes 530000 landmark faces
[2016-11-30 21:54:15,357][INFO] writes 531000 landmark faces
[2016-11-30 21:54:15,565][INFO] writes 532000 landmark faces
[2016-11-30 21:54:15,778][INFO] writes 533000 landmark faces
[2016-11-30 21:54:15,981][INFO] writes 534000 landmark faces
[2016-11-30 21:54:16,203][INFO] writes 535000 landmark faces
[2016-11-30 21:54:16,402][INFO] writes 536000 landmark faces
[2016-11-30 21:54:16,636][INFO] writes 537000 landmark faces
[2016-11-30 21:54:16,867][INFO] writes 538000 landmark faces
[2016-11-30 21:54:17,085][INFO] writes 539000 landmark faces
[2016-11-30 21:54:17,306][INFO] writes 540000 landmark faces
[2016-11-30 21:54:17,519][INFO] writes 541000 landmark faces
[2016-11-30 21:54:17,742][INFO] writes 542000 landmark faces
[2016-11-30 21:54:17,976][INFO] writes 543000 landmark faces
[2016-11-30 21:54:18,211][INFO] writes 544000 landmark faces
[2016-11-30 21:54:18,422][INFO] writes 545000 landmark faces
[2016-11-30 21:54:18,635][INFO] writes 546000 landmark faces
[2016-11-30 21:54:18,847][INFO] writes 547000 landmark faces
[2016-11-30 21:54:19,108][INFO] writes 548000 landmark faces
[2016-11-30 21:54:19,328][INFO] writes 549000 landmark faces
[2016-11-30 21:54:19,448][INFO] Process-7 reads 7000
[2016-11-30 21:54:19,577][INFO] writes 550000 landmark faces
[2016-11-30 21:54:19,786][INFO] writes 551000 landmark faces
[2016-11-30 21:54:20,025][INFO] writes 552000 landmark faces
[2016-11-30 21:54:20,307][INFO] writes 553000 landmark faces
[2016-11-30 21:54:20,567][INFO] writes 554000 landmark faces
[2016-11-30 21:54:20,705][INFO] Process-2 reads 7000
[2016-11-30 21:54:20,847][INFO] writes 555000 landmark faces
[2016-11-30 21:54:20,931][INFO] Process-8 reads 7000
[2016-11-30 21:54:21,052][INFO] writes 556000 landmark faces
[2016-11-30 21:54:21,306][INFO] writes 557000 landmark faces
[2016-11-30 21:54:21,554][INFO] writes 558000 landmark faces
[2016-11-30 21:54:21,809][INFO] writes 559000 landmark faces
[2016-11-30 21:54:21,914][INFO] Process-6 reads 7000
[2016-11-30 21:54:22,015][INFO] writes 560000 landmark faces
[2016-11-30 21:54:22,252][INFO] writes 561000 landmark faces
[2016-11-30 21:54:22,400][INFO] Process-3 reads 7000
[2016-11-30 21:54:22,478][INFO] writes 562000 landmark faces
[2016-11-30 21:54:22,759][INFO] writes 563000 landmark faces
[2016-11-30 21:54:23,002][INFO] writes 564000 landmark faces
[2016-11-30 21:54:23,128][INFO] Process-1 reads 7000
[2016-11-30 21:54:23,215][INFO] writes 565000 landmark faces
[2016-11-30 21:54:23,418][INFO] Process-5 reads 7000
[2016-11-30 21:54:23,423][INFO] writes 566000 landmark faces
[2016-11-30 21:54:23,679][INFO] writes 567000 landmark faces
[2016-11-30 21:54:23,893][INFO] writes 568000 landmark faces
[2016-11-30 21:54:24,159][INFO] writes 569000 landmark faces
[2016-11-30 21:54:24,420][INFO] writes 570000 landmark faces
[2016-11-30 21:54:24,646][INFO] Process-4 reads 7000
[2016-11-30 21:54:24,669][INFO] writes 571000 landmark faces
[2016-11-30 21:54:24,915][INFO] writes 572000 landmark faces
[2016-11-30 21:54:25,143][INFO] writes 573000 landmark faces
[2016-11-30 21:54:25,384][INFO] writes 574000 landmark faces
[2016-11-30 21:54:25,622][INFO] writes 575000 landmark faces
[2016-11-30 21:54:25,867][INFO] writes 576000 landmark faces
[2016-11-30 21:54:26,079][INFO] writes 577000 landmark faces
[2016-11-30 21:54:26,287][INFO] writes 578000 landmark faces
[2016-11-30 21:54:26,528][INFO] writes 579000 landmark faces
[2016-11-30 21:54:26,747][INFO] writes 580000 landmark faces
[2016-11-30 21:54:26,973][INFO] writes 581000 landmark faces
[2016-11-30 21:54:27,244][INFO] writes 582000 landmark faces
[2016-11-30 21:54:27,447][INFO] writes 583000 landmark faces
[2016-11-30 21:54:27,678][INFO] writes 584000 landmark faces
[2016-11-30 21:54:27,957][INFO] writes 585000 landmark faces
[2016-11-30 21:54:28,244][INFO] writes 586000 landmark faces
[2016-11-30 21:54:28,494][INFO] writes 587000 landmark faces
[2016-11-30 21:54:28,732][INFO] writes 588000 landmark faces
[2016-11-30 21:54:28,993][INFO] writes 589000 landmark faces
[2016-11-30 21:54:29,195][INFO] writes 590000 landmark faces
[2016-11-30 21:54:29,459][INFO] writes 591000 landmark faces
[2016-11-30 21:54:29,697][INFO] writes 592000 landmark faces
[2016-11-30 21:54:29,909][INFO] writes 593000 landmark faces
[2016-11-30 21:54:30,139][INFO] writes 594000 landmark faces
[2016-11-30 21:54:30,351][INFO] writes 595000 landmark faces
[2016-11-30 21:54:30,646][INFO] writes 596000 landmark faces
[2016-11-30 21:54:30,950][INFO] writes 597000 landmark faces
[2016-11-30 21:54:31,236][INFO] writes 598000 landmark faces
[2016-11-30 21:54:31,458][INFO] writes 599000 landmark faces
[2016-11-30 21:54:31,669][INFO] writes 600000 landmark faces
[2016-11-30 21:54:31,854][INFO] writes 601000 landmark faces
[2016-11-30 21:54:32,102][INFO] writes 602000 landmark faces
[2016-11-30 21:54:32,321][INFO] writes 603000 landmark faces
[2016-11-30 21:54:32,512][INFO] writes 604000 landmark faces
[2016-11-30 21:54:32,750][INFO] writes 605000 landmark faces
[2016-11-30 21:54:32,969][INFO] writes 606000 landmark faces
[2016-11-30 21:54:33,185][INFO] writes 607000 landmark faces
[2016-11-30 21:54:33,418][INFO] writes 608000 landmark faces
[2016-11-30 21:54:33,623][INFO] writes 609000 landmark faces
[2016-11-30 21:54:33,871][INFO] writes 610000 landmark faces
[2016-11-30 21:54:34,104][INFO] writes 611000 landmark faces
[2016-11-30 21:54:34,318][INFO] writes 612000 landmark faces
[2016-11-30 21:54:34,535][INFO] writes 613000 landmark faces
[2016-11-30 21:54:34,781][INFO] writes 614000 landmark faces
[2016-11-30 21:54:35,016][INFO] writes 615000 landmark faces
[2016-11-30 21:54:35,242][INFO] writes 616000 landmark faces
[2016-11-30 21:54:35,459][INFO] writes 617000 landmark faces
[2016-11-30 21:54:35,711][INFO] writes 618000 landmark faces
[2016-11-30 21:54:35,912][INFO] writes 619000 landmark faces
[2016-11-30 21:54:36,127][INFO] writes 620000 landmark faces
[2016-11-30 21:54:36,352][INFO] writes 621000 landmark faces
[2016-11-30 21:54:36,593][INFO] writes 622000 landmark faces
[2016-11-30 21:54:36,848][INFO] writes 623000 landmark faces
[2016-11-30 21:54:37,061][INFO] writes 624000 landmark faces
[2016-11-30 21:54:37,285][INFO] writes 625000 landmark faces
[2016-11-30 21:54:37,508][INFO] writes 626000 landmark faces
[2016-11-30 21:54:37,764][INFO] writes 627000 landmark faces
[2016-11-30 21:54:38,000][INFO] writes 628000 landmark faces
[2016-11-30 21:54:38,213][INFO] writes 629000 landmark faces
[2016-11-30 21:54:38,462][INFO] writes 630000 landmark faces
[2016-11-30 21:54:38,711][INFO] writes 631000 landmark faces
[2016-11-30 21:54:38,906][INFO] Process-7 reads 8000
[2016-11-30 21:54:38,931][INFO] writes 632000 landmark faces
[2016-11-30 21:54:39,152][INFO] writes 633000 landmark faces
[2016-11-30 21:54:39,394][INFO] writes 634000 landmark faces
[2016-11-30 21:54:39,608][INFO] writes 635000 landmark faces
[2016-11-30 21:54:39,639][INFO] Process-2 reads 8000
[2016-11-30 21:54:39,686][INFO] Process-8 reads 8000
[2016-11-30 21:54:39,831][INFO] writes 636000 landmark faces
[2016-11-30 21:54:39,894][INFO] Process-6 reads 8000
[2016-11-30 21:54:40,031][INFO] writes 637000 landmark faces
[2016-11-30 21:54:40,263][INFO] writes 638000 landmark faces
[2016-11-30 21:54:40,467][INFO] writes 639000 landmark faces
[2016-11-30 21:54:40,684][INFO] writes 640000 landmark faces
[2016-11-30 21:54:40,883][INFO] Process-3 reads 8000
[2016-11-30 21:54:40,929][INFO] writes 641000 landmark faces
[2016-11-30 21:54:41,156][INFO] writes 642000 landmark faces
[2016-11-30 21:54:41,180][INFO] Process-5 reads 8000
[2016-11-30 21:54:41,376][INFO] writes 643000 landmark faces
[2016-11-30 21:54:41,610][INFO] writes 644000 landmark faces
[2016-11-30 21:54:41,838][INFO] writes 645000 landmark faces
[2016-11-30 21:54:42,090][INFO] writes 646000 landmark faces
[2016-11-30 21:54:42,324][INFO] writes 647000 landmark faces
[2016-11-30 21:54:42,478][INFO] Process-1 reads 8000
[2016-11-30 21:54:42,548][INFO] writes 648000 landmark faces
[2016-11-30 21:54:42,802][INFO] writes 649000 landmark faces
[2016-11-30 21:54:43,054][INFO] writes 650000 landmark faces
[2016-11-30 21:54:43,288][INFO] writes 651000 landmark faces
[2016-11-30 21:54:43,316][INFO] Process-4 reads 8000
[2016-11-30 21:54:43,486][INFO] writes 652000 landmark faces
[2016-11-30 21:54:43,722][INFO] writes 653000 landmark faces
[2016-11-30 21:54:43,940][INFO] writes 654000 landmark faces
[2016-11-30 21:54:44,175][INFO] writes 655000 landmark faces
[2016-11-30 21:54:44,459][INFO] writes 656000 landmark faces
[2016-11-30 21:54:44,692][INFO] writes 657000 landmark faces
[2016-11-30 21:54:44,939][INFO] writes 658000 landmark faces
[2016-11-30 21:54:45,195][INFO] writes 659000 landmark faces
[2016-11-30 21:54:45,448][INFO] writes 660000 landmark faces
[2016-11-30 21:54:45,654][INFO] writes 661000 landmark faces
[2016-11-30 21:54:45,891][INFO] writes 662000 landmark faces
[2016-11-30 21:54:46,125][INFO] writes 663000 landmark faces
[2016-11-30 21:54:46,375][INFO] writes 664000 landmark faces
[2016-11-30 21:54:46,598][INFO] writes 665000 landmark faces
[2016-11-30 21:54:46,827][INFO] writes 666000 landmark faces
[2016-11-30 21:54:47,075][INFO] writes 667000 landmark faces
[2016-11-30 21:54:47,284][INFO] writes 668000 landmark faces
[2016-11-30 21:54:47,521][INFO] writes 669000 landmark faces
[2016-11-30 21:54:47,731][INFO] writes 670000 landmark faces
[2016-11-30 21:54:47,947][INFO] writes 671000 landmark faces
[2016-11-30 21:54:48,186][INFO] writes 672000 landmark faces
[2016-11-30 21:54:48,421][INFO] writes 673000 landmark faces
[2016-11-30 21:54:48,659][INFO] writes 674000 landmark faces
[2016-11-30 21:54:48,873][INFO] writes 675000 landmark faces
[2016-11-30 21:54:49,097][INFO] writes 676000 landmark faces
[2016-11-30 21:54:49,308][INFO] writes 677000 landmark faces
[2016-11-30 21:54:49,531][INFO] writes 678000 landmark faces
[2016-11-30 21:54:49,755][INFO] writes 679000 landmark faces
[2016-11-30 21:54:50,007][INFO] writes 680000 landmark faces
[2016-11-30 21:54:50,230][INFO] writes 681000 landmark faces
[2016-11-30 21:54:50,434][INFO] writes 682000 landmark faces
[2016-11-30 21:54:50,648][INFO] writes 683000 landmark faces
[2016-11-30 21:54:50,892][INFO] writes 684000 landmark faces
[2016-11-30 21:54:51,129][INFO] writes 685000 landmark faces
[2016-11-30 21:54:51,359][INFO] writes 686000 landmark faces
[2016-11-30 21:54:51,595][INFO] writes 687000 landmark faces
[2016-11-30 21:54:51,836][INFO] writes 688000 landmark faces
[2016-11-30 21:54:52,056][INFO] writes 689000 landmark faces
[2016-11-30 21:54:52,284][INFO] writes 690000 landmark faces
[2016-11-30 21:54:52,522][INFO] writes 691000 landmark faces
[2016-11-30 21:54:52,781][INFO] writes 692000 landmark faces
[2016-11-30 21:54:53,005][INFO] writes 693000 landmark faces
[2016-11-30 21:54:53,211][INFO] writes 694000 landmark faces
[2016-11-30 21:54:53,427][INFO] writes 695000 landmark faces
[2016-11-30 21:54:53,636][INFO] writes 696000 landmark faces
[2016-11-30 21:54:53,853][INFO] writes 697000 landmark faces
[2016-11-30 21:54:54,090][INFO] writes 698000 landmark faces
[2016-11-30 21:54:54,308][INFO] writes 699000 landmark faces
[2016-11-30 21:54:54,520][INFO] writes 700000 landmark faces
[2016-11-30 21:54:54,724][INFO] writes 701000 landmark faces
[2016-11-30 21:54:54,931][INFO] writes 702000 landmark faces
[2016-11-30 21:54:55,155][INFO] writes 703000 landmark faces
[2016-11-30 21:54:55,357][INFO] writes 704000 landmark faces
[2016-11-30 21:54:55,597][INFO] writes 705000 landmark faces
[2016-11-30 21:54:55,819][INFO] writes 706000 landmark faces
[2016-11-30 21:54:56,068][INFO] writes 707000 landmark faces
[2016-11-30 21:54:56,312][INFO] writes 708000 landmark faces
[2016-11-30 21:54:56,520][INFO] writes 709000 landmark faces
[2016-11-30 21:54:56,757][INFO] writes 710000 landmark faces
[2016-11-30 21:54:56,908][INFO] Process-7 reads 9000
[2016-11-30 21:54:56,972][INFO] writes 711000 landmark faces
[2016-11-30 21:54:56,997][INFO] Process-8 reads 9000
[2016-11-30 21:54:57,190][INFO] writes 712000 landmark faces
[2016-11-30 21:54:57,411][INFO] writes 713000 landmark faces
[2016-11-30 21:54:57,674][INFO] writes 714000 landmark faces
[2016-11-30 21:54:57,883][INFO] writes 715000 landmark faces
[2016-11-30 21:54:58,143][INFO] writes 716000 landmark faces
[2016-11-30 21:54:58,320][INFO] writes 717000 landmark faces
[2016-11-30 21:54:58,548][INFO] writes 718000 landmark faces
[2016-11-30 21:54:58,658][INFO] Process-6 reads 9000
[2016-11-30 21:54:58,795][INFO] Process-5 reads 9000
[2016-11-30 21:54:58,808][INFO] writes 719000 landmark faces
[2016-11-30 21:54:59,013][INFO] Process-2 reads 9000
[2016-11-30 21:54:59,038][INFO] writes 720000 landmark faces
[2016-11-30 21:54:59,248][INFO] writes 721000 landmark faces
[2016-11-30 21:54:59,454][INFO] writes 722000 landmark faces
[2016-11-30 21:54:59,588][INFO] Process-3 reads 9000
[2016-11-30 21:54:59,690][INFO] writes 723000 landmark faces
[2016-11-30 21:54:59,938][INFO] writes 724000 landmark faces
[2016-11-30 21:55:00,153][INFO] writes 725000 landmark faces
[2016-11-30 21:55:00,371][INFO] writes 726000 landmark faces
[2016-11-30 21:55:00,618][INFO] writes 727000 landmark faces
[2016-11-30 21:55:00,778][INFO] Process-1 reads 9000
[2016-11-30 21:55:00,835][INFO] writes 728000 landmark faces
[2016-11-30 21:55:01,052][INFO] writes 729000 landmark faces
[2016-11-30 21:55:01,289][INFO] writes 730000 landmark faces
[2016-11-30 21:55:01,530][INFO] writes 731000 landmark faces
[2016-11-30 21:55:01,583][INFO] Process-4 reads 9000
[2016-11-30 21:55:01,750][INFO] writes 732000 landmark faces
[2016-11-30 21:55:01,966][INFO] writes 733000 landmark faces
[2016-11-30 21:55:02,188][INFO] writes 734000 landmark faces
[2016-11-30 21:55:02,415][INFO] writes 735000 landmark faces
[2016-11-30 21:55:02,636][INFO] writes 736000 landmark faces
[2016-11-30 21:55:02,937][INFO] writes 737000 landmark faces
[2016-11-30 21:55:03,169][INFO] writes 738000 landmark faces
[2016-11-30 21:55:03,368][INFO] writes 739000 landmark faces
[2016-11-30 21:55:03,590][INFO] writes 740000 landmark faces
[2016-11-30 21:55:03,853][INFO] writes 741000 landmark faces
[2016-11-30 21:55:04,098][INFO] writes 742000 landmark faces
[2016-11-30 21:55:04,338][INFO] writes 743000 landmark faces
[2016-11-30 21:55:04,587][INFO] writes 744000 landmark faces
[2016-11-30 21:55:04,823][INFO] writes 745000 landmark faces
[2016-11-30 21:55:05,087][INFO] writes 746000 landmark faces
[2016-11-30 21:55:05,369][INFO] writes 747000 landmark faces
[2016-11-30 21:55:05,622][INFO] writes 748000 landmark faces
[2016-11-30 21:55:05,850][INFO] writes 749000 landmark faces
[2016-11-30 21:55:06,083][INFO] writes 750000 landmark faces
[2016-11-30 21:55:06,307][INFO] writes 751000 landmark faces
[2016-11-30 21:55:06,551][INFO] writes 752000 landmark faces
[2016-11-30 21:55:06,808][INFO] writes 753000 landmark faces
[2016-11-30 21:55:07,055][INFO] writes 754000 landmark faces
[2016-11-30 21:55:07,275][INFO] writes 755000 landmark faces
[2016-11-30 21:55:07,541][INFO] writes 756000 landmark faces
[2016-11-30 21:55:07,750][INFO] writes 757000 landmark faces
[2016-11-30 21:55:07,995][INFO] writes 758000 landmark faces
[2016-11-30 21:55:08,274][INFO] writes 759000 landmark faces
[2016-11-30 21:55:08,525][INFO] writes 760000 landmark faces
[2016-11-30 21:55:08,743][INFO] writes 761000 landmark faces
[2016-11-30 21:55:08,950][INFO] writes 762000 landmark faces
[2016-11-30 21:55:09,157][INFO] writes 763000 landmark faces
[2016-11-30 21:55:09,368][INFO] writes 764000 landmark faces
[2016-11-30 21:55:09,589][INFO] writes 765000 landmark faces
[2016-11-30 21:55:09,812][INFO] writes 766000 landmark faces
[2016-11-30 21:55:10,019][INFO] writes 767000 landmark faces
[2016-11-30 21:55:10,216][INFO] writes 768000 landmark faces
[2016-11-30 21:55:10,459][INFO] writes 769000 landmark faces
[2016-11-30 21:55:10,691][INFO] writes 770000 landmark faces
[2016-11-30 21:55:10,916][INFO] writes 771000 landmark faces
[2016-11-30 21:55:11,141][INFO] writes 772000 landmark faces
[2016-11-30 21:55:11,378][INFO] writes 773000 landmark faces
[2016-11-30 21:55:11,614][INFO] writes 774000 landmark faces
[2016-11-30 21:55:11,837][INFO] writes 775000 landmark faces
[2016-11-30 21:55:12,070][INFO] writes 776000 landmark faces
[2016-11-30 21:55:12,281][INFO] writes 777000 landmark faces
[2016-11-30 21:55:12,498][INFO] writes 778000 landmark faces
[2016-11-30 21:55:12,709][INFO] writes 779000 landmark faces
[2016-11-30 21:55:12,935][INFO] writes 780000 landmark faces
[2016-11-30 21:55:13,238][INFO] writes 781000 landmark faces
[2016-11-30 21:55:13,414][INFO] writes 782000 landmark faces
[2016-11-30 21:55:13,641][INFO] writes 783000 landmark faces
[2016-11-30 21:55:13,853][INFO] writes 784000 landmark faces
[2016-11-30 21:55:14,049][INFO] writes 785000 landmark faces
[2016-11-30 21:55:14,276][INFO] writes 786000 landmark faces
[2016-11-30 21:55:14,495][INFO] writes 787000 landmark faces
[2016-11-30 21:55:14,588][INFO] Process-8 reads 10000
[2016-11-30 21:55:14,718][INFO] writes 788000 landmark faces
[2016-11-30 21:55:14,879][INFO] Process-7 reads 10000
[2016-11-30 21:55:14,937][INFO] writes 789000 landmark faces
[2016-11-30 21:55:15,159][INFO] writes 790000 landmark faces
[2016-11-30 21:55:15,377][INFO] writes 791000 landmark faces
[2016-11-30 21:55:15,612][INFO] writes 792000 landmark faces
[2016-11-30 21:55:15,845][INFO] writes 793000 landmark faces
[2016-11-30 21:55:16,057][INFO] writes 794000 landmark faces
[2016-11-30 21:55:16,276][INFO] writes 795000 landmark faces
[2016-11-30 21:55:16,497][INFO] writes 796000 landmark faces
[2016-11-30 21:55:16,755][INFO] writes 797000 landmark faces
[2016-11-30 21:55:16,841][INFO] Process-5 reads 10000
[2016-11-30 21:55:16,854][INFO] Process-6 reads 10000
[2016-11-30 21:55:16,984][INFO] writes 798000 landmark faces
[2016-11-30 21:55:17,217][INFO] writes 799000 landmark faces
[2016-11-30 21:55:17,427][INFO] writes 800000 landmark faces
[2016-11-30 21:55:17,656][INFO] writes 801000 landmark faces
[2016-11-30 21:55:17,868][INFO] writes 802000 landmark faces
[2016-11-30 21:55:18,084][INFO] writes 803000 landmark faces
[2016-11-30 21:55:18,183][INFO] Process-2 reads 10000
[2016-11-30 21:55:18,301][INFO] writes 804000 landmark faces
[2016-11-30 21:55:18,425][INFO] Process-3 reads 10000
[2016-11-30 21:55:18,518][INFO] writes 805000 landmark faces
[2016-11-30 21:55:18,728][INFO] writes 806000 landmark faces
[2016-11-30 21:55:18,954][INFO] writes 807000 landmark faces
[2016-11-30 21:55:19,175][INFO] writes 808000 landmark faces
[2016-11-30 21:55:19,443][INFO] writes 809000 landmark faces
[2016-11-30 21:55:19,499][INFO] Process-4 reads 10000
[2016-11-30 21:55:19,664][INFO] writes 810000 landmark faces
[2016-11-30 21:55:19,885][INFO] writes 811000 landmark faces
[2016-11-30 21:55:19,990][INFO] Process-1 reads 10000
[2016-11-30 21:55:20,101][INFO] writes 812000 landmark faces
[2016-11-30 21:55:20,330][INFO] writes 813000 landmark faces
[2016-11-30 21:55:20,575][INFO] writes 814000 landmark faces
[2016-11-30 21:55:20,790][INFO] writes 815000 landmark faces
[2016-11-30 21:55:20,997][INFO] writes 816000 landmark faces
[2016-11-30 21:55:21,215][INFO] writes 817000 landmark faces
[2016-11-30 21:55:21,429][INFO] writes 818000 landmark faces
[2016-11-30 21:55:21,635][INFO] writes 819000 landmark faces
[2016-11-30 21:55:21,846][INFO] writes 820000 landmark faces
[2016-11-30 21:55:22,094][INFO] writes 821000 landmark faces
[2016-11-30 21:55:22,292][INFO] writes 822000 landmark faces
[2016-11-30 21:55:22,504][INFO] writes 823000 landmark faces
[2016-11-30 21:55:22,742][INFO] writes 824000 landmark faces
[2016-11-30 21:55:22,988][INFO] writes 825000 landmark faces
[2016-11-30 21:55:23,230][INFO] writes 826000 landmark faces
[2016-11-30 21:55:23,471][INFO] writes 827000 landmark faces
[2016-11-30 21:55:23,694][INFO] writes 828000 landmark faces
[2016-11-30 21:55:23,960][INFO] writes 829000 landmark faces
[2016-11-30 21:55:24,178][INFO] writes 830000 landmark faces
[2016-11-30 21:55:24,413][INFO] writes 831000 landmark faces
[2016-11-30 21:55:24,662][INFO] writes 832000 landmark faces
[2016-11-30 21:55:24,878][INFO] writes 833000 landmark faces
[2016-11-30 21:55:25,116][INFO] writes 834000 landmark faces
[2016-11-30 21:55:25,349][INFO] writes 835000 landmark faces
[2016-11-30 21:55:25,587][INFO] writes 836000 landmark faces
[2016-11-30 21:55:25,841][INFO] writes 837000 landmark faces
[2016-11-30 21:55:26,080][INFO] writes 838000 landmark faces
[2016-11-30 21:55:26,324][INFO] writes 839000 landmark faces
[2016-11-30 21:55:26,543][INFO] writes 840000 landmark faces
[2016-11-30 21:55:26,798][INFO] writes 841000 landmark faces
[2016-11-30 21:55:27,031][INFO] writes 842000 landmark faces
[2016-11-30 21:55:27,248][INFO] writes 843000 landmark faces
[2016-11-30 21:55:27,496][INFO] writes 844000 landmark faces
[2016-11-30 21:55:27,713][INFO] writes 845000 landmark faces
[2016-11-30 21:55:27,964][INFO] writes 846000 landmark faces
[2016-11-30 21:55:28,172][INFO] writes 847000 landmark faces
[2016-11-30 21:55:28,377][INFO] writes 848000 landmark faces
[2016-11-30 21:55:28,635][INFO] writes 849000 landmark faces
[2016-11-30 21:55:28,855][INFO] writes 850000 landmark faces
[2016-11-30 21:55:29,070][INFO] writes 851000 landmark faces
[2016-11-30 21:55:29,347][INFO] writes 852000 landmark faces
[2016-11-30 21:55:29,624][INFO] writes 853000 landmark faces
[2016-11-30 21:55:29,832][INFO] writes 854000 landmark faces
[2016-11-30 21:55:30,065][INFO] writes 855000 landmark faces
[2016-11-30 21:55:30,288][INFO] writes 856000 landmark faces
[2016-11-30 21:55:30,516][INFO] writes 857000 landmark faces
[2016-11-30 21:55:30,742][INFO] writes 858000 landmark faces
[2016-11-30 21:55:30,996][INFO] writes 859000 landmark faces
[2016-11-30 21:55:31,190][INFO] writes 860000 landmark faces
[2016-11-30 21:55:31,440][INFO] writes 861000 landmark faces
[2016-11-30 21:55:31,661][INFO] writes 862000 landmark faces
[2016-11-30 21:55:31,901][INFO] writes 863000 landmark faces
[2016-11-30 21:55:32,201][INFO] writes 864000 landmark faces
[2016-11-30 21:55:32,444][INFO] writes 865000 landmark faces
[2016-11-30 21:55:32,478][INFO] Process-8 reads 11000
[2016-11-30 21:55:32,657][INFO] writes 866000 landmark faces
[2016-11-30 21:55:32,845][INFO] writes 867000 landmark faces
[2016-11-30 21:55:33,106][INFO] writes 868000 landmark faces
[2016-11-30 21:55:33,332][INFO] writes 869000 landmark faces
[2016-11-30 21:55:33,599][INFO] writes 870000 landmark faces
[2016-11-30 21:55:33,829][INFO] writes 871000 landmark faces
[2016-11-30 21:55:34,053][INFO] writes 872000 landmark faces
[2016-11-30 21:55:34,268][INFO] writes 873000 landmark faces
[2016-11-30 21:55:34,280][INFO] Process-5 reads 11000
[2016-11-30 21:55:34,496][INFO] writes 874000 landmark faces
[2016-11-30 21:55:34,709][INFO] writes 875000 landmark faces
[2016-11-30 21:55:34,973][INFO] writes 876000 landmark faces
[2016-11-30 21:55:35,019][INFO] Process-7 reads 11000
[2016-11-30 21:55:35,218][INFO] writes 877000 landmark faces
[2016-11-30 21:55:35,256][INFO] Process-6 reads 11000
[2016-11-30 21:55:35,422][INFO] writes 878000 landmark faces
[2016-11-30 21:55:35,662][INFO] writes 879000 landmark faces
[2016-11-30 21:55:35,917][INFO] writes 880000 landmark faces
[2016-11-30 21:55:36,154][INFO] writes 881000 landmark faces
[2016-11-30 21:55:36,386][INFO] writes 882000 landmark faces
[2016-11-30 21:55:36,610][INFO] Process-2 reads 11000
[2016-11-30 21:55:36,615][INFO] writes 883000 landmark faces
[2016-11-30 21:55:36,785][INFO] Process-3 reads 11000
[2016-11-30 21:55:36,865][INFO] writes 884000 landmark faces
[2016-11-30 21:55:37,101][INFO] writes 885000 landmark faces
[2016-11-30 21:55:37,336][INFO] writes 886000 landmark faces
[2016-11-30 21:55:37,560][INFO] writes 887000 landmark faces
[2016-11-30 21:55:37,798][INFO] writes 888000 landmark faces
[2016-11-30 21:55:38,044][INFO] writes 889000 landmark faces
[2016-11-30 21:55:38,276][INFO] writes 890000 landmark faces
[2016-11-30 21:55:38,550][INFO] writes 891000 landmark faces
[2016-11-30 21:55:38,570][INFO] Process-4 reads 11000
[2016-11-30 21:55:38,694][INFO] Process-1 reads 11000
[2016-11-30 21:55:38,797][INFO] writes 892000 landmark faces
[2016-11-30 21:55:39,044][INFO] writes 893000 landmark faces
[2016-11-30 21:55:39,305][INFO] writes 894000 landmark faces
[2016-11-30 21:55:39,546][INFO] writes 895000 landmark faces
[2016-11-30 21:55:39,748][INFO] writes 896000 landmark faces
[2016-11-30 21:55:39,997][INFO] writes 897000 landmark faces
[2016-11-30 21:55:40,254][INFO] writes 898000 landmark faces
[2016-11-30 21:55:40,492][INFO] writes 899000 landmark faces
[2016-11-30 21:55:40,690][INFO] writes 900000 landmark faces
[2016-11-30 21:55:40,979][INFO] writes 901000 landmark faces
[2016-11-30 21:55:41,237][INFO] writes 902000 landmark faces
[2016-11-30 21:55:41,492][INFO] writes 903000 landmark faces
[2016-11-30 21:55:41,713][INFO] writes 904000 landmark faces
[2016-11-30 21:55:41,951][INFO] writes 905000 landmark faces
[2016-11-30 21:55:42,213][INFO] writes 906000 landmark faces
[2016-11-30 21:55:42,476][INFO] writes 907000 landmark faces
[2016-11-30 21:55:42,702][INFO] writes 908000 landmark faces
[2016-11-30 21:55:42,923][INFO] writes 909000 landmark faces
[2016-11-30 21:55:43,167][INFO] writes 910000 landmark faces
[2016-11-30 21:55:43,403][INFO] writes 911000 landmark faces
[2016-11-30 21:55:43,658][INFO] writes 912000 landmark faces
[2016-11-30 21:55:43,936][INFO] writes 913000 landmark faces
[2016-11-30 21:55:44,182][INFO] writes 914000 landmark faces
[2016-11-30 21:55:44,447][INFO] writes 915000 landmark faces
[2016-11-30 21:55:44,710][INFO] writes 916000 landmark faces
[2016-11-30 21:55:44,955][INFO] writes 917000 landmark faces
[2016-11-30 21:55:45,193][INFO] writes 918000 landmark faces
[2016-11-30 21:55:45,417][INFO] writes 919000 landmark faces
[2016-11-30 21:55:45,632][INFO] writes 920000 landmark faces
[2016-11-30 21:55:45,846][INFO] writes 921000 landmark faces
[2016-11-30 21:55:46,049][INFO] writes 922000 landmark faces
[2016-11-30 21:55:46,266][INFO] writes 923000 landmark faces
[2016-11-30 21:55:46,527][INFO] writes 924000 landmark faces
[2016-11-30 21:55:46,757][INFO] writes 925000 landmark faces
[2016-11-30 21:55:46,975][INFO] writes 926000 landmark faces
[2016-11-30 21:55:47,178][INFO] writes 927000 landmark faces
[2016-11-30 21:55:47,413][INFO] writes 928000 landmark faces
[2016-11-30 21:55:47,658][INFO] writes 929000 landmark faces
[2016-11-30 21:55:47,872][INFO] writes 930000 landmark faces
[2016-11-30 21:55:48,086][INFO] writes 931000 landmark faces
[2016-11-30 21:55:48,315][INFO] writes 932000 landmark faces
[2016-11-30 21:55:48,544][INFO] writes 933000 landmark faces
[2016-11-30 21:55:48,831][INFO] writes 934000 landmark faces
[2016-11-30 21:55:49,075][INFO] writes 935000 landmark faces
[2016-11-30 21:55:49,292][INFO] writes 936000 landmark faces
[2016-11-30 21:55:49,529][INFO] writes 937000 landmark faces
[2016-11-30 21:55:49,791][INFO] writes 938000 landmark faces
[2016-11-30 21:55:50,030][INFO] writes 939000 landmark faces
[2016-11-30 21:55:50,268][INFO] writes 940000 landmark faces
[2016-11-30 21:55:50,480][INFO] writes 941000 landmark faces
[2016-11-30 21:55:50,711][INFO] writes 942000 landmark faces
[2016-11-30 21:55:50,927][INFO] writes 943000 landmark faces
[2016-11-30 21:55:51,208][INFO] writes 944000 landmark faces
[2016-11-30 21:55:51,425][INFO] writes 945000 landmark faces
[2016-11-30 21:55:51,718][INFO] writes 946000 landmark faces
[2016-11-30 21:55:51,952][INFO] writes 947000 landmark faces
[2016-11-30 21:55:52,173][INFO] writes 948000 landmark faces
[2016-11-30 21:55:52,378][INFO] Process-8 reads 12000
[2016-11-30 21:55:52,391][INFO] writes 949000 landmark faces
[2016-11-30 21:55:52,619][INFO] writes 950000 landmark faces
[2016-11-30 21:55:52,721][INFO] Process-5 reads 12000
[2016-11-30 21:55:52,866][INFO] writes 951000 landmark faces
[2016-11-30 21:55:53,109][INFO] writes 952000 landmark faces
[2016-11-30 21:55:53,337][INFO] writes 953000 landmark faces
[2016-11-30 21:55:53,556][INFO] writes 954000 landmark faces
[2016-11-30 21:55:53,784][INFO] Process-7 reads 12000
[2016-11-30 21:55:53,797][INFO] writes 955000 landmark faces
[2016-11-30 21:55:53,993][INFO] Process-6 reads 12000
[2016-11-30 21:55:54,077][INFO] writes 956000 landmark faces
[2016-11-30 21:55:54,298][INFO] writes 957000 landmark faces
[2016-11-30 21:55:54,523][INFO] writes 958000 landmark faces
[2016-11-30 21:55:54,750][INFO] writes 959000 landmark faces
[2016-11-30 21:55:54,982][INFO] writes 960000 landmark faces
[2016-11-30 21:55:55,211][INFO] writes 961000 landmark faces
[2016-11-30 21:55:55,461][INFO] writes 962000 landmark faces
[2016-11-30 21:55:55,638][INFO] Process-3 reads 12000
[2016-11-30 21:55:55,689][INFO] writes 963000 landmark faces
[2016-11-30 21:55:55,948][INFO] writes 964000 landmark faces
[2016-11-30 21:55:56,180][INFO] writes 965000 landmark faces
[2016-11-30 21:55:56,397][INFO] Process-2 reads 12000
[2016-11-30 21:55:56,433][INFO] writes 966000 landmark faces
[2016-11-30 21:55:56,675][INFO] writes 967000 landmark faces
[2016-11-30 21:55:56,867][INFO] writes 968000 landmark faces
[2016-11-30 21:55:57,124][INFO] writes 969000 landmark faces
[2016-11-30 21:55:57,363][INFO] writes 970000 landmark faces
[2016-11-30 21:55:57,545][INFO] Process-4 reads 12000
[2016-11-30 21:55:57,582][INFO] writes 971000 landmark faces
[2016-11-30 21:55:57,667][INFO] Process-1 reads 12000
[2016-11-30 21:55:57,846][INFO] writes 972000 landmark faces
[2016-11-30 21:55:58,067][INFO] writes 973000 landmark faces
[2016-11-30 21:55:58,293][INFO] writes 974000 landmark faces
[2016-11-30 21:55:58,509][INFO] writes 975000 landmark faces
[2016-11-30 21:55:58,719][INFO] writes 976000 landmark faces
[2016-11-30 21:55:58,961][INFO] writes 977000 landmark faces
[2016-11-30 21:55:59,214][INFO] writes 978000 landmark faces
[2016-11-30 21:55:59,453][INFO] writes 979000 landmark faces
[2016-11-30 21:55:59,689][INFO] writes 980000 landmark faces
[2016-11-30 21:55:59,934][INFO] writes 981000 landmark faces
[2016-11-30 21:56:00,143][INFO] writes 982000 landmark faces
[2016-11-30 21:56:00,400][INFO] writes 983000 landmark faces
[2016-11-30 21:56:00,657][INFO] writes 984000 landmark faces
[2016-11-30 21:56:00,951][INFO] writes 985000 landmark faces
[2016-11-30 21:56:01,239][INFO] writes 986000 landmark faces
[2016-11-30 21:56:01,452][INFO] writes 987000 landmark faces
[2016-11-30 21:56:01,671][INFO] writes 988000 landmark faces
[2016-11-30 21:56:01,897][INFO] writes 989000 landmark faces
[2016-11-30 21:56:02,128][INFO] writes 990000 landmark faces
[2016-11-30 21:56:02,336][INFO] writes 991000 landmark faces
[2016-11-30 21:56:02,555][INFO] writes 992000 landmark faces
[2016-11-30 21:56:02,771][INFO] writes 993000 landmark faces
[2016-11-30 21:56:03,021][INFO] writes 994000 landmark faces
[2016-11-30 21:56:03,267][INFO] writes 995000 landmark faces
[2016-11-30 21:56:03,522][INFO] writes 996000 landmark faces
[2016-11-30 21:56:03,752][INFO] writes 997000 landmark faces
[2016-11-30 21:56:03,994][INFO] writes 998000 landmark faces
[2016-11-30 21:56:04,206][INFO] writes 999000 landmark faces
[2016-11-30 21:56:04,427][INFO] writes 1000000 landmark faces
[2016-11-30 21:56:04,627][INFO] writes 1001000 landmark faces
[2016-11-30 21:56:04,888][INFO] writes 1002000 landmark faces
[2016-11-30 21:56:05,090][INFO] writes 1003000 landmark faces
[2016-11-30 21:56:05,324][INFO] writes 1004000 landmark faces
[2016-11-30 21:56:05,557][INFO] writes 1005000 landmark faces
[2016-11-30 21:56:05,787][INFO] writes 1006000 landmark faces
[2016-11-30 21:56:06,068][INFO] writes 1007000 landmark faces
[2016-11-30 21:56:06,294][INFO] writes 1008000 landmark faces
[2016-11-30 21:56:06,541][INFO] writes 1009000 landmark faces
[2016-11-30 21:56:06,779][INFO] writes 1010000 landmark faces
[2016-11-30 21:56:07,026][INFO] writes 1011000 landmark faces
[2016-11-30 21:56:07,248][INFO] writes 1012000 landmark faces
[2016-11-30 21:56:07,501][INFO] writes 1013000 landmark faces
[2016-11-30 21:56:07,726][INFO] writes 1014000 landmark faces
[2016-11-30 21:56:07,926][INFO] writes 1015000 landmark faces
[2016-11-30 21:56:08,189][INFO] writes 1016000 landmark faces
[2016-11-30 21:56:08,422][INFO] writes 1017000 landmark faces
[2016-11-30 21:56:08,676][INFO] writes 1018000 landmark faces
[2016-11-30 21:56:08,883][INFO] writes 1019000 landmark faces
[2016-11-30 21:56:09,144][INFO] writes 1020000 landmark faces
[2016-11-30 21:56:09,405][INFO] writes 1021000 landmark faces
[2016-11-30 21:56:09,674][INFO] writes 1022000 landmark faces
[2016-11-30 21:56:09,881][INFO] writes 1023000 landmark faces
[2016-11-30 21:56:10,102][INFO] writes 1024000 landmark faces
[2016-11-30 21:56:10,379][INFO] writes 1025000 landmark faces
[2016-11-30 21:56:10,506][INFO] Process-8 reads 13000
[2016-11-30 21:56:10,592][INFO] writes 1026000 landmark faces
[2016-11-30 21:56:10,824][INFO] writes 1027000 landmark faces
[2016-11-30 21:56:11,044][INFO] writes 1028000 landmark faces
[2016-11-30 21:56:11,256][INFO] writes 1029000 landmark faces
[2016-11-30 21:56:11,472][INFO] writes 1030000 landmark faces
[2016-11-30 21:56:11,697][INFO] writes 1031000 landmark faces
[2016-11-30 21:56:11,951][INFO] writes 1032000 landmark faces
[2016-11-30 21:56:12,050][INFO] Process-5 reads 13000
[2016-11-30 21:56:12,181][INFO] writes 1033000 landmark faces
[2016-11-30 21:56:12,290][INFO] Process-6 reads 13000
[2016-11-30 21:56:12,317][INFO] Process-7 reads 13000
[2016-11-30 21:56:12,442][INFO] writes 1034000 landmark faces
[2016-11-30 21:56:12,659][INFO] writes 1035000 landmark faces
[2016-11-30 21:56:12,861][INFO] writes 1036000 landmark faces
[2016-11-30 21:56:13,092][INFO] writes 1037000 landmark faces
[2016-11-30 21:56:13,365][INFO] writes 1038000 landmark faces
[2016-11-30 21:56:13,623][INFO] writes 1039000 landmark faces
[2016-11-30 21:56:13,821][INFO] writes 1040000 landmark faces
[2016-11-30 21:56:14,020][INFO] writes 1041000 landmark faces
[2016-11-30 21:56:14,228][INFO] writes 1042000 landmark faces
[2016-11-30 21:56:14,471][INFO] writes 1043000 landmark faces
[2016-11-30 21:56:14,722][INFO] writes 1044000 landmark faces
[2016-11-30 21:56:14,964][INFO] writes 1045000 landmark faces
[2016-11-30 21:56:15,232][INFO] Process-3 reads 13000
[2016-11-30 21:56:15,251][INFO] writes 1046000 landmark faces
[2016-11-30 21:56:15,254][INFO] Process-2 reads 13000
[2016-11-30 21:56:15,535][INFO] writes 1047000 landmark faces
[2016-11-30 21:56:15,749][INFO] writes 1048000 landmark faces
[2016-11-30 21:56:15,959][INFO] writes 1049000 landmark faces
[2016-11-30 21:56:16,150][INFO] Process-1 reads 13000
[2016-11-30 21:56:16,161][INFO] writes 1050000 landmark faces
[2016-11-30 21:56:16,372][INFO] writes 1051000 landmark faces
[2016-11-30 21:56:16,592][INFO] writes 1052000 landmark faces
[2016-11-30 21:56:16,627][INFO] Process-4 reads 13000
[2016-11-30 21:56:16,804][INFO] writes 1053000 landmark faces
[2016-11-30 21:56:17,057][INFO] writes 1054000 landmark faces
[2016-11-30 21:56:17,297][INFO] writes 1055000 landmark faces
[2016-11-30 21:56:17,516][INFO] writes 1056000 landmark faces
[2016-11-30 21:56:17,708][INFO] writes 1057000 landmark faces
[2016-11-30 21:56:17,939][INFO] writes 1058000 landmark faces
[2016-11-30 21:56:18,203][INFO] writes 1059000 landmark faces
[2016-11-30 21:56:18,471][INFO] writes 1060000 landmark faces
[2016-11-30 21:56:18,704][INFO] writes 1061000 landmark faces
[2016-11-30 21:56:18,914][INFO] writes 1062000 landmark faces
[2016-11-30 21:56:19,152][INFO] writes 1063000 landmark faces
[2016-11-30 21:56:19,401][INFO] writes 1064000 landmark faces
[2016-11-30 21:56:19,607][INFO] writes 1065000 landmark faces
[2016-11-30 21:56:19,820][INFO] writes 1066000 landmark faces
[2016-11-30 21:56:20,054][INFO] writes 1067000 landmark faces
[2016-11-30 21:56:20,268][INFO] writes 1068000 landmark faces
[2016-11-30 21:56:20,500][INFO] writes 1069000 landmark faces
[2016-11-30 21:56:20,743][INFO] writes 1070000 landmark faces
[2016-11-30 21:56:20,964][INFO] writes 1071000 landmark faces
[2016-11-30 21:56:21,232][INFO] writes 1072000 landmark faces
[2016-11-30 21:56:21,471][INFO] writes 1073000 landmark faces
[2016-11-30 21:56:21,750][INFO] writes 1074000 landmark faces
[2016-11-30 21:56:21,922][INFO] writes 1075000 landmark faces
[2016-11-30 21:56:22,129][INFO] writes 1076000 landmark faces
[2016-11-30 21:56:22,347][INFO] writes 1077000 landmark faces
[2016-11-30 21:56:22,600][INFO] writes 1078000 landmark faces
[2016-11-30 21:56:22,843][INFO] writes 1079000 landmark faces
[2016-11-30 21:56:23,085][INFO] writes 1080000 landmark faces
[2016-11-30 21:56:23,308][INFO] writes 1081000 landmark faces
[2016-11-30 21:56:23,505][INFO] writes 1082000 landmark faces
[2016-11-30 21:56:23,757][INFO] writes 1083000 landmark faces
[2016-11-30 21:56:24,005][INFO] writes 1084000 landmark faces
[2016-11-30 21:56:24,253][INFO] writes 1085000 landmark faces
[2016-11-30 21:56:24,477][INFO] writes 1086000 landmark faces
[2016-11-30 21:56:24,702][INFO] writes 1087000 landmark faces
[2016-11-30 21:56:24,939][INFO] writes 1088000 landmark faces
[2016-11-30 21:56:25,156][INFO] writes 1089000 landmark faces
[2016-11-30 21:56:25,393][INFO] writes 1090000 landmark faces
[2016-11-30 21:56:25,642][INFO] writes 1091000 landmark faces
[2016-11-30 21:56:25,858][INFO] writes 1092000 landmark faces
[2016-11-30 21:56:26,078][INFO] writes 1093000 landmark faces
[2016-11-30 21:56:26,326][INFO] writes 1094000 landmark faces
[2016-11-30 21:56:26,547][INFO] writes 1095000 landmark faces
[2016-11-30 21:56:26,775][INFO] writes 1096000 landmark faces
[2016-11-30 21:56:26,997][INFO] writes 1097000 landmark faces
[2016-11-30 21:56:27,215][INFO] writes 1098000 landmark faces
[2016-11-30 21:56:27,439][INFO] writes 1099000 landmark faces
[2016-11-30 21:56:27,685][INFO] writes 1100000 landmark faces
[2016-11-30 21:56:27,935][INFO] writes 1101000 landmark faces
[2016-11-30 21:56:28,164][INFO] writes 1102000 landmark faces
[2016-11-30 21:56:28,409][INFO] writes 1103000 landmark faces
[2016-11-30 21:56:28,622][INFO] writes 1104000 landmark faces
[2016-11-30 21:56:28,836][INFO] writes 1105000 landmark faces
[2016-11-30 21:56:29,085][INFO] writes 1106000 landmark faces
[2016-11-30 21:56:29,237][INFO] Process-5 reads 14000
[2016-11-30 21:56:29,304][INFO] writes 1107000 landmark faces
[2016-11-30 21:56:29,522][INFO] writes 1108000 landmark faces
[2016-11-30 21:56:29,748][INFO] writes 1109000 landmark faces
[2016-11-30 21:56:29,961][INFO] writes 1110000 landmark faces
[2016-11-30 21:56:30,196][INFO] writes 1111000 landmark faces
[2016-11-30 21:56:30,443][INFO] writes 1112000 landmark faces
[2016-11-30 21:56:30,497][INFO] Process-6 reads 14000
[2016-11-30 21:56:30,507][INFO] Process-8 reads 14000
[2016-11-30 21:56:30,676][INFO] writes 1113000 landmark faces
[2016-11-30 21:56:30,875][INFO] Process-7 reads 14000
[2016-11-30 21:56:30,907][INFO] writes 1114000 landmark faces
[2016-11-30 21:56:31,115][INFO] writes 1115000 landmark faces
[2016-11-30 21:56:31,340][INFO] writes 1116000 landmark faces
[2016-11-30 21:56:31,602][INFO] writes 1117000 landmark faces
[2016-11-30 21:56:31,815][INFO] writes 1118000 landmark faces
[2016-11-30 21:56:32,051][INFO] writes 1119000 landmark faces
[2016-11-30 21:56:32,259][INFO] writes 1120000 landmark faces
[2016-11-30 21:56:32,466][INFO] writes 1121000 landmark faces
[2016-11-30 21:56:32,715][INFO] writes 1122000 landmark faces
[2016-11-30 21:56:32,923][INFO] writes 1123000 landmark faces
[2016-11-30 21:56:33,184][INFO] writes 1124000 landmark faces
[2016-11-30 21:56:33,199][INFO] Process-3 reads 14000
[2016-11-30 21:56:33,447][INFO] writes 1125000 landmark faces
[2016-11-30 21:56:33,668][INFO] writes 1126000 landmark faces
[2016-11-30 21:56:33,785][INFO] Process-2 reads 14000
[2016-11-30 21:56:33,899][INFO] writes 1127000 landmark faces
[2016-11-30 21:56:34,111][INFO] writes 1128000 landmark faces
[2016-11-30 21:56:34,325][INFO] writes 1129000 landmark faces
[2016-11-30 21:56:34,525][INFO] writes 1130000 landmark faces
[2016-11-30 21:56:34,744][INFO] writes 1131000 landmark faces
[2016-11-30 21:56:34,974][INFO] writes 1132000 landmark faces
[2016-11-30 21:56:35,053][INFO] Process-4 reads 14000
[2016-11-30 21:56:35,143][INFO] Process-1 reads 14000
[2016-11-30 21:56:35,179][INFO] writes 1133000 landmark faces
[2016-11-30 21:56:35,400][INFO] writes 1134000 landmark faces
[2016-11-30 21:56:35,643][INFO] writes 1135000 landmark faces
[2016-11-30 21:56:35,854][INFO] writes 1136000 landmark faces
[2016-11-30 21:56:36,101][INFO] writes 1137000 landmark faces
[2016-11-30 21:56:36,334][INFO] writes 1138000 landmark faces
[2016-11-30 21:56:36,619][INFO] writes 1139000 landmark faces
[2016-11-30 21:56:36,771][INFO] writes 1140000 landmark faces
[2016-11-30 21:56:37,023][INFO] writes 1141000 landmark faces
[2016-11-30 21:56:37,242][INFO] writes 1142000 landmark faces
[2016-11-30 21:56:37,486][INFO] writes 1143000 landmark faces
[2016-11-30 21:56:37,706][INFO] writes 1144000 landmark faces
[2016-11-30 21:56:37,953][INFO] writes 1145000 landmark faces
[2016-11-30 21:56:38,154][INFO] writes 1146000 landmark faces
[2016-11-30 21:56:38,374][INFO] writes 1147000 landmark faces
[2016-11-30 21:56:38,596][INFO] writes 1148000 landmark faces
[2016-11-30 21:56:38,804][INFO] writes 1149000 landmark faces
[2016-11-30 21:56:39,007][INFO] writes 1150000 landmark faces
[2016-11-30 21:56:39,249][INFO] writes 1151000 landmark faces
[2016-11-30 21:56:39,503][INFO] writes 1152000 landmark faces
[2016-11-30 21:56:39,723][INFO] writes 1153000 landmark faces
[2016-11-30 21:56:39,963][INFO] writes 1154000 landmark faces
[2016-11-30 21:56:40,178][INFO] writes 1155000 landmark faces
[2016-11-30 21:56:40,405][INFO] writes 1156000 landmark faces
[2016-11-30 21:56:40,642][INFO] writes 1157000 landmark faces
[2016-11-30 21:56:40,876][INFO] writes 1158000 landmark faces
[2016-11-30 21:56:41,122][INFO] writes 1159000 landmark faces
[2016-11-30 21:56:41,344][INFO] writes 1160000 landmark faces
[2016-11-30 21:56:41,581][INFO] writes 1161000 landmark faces
[2016-11-30 21:56:41,790][INFO] writes 1162000 landmark faces
[2016-11-30 21:56:42,042][INFO] writes 1163000 landmark faces
[2016-11-30 21:56:42,238][INFO] writes 1164000 landmark faces
[2016-11-30 21:56:42,460][INFO] writes 1165000 landmark faces
[2016-11-30 21:56:42,664][INFO] writes 1166000 landmark faces
[2016-11-30 21:56:42,873][INFO] writes 1167000 landmark faces
[2016-11-30 21:56:43,085][INFO] writes 1168000 landmark faces
[2016-11-30 21:56:43,328][INFO] writes 1169000 landmark faces
[2016-11-30 21:56:43,570][INFO] writes 1170000 landmark faces
[2016-11-30 21:56:43,817][INFO] writes 1171000 landmark faces
[2016-11-30 21:56:44,025][INFO] writes 1172000 landmark faces
[2016-11-30 21:56:44,262][INFO] writes 1173000 landmark faces
[2016-11-30 21:56:44,502][INFO] writes 1174000 landmark faces
[2016-11-30 21:56:44,712][INFO] writes 1175000 landmark faces
[2016-11-30 21:56:44,945][INFO] writes 1176000 landmark faces
[2016-11-30 21:56:45,198][INFO] writes 1177000 landmark faces
[2016-11-30 21:56:45,419][INFO] writes 1178000 landmark faces
[2016-11-30 21:56:45,660][INFO] writes 1179000 landmark faces
[2016-11-30 21:56:45,894][INFO] writes 1180000 landmark faces
[2016-11-30 21:56:46,098][INFO] writes 1181000 landmark faces
[2016-11-30 21:56:46,330][INFO] writes 1182000 landmark faces
[2016-11-30 21:56:46,541][INFO] writes 1183000 landmark faces
[2016-11-30 21:56:46,758][INFO] writes 1184000 landmark faces
[2016-11-30 21:56:46,798][INFO] Process-5 reads 15000
[2016-11-30 21:56:46,990][INFO] writes 1185000 landmark faces
[2016-11-30 21:56:47,254][INFO] writes 1186000 landmark faces
[2016-11-30 21:56:47,448][INFO] writes 1187000 landmark faces
[2016-11-30 21:56:47,681][INFO] writes 1188000 landmark faces
[2016-11-30 21:56:47,907][INFO] writes 1189000 landmark faces
[2016-11-30 21:56:47,963][INFO] Process-6 reads 15000
[2016-11-30 21:56:48,147][INFO] writes 1190000 landmark faces
[2016-11-30 21:56:48,365][INFO] writes 1191000 landmark faces
[2016-11-30 21:56:48,597][INFO] writes 1192000 landmark faces
[2016-11-30 21:56:48,865][INFO] writes 1193000 landmark faces
[2016-11-30 21:56:49,129][INFO] writes 1194000 landmark faces
[2016-11-30 21:56:49,258][INFO] Process-8 reads 15000
[2016-11-30 21:56:49,396][INFO] writes 1195000 landmark faces
[2016-11-30 21:56:49,640][INFO] writes 1196000 landmark faces
[2016-11-30 21:56:49,854][INFO] writes 1197000 landmark faces
[2016-11-30 21:56:49,891][INFO] Process-7 reads 15000
[2016-11-30 21:56:50,085][INFO] writes 1198000 landmark faces
[2016-11-30 21:56:50,300][INFO] writes 1199000 landmark faces
[2016-11-30 21:56:50,563][INFO] writes 1200000 landmark faces
[2016-11-30 21:56:50,788][INFO] writes 1201000 landmark faces
[2016-11-30 21:56:51,102][INFO] writes 1202000 landmark faces
[2016-11-30 21:56:51,213][INFO] Process-3 reads 15000
[2016-11-30 21:56:51,315][INFO] writes 1203000 landmark faces
[2016-11-30 21:56:51,670][INFO] writes 1204000 landmark faces
[2016-11-30 21:56:51,792][INFO] writes 1205000 landmark faces
[2016-11-30 21:56:52,034][INFO] writes 1206000 landmark faces
[2016-11-30 21:56:52,263][INFO] writes 1207000 landmark faces
[2016-11-30 21:56:52,305][INFO] Process-2 reads 15000
[2016-11-30 21:56:52,509][INFO] writes 1208000 landmark faces
[2016-11-30 21:56:52,726][INFO] writes 1209000 landmark faces
[2016-11-30 21:56:52,819][INFO] Process-1 reads 15000
[2016-11-30 21:56:52,953][INFO] writes 1210000 landmark faces
[2016-11-30 21:56:53,045][INFO] Process-4 reads 15000
[2016-11-30 21:56:53,171][INFO] writes 1211000 landmark faces
[2016-11-30 21:56:53,426][INFO] writes 1212000 landmark faces
[2016-11-30 21:56:53,703][INFO] writes 1213000 landmark faces
[2016-11-30 21:56:53,944][INFO] writes 1214000 landmark faces
[2016-11-30 21:56:54,211][INFO] writes 1215000 landmark faces
[2016-11-30 21:56:54,456][INFO] writes 1216000 landmark faces
[2016-11-30 21:56:54,692][INFO] writes 1217000 landmark faces
[2016-11-30 21:56:54,906][INFO] writes 1218000 landmark faces
[2016-11-30 21:56:55,120][INFO] writes 1219000 landmark faces
[2016-11-30 21:56:55,330][INFO] writes 1220000 landmark faces
[2016-11-30 21:56:55,549][INFO] writes 1221000 landmark faces
[2016-11-30 21:56:55,801][INFO] writes 1222000 landmark faces
[2016-11-30 21:56:56,008][INFO] writes 1223000 landmark faces
[2016-11-30 21:56:56,219][INFO] writes 1224000 landmark faces
[2016-11-30 21:56:56,432][INFO] writes 1225000 landmark faces
[2016-11-30 21:56:56,679][INFO] writes 1226000 landmark faces
[2016-11-30 21:56:56,914][INFO] writes 1227000 landmark faces
[2016-11-30 21:56:57,182][INFO] writes 1228000 landmark faces
[2016-11-30 21:56:57,406][INFO] writes 1229000 landmark faces
[2016-11-30 21:56:57,628][INFO] writes 1230000 landmark faces
[2016-11-30 21:56:57,900][INFO] writes 1231000 landmark faces
[2016-11-30 21:56:58,148][INFO] writes 1232000 landmark faces
[2016-11-30 21:56:58,415][INFO] writes 1233000 landmark faces
[2016-11-30 21:56:58,656][INFO] writes 1234000 landmark faces
[2016-11-30 21:56:58,947][INFO] writes 1235000 landmark faces
[2016-11-30 21:56:59,175][INFO] writes 1236000 landmark faces
[2016-11-30 21:56:59,469][INFO] writes 1237000 landmark faces
[2016-11-30 21:56:59,679][INFO] writes 1238000 landmark faces
[2016-11-30 21:56:59,892][INFO] writes 1239000 landmark faces
[2016-11-30 21:57:00,130][INFO] writes 1240000 landmark faces
[2016-11-30 21:57:00,366][INFO] writes 1241000 landmark faces
[2016-11-30 21:57:00,577][INFO] writes 1242000 landmark faces
[2016-11-30 21:57:00,809][INFO] writes 1243000 landmark faces
[2016-11-30 21:57:01,040][INFO] writes 1244000 landmark faces
[2016-11-30 21:57:01,265][INFO] writes 1245000 landmark faces
[2016-11-30 21:57:01,470][INFO] writes 1246000 landmark faces
[2016-11-30 21:57:01,684][INFO] writes 1247000 landmark faces
[2016-11-30 21:57:01,882][INFO] writes 1248000 landmark faces
[2016-11-30 21:57:02,078][INFO] writes 1249000 landmark faces
[2016-11-30 21:57:02,278][INFO] writes 1250000 landmark faces
[2016-11-30 21:57:02,508][INFO] writes 1251000 landmark faces
[2016-11-30 21:57:02,714][INFO] writes 1252000 landmark faces
[2016-11-30 21:57:02,938][INFO] writes 1253000 landmark faces
[2016-11-30 21:57:03,167][INFO] writes 1254000 landmark faces
[2016-11-30 21:57:03,395][INFO] writes 1255000 landmark faces
[2016-11-30 21:57:03,599][INFO] writes 1256000 landmark faces
[2016-11-30 21:57:03,853][INFO] writes 1257000 landmark faces
[2016-11-30 21:57:04,063][INFO] writes 1258000 landmark faces
[2016-11-30 21:57:04,269][INFO] writes 1259000 landmark faces
[2016-11-30 21:57:04,500][INFO] writes 1260000 landmark faces
[2016-11-30 21:57:04,741][INFO] writes 1261000 landmark faces
[2016-11-30 21:57:04,960][INFO] writes 1262000 landmark faces
[2016-11-30 21:57:05,202][INFO] writes 1263000 landmark faces
[2016-11-30 21:57:05,426][INFO] writes 1264000 landmark faces
[2016-11-30 21:57:05,621][INFO] writes 1265000 landmark faces
[2016-11-30 21:57:05,860][INFO] writes 1266000 landmark faces
[2016-11-30 21:57:05,864][INFO] Process-6 reads 16000
[2016-11-30 21:57:06,081][INFO] writes 1267000 landmark faces
[2016-11-30 21:57:06,307][INFO] writes 1268000 landmark faces
[2016-11-30 21:57:06,340][INFO] Process-5 reads 16000
[2016-11-30 21:57:06,529][INFO] writes 1269000 landmark faces
[2016-11-30 21:57:06,765][INFO] writes 1270000 landmark faces
[2016-11-30 21:57:07,019][INFO] writes 1271000 landmark faces
[2016-11-30 21:57:07,244][INFO] writes 1272000 landmark faces
[2016-11-30 21:57:07,460][INFO] writes 1273000 landmark faces
[2016-11-30 21:57:07,726][INFO] writes 1274000 landmark faces
[2016-11-30 21:57:07,954][INFO] writes 1275000 landmark faces
[2016-11-30 21:57:08,173][INFO] writes 1276000 landmark faces
[2016-11-30 21:57:08,390][INFO] writes 1277000 landmark faces
[2016-11-30 21:57:08,571][INFO] Process-7 reads 16000
[2016-11-30 21:57:08,595][INFO] Process-8 reads 16000
[2016-11-30 21:57:08,617][INFO] writes 1278000 landmark faces
[2016-11-30 21:57:08,818][INFO] writes 1279000 landmark faces
[2016-11-30 21:57:09,033][INFO] writes 1280000 landmark faces
[2016-11-30 21:57:09,233][INFO] writes 1281000 landmark faces
[2016-11-30 21:57:09,483][INFO] writes 1282000 landmark faces
[2016-11-30 21:57:09,637][INFO] Process-3 reads 16000
[2016-11-30 21:57:09,723][INFO] writes 1283000 landmark faces
[2016-11-30 21:57:09,915][INFO] writes 1284000 landmark faces
[2016-11-30 21:57:10,130][INFO] writes 1285000 landmark faces
[2016-11-30 21:57:10,310][INFO] Process-2 reads 16000
[2016-11-30 21:57:10,359][INFO] writes 1286000 landmark faces
[2016-11-30 21:57:10,576][INFO] writes 1287000 landmark faces
[2016-11-30 21:57:10,801][INFO] writes 1288000 landmark faces
[2016-11-30 21:57:10,996][INFO] writes 1289000 landmark faces
[2016-11-30 21:57:11,213][INFO] writes 1290000 landmark faces
[2016-11-30 21:57:11,348][INFO] Process-4 reads 16000
[2016-11-30 21:57:11,460][INFO] Process-1 reads 16000
[2016-11-30 21:57:11,460][INFO] writes 1291000 landmark faces
[2016-11-30 21:57:11,714][INFO] writes 1292000 landmark faces
[2016-11-30 21:57:11,930][INFO] writes 1293000 landmark faces
[2016-11-30 21:57:12,136][INFO] writes 1294000 landmark faces
[2016-11-30 21:57:12,375][INFO] writes 1295000 landmark faces
[2016-11-30 21:57:12,613][INFO] writes 1296000 landmark faces
[2016-11-30 21:57:12,822][INFO] writes 1297000 landmark faces
[2016-11-30 21:57:13,055][INFO] writes 1298000 landmark faces
[2016-11-30 21:57:13,279][INFO] writes 1299000 landmark faces
[2016-11-30 21:57:13,496][INFO] writes 1300000 landmark faces
[2016-11-30 21:57:13,718][INFO] writes 1301000 landmark faces
[2016-11-30 21:57:13,943][INFO] writes 1302000 landmark faces
[2016-11-30 21:57:14,154][INFO] writes 1303000 landmark faces
[2016-11-30 21:57:14,362][INFO] writes 1304000 landmark faces
[2016-11-30 21:57:14,616][INFO] writes 1305000 landmark faces
[2016-11-30 21:57:14,819][INFO] writes 1306000 landmark faces
[2016-11-30 21:57:15,054][INFO] writes 1307000 landmark faces
[2016-11-30 21:57:15,270][INFO] writes 1308000 landmark faces
[2016-11-30 21:57:15,494][INFO] writes 1309000 landmark faces
[2016-11-30 21:57:15,736][INFO] writes 1310000 landmark faces
[2016-11-30 21:57:15,959][INFO] writes 1311000 landmark faces
[2016-11-30 21:57:16,172][INFO] writes 1312000 landmark faces
[2016-11-30 21:57:16,425][INFO] writes 1313000 landmark faces
[2016-11-30 21:57:16,665][INFO] writes 1314000 landmark faces
[2016-11-30 21:57:16,899][INFO] writes 1315000 landmark faces
[2016-11-30 21:57:17,107][INFO] writes 1316000 landmark faces
[2016-11-30 21:57:17,321][INFO] writes 1317000 landmark faces
[2016-11-30 21:57:17,599][INFO] writes 1318000 landmark faces
[2016-11-30 21:57:17,839][INFO] writes 1319000 landmark faces
[2016-11-30 21:57:18,079][INFO] writes 1320000 landmark faces
[2016-11-30 21:57:18,318][INFO] writes 1321000 landmark faces
[2016-11-30 21:57:18,557][INFO] writes 1322000 landmark faces
[2016-11-30 21:57:18,779][INFO] writes 1323000 landmark faces
[2016-11-30 21:57:19,006][INFO] writes 1324000 landmark faces
[2016-11-30 21:57:19,213][INFO] writes 1325000 landmark faces
[2016-11-30 21:57:19,439][INFO] writes 1326000 landmark faces
[2016-11-30 21:57:19,651][INFO] writes 1327000 landmark faces
[2016-11-30 21:57:19,858][INFO] writes 1328000 landmark faces
[2016-11-30 21:57:20,074][INFO] writes 1329000 landmark faces
[2016-11-30 21:57:20,298][INFO] writes 1330000 landmark faces
[2016-11-30 21:57:20,559][INFO] writes 1331000 landmark faces
[2016-11-30 21:57:20,818][INFO] writes 1332000 landmark faces
[2016-11-30 21:57:21,035][INFO] writes 1333000 landmark faces
[2016-11-30 21:57:21,261][INFO] writes 1334000 landmark faces
[2016-11-30 21:57:21,498][INFO] writes 1335000 landmark faces
[2016-11-30 21:57:21,713][INFO] writes 1336000 landmark faces
[2016-11-30 21:57:21,970][INFO] writes 1337000 landmark faces
[2016-11-30 21:57:22,190][INFO] writes 1338000 landmark faces
[2016-11-30 21:57:22,462][INFO] writes 1339000 landmark faces
[2016-11-30 21:57:22,673][INFO] writes 1340000 landmark faces
[2016-11-30 21:57:22,901][INFO] writes 1341000 landmark faces
[2016-11-30 21:57:22,976][INFO] Process-6 reads 17000
[2016-11-30 21:57:23,106][INFO] writes 1342000 landmark faces
[2016-11-30 21:57:23,327][INFO] writes 1343000 landmark faces
[2016-11-30 21:57:23,532][INFO] writes 1344000 landmark faces
[2016-11-30 21:57:23,759][INFO] writes 1345000 landmark faces
[2016-11-30 21:57:24,023][INFO] writes 1346000 landmark faces
[2016-11-30 21:57:24,313][INFO] writes 1347000 landmark faces
[2016-11-30 21:57:24,512][INFO] writes 1348000 landmark faces
[2016-11-30 21:57:24,776][INFO] writes 1349000 landmark faces
[2016-11-30 21:57:24,829][INFO] Process-5 reads 17000
[2016-11-30 21:57:24,992][INFO] writes 1350000 landmark faces
[2016-11-30 21:57:25,229][INFO] writes 1351000 landmark faces
[2016-11-30 21:57:25,446][INFO] writes 1352000 landmark faces
[2016-11-30 21:57:25,699][INFO] writes 1353000 landmark faces
[2016-11-30 21:57:25,936][INFO] writes 1354000 landmark faces
[2016-11-30 21:57:26,142][INFO] writes 1355000 landmark faces
[2016-11-30 21:57:26,409][INFO] writes 1356000 landmark faces
[2016-11-30 21:57:26,595][INFO] Process-7 reads 17000
[2016-11-30 21:57:26,650][INFO] writes 1357000 landmark faces
[2016-11-30 21:57:26,893][INFO] writes 1358000 landmark faces
[2016-11-30 21:57:27,102][INFO] writes 1359000 landmark faces
[2016-11-30 21:57:27,173][INFO] Process-8 reads 17000
[2016-11-30 21:57:27,319][INFO] writes 1360000 landmark faces
[2016-11-30 21:57:27,562][INFO] writes 1361000 landmark faces
[2016-11-30 21:57:27,822][INFO] writes 1362000 landmark faces
[2016-11-30 21:57:28,084][INFO] writes 1363000 landmark faces
[2016-11-30 21:57:28,316][INFO] writes 1364000 landmark faces
[2016-11-30 21:57:28,489][INFO] Process-3 reads 17000
[2016-11-30 21:57:28,586][INFO] writes 1365000 landmark faces
[2016-11-30 21:57:28,826][INFO] writes 1366000 landmark faces
[2016-11-30 21:57:28,844][INFO] Process-2 reads 17000
[2016-11-30 21:57:29,086][INFO] writes 1367000 landmark faces
[2016-11-30 21:57:29,298][INFO] writes 1368000 landmark faces
[2016-11-30 21:57:29,534][INFO] writes 1369000 landmark faces
[2016-11-30 21:57:29,795][INFO] writes 1370000 landmark faces
[2016-11-30 21:57:30,015][INFO] writes 1371000 landmark faces
[2016-11-30 21:57:30,240][INFO] writes 1372000 landmark faces
[2016-11-30 21:57:30,301][INFO] Process-1 reads 17000
[2016-11-30 21:57:30,397][INFO] Process-4 reads 17000
[2016-11-30 21:57:30,464][INFO] writes 1373000 landmark faces
[2016-11-30 21:57:30,662][INFO] writes 1374000 landmark faces
[2016-11-30 21:57:30,898][INFO] writes 1375000 landmark faces
[2016-11-30 21:57:31,145][INFO] writes 1376000 landmark faces
[2016-11-30 21:57:31,406][INFO] writes 1377000 landmark faces
[2016-11-30 21:57:31,590][INFO] writes 1378000 landmark faces
[2016-11-30 21:57:31,826][INFO] writes 1379000 landmark faces
[2016-11-30 21:57:32,064][INFO] writes 1380000 landmark faces
[2016-11-30 21:57:32,287][INFO] writes 1381000 landmark faces
[2016-11-30 21:57:32,516][INFO] writes 1382000 landmark faces
[2016-11-30 21:57:32,729][INFO] writes 1383000 landmark faces
[2016-11-30 21:57:32,988][INFO] writes 1384000 landmark faces
[2016-11-30 21:57:33,226][INFO] writes 1385000 landmark faces
[2016-11-30 21:57:33,515][INFO] writes 1386000 landmark faces
[2016-11-30 21:57:33,747][INFO] writes 1387000 landmark faces
[2016-11-30 21:57:33,958][INFO] writes 1388000 landmark faces
[2016-11-30 21:57:34,176][INFO] writes 1389000 landmark faces
[2016-11-30 21:57:34,392][INFO] writes 1390000 landmark faces
[2016-11-30 21:57:34,639][INFO] writes 1391000 landmark faces
[2016-11-30 21:57:34,842][INFO] writes 1392000 landmark faces
[2016-11-30 21:57:35,037][INFO] writes 1393000 landmark faces
[2016-11-30 21:57:35,255][INFO] writes 1394000 landmark faces
[2016-11-30 21:57:35,477][INFO] writes 1395000 landmark faces
[2016-11-30 21:57:35,716][INFO] writes 1396000 landmark faces
[2016-11-30 21:57:35,935][INFO] writes 1397000 landmark faces
[2016-11-30 21:57:36,178][INFO] writes 1398000 landmark faces
[2016-11-30 21:57:36,387][INFO] writes 1399000 landmark faces
[2016-11-30 21:57:36,628][INFO] writes 1400000 landmark faces
[2016-11-30 21:57:36,856][INFO] writes 1401000 landmark faces
[2016-11-30 21:57:37,087][INFO] writes 1402000 landmark faces
[2016-11-30 21:57:37,310][INFO] writes 1403000 landmark faces
[2016-11-30 21:57:37,557][INFO] writes 1404000 landmark faces
[2016-11-30 21:57:37,808][INFO] writes 1405000 landmark faces
[2016-11-30 21:57:38,065][INFO] writes 1406000 landmark faces
[2016-11-30 21:57:38,270][INFO] writes 1407000 landmark faces
[2016-11-30 21:57:38,492][INFO] writes 1408000 landmark faces
[2016-11-30 21:57:38,729][INFO] writes 1409000 landmark faces
[2016-11-30 21:57:38,962][INFO] writes 1410000 landmark faces
[2016-11-30 21:57:39,212][INFO] writes 1411000 landmark faces
[2016-11-30 21:57:39,460][INFO] writes 1412000 landmark faces
[2016-11-30 21:57:39,678][INFO] writes 1413000 landmark faces
[2016-11-30 21:57:39,892][INFO] writes 1414000 landmark faces
[2016-11-30 21:57:40,155][INFO] writes 1415000 landmark faces
[2016-11-30 21:57:40,391][INFO] writes 1416000 landmark faces
[2016-11-30 21:57:40,403][INFO] Process-6 reads 18000
[2016-11-30 21:57:40,592][INFO] writes 1417000 landmark faces
[2016-11-30 21:57:40,803][INFO] writes 1418000 landmark faces
[2016-11-30 21:57:41,024][INFO] writes 1419000 landmark faces
[2016-11-30 21:57:41,248][INFO] writes 1420000 landmark faces
[2016-11-30 21:57:41,479][INFO] writes 1421000 landmark faces
[2016-11-30 21:57:41,719][INFO] writes 1422000 landmark faces
[2016-11-30 21:57:41,908][INFO] writes 1423000 landmark faces
[2016-11-30 21:57:42,146][INFO] writes 1424000 landmark faces
[2016-11-30 21:57:42,347][INFO] writes 1425000 landmark faces
[2016-11-30 21:57:42,561][INFO] writes 1426000 landmark faces
[2016-11-30 21:57:42,610][INFO] Process-5 reads 18000
[2016-11-30 21:57:42,806][INFO] writes 1427000 landmark faces
[2016-11-30 21:57:43,057][INFO] writes 1428000 landmark faces
[2016-11-30 21:57:43,301][INFO] writes 1429000 landmark faces
[2016-11-30 21:57:43,534][INFO] writes 1430000 landmark faces
[2016-11-30 21:57:43,769][INFO] writes 1431000 landmark faces
[2016-11-30 21:57:44,038][INFO] writes 1432000 landmark faces
[2016-11-30 21:57:44,224][INFO] writes 1433000 landmark faces
[2016-11-30 21:57:44,427][INFO] writes 1434000 landmark faces
[2016-11-30 21:57:44,646][INFO] writes 1435000 landmark faces
[2016-11-30 21:57:44,894][INFO] writes 1436000 landmark faces
[2016-11-30 21:57:45,164][INFO] writes 1437000 landmark faces
[2016-11-30 21:57:45,416][INFO] writes 1438000 landmark faces
[2016-11-30 21:57:45,649][INFO] writes 1439000 landmark faces
[2016-11-30 21:57:45,870][INFO] writes 1440000 landmark faces
[2016-11-30 21:57:45,929][INFO] Process-7 reads 18000
[2016-11-30 21:57:46,079][INFO] writes 1441000 landmark faces
[2016-11-30 21:57:46,306][INFO] writes 1442000 landmark faces
[2016-11-30 21:57:46,593][INFO] writes 1443000 landmark faces
[2016-11-30 21:57:46,639][INFO] Process-8 reads 18000
[2016-11-30 21:57:46,810][INFO] writes 1444000 landmark faces
[2016-11-30 21:57:46,853][INFO] Process-3 reads 18000
[2016-11-30 21:57:47,030][INFO] writes 1445000 landmark faces
[2016-11-30 21:57:47,275][INFO] writes 1446000 landmark faces
[2016-11-30 21:57:47,474][INFO] writes 1447000 landmark faces
[2016-11-30 21:57:47,669][INFO] Process-2 reads 18000
[2016-11-30 21:57:47,672][INFO] writes 1448000 landmark faces
[2016-11-30 21:57:47,897][INFO] writes 1449000 landmark faces
[2016-11-30 21:57:48,122][INFO] writes 1450000 landmark faces
[2016-11-30 21:57:48,351][INFO] writes 1451000 landmark faces
[2016-11-30 21:57:48,518][INFO] Process-1 reads 18000
[2016-11-30 21:57:48,572][INFO] writes 1452000 landmark faces
[2016-11-30 21:57:48,815][INFO] writes 1453000 landmark faces
[2016-11-30 21:57:48,993][INFO] Process-4 reads 18000
[2016-11-30 21:57:49,035][INFO] writes 1454000 landmark faces
[2016-11-30 21:57:49,245][INFO] writes 1455000 landmark faces
[2016-11-30 21:57:49,480][INFO] writes 1456000 landmark faces
[2016-11-30 21:57:49,729][INFO] writes 1457000 landmark faces
[2016-11-30 21:57:49,965][INFO] writes 1458000 landmark faces
[2016-11-30 21:57:50,204][INFO] writes 1459000 landmark faces
[2016-11-30 21:57:50,436][INFO] writes 1460000 landmark faces
[2016-11-30 21:57:50,711][INFO] writes 1461000 landmark faces
[2016-11-30 21:57:50,917][INFO] writes 1462000 landmark faces
[2016-11-30 21:57:51,133][INFO] writes 1463000 landmark faces
[2016-11-30 21:57:51,383][INFO] writes 1464000 landmark faces
[2016-11-30 21:57:51,604][INFO] writes 1465000 landmark faces
[2016-11-30 21:57:51,828][INFO] writes 1466000 landmark faces
[2016-11-30 21:57:52,041][INFO] writes 1467000 landmark faces
[2016-11-30 21:57:52,246][INFO] writes 1468000 landmark faces
[2016-11-30 21:57:52,460][INFO] writes 1469000 landmark faces
[2016-11-30 21:57:52,732][INFO] writes 1470000 landmark faces
[2016-11-30 21:57:52,979][INFO] writes 1471000 landmark faces
[2016-11-30 21:57:53,209][INFO] writes 1472000 landmark faces
[2016-11-30 21:57:53,428][INFO] writes 1473000 landmark faces
[2016-11-30 21:57:53,683][INFO] writes 1474000 landmark faces
[2016-11-30 21:57:53,902][INFO] writes 1475000 landmark faces
[2016-11-30 21:57:54,144][INFO] writes 1476000 landmark faces
[2016-11-30 21:57:54,370][INFO] writes 1477000 landmark faces
[2016-11-30 21:57:54,588][INFO] writes 1478000 landmark faces
[2016-11-30 21:57:54,859][INFO] writes 1479000 landmark faces
[2016-11-30 21:57:55,077][INFO] writes 1480000 landmark faces
[2016-11-30 21:57:55,306][INFO] writes 1481000 landmark faces
[2016-11-30 21:57:55,539][INFO] writes 1482000 landmark faces
[2016-11-30 21:57:55,761][INFO] writes 1483000 landmark faces
[2016-11-30 21:57:55,971][INFO] writes 1484000 landmark faces
[2016-11-30 21:57:56,210][INFO] writes 1485000 landmark faces
[2016-11-30 21:57:56,427][INFO] writes 1486000 landmark faces
[2016-11-30 21:57:56,677][INFO] writes 1487000 landmark faces
[2016-11-30 21:57:56,902][INFO] writes 1488000 landmark faces
[2016-11-30 21:57:57,126][INFO] writes 1489000 landmark faces
[2016-11-30 21:57:57,161][INFO] Process-6 reads 19000
[2016-11-30 21:57:57,341][INFO] writes 1490000 landmark faces
[2016-11-30 21:57:57,580][INFO] writes 1491000 landmark faces
[2016-11-30 21:57:57,789][INFO] writes 1492000 landmark faces
[2016-11-30 21:57:58,015][INFO] writes 1493000 landmark faces
[2016-11-30 21:57:58,217][INFO] writes 1494000 landmark faces
[2016-11-30 21:57:58,439][INFO] writes 1495000 landmark faces
[2016-11-30 21:57:58,636][INFO] writes 1496000 landmark faces
[2016-11-30 21:57:58,936][INFO] writes 1497000 landmark faces
[2016-11-30 21:57:59,114][INFO] writes 1498000 landmark faces
[2016-11-30 21:57:59,356][INFO] writes 1499000 landmark faces
[2016-11-30 21:57:59,618][INFO] writes 1500000 landmark faces
[2016-11-30 21:57:59,821][INFO] writes 1501000 landmark faces
[2016-11-30 21:58:00,048][INFO] writes 1502000 landmark faces
[2016-11-30 21:58:00,303][INFO] writes 1503000 landmark faces
[2016-11-30 21:58:00,525][INFO] writes 1504000 landmark faces
[2016-11-30 21:58:00,763][INFO] writes 1505000 landmark faces
[2016-11-30 21:58:01,010][INFO] writes 1506000 landmark faces
[2016-11-30 21:58:01,223][INFO] writes 1507000 landmark faces
[2016-11-30 21:58:01,453][INFO] writes 1508000 landmark faces
[2016-11-30 21:58:01,696][INFO] writes 1509000 landmark faces
[2016-11-30 21:58:01,943][INFO] writes 1510000 landmark faces
[2016-11-30 21:58:02,043][INFO] Process-5 reads 19000
[2016-11-30 21:58:02,163][INFO] writes 1511000 landmark faces
[2016-11-30 21:58:02,376][INFO] writes 1512000 landmark faces
[2016-11-30 21:58:02,596][INFO] writes 1513000 landmark faces
[2016-11-30 21:58:02,811][INFO] writes 1514000 landmark faces
[2016-11-30 21:58:03,024][INFO] writes 1515000 landmark faces
[2016-11-30 21:58:03,238][INFO] writes 1516000 landmark faces
[2016-11-30 21:58:03,478][INFO] writes 1517000 landmark faces
[2016-11-30 21:58:03,748][INFO] writes 1518000 landmark faces
[2016-11-30 21:58:04,020][INFO] writes 1519000 landmark faces
[2016-11-30 21:58:04,305][INFO] writes 1520000 landmark faces
[2016-11-30 21:58:04,562][INFO] writes 1521000 landmark faces
[2016-11-30 21:58:04,802][INFO] writes 1522000 landmark faces
[2016-11-30 21:58:04,941][INFO] Process-3 reads 19000
[2016-11-30 21:58:05,012][INFO] Process-7 reads 19000
[2016-11-30 21:58:05,045][INFO] writes 1523000 landmark faces
[2016-11-30 21:58:05,270][INFO] writes 1524000 landmark faces
[2016-11-30 21:58:05,488][INFO] writes 1525000 landmark faces
[2016-11-30 21:58:05,748][INFO] writes 1526000 landmark faces
[2016-11-30 21:58:05,843][INFO] Process-2 reads 19000
[2016-11-30 21:58:06,026][INFO] writes 1527000 landmark faces
[2016-11-30 21:58:06,272][INFO] writes 1528000 landmark faces
[2016-11-30 21:58:06,551][INFO] writes 1529000 landmark faces
[2016-11-30 21:58:06,568][INFO] Process-8 reads 19000
[2016-11-30 21:58:06,789][INFO] writes 1530000 landmark faces
[2016-11-30 21:58:07,030][INFO] writes 1531000 landmark faces
[2016-11-30 21:58:07,239][INFO] writes 1532000 landmark faces
[2016-11-30 21:58:07,396][INFO] Process-4 reads 19000
[2016-11-30 21:58:07,435][INFO] Process-1 reads 19000
[2016-11-30 21:58:07,449][INFO] writes 1533000 landmark faces
[2016-11-30 21:58:07,678][INFO] writes 1534000 landmark faces
[2016-11-30 21:58:07,910][INFO] writes 1535000 landmark faces
[2016-11-30 21:58:08,119][INFO] writes 1536000 landmark faces
[2016-11-30 21:58:08,332][INFO] writes 1537000 landmark faces
[2016-11-30 21:58:08,558][INFO] writes 1538000 landmark faces
[2016-11-30 21:58:08,804][INFO] writes 1539000 landmark faces
[2016-11-30 21:58:09,048][INFO] writes 1540000 landmark faces
[2016-11-30 21:58:09,280][INFO] writes 1541000 landmark faces
[2016-11-30 21:58:09,537][INFO] writes 1542000 landmark faces
[2016-11-30 21:58:09,784][INFO] writes 1543000 landmark faces
[2016-11-30 21:58:10,007][INFO] writes 1544000 landmark faces
[2016-11-30 21:58:10,240][INFO] writes 1545000 landmark faces
[2016-11-30 21:58:10,464][INFO] writes 1546000 landmark faces
[2016-11-30 21:58:10,686][INFO] writes 1547000 landmark faces
[2016-11-30 21:58:10,952][INFO] writes 1548000 landmark faces
[2016-11-30 21:58:11,216][INFO] writes 1549000 landmark faces
[2016-11-30 21:58:11,453][INFO] writes 1550000 landmark faces
[2016-11-30 21:58:11,668][INFO] writes 1551000 landmark faces
[2016-11-30 21:58:11,912][INFO] writes 1552000 landmark faces
[2016-11-30 21:58:12,145][INFO] writes 1553000 landmark faces
[2016-11-30 21:58:12,431][INFO] writes 1554000 landmark faces
[2016-11-30 21:58:12,675][INFO] writes 1555000 landmark faces
[2016-11-30 21:58:12,940][INFO] writes 1556000 landmark faces
[2016-11-30 21:58:13,152][INFO] writes 1557000 landmark faces
[2016-11-30 21:58:13,358][INFO] writes 1558000 landmark faces
[2016-11-30 21:58:13,595][INFO] writes 1559000 landmark faces
[2016-11-30 21:58:13,834][INFO] writes 1560000 landmark faces
[2016-11-30 21:58:13,983][INFO] Process-6 reads 20000
[2016-11-30 21:58:14,082][INFO] writes 1561000 landmark faces
[2016-11-30 21:58:14,364][INFO] writes 1562000 landmark faces
[2016-11-30 21:58:14,530][INFO] writes 1563000 landmark faces
[2016-11-30 21:58:14,738][INFO] writes 1564000 landmark faces
[2016-11-30 21:58:14,955][INFO] writes 1565000 landmark faces
[2016-11-30 21:58:15,200][INFO] writes 1566000 landmark faces
[2016-11-30 21:58:15,434][INFO] writes 1567000 landmark faces
[2016-11-30 21:58:15,687][INFO] writes 1568000 landmark faces
[2016-11-30 21:58:15,947][INFO] writes 1569000 landmark faces
[2016-11-30 21:58:16,187][INFO] writes 1570000 landmark faces
[2016-11-30 21:58:16,393][INFO] writes 1571000 landmark faces
[2016-11-30 21:58:16,625][INFO] writes 1572000 landmark faces
[2016-11-30 21:58:16,837][INFO] writes 1573000 landmark faces
[2016-11-30 21:58:17,066][INFO] writes 1574000 landmark faces
[2016-11-30 21:58:17,306][INFO] writes 1575000 landmark faces
[2016-11-30 21:58:17,528][INFO] writes 1576000 landmark faces
[2016-11-30 21:58:17,769][INFO] writes 1577000 landmark faces
[2016-11-30 21:58:18,058][INFO] writes 1578000 landmark faces
[2016-11-30 21:58:18,294][INFO] writes 1579000 landmark faces
[2016-11-30 21:58:18,530][INFO] writes 1580000 landmark faces
[2016-11-30 21:58:18,757][INFO] writes 1581000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:58:19,057][INFO] writes 1582000 landmark faces
[2016-11-30 21:58:19,341][INFO] writes 1583000 landmark faces
[2016-11-30 21:58:19,593][INFO] writes 1584000 landmark faces
[2016-11-30 21:58:19,851][INFO] writes 1585000 landmark faces
[2016-11-30 21:58:20,163][INFO] writes 1586000 landmark faces
[2016-11-30 21:58:20,383][INFO] writes 1587000 landmark faces
[2016-11-30 21:58:20,655][INFO] writes 1588000 landmark faces
[2016-11-30 21:58:20,912][INFO] writes 1589000 landmark faces
[2016-11-30 21:58:20,999][INFO] Process-5 reads 20000
[2016-11-30 21:58:21,175][INFO] writes 1590000 landmark faces
[2016-11-30 21:58:21,444][INFO] writes 1591000 landmark faces
[2016-11-30 21:58:21,726][INFO] writes 1592000 landmark faces
[2016-11-30 21:58:21,968][INFO] writes 1593000 landmark faces
[2016-11-30 21:58:22,233][INFO] writes 1594000 landmark faces
[2016-11-30 21:58:22,484][INFO] writes 1595000 landmark faces
[2016-11-30 21:58:22,720][INFO] writes 1596000 landmark faces
[2016-11-30 21:58:22,977][INFO] writes 1597000 landmark faces
[2016-11-30 21:58:23,210][INFO] writes 1598000 landmark faces
[2016-11-30 21:58:23,370][INFO] Process-7 reads 20000
[2016-11-30 21:58:23,463][INFO] writes 1599000 landmark faces
[2016-11-30 21:58:23,713][INFO] writes 1600000 landmark faces
[2016-11-30 21:58:23,967][INFO] writes 1601000 landmark faces
[2016-11-30 21:58:24,227][INFO] writes 1602000 landmark faces
[2016-11-30 21:58:24,472][INFO] writes 1603000 landmark faces
[2016-11-30 21:58:24,746][INFO] writes 1604000 landmark faces
[2016-11-30 21:58:24,823][INFO] Process-3 reads 20000
[2016-11-30 21:58:25,000][INFO] writes 1605000 landmark faces
[2016-11-30 21:58:25,226][INFO] Process-8 reads 20000
[2016-11-30 21:58:25,271][INFO] writes 1606000 landmark faces
[2016-11-30 21:58:25,323][INFO] Process-1 reads 20000
[2016-11-30 21:58:25,327][INFO] Process-2 reads 20000
[2016-11-30 21:58:25,568][INFO] writes 1607000 landmark faces
[2016-11-30 21:58:25,859][INFO] writes 1608000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:58:26,065][INFO] Process-4 reads 20000
[2016-11-30 21:58:26,180][INFO] writes 1609000 landmark faces
[2016-11-30 21:58:26,476][INFO] writes 1610000 landmark faces
[2016-11-30 21:58:26,834][INFO] writes 1611000 landmark faces
[2016-11-30 21:58:27,103][INFO] writes 1612000 landmark faces
[2016-11-30 21:58:27,371][INFO] writes 1613000 landmark faces
[2016-11-30 21:58:27,644][INFO] writes 1614000 landmark faces
[2016-11-30 21:58:27,967][INFO] writes 1615000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:58:28,349][INFO] writes 1616000 landmark faces
[2016-11-30 21:58:28,674][INFO] writes 1617000 landmark faces
[2016-11-30 21:58:29,010][INFO] writes 1618000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:58:29,378][INFO] writes 1619000 landmark faces
[2016-11-30 21:58:29,777][INFO] writes 1620000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 21:58:35,231][INFO] Finish
[2016-11-30 21:58:35,251][INFO] writing val data, 40520 images
[2016-11-30 21:58:35,252][INFO] remove data/rnet_landmark_val
[2016-11-30 21:58:35,253][INFO] fill queues
[2016-11-30 21:58:35,935][INFO] writes 1000 landmark faces
[2016-11-30 21:58:36,177][INFO] writes 2000 landmark faces
[2016-11-30 21:58:36,424][INFO] writes 3000 landmark faces
[2016-11-30 21:58:36,653][INFO] writes 4000 landmark faces
[2016-11-30 21:58:36,881][INFO] writes 5000 landmark faces
[2016-11-30 21:58:37,113][INFO] writes 6000 landmark faces
[2016-11-30 21:58:37,367][INFO] writes 7000 landmark faces
[2016-11-30 21:58:37,609][INFO] writes 8000 landmark faces
[2016-11-30 21:58:37,890][INFO] writes 9000 landmark faces
[2016-11-30 21:58:38,159][INFO] writes 10000 landmark faces
[2016-11-30 21:58:38,423][INFO] writes 11000 landmark faces
[2016-11-30 21:58:38,692][INFO] writes 12000 landmark faces
[2016-11-30 21:58:38,915][INFO] writes 13000 landmark faces
[2016-11-30 21:58:39,122][INFO] writes 14000 landmark faces
[2016-11-30 21:58:39,324][INFO] writes 15000 landmark faces
[2016-11-30 21:58:39,556][INFO] writes 16000 landmark faces
[2016-11-30 21:58:39,821][INFO] writes 17000 landmark faces
[2016-11-30 21:58:40,049][INFO] writes 18000 landmark faces
[2016-11-30 21:58:40,289][INFO] writes 19000 landmark faces
[2016-11-30 21:58:40,552][INFO] writes 20000 landmark faces
[2016-11-30 21:58:40,795][INFO] writes 21000 landmark faces
[2016-11-30 21:58:41,018][INFO] writes 22000 landmark faces
[2016-11-30 21:58:41,247][INFO] writes 23000 landmark faces
[2016-11-30 21:58:41,487][INFO] writes 24000 landmark faces
[2016-11-30 21:58:41,738][INFO] writes 25000 landmark faces
[2016-11-30 21:58:41,977][INFO] writes 26000 landmark faces
[2016-11-30 21:58:42,225][INFO] writes 27000 landmark faces
[2016-11-30 21:58:42,478][INFO] writes 28000 landmark faces
[2016-11-30 21:58:42,710][INFO] writes 29000 landmark faces
[2016-11-30 21:58:42,958][INFO] writes 30000 landmark faces
[2016-11-30 21:58:43,209][INFO] writes 31000 landmark faces
[2016-11-30 21:58:43,441][INFO] writes 32000 landmark faces
[2016-11-30 21:58:43,734][INFO] writes 33000 landmark faces
[2016-11-30 21:58:43,951][INFO] writes 34000 landmark faces
[2016-11-30 21:58:44,173][INFO] writes 35000 landmark faces
[2016-11-30 21:58:44,394][INFO] writes 36000 landmark faces
[2016-11-30 21:58:44,617][INFO] writes 37000 landmark faces
[2016-11-30 21:58:44,857][INFO] writes 38000 landmark faces
[2016-11-30 21:58:45,086][INFO] writes 39000 landmark faces
[2016-11-30 21:58:45,310][INFO] writes 40000 landmark faces
[2016-11-30 21:58:45,528][INFO] writes 41000 landmark faces
[2016-11-30 21:58:45,738][INFO] writes 42000 landmark faces
[2016-11-30 21:58:45,999][INFO] writes 43000 landmark faces
[2016-11-30 21:58:46,279][INFO] writes 44000 landmark faces
[2016-11-30 21:58:46,522][INFO] writes 45000 landmark faces
[2016-11-30 21:58:46,734][INFO] writes 46000 landmark faces
[2016-11-30 21:58:47,002][INFO] writes 47000 landmark faces
[2016-11-30 21:58:47,216][INFO] writes 48000 landmark faces
[2016-11-30 21:58:47,423][INFO] writes 49000 landmark faces
[2016-11-30 21:58:47,663][INFO] writes 50000 landmark faces
[2016-11-30 21:58:47,904][INFO] writes 51000 landmark faces
[2016-11-30 21:58:48,143][INFO] writes 52000 landmark faces
[2016-11-30 21:58:48,375][INFO] writes 53000 landmark faces
[2016-11-30 21:58:48,655][INFO] writes 54000 landmark faces
[2016-11-30 21:58:48,876][INFO] writes 55000 landmark faces
[2016-11-30 21:58:49,084][INFO] writes 56000 landmark faces
[2016-11-30 21:58:49,329][INFO] writes 57000 landmark faces
[2016-11-30 21:58:49,593][INFO] writes 58000 landmark faces
[2016-11-30 21:58:49,802][INFO] writes 59000 landmark faces
[2016-11-30 21:58:50,033][INFO] writes 60000 landmark faces
[2016-11-30 21:58:50,268][INFO] writes 61000 landmark faces
[2016-11-30 21:58:50,512][INFO] writes 62000 landmark faces
[2016-11-30 21:58:50,754][INFO] writes 63000 landmark faces
[2016-11-30 21:58:50,996][INFO] writes 64000 landmark faces
[2016-11-30 21:58:51,282][INFO] writes 65000 landmark faces
[2016-11-30 21:58:51,501][INFO] writes 66000 landmark faces
[2016-11-30 21:58:51,750][INFO] writes 67000 landmark faces
[2016-11-30 21:58:51,971][INFO] writes 68000 landmark faces
[2016-11-30 21:58:52,239][INFO] writes 69000 landmark faces
[2016-11-30 21:58:52,462][INFO] writes 70000 landmark faces
[2016-11-30 21:58:52,687][INFO] writes 71000 landmark faces
[2016-11-30 21:58:52,914][INFO] writes 72000 landmark faces
[2016-11-30 21:58:53,120][INFO] writes 73000 landmark faces
[2016-11-30 21:58:53,338][INFO] writes 74000 landmark faces
[2016-11-30 21:58:53,569][INFO] writes 75000 landmark faces
[2016-11-30 21:58:53,628][INFO] Process-10 reads 1000
[2016-11-30 21:58:53,766][INFO] writes 76000 landmark faces
[2016-11-30 21:58:53,980][INFO] writes 77000 landmark faces
[2016-11-30 21:58:54,005][INFO] Process-16 reads 1000
[2016-11-30 21:58:54,159][INFO] Process-13 reads 1000
[2016-11-30 21:58:54,238][INFO] writes 78000 landmark faces
[2016-11-30 21:58:54,322][INFO] Process-15 reads 1000
[2016-11-30 21:58:54,467][INFO] writes 79000 landmark faces
[2016-11-30 21:58:54,727][INFO] writes 80000 landmark faces
[2016-11-30 21:58:54,784][INFO] Process-17 reads 1000
[2016-11-30 21:58:54,964][INFO] writes 81000 landmark faces
[2016-11-30 21:58:55,012][INFO] Process-11 reads 1000
[2016-11-30 21:58:55,199][INFO] writes 82000 landmark faces
[2016-11-30 21:58:55,449][INFO] writes 83000 landmark faces
[2016-11-30 21:58:55,583][INFO] Process-12 reads 1000
[2016-11-30 21:58:55,698][INFO] writes 84000 landmark faces
[2016-11-30 21:58:55,963][INFO] writes 85000 landmark faces
[2016-11-30 21:58:56,177][INFO] writes 86000 landmark faces
[2016-11-30 21:58:56,416][INFO] writes 87000 landmark faces
[2016-11-30 21:58:56,561][INFO] Process-14 reads 1000
[2016-11-30 21:58:56,665][INFO] writes 88000 landmark faces
[2016-11-30 21:58:56,891][INFO] writes 89000 landmark faces
[2016-11-30 21:58:57,102][INFO] writes 90000 landmark faces
[2016-11-30 21:58:57,319][INFO] writes 91000 landmark faces
[2016-11-30 21:58:57,529][INFO] writes 92000 landmark faces
[2016-11-30 21:58:57,770][INFO] writes 93000 landmark faces
[2016-11-30 21:58:57,989][INFO] writes 94000 landmark faces
[2016-11-30 21:58:58,245][INFO] writes 95000 landmark faces
[2016-11-30 21:58:58,510][INFO] writes 96000 landmark faces
[2016-11-30 21:58:58,763][INFO] writes 97000 landmark faces
[2016-11-30 21:58:59,024][INFO] writes 98000 landmark faces
[2016-11-30 21:58:59,270][INFO] writes 99000 landmark faces
[2016-11-30 21:58:59,493][INFO] writes 100000 landmark faces
[2016-11-30 21:58:59,725][INFO] writes 101000 landmark faces
[2016-11-30 21:58:59,931][INFO] writes 102000 landmark faces
[2016-11-30 21:59:00,165][INFO] writes 103000 landmark faces
[2016-11-30 21:59:00,409][INFO] writes 104000 landmark faces
[2016-11-30 21:59:00,620][INFO] writes 105000 landmark faces
[2016-11-30 21:59:00,846][INFO] writes 106000 landmark faces
[2016-11-30 21:59:01,119][INFO] writes 107000 landmark faces
[2016-11-30 21:59:01,347][INFO] writes 108000 landmark faces
[2016-11-30 21:59:01,600][INFO] writes 109000 landmark faces
[2016-11-30 21:59:01,834][INFO] writes 110000 landmark faces
[2016-11-30 21:59:02,075][INFO] writes 111000 landmark faces
[2016-11-30 21:59:02,301][INFO] writes 112000 landmark faces
[2016-11-30 21:59:02,543][INFO] writes 113000 landmark faces
[2016-11-30 21:59:02,760][INFO] writes 114000 landmark faces
[2016-11-30 21:59:02,993][INFO] writes 115000 landmark faces
[2016-11-30 21:59:03,210][INFO] writes 116000 landmark faces
[2016-11-30 21:59:03,432][INFO] writes 117000 landmark faces
[2016-11-30 21:59:03,652][INFO] writes 118000 landmark faces
[2016-11-30 21:59:03,904][INFO] writes 119000 landmark faces
[2016-11-30 21:59:04,133][INFO] writes 120000 landmark faces
[2016-11-30 21:59:04,365][INFO] writes 121000 landmark faces
[2016-11-30 21:59:04,601][INFO] writes 122000 landmark faces
[2016-11-30 21:59:04,836][INFO] writes 123000 landmark faces
[2016-11-30 21:59:05,065][INFO] writes 124000 landmark faces
[2016-11-30 21:59:05,269][INFO] writes 125000 landmark faces
[2016-11-30 21:59:05,500][INFO] writes 126000 landmark faces
[2016-11-30 21:59:05,752][INFO] writes 127000 landmark faces
[2016-11-30 21:59:06,005][INFO] writes 128000 landmark faces
[2016-11-30 21:59:06,214][INFO] writes 129000 landmark faces
[2016-11-30 21:59:06,450][INFO] writes 130000 landmark faces
[2016-11-30 21:59:06,686][INFO] writes 131000 landmark faces
[2016-11-30 21:59:06,893][INFO] writes 132000 landmark faces
[2016-11-30 21:59:07,126][INFO] writes 133000 landmark faces
[2016-11-30 21:59:07,389][INFO] writes 134000 landmark faces
[2016-11-30 21:59:07,627][INFO] writes 135000 landmark faces
[2016-11-30 21:59:07,887][INFO] writes 136000 landmark faces
[2016-11-30 21:59:08,171][INFO] writes 137000 landmark faces
[2016-11-30 21:59:08,480][INFO] writes 138000 landmark faces
[2016-11-30 21:59:08,731][INFO] writes 139000 landmark faces
[2016-11-30 21:59:08,993][INFO] writes 140000 landmark faces
[2016-11-30 21:59:09,255][INFO] writes 141000 landmark faces
[2016-11-30 21:59:09,522][INFO] writes 142000 landmark faces
[2016-11-30 21:59:09,738][INFO] writes 143000 landmark faces
[2016-11-30 21:59:10,009][INFO] writes 144000 landmark faces
[2016-11-30 21:59:10,260][INFO] writes 145000 landmark faces
[2016-11-30 21:59:10,464][INFO] writes 146000 landmark faces
[2016-11-30 21:59:10,716][INFO] writes 147000 landmark faces
[2016-11-30 21:59:10,952][INFO] writes 148000 landmark faces
[2016-11-30 21:59:11,228][INFO] writes 149000 landmark faces
[2016-11-30 21:59:11,486][INFO] writes 150000 landmark faces
[2016-11-30 21:59:11,745][INFO] writes 151000 landmark faces
[2016-11-30 21:59:12,002][INFO] writes 152000 landmark faces
[2016-11-30 21:59:12,230][INFO] Process-10 reads 2000
[2016-11-30 21:59:12,236][INFO] writes 153000 landmark faces
[2016-11-30 21:59:12,398][INFO] Process-15 reads 2000
[2016-11-30 21:59:12,443][INFO] writes 154000 landmark faces
[2016-11-30 21:59:12,672][INFO] writes 155000 landmark faces
[2016-11-30 21:59:12,934][INFO] writes 156000 landmark faces
[2016-11-30 21:59:13,008][INFO] Process-13 reads 2000
[2016-11-30 21:59:13,155][INFO] writes 157000 landmark faces
[2016-11-30 21:59:13,384][INFO] writes 158000 landmark faces
[2016-11-30 21:59:13,400][INFO] Process-17 reads 2000
[2016-11-30 21:59:13,446][INFO] Process-11 reads 2000
[2016-11-30 21:59:13,627][INFO] writes 159000 landmark faces
[2016-11-30 21:59:13,857][INFO] writes 160000 landmark faces
[2016-11-30 21:59:14,096][INFO] writes 161000 landmark faces
[2016-11-30 21:59:14,116][INFO] Process-16 reads 2000
[2016-11-30 21:59:14,326][INFO] writes 162000 landmark faces
[2016-11-30 21:59:14,566][INFO] writes 163000 landmark faces
[2016-11-30 21:59:14,838][INFO] writes 164000 landmark faces
[2016-11-30 21:59:15,083][INFO] writes 165000 landmark faces
[2016-11-30 21:59:15,363][INFO] writes 166000 landmark faces
[2016-11-30 21:59:15,593][INFO] writes 167000 landmark faces
[2016-11-30 21:59:15,856][INFO] writes 168000 landmark faces
[2016-11-30 21:59:16,080][INFO] writes 169000 landmark faces
[2016-11-30 21:59:16,095][INFO] Process-14 reads 2000
[2016-11-30 21:59:16,226][INFO] Process-12 reads 2000
[2016-11-30 21:59:16,312][INFO] writes 170000 landmark faces
[2016-11-30 21:59:16,519][INFO] writes 171000 landmark faces
[2016-11-30 21:59:16,762][INFO] writes 172000 landmark faces
[2016-11-30 21:59:17,020][INFO] writes 173000 landmark faces
[2016-11-30 21:59:17,258][INFO] writes 174000 landmark faces
[2016-11-30 21:59:17,473][INFO] writes 175000 landmark faces
[2016-11-30 21:59:17,683][INFO] writes 176000 landmark faces
[2016-11-30 21:59:17,890][INFO] writes 177000 landmark faces
[2016-11-30 21:59:18,142][INFO] writes 178000 landmark faces
[2016-11-30 21:59:18,385][INFO] writes 179000 landmark faces
[2016-11-30 21:59:18,591][INFO] writes 180000 landmark faces
[2016-11-30 21:59:18,798][INFO] writes 181000 landmark faces
[2016-11-30 21:59:19,031][INFO] writes 182000 landmark faces
[2016-11-30 21:59:19,243][INFO] writes 183000 landmark faces
[2016-11-30 21:59:19,488][INFO] writes 184000 landmark faces
[2016-11-30 21:59:19,703][INFO] writes 185000 landmark faces
[2016-11-30 21:59:19,930][INFO] writes 186000 landmark faces
[2016-11-30 21:59:20,167][INFO] writes 187000 landmark faces
[2016-11-30 21:59:20,389][INFO] writes 188000 landmark faces
[2016-11-30 21:59:20,604][INFO] writes 189000 landmark faces
[2016-11-30 21:59:20,843][INFO] writes 190000 landmark faces
[2016-11-30 21:59:21,085][INFO] writes 191000 landmark faces
[2016-11-30 21:59:21,301][INFO] writes 192000 landmark faces
[2016-11-30 21:59:21,566][INFO] writes 193000 landmark faces
[2016-11-30 21:59:21,847][INFO] writes 194000 landmark faces
[2016-11-30 21:59:22,095][INFO] writes 195000 landmark faces
[2016-11-30 21:59:22,364][INFO] writes 196000 landmark faces
[2016-11-30 21:59:22,594][INFO] writes 197000 landmark faces
[2016-11-30 21:59:22,825][INFO] writes 198000 landmark faces
[2016-11-30 21:59:23,055][INFO] writes 199000 landmark faces
[2016-11-30 21:59:23,270][INFO] writes 200000 landmark faces
[2016-11-30 21:59:23,506][INFO] writes 201000 landmark faces
[2016-11-30 21:59:23,711][INFO] writes 202000 landmark faces
[2016-11-30 21:59:23,925][INFO] writes 203000 landmark faces
[2016-11-30 21:59:24,116][INFO] writes 204000 landmark faces
[2016-11-30 21:59:24,344][INFO] writes 205000 landmark faces
[2016-11-30 21:59:24,566][INFO] writes 206000 landmark faces
[2016-11-30 21:59:24,792][INFO] writes 207000 landmark faces
[2016-11-30 21:59:25,020][INFO] writes 208000 landmark faces
[2016-11-30 21:59:25,232][INFO] writes 209000 landmark faces
[2016-11-30 21:59:25,454][INFO] writes 210000 landmark faces
[2016-11-30 21:59:25,671][INFO] writes 211000 landmark faces
[2016-11-30 21:59:25,919][INFO] writes 212000 landmark faces
[2016-11-30 21:59:26,141][INFO] writes 213000 landmark faces
[2016-11-30 21:59:26,414][INFO] writes 214000 landmark faces
[2016-11-30 21:59:26,633][INFO] writes 215000 landmark faces
[2016-11-30 21:59:26,876][INFO] writes 216000 landmark faces
[2016-11-30 21:59:27,082][INFO] writes 217000 landmark faces
[2016-11-30 21:59:27,310][INFO] writes 218000 landmark faces
[2016-11-30 21:59:27,530][INFO] writes 219000 landmark faces
[2016-11-30 21:59:27,788][INFO] writes 220000 landmark faces
[2016-11-30 21:59:27,988][INFO] writes 221000 landmark faces
[2016-11-30 21:59:28,199][INFO] writes 222000 landmark faces
[2016-11-30 21:59:28,432][INFO] writes 223000 landmark faces
[2016-11-30 21:59:28,670][INFO] writes 224000 landmark faces
[2016-11-30 21:59:28,895][INFO] writes 225000 landmark faces
[2016-11-30 21:59:29,114][INFO] writes 226000 landmark faces
[2016-11-30 21:59:29,338][INFO] writes 227000 landmark faces
[2016-11-30 21:59:29,578][INFO] writes 228000 landmark faces
[2016-11-30 21:59:29,802][INFO] writes 229000 landmark faces
[2016-11-30 21:59:30,016][INFO] writes 230000 landmark faces
[2016-11-30 21:59:30,242][INFO] writes 231000 landmark faces
[2016-11-30 21:59:30,463][INFO] writes 232000 landmark faces
[2016-11-30 21:59:30,694][INFO] writes 233000 landmark faces
[2016-11-30 21:59:30,773][INFO] Process-15 reads 3000
[2016-11-30 21:59:30,837][INFO] Process-10 reads 3000
[2016-11-30 21:59:30,923][INFO] writes 234000 landmark faces
[2016-11-30 21:59:31,094][INFO] Process-11 reads 3000
[2016-11-30 21:59:31,168][INFO] writes 235000 landmark faces
[2016-11-30 21:59:31,392][INFO] writes 236000 landmark faces
[2016-11-30 21:59:31,573][INFO] Process-13 reads 3000
[2016-11-30 21:59:31,631][INFO] writes 237000 landmark faces
[2016-11-30 21:59:31,844][INFO] writes 238000 landmark faces
[2016-11-30 21:59:32,045][INFO] writes 239000 landmark faces
[2016-11-30 21:59:32,307][INFO] writes 240000 landmark faces
[2016-11-30 21:59:32,326][INFO] Process-17 reads 3000
[2016-11-30 21:59:32,499][INFO] Process-16 reads 3000
[2016-11-30 21:59:32,542][INFO] writes 241000 landmark faces
[2016-11-30 21:59:32,768][INFO] writes 242000 landmark faces
[2016-11-30 21:59:33,009][INFO] writes 243000 landmark faces
[2016-11-30 21:59:33,239][INFO] writes 244000 landmark faces
[2016-11-30 21:59:33,470][INFO] writes 245000 landmark faces
[2016-11-30 21:59:33,672][INFO] writes 246000 landmark faces
[2016-11-30 21:59:33,918][INFO] writes 247000 landmark faces
[2016-11-30 21:59:34,029][INFO] Process-14 reads 3000
[2016-11-30 21:59:34,120][INFO] writes 248000 landmark faces
[2016-11-30 21:59:34,417][INFO] writes 249000 landmark faces
[2016-11-30 21:59:34,660][INFO] writes 250000 landmark faces
[2016-11-30 21:59:34,912][INFO] writes 251000 landmark faces
[2016-11-30 21:59:34,971][INFO] Process-12 reads 3000
[2016-11-30 21:59:35,137][INFO] writes 252000 landmark faces
[2016-11-30 21:59:35,365][INFO] writes 253000 landmark faces
[2016-11-30 21:59:35,588][INFO] writes 254000 landmark faces
[2016-11-30 21:59:35,793][INFO] writes 255000 landmark faces
[2016-11-30 21:59:36,053][INFO] writes 256000 landmark faces
[2016-11-30 21:59:36,273][INFO] writes 257000 landmark faces
[2016-11-30 21:59:36,480][INFO] writes 258000 landmark faces
[2016-11-30 21:59:36,699][INFO] writes 259000 landmark faces
[2016-11-30 21:59:36,950][INFO] writes 260000 landmark faces
[2016-11-30 21:59:37,191][INFO] writes 261000 landmark faces
[2016-11-30 21:59:37,385][INFO] writes 262000 landmark faces
[2016-11-30 21:59:37,602][INFO] writes 263000 landmark faces
[2016-11-30 21:59:37,817][INFO] writes 264000 landmark faces
[2016-11-30 21:59:38,025][INFO] writes 265000 landmark faces
[2016-11-30 21:59:38,269][INFO] writes 266000 landmark faces
[2016-11-30 21:59:38,460][INFO] writes 267000 landmark faces
[2016-11-30 21:59:38,680][INFO] writes 268000 landmark faces
[2016-11-30 21:59:38,894][INFO] writes 269000 landmark faces
[2016-11-30 21:59:39,100][INFO] writes 270000 landmark faces
[2016-11-30 21:59:39,371][INFO] writes 271000 landmark faces
[2016-11-30 21:59:39,589][INFO] writes 272000 landmark faces
[2016-11-30 21:59:39,842][INFO] writes 273000 landmark faces
[2016-11-30 21:59:40,040][INFO] writes 274000 landmark faces
[2016-11-30 21:59:40,245][INFO] writes 275000 landmark faces
[2016-11-30 21:59:40,467][INFO] writes 276000 landmark faces
[2016-11-30 21:59:40,706][INFO] writes 277000 landmark faces
[2016-11-30 21:59:40,962][INFO] writes 278000 landmark faces
[2016-11-30 21:59:41,193][INFO] writes 279000 landmark faces
[2016-11-30 21:59:41,412][INFO] writes 280000 landmark faces
[2016-11-30 21:59:41,603][INFO] writes 281000 landmark faces
[2016-11-30 21:59:41,863][INFO] writes 282000 landmark faces
[2016-11-30 21:59:42,122][INFO] writes 283000 landmark faces
[2016-11-30 21:59:42,362][INFO] writes 284000 landmark faces
[2016-11-30 21:59:42,564][INFO] writes 285000 landmark faces
[2016-11-30 21:59:42,789][INFO] writes 286000 landmark faces
[2016-11-30 21:59:43,010][INFO] writes 287000 landmark faces
[2016-11-30 21:59:43,239][INFO] writes 288000 landmark faces
[2016-11-30 21:59:43,461][INFO] writes 289000 landmark faces
[2016-11-30 21:59:43,680][INFO] writes 290000 landmark faces
[2016-11-30 21:59:43,923][INFO] writes 291000 landmark faces
[2016-11-30 21:59:44,156][INFO] writes 292000 landmark faces
[2016-11-30 21:59:44,454][INFO] writes 293000 landmark faces
[2016-11-30 21:59:44,620][INFO] writes 294000 landmark faces
[2016-11-30 21:59:44,820][INFO] writes 295000 landmark faces
[2016-11-30 21:59:45,065][INFO] writes 296000 landmark faces
[2016-11-30 21:59:45,305][INFO] writes 297000 landmark faces
[2016-11-30 21:59:45,535][INFO] writes 298000 landmark faces
[2016-11-30 21:59:45,736][INFO] writes 299000 landmark faces
[2016-11-30 21:59:45,956][INFO] writes 300000 landmark faces
[2016-11-30 21:59:46,208][INFO] writes 301000 landmark faces
[2016-11-30 21:59:46,433][INFO] writes 302000 landmark faces
[2016-11-30 21:59:46,649][INFO] writes 303000 landmark faces
[2016-11-30 21:59:46,862][INFO] writes 304000 landmark faces
[2016-11-30 21:59:47,106][INFO] writes 305000 landmark faces
[2016-11-30 21:59:47,324][INFO] writes 306000 landmark faces
[2016-11-30 21:59:47,572][INFO] writes 307000 landmark faces
[2016-11-30 21:59:47,827][INFO] writes 308000 landmark faces
[2016-11-30 21:59:48,068][INFO] writes 309000 landmark faces
[2016-11-30 21:59:48,309][INFO] writes 310000 landmark faces
[2016-11-30 21:59:48,537][INFO] writes 311000 landmark faces
[2016-11-30 21:59:48,633][INFO] Process-15 reads 4000
[2016-11-30 21:59:48,744][INFO] writes 312000 landmark faces
[2016-11-30 21:59:48,983][INFO] writes 313000 landmark faces
[2016-11-30 21:59:49,211][INFO] writes 314000 landmark faces
[2016-11-30 21:59:49,444][INFO] writes 315000 landmark faces
[2016-11-30 21:59:49,449][INFO] Process-11 reads 4000
[2016-11-30 21:59:49,531][INFO] Process-10 reads 4000
[2016-11-30 21:59:49,677][INFO] writes 316000 landmark faces
[2016-11-30 21:59:49,826][INFO] Process-17 reads 4000
[2016-11-30 21:59:49,912][INFO] writes 317000 landmark faces
[2016-11-30 21:59:50,058][INFO] Process-13 reads 4000
[2016-11-30 21:59:50,116][INFO] writes 318000 landmark faces
[2016-11-30 21:59:50,332][INFO] writes 319000 landmark faces
[2016-11-30 21:59:50,563][INFO] writes 320000 landmark faces
[2016-11-30 21:59:50,804][INFO] writes 321000 landmark faces
[2016-11-30 21:59:51,050][INFO] writes 322000 landmark faces
[2016-11-30 21:59:51,288][INFO] writes 323000 landmark faces
[2016-11-30 21:59:51,362][INFO] Process-16 reads 4000
[2016-11-30 21:59:51,522][INFO] writes 324000 landmark faces
[2016-11-30 21:59:51,759][INFO] writes 325000 landmark faces
[2016-11-30 21:59:51,968][INFO] writes 326000 landmark faces
[2016-11-30 21:59:52,202][INFO] writes 327000 landmark faces
[2016-11-30 21:59:52,278][INFO] Process-14 reads 4000
[2016-11-30 21:59:52,448][INFO] writes 328000 landmark faces
[2016-11-30 21:59:52,659][INFO] writes 329000 landmark faces
[2016-11-30 21:59:52,855][INFO] writes 330000 landmark faces
[2016-11-30 21:59:53,087][INFO] writes 331000 landmark faces
[2016-11-30 21:59:53,329][INFO] writes 332000 landmark faces
[2016-11-30 21:59:53,540][INFO] writes 333000 landmark faces
[2016-11-30 21:59:53,584][INFO] Process-12 reads 4000
[2016-11-30 21:59:53,763][INFO] writes 334000 landmark faces
[2016-11-30 21:59:53,984][INFO] writes 335000 landmark faces
[2016-11-30 21:59:54,200][INFO] writes 336000 landmark faces
[2016-11-30 21:59:54,409][INFO] writes 337000 landmark faces
[2016-11-30 21:59:54,615][INFO] writes 338000 landmark faces
[2016-11-30 21:59:54,858][INFO] writes 339000 landmark faces
[2016-11-30 21:59:55,063][INFO] writes 340000 landmark faces
[2016-11-30 21:59:55,280][INFO] writes 341000 landmark faces
[2016-11-30 21:59:55,504][INFO] writes 342000 landmark faces
[2016-11-30 21:59:55,721][INFO] writes 343000 landmark faces
[2016-11-30 21:59:55,940][INFO] writes 344000 landmark faces
[2016-11-30 21:59:56,148][INFO] writes 345000 landmark faces
[2016-11-30 21:59:56,396][INFO] writes 346000 landmark faces
[2016-11-30 21:59:56,643][INFO] writes 347000 landmark faces
[2016-11-30 21:59:56,881][INFO] writes 348000 landmark faces
[2016-11-30 21:59:57,130][INFO] writes 349000 landmark faces
[2016-11-30 21:59:57,373][INFO] writes 350000 landmark faces
[2016-11-30 21:59:57,595][INFO] writes 351000 landmark faces
[2016-11-30 21:59:57,839][INFO] writes 352000 landmark faces
[2016-11-30 21:59:58,044][INFO] writes 353000 landmark faces
[2016-11-30 21:59:58,271][INFO] writes 354000 landmark faces
[2016-11-30 21:59:58,477][INFO] writes 355000 landmark faces
[2016-11-30 21:59:58,677][INFO] writes 356000 landmark faces
[2016-11-30 21:59:58,916][INFO] writes 357000 landmark faces
[2016-11-30 21:59:59,218][INFO] writes 358000 landmark faces
[2016-11-30 21:59:59,422][INFO] writes 359000 landmark faces
[2016-11-30 21:59:59,656][INFO] writes 360000 landmark faces
[2016-11-30 21:59:59,895][INFO] writes 361000 landmark faces
[2016-11-30 22:00:00,123][INFO] writes 362000 landmark faces
[2016-11-30 22:00:00,355][INFO] writes 363000 landmark faces
[2016-11-30 22:00:00,580][INFO] writes 364000 landmark faces
[2016-11-30 22:00:00,782][INFO] writes 365000 landmark faces
[2016-11-30 22:00:01,023][INFO] writes 366000 landmark faces
[2016-11-30 22:00:01,291][INFO] writes 367000 landmark faces
[2016-11-30 22:00:01,508][INFO] writes 368000 landmark faces
[2016-11-30 22:00:01,722][INFO] writes 369000 landmark faces
[2016-11-30 22:00:01,942][INFO] writes 370000 landmark faces
[2016-11-30 22:00:02,141][INFO] writes 371000 landmark faces
[2016-11-30 22:00:02,409][INFO] writes 372000 landmark faces
[2016-11-30 22:00:02,653][INFO] writes 373000 landmark faces
[2016-11-30 22:00:02,903][INFO] writes 374000 landmark faces
[2016-11-30 22:00:03,128][INFO] writes 375000 landmark faces
[2016-11-30 22:00:03,359][INFO] writes 376000 landmark faces
[2016-11-30 22:00:03,592][INFO] writes 377000 landmark faces
[2016-11-30 22:00:03,804][INFO] writes 378000 landmark faces
[2016-11-30 22:00:04,036][INFO] writes 379000 landmark faces
[2016-11-30 22:00:04,270][INFO] writes 380000 landmark faces
[2016-11-30 22:00:04,503][INFO] writes 381000 landmark faces
[2016-11-30 22:00:04,729][INFO] writes 382000 landmark faces
[2016-11-30 22:00:04,985][INFO] writes 383000 landmark faces
[2016-11-30 22:00:05,194][INFO] writes 384000 landmark faces
[2016-11-30 22:00:05,408][INFO] writes 385000 landmark faces
[2016-11-30 22:00:05,639][INFO] writes 386000 landmark faces
[2016-11-30 22:00:05,894][INFO] writes 387000 landmark faces
[2016-11-30 22:00:06,127][INFO] writes 388000 landmark faces
[2016-11-30 22:00:06,340][INFO] writes 389000 landmark faces
[2016-11-30 22:00:06,572][INFO] writes 390000 landmark faces
[2016-11-30 22:00:06,779][INFO] writes 391000 landmark faces
[2016-11-30 22:00:07,009][INFO] writes 392000 landmark faces
[2016-11-30 22:00:07,224][INFO] writes 393000 landmark faces
[2016-11-30 22:00:07,332][INFO] Process-17 reads 5000
[2016-11-30 22:00:07,434][INFO] Process-11 reads 5000
[2016-11-30 22:00:07,464][INFO] writes 394000 landmark faces
[2016-11-30 22:00:07,622][INFO] Process-13 reads 5000
[2016-11-30 22:00:07,712][INFO] writes 395000 landmark faces
[2016-11-30 22:00:07,952][INFO] writes 396000 landmark faces
[2016-11-30 22:00:07,974][INFO] Process-15 reads 5000
[2016-11-30 22:00:08,019][INFO] Process-10 reads 5000
[2016-11-30 22:00:08,145][INFO] writes 397000 landmark faces
[2016-11-30 22:00:08,384][INFO] writes 398000 landmark faces
[2016-11-30 22:00:08,602][INFO] writes 399000 landmark faces
[2016-11-30 22:00:08,884][INFO] writes 400000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 22:00:08,990][INFO] Process-14 reads 5000
[2016-11-30 22:00:09,368][INFO] writes 401000 landmark faces
[2016-11-30 22:00:09,920][INFO] writes 402000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 22:00:10,665][INFO] writes 403000 landmark faces
[2016-11-30 22:00:10,953][INFO] Process-16 reads 5000
[2016-11-30 22:00:11,427][INFO] writes 404000 landmark faces
[2016-11-30 22:00:11,734][INFO] Process-12 reads 5000
[2016-11-30 22:00:12,381][INFO] writes 405000 landmark faces
[2016-11-30 22:00:18,533][INFO] Finish
[2016-11-30 22:00:19,566][INFO] loading WIDER
[2016-11-30 22:00:20,108][INFO] total images, train: 12797, val: 3196
[2016-11-30 22:00:20,110][INFO] total faces, train: 97311, val: 24101
[2016-11-30 22:00:20,110][INFO] writing train data, 12797 images
[2016-11-30 22:00:20,110][INFO] remove data/rnet_positive_train
[2016-11-30 22:00:20,110][INFO] remove data/rnet_negative_train
[2016-11-30 22:00:20,111][INFO] remove data/rnet_part_train
[2016-11-30 22:00:20,111][INFO] fill queues
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 22:00:22.839839 11664 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
  }
}
I1130 22:00:22.839948 11664 layer_factory.hpp:77] Creating layer data
I1130 22:00:22.839963 11664 net.cpp:100] Creating Layer data
I1130 22:00:22.839970 11664 net.cpp:408] data -> data
I1130 22:00:22.855528 11664 net.cpp:150] Setting up data
I1130 22:00:22.855577 11664 net.cpp:157] Top shape: 1 3 12 12 (432)
I1130 22:00:22.855581 11664 net.cpp:165] Memory required for data: 1728
I1130 22:00:22.855588 11664 layer_factory.hpp:77] Creating layer conv1
I1130 22:00:22.855607 11664 net.cpp:100] Creating Layer conv1
I1130 22:00:22.855612 11664 net.cpp:434] conv1 <- data
I1130 22:00:22.855618 11664 net.cpp:408] conv1 -> conv1
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 22:00:22.884469 11665 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
  }
}
I1130 22:00:22.884606 11665 layer_factory.hpp:77] Creating layer data
I1130 22:00:22.884629 11665 net.cpp:100] Creating Layer data
I1130 22:00:22.884635 11665 net.cpp:408] data -> data
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 22:00:22.899668 11663 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
  }
}
I1130 22:00:22.899849 11663 layer_factory.hpp:77] Creating layer data
I1130 22:00:22.899879 11663 net.cpp:100] Creating Layer data
I1130 22:00:22.899888 11663 net.cpp:408] data -> data
I1130 22:00:22.903762 11665 net.cpp:150] Setting up data
I1130 22:00:22.903825 11665 net.cpp:157] Top shape: 1 3 12 12 (432)
I1130 22:00:22.903831 11665 net.cpp:165] Memory required for data: 1728
I1130 22:00:22.903841 11665 layer_factory.hpp:77] Creating layer conv1
I1130 22:00:22.903875 11665 net.cpp:100] Creating Layer conv1
I1130 22:00:22.903882 11665 net.cpp:434] conv1 <- data
I1130 22:00:22.903889 11665 net.cpp:408] conv1 -> conv1
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 22:00:22.916187 11666 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
  }
}
I1130 22:00:22.916332 11666 layer_factory.hpp:77] Creating layer data
I1130 22:00:22.916350 11666 net.cpp:100] Creating Layer data
I1130 22:00:22.916359 11666 net.cpp:408] data -> data
I1130 22:00:22.948809 11663 net.cpp:150] Setting up data
I1130 22:00:22.948839 11663 net.cpp:157] Top shape: 1 3 12 12 (432)
I1130 22:00:22.948845 11663 net.cpp:165] Memory required for data: 1728
I1130 22:00:22.948851 11663 layer_factory.hpp:77] Creating layer conv1
I1130 22:00:22.948866 11663 net.cpp:100] Creating Layer conv1
I1130 22:00:22.948871 11663 net.cpp:434] conv1 <- data
I1130 22:00:22.948879 11663 net.cpp:408] conv1 -> conv1
I1130 22:00:22.955147 11666 net.cpp:150] Setting up data
I1130 22:00:22.955198 11666 net.cpp:157] Top shape: 1 3 12 12 (432)
I1130 22:00:22.955204 11666 net.cpp:165] Memory required for data: 1728
I1130 22:00:22.955211 11666 layer_factory.hpp:77] Creating layer conv1
I1130 22:00:22.955231 11666 net.cpp:100] Creating Layer conv1
I1130 22:00:22.955236 11666 net.cpp:434] conv1 <- data
I1130 22:00:22.955245 11666 net.cpp:408] conv1 -> conv1
I1130 22:00:23.105929 11664 net.cpp:150] Setting up conv1
I1130 22:00:23.105993 11664 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:00:23.105998 11664 net.cpp:165] Memory required for data: 5728
I1130 22:00:23.106022 11664 layer_factory.hpp:77] Creating layer prelu1
I1130 22:00:23.106040 11664 net.cpp:100] Creating Layer prelu1
I1130 22:00:23.106045 11664 net.cpp:434] prelu1 <- conv1
I1130 22:00:23.106051 11664 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:00:23.106169 11664 net.cpp:150] Setting up prelu1
I1130 22:00:23.106179 11664 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:00:23.106183 11664 net.cpp:165] Memory required for data: 9728
I1130 22:00:23.106189 11664 layer_factory.hpp:77] Creating layer pool1
I1130 22:00:23.106200 11664 net.cpp:100] Creating Layer pool1
I1130 22:00:23.106204 11664 net.cpp:434] pool1 <- conv1
I1130 22:00:23.106211 11664 net.cpp:408] pool1 -> pool1
I1130 22:00:23.106252 11664 net.cpp:150] Setting up pool1
I1130 22:00:23.106259 11664 net.cpp:157] Top shape: 1 10 5 5 (250)
I1130 22:00:23.106276 11664 net.cpp:165] Memory required for data: 10728
I1130 22:00:23.106278 11664 layer_factory.hpp:77] Creating layer conv2
I1130 22:00:23.106292 11664 net.cpp:100] Creating Layer conv2
I1130 22:00:23.106294 11664 net.cpp:434] conv2 <- pool1
I1130 22:00:23.106302 11664 net.cpp:408] conv2 -> conv2
I1130 22:00:23.108693 11664 net.cpp:150] Setting up conv2
I1130 22:00:23.108712 11664 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:00:23.108716 11664 net.cpp:165] Memory required for data: 11304
I1130 22:00:23.108726 11664 layer_factory.hpp:77] Creating layer prelu2
I1130 22:00:23.108731 11664 net.cpp:100] Creating Layer prelu2
I1130 22:00:23.108734 11664 net.cpp:434] prelu2 <- conv2
I1130 22:00:23.108741 11664 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:00:23.108834 11664 net.cpp:150] Setting up prelu2
I1130 22:00:23.108840 11664 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:00:23.108844 11664 net.cpp:165] Memory required for data: 11880
I1130 22:00:23.108847 11664 layer_factory.hpp:77] Creating layer conv3
I1130 22:00:23.108858 11664 net.cpp:100] Creating Layer conv3
I1130 22:00:23.108861 11664 net.cpp:434] conv3 <- conv2
I1130 22:00:23.108866 11664 net.cpp:408] conv3 -> conv3
I1130 22:00:23.111030 11664 net.cpp:150] Setting up conv3
I1130 22:00:23.111047 11664 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.111050 11664 net.cpp:165] Memory required for data: 12008
I1130 22:00:23.111057 11664 layer_factory.hpp:77] Creating layer prelu3
I1130 22:00:23.111070 11664 net.cpp:100] Creating Layer prelu3
I1130 22:00:23.111076 11664 net.cpp:434] prelu3 <- conv3
I1130 22:00:23.111083 11664 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:00:23.111161 11664 net.cpp:150] Setting up prelu3
I1130 22:00:23.111167 11664 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.111171 11664 net.cpp:165] Memory required for data: 12136
I1130 22:00:23.111181 11664 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 22:00:23.111189 11664 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 22:00:23.111193 11664 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 22:00:23.111199 11664 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 22:00:23.111205 11664 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 22:00:23.111210 11664 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 22:00:23.111254 11664 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 22:00:23.111259 11664 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.111263 11664 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.111266 11664 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.111269 11664 net.cpp:165] Memory required for data: 12520
I1130 22:00:23.111273 11664 layer_factory.hpp:77] Creating layer score
I1130 22:00:23.111291 11664 net.cpp:100] Creating Layer score
I1130 22:00:23.111294 11664 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 22:00:23.111299 11664 net.cpp:408] score -> score
I1130 22:00:23.112185 11664 net.cpp:150] Setting up score
I1130 22:00:23.112200 11664 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:00:23.112203 11664 net.cpp:165] Memory required for data: 12528
I1130 22:00:23.112210 11664 layer_factory.hpp:77] Creating layer prob
I1130 22:00:23.112218 11664 net.cpp:100] Creating Layer prob
I1130 22:00:23.112222 11664 net.cpp:434] prob <- score
I1130 22:00:23.112229 11664 net.cpp:408] prob -> prob
I1130 22:00:23.112434 11664 net.cpp:150] Setting up prob
I1130 22:00:23.112443 11664 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:00:23.112447 11664 net.cpp:165] Memory required for data: 12536
I1130 22:00:23.112450 11664 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:00:23.112460 11664 net.cpp:100] Creating Layer bbox_pred
I1130 22:00:23.112463 11664 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 22:00:23.112468 11664 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:00:23.113384 11664 net.cpp:150] Setting up bbox_pred
I1130 22:00:23.113399 11664 net.cpp:157] Top shape: 1 4 1 1 (4)
I1130 22:00:23.113402 11664 net.cpp:165] Memory required for data: 12552
I1130 22:00:23.113418 11664 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:00:23.113428 11664 net.cpp:100] Creating Layer landmark_pred
I1130 22:00:23.113432 11664 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 22:00:23.113437 11664 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:00:23.114353 11664 net.cpp:150] Setting up landmark_pred
I1130 22:00:23.114372 11664 net.cpp:157] Top shape: 1 10 1 1 (10)
I1130 22:00:23.114375 11664 net.cpp:165] Memory required for data: 12592
I1130 22:00:23.114382 11664 net.cpp:228] landmark_pred does not need backward computation.
I1130 22:00:23.114385 11664 net.cpp:228] bbox_pred does not need backward computation.
I1130 22:00:23.114388 11664 net.cpp:228] prob does not need backward computation.
I1130 22:00:23.114392 11664 net.cpp:228] score does not need backward computation.
I1130 22:00:23.114395 11664 net.cpp:228] conv3_prelu3_0_split does not need backward computation.
I1130 22:00:23.114398 11664 net.cpp:228] prelu3 does not need backward computation.
I1130 22:00:23.114400 11664 net.cpp:228] conv3 does not need backward computation.
I1130 22:00:23.114403 11664 net.cpp:228] prelu2 does not need backward computation.
I1130 22:00:23.114406 11664 net.cpp:228] conv2 does not need backward computation.
I1130 22:00:23.114410 11664 net.cpp:228] pool1 does not need backward computation.
I1130 22:00:23.114413 11664 net.cpp:228] prelu1 does not need backward computation.
I1130 22:00:23.114415 11664 net.cpp:228] conv1 does not need backward computation.
I1130 22:00:23.114418 11664 net.cpp:228] data does not need backward computation.
I1130 22:00:23.114421 11664 net.cpp:270] This network produces output bbox_pred
I1130 22:00:23.114424 11664 net.cpp:270] This network produces output landmark_pred
I1130 22:00:23.114428 11664 net.cpp:270] This network produces output prob
I1130 22:00:23.114439 11664 net.cpp:283] Network initialization done.
I1130 22:00:23.114694 11664 net.cpp:761] Ignoring source layer loss
I1130 22:00:23.194190 11665 net.cpp:150] Setting up conv1
I1130 22:00:23.194243 11665 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:00:23.194248 11665 net.cpp:165] Memory required for data: 5728
I1130 22:00:23.194274 11665 layer_factory.hpp:77] Creating layer prelu1
I1130 22:00:23.194290 11665 net.cpp:100] Creating Layer prelu1
I1130 22:00:23.194296 11665 net.cpp:434] prelu1 <- conv1
I1130 22:00:23.194303 11665 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:00:23.194420 11665 net.cpp:150] Setting up prelu1
I1130 22:00:23.194428 11665 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:00:23.194432 11665 net.cpp:165] Memory required for data: 9728
I1130 22:00:23.194439 11665 layer_factory.hpp:77] Creating layer pool1
I1130 22:00:23.194450 11665 net.cpp:100] Creating Layer pool1
I1130 22:00:23.194454 11665 net.cpp:434] pool1 <- conv1
I1130 22:00:23.194463 11665 net.cpp:408] pool1 -> pool1
I1130 22:00:23.194502 11665 net.cpp:150] Setting up pool1
I1130 22:00:23.194510 11665 net.cpp:157] Top shape: 1 10 5 5 (250)
I1130 22:00:23.194514 11665 net.cpp:165] Memory required for data: 10728
I1130 22:00:23.194517 11665 layer_factory.hpp:77] Creating layer conv2
I1130 22:00:23.194531 11665 net.cpp:100] Creating Layer conv2
I1130 22:00:23.194535 11665 net.cpp:434] conv2 <- pool1
I1130 22:00:23.194542 11665 net.cpp:408] conv2 -> conv2
I1130 22:00:23.196725 11665 net.cpp:150] Setting up conv2
I1130 22:00:23.196748 11665 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:00:23.196753 11665 net.cpp:165] Memory required for data: 11304
I1130 22:00:23.196764 11665 layer_factory.hpp:77] Creating layer prelu2
I1130 22:00:23.196771 11665 net.cpp:100] Creating Layer prelu2
I1130 22:00:23.196776 11665 net.cpp:434] prelu2 <- conv2
I1130 22:00:23.196784 11665 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:00:23.196878 11665 net.cpp:150] Setting up prelu2
I1130 22:00:23.196887 11665 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:00:23.196890 11665 net.cpp:165] Memory required for data: 11880
I1130 22:00:23.196895 11665 layer_factory.hpp:77] Creating layer conv3
I1130 22:00:23.196907 11665 net.cpp:100] Creating Layer conv3
I1130 22:00:23.196918 11665 net.cpp:434] conv3 <- conv2
I1130 22:00:23.196925 11665 net.cpp:408] conv3 -> conv3
I1130 22:00:23.199115 11665 net.cpp:150] Setting up conv3
I1130 22:00:23.199139 11665 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.199144 11665 net.cpp:165] Memory required for data: 12008
I1130 22:00:23.199152 11665 layer_factory.hpp:77] Creating layer prelu3
I1130 22:00:23.199162 11665 net.cpp:100] Creating Layer prelu3
I1130 22:00:23.199167 11665 net.cpp:434] prelu3 <- conv3
I1130 22:00:23.199174 11665 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:00:23.199265 11665 net.cpp:150] Setting up prelu3
I1130 22:00:23.199272 11665 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.199275 11665 net.cpp:165] Memory required for data: 12136
I1130 22:00:23.199285 11665 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 22:00:23.199296 11665 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 22:00:23.199301 11665 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 22:00:23.199307 11665 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 22:00:23.199314 11665 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 22:00:23.199319 11665 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 22:00:23.199368 11665 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 22:00:23.199374 11665 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.199379 11665 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.199383 11665 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.199386 11665 net.cpp:165] Memory required for data: 12520
I1130 22:00:23.199389 11665 layer_factory.hpp:77] Creating layer score
I1130 22:00:23.199400 11665 net.cpp:100] Creating Layer score
I1130 22:00:23.199404 11665 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 22:00:23.199410 11665 net.cpp:408] score -> score
I1130 22:00:23.200435 11665 net.cpp:150] Setting up score
I1130 22:00:23.200454 11665 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:00:23.200459 11665 net.cpp:165] Memory required for data: 12528
I1130 22:00:23.200466 11665 layer_factory.hpp:77] Creating layer prob
I1130 22:00:23.200476 11665 net.cpp:100] Creating Layer prob
I1130 22:00:23.200481 11665 net.cpp:434] prob <- score
I1130 22:00:23.200489 11665 net.cpp:408] prob -> prob
I1130 22:00:23.200722 11665 net.cpp:150] Setting up prob
I1130 22:00:23.200733 11665 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:00:23.200736 11665 net.cpp:165] Memory required for data: 12536
I1130 22:00:23.200740 11665 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:00:23.200752 11665 net.cpp:100] Creating Layer bbox_pred
I1130 22:00:23.200757 11665 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 22:00:23.200762 11665 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:00:23.201814 11665 net.cpp:150] Setting up bbox_pred
I1130 22:00:23.201831 11665 net.cpp:157] Top shape: 1 4 1 1 (4)
I1130 22:00:23.201836 11665 net.cpp:165] Memory required for data: 12552
I1130 22:00:23.201844 11665 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:00:23.201855 11665 net.cpp:100] Creating Layer landmark_pred
I1130 22:00:23.201859 11665 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 22:00:23.201866 11665 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:00:23.202925 11665 net.cpp:150] Setting up landmark_pred
I1130 22:00:23.202944 11665 net.cpp:157] Top shape: 1 10 1 1 (10)
I1130 22:00:23.202950 11665 net.cpp:165] Memory required for data: 12592
I1130 22:00:23.202957 11665 net.cpp:228] landmark_pred does not need backward computation.
I1130 22:00:23.202962 11665 net.cpp:228] bbox_pred does not need backward computation.
I1130 22:00:23.202966 11665 net.cpp:228] prob does not need backward computation.
I1130 22:00:23.202970 11665 net.cpp:228] score does not need backward computation.
I1130 22:00:23.202975 11665 net.cpp:228] conv3_prelu3_0_split does not need backward computation.
I1130 22:00:23.202980 11665 net.cpp:228] prelu3 does not need backward computation.
I1130 22:00:23.202982 11665 net.cpp:228] conv3 does not need backward computation.
I1130 22:00:23.202998 11665 net.cpp:228] prelu2 does not need backward computation.
I1130 22:00:23.203002 11665 net.cpp:228] conv2 does not need backward computation.
I1130 22:00:23.203006 11665 net.cpp:228] pool1 does not need backward computation.
I1130 22:00:23.203011 11665 net.cpp:228] prelu1 does not need backward computation.
I1130 22:00:23.203013 11665 net.cpp:228] conv1 does not need backward computation.
I1130 22:00:23.203017 11665 net.cpp:228] data does not need backward computation.
I1130 22:00:23.203021 11665 net.cpp:270] This network produces output bbox_pred
I1130 22:00:23.203024 11665 net.cpp:270] This network produces output landmark_pred
I1130 22:00:23.203028 11665 net.cpp:270] This network produces output prob
I1130 22:00:23.203040 11665 net.cpp:283] Network initialization done.
I1130 22:00:23.203289 11665 net.cpp:761] Ignoring source layer loss
I1130 22:00:23.239348 11666 net.cpp:150] Setting up conv1
I1130 22:00:23.239399 11666 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:00:23.239404 11666 net.cpp:165] Memory required for data: 5728
I1130 22:00:23.239428 11666 layer_factory.hpp:77] Creating layer prelu1
I1130 22:00:23.239446 11666 net.cpp:100] Creating Layer prelu1
I1130 22:00:23.239451 11666 net.cpp:434] prelu1 <- conv1
I1130 22:00:23.239457 11666 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:00:23.239578 11666 net.cpp:150] Setting up prelu1
I1130 22:00:23.239586 11666 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:00:23.239590 11666 net.cpp:165] Memory required for data: 9728
I1130 22:00:23.239598 11666 layer_factory.hpp:77] Creating layer pool1
I1130 22:00:23.239609 11666 net.cpp:100] Creating Layer pool1
I1130 22:00:23.239612 11666 net.cpp:434] pool1 <- conv1
I1130 22:00:23.239619 11666 net.cpp:408] pool1 -> pool1
I1130 22:00:23.239660 11666 net.cpp:150] Setting up pool1
I1130 22:00:23.239668 11666 net.cpp:157] Top shape: 1 10 5 5 (250)
I1130 22:00:23.239671 11666 net.cpp:165] Memory required for data: 10728
I1130 22:00:23.239675 11666 layer_factory.hpp:77] Creating layer conv2
I1130 22:00:23.239687 11666 net.cpp:100] Creating Layer conv2
I1130 22:00:23.239691 11666 net.cpp:434] conv2 <- pool1
I1130 22:00:23.239698 11666 net.cpp:408] conv2 -> conv2
I1130 22:00:23.241811 11666 net.cpp:150] Setting up conv2
I1130 22:00:23.241830 11666 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:00:23.241835 11666 net.cpp:165] Memory required for data: 11304
I1130 22:00:23.241845 11666 layer_factory.hpp:77] Creating layer prelu2
I1130 22:00:23.241852 11666 net.cpp:100] Creating Layer prelu2
I1130 22:00:23.241857 11666 net.cpp:434] prelu2 <- conv2
I1130 22:00:23.241864 11666 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:00:23.241955 11666 net.cpp:150] Setting up prelu2
I1130 22:00:23.241963 11666 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:00:23.241966 11666 net.cpp:165] Memory required for data: 11880
I1130 22:00:23.241972 11666 layer_factory.hpp:77] Creating layer conv3
I1130 22:00:23.241981 11666 net.cpp:100] Creating Layer conv3
I1130 22:00:23.241986 11666 net.cpp:434] conv3 <- conv2
I1130 22:00:23.241991 11666 net.cpp:408] conv3 -> conv3
I1130 22:00:23.244129 11666 net.cpp:150] Setting up conv3
I1130 22:00:23.244148 11666 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.244153 11666 net.cpp:165] Memory required for data: 12008
I1130 22:00:23.244161 11666 layer_factory.hpp:77] Creating layer prelu3
I1130 22:00:23.244170 11666 net.cpp:100] Creating Layer prelu3
I1130 22:00:23.244175 11666 net.cpp:434] prelu3 <- conv3
I1130 22:00:23.244182 11666 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:00:23.244272 11666 net.cpp:150] Setting up prelu3
I1130 22:00:23.244279 11666 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.244283 11666 net.cpp:165] Memory required for data: 12136
I1130 22:00:23.244293 11666 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 22:00:23.244303 11666 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 22:00:23.244307 11666 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 22:00:23.244314 11666 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 22:00:23.244328 11666 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 22:00:23.244334 11666 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 22:00:23.244384 11666 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 22:00:23.244390 11666 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.244395 11666 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.244398 11666 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.244401 11666 net.cpp:165] Memory required for data: 12520
I1130 22:00:23.244405 11666 layer_factory.hpp:77] Creating layer score
I1130 22:00:23.244417 11666 net.cpp:100] Creating Layer score
I1130 22:00:23.244421 11666 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 22:00:23.244426 11666 net.cpp:408] score -> score
I1130 22:00:23.245450 11666 net.cpp:150] Setting up score
I1130 22:00:23.245468 11666 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:00:23.245473 11666 net.cpp:165] Memory required for data: 12528
I1130 22:00:23.245481 11666 layer_factory.hpp:77] Creating layer prob
I1130 22:00:23.245489 11666 net.cpp:100] Creating Layer prob
I1130 22:00:23.245493 11666 net.cpp:434] prob <- score
I1130 22:00:23.245501 11666 net.cpp:408] prob -> prob
I1130 22:00:23.245738 11666 net.cpp:150] Setting up prob
I1130 22:00:23.245748 11666 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:00:23.245751 11666 net.cpp:165] Memory required for data: 12536
I1130 22:00:23.245755 11666 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:00:23.245766 11666 net.cpp:100] Creating Layer bbox_pred
I1130 22:00:23.245770 11666 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 22:00:23.245776 11666 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:00:23.246819 11666 net.cpp:150] Setting up bbox_pred
I1130 22:00:23.246836 11666 net.cpp:157] Top shape: 1 4 1 1 (4)
I1130 22:00:23.246841 11666 net.cpp:165] Memory required for data: 12552
I1130 22:00:23.246850 11666 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:00:23.246860 11666 net.cpp:100] Creating Layer landmark_pred
I1130 22:00:23.246865 11666 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 22:00:23.246870 11666 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:00:23.247925 11666 net.cpp:150] Setting up landmark_pred
I1130 22:00:23.247944 11666 net.cpp:157] Top shape: 1 10 1 1 (10)
I1130 22:00:23.247948 11666 net.cpp:165] Memory required for data: 12592
I1130 22:00:23.247956 11666 net.cpp:228] landmark_pred does not need backward computation.
I1130 22:00:23.247961 11666 net.cpp:228] bbox_pred does not need backward computation.
I1130 22:00:23.247966 11666 net.cpp:228] prob does not need backward computation.
I1130 22:00:23.247968 11666 net.cpp:228] score does not need backward computation.
I1130 22:00:23.247972 11666 net.cpp:228] conv3_prelu3_0_split does not need backward computation.
I1130 22:00:23.247975 11666 net.cpp:228] prelu3 does not need backward computation.
I1130 22:00:23.247979 11666 net.cpp:228] conv3 does not need backward computation.
I1130 22:00:23.247982 11666 net.cpp:228] prelu2 does not need backward computation.
I1130 22:00:23.247987 11666 net.cpp:228] conv2 does not need backward computation.
I1130 22:00:23.247989 11666 net.cpp:228] pool1 does not need backward computation.
I1130 22:00:23.247993 11666 net.cpp:228] prelu1 does not need backward computation.
I1130 22:00:23.247997 11666 net.cpp:228] conv1 does not need backward computation.
I1130 22:00:23.248000 11666 net.cpp:228] data does not need backward computation.
I1130 22:00:23.248003 11666 net.cpp:270] This network produces output bbox_pred
I1130 22:00:23.248008 11666 net.cpp:270] This network produces output landmark_pred
I1130 22:00:23.248011 11666 net.cpp:270] This network produces output prob
I1130 22:00:23.248023 11666 net.cpp:283] Network initialization done.
I1130 22:00:23.248260 11666 net.cpp:761] Ignoring source layer loss
I1130 22:00:23.265812 11663 net.cpp:150] Setting up conv1
I1130 22:00:23.265861 11663 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:00:23.265866 11663 net.cpp:165] Memory required for data: 5728
I1130 22:00:23.265902 11663 layer_factory.hpp:77] Creating layer prelu1
I1130 22:00:23.265941 11663 net.cpp:100] Creating Layer prelu1
I1130 22:00:23.265949 11663 net.cpp:434] prelu1 <- conv1
I1130 22:00:23.265955 11663 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:00:23.266078 11663 net.cpp:150] Setting up prelu1
I1130 22:00:23.266090 11663 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:00:23.266094 11663 net.cpp:165] Memory required for data: 9728
I1130 22:00:23.266103 11663 layer_factory.hpp:77] Creating layer pool1
I1130 22:00:23.266115 11663 net.cpp:100] Creating Layer pool1
I1130 22:00:23.266120 11663 net.cpp:434] pool1 <- conv1
I1130 22:00:23.266127 11663 net.cpp:408] pool1 -> pool1
I1130 22:00:23.266170 11663 net.cpp:150] Setting up pool1
I1130 22:00:23.266177 11663 net.cpp:157] Top shape: 1 10 5 5 (250)
I1130 22:00:23.266180 11663 net.cpp:165] Memory required for data: 10728
I1130 22:00:23.266183 11663 layer_factory.hpp:77] Creating layer conv2
I1130 22:00:23.266196 11663 net.cpp:100] Creating Layer conv2
I1130 22:00:23.266199 11663 net.cpp:434] conv2 <- pool1
I1130 22:00:23.266206 11663 net.cpp:408] conv2 -> conv2
I1130 22:00:23.268440 11663 net.cpp:150] Setting up conv2
I1130 22:00:23.268457 11663 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:00:23.268462 11663 net.cpp:165] Memory required for data: 11304
I1130 22:00:23.268473 11663 layer_factory.hpp:77] Creating layer prelu2
I1130 22:00:23.268481 11663 net.cpp:100] Creating Layer prelu2
I1130 22:00:23.268484 11663 net.cpp:434] prelu2 <- conv2
I1130 22:00:23.268492 11663 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:00:23.268589 11663 net.cpp:150] Setting up prelu2
I1130 22:00:23.268596 11663 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:00:23.268600 11663 net.cpp:165] Memory required for data: 11880
I1130 22:00:23.268604 11663 layer_factory.hpp:77] Creating layer conv3
I1130 22:00:23.268615 11663 net.cpp:100] Creating Layer conv3
I1130 22:00:23.268617 11663 net.cpp:434] conv3 <- conv2
I1130 22:00:23.268623 11663 net.cpp:408] conv3 -> conv3
I1130 22:00:23.270757 11663 net.cpp:150] Setting up conv3
I1130 22:00:23.270776 11663 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.270781 11663 net.cpp:165] Memory required for data: 12008
I1130 22:00:23.270789 11663 layer_factory.hpp:77] Creating layer prelu3
I1130 22:00:23.270798 11663 net.cpp:100] Creating Layer prelu3
I1130 22:00:23.270802 11663 net.cpp:434] prelu3 <- conv3
I1130 22:00:23.270810 11663 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:00:23.270900 11663 net.cpp:150] Setting up prelu3
I1130 22:00:23.270908 11663 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.270911 11663 net.cpp:165] Memory required for data: 12136
I1130 22:00:23.270922 11663 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 22:00:23.270933 11663 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 22:00:23.270937 11663 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 22:00:23.270944 11663 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 22:00:23.270951 11663 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 22:00:23.270957 11663 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 22:00:23.271010 11663 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 22:00:23.271016 11663 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.271021 11663 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.271025 11663 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:00:23.271028 11663 net.cpp:165] Memory required for data: 12520
I1130 22:00:23.271033 11663 layer_factory.hpp:77] Creating layer score
I1130 22:00:23.271042 11663 net.cpp:100] Creating Layer score
I1130 22:00:23.271046 11663 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 22:00:23.271052 11663 net.cpp:408] score -> score
I1130 22:00:23.272094 11663 net.cpp:150] Setting up score
I1130 22:00:23.272112 11663 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:00:23.272117 11663 net.cpp:165] Memory required for data: 12528
I1130 22:00:23.272126 11663 layer_factory.hpp:77] Creating layer prob
I1130 22:00:23.272140 11663 net.cpp:100] Creating Layer prob
I1130 22:00:23.272145 11663 net.cpp:434] prob <- score
I1130 22:00:23.272155 11663 net.cpp:408] prob -> prob
I1130 22:00:23.272388 11663 net.cpp:150] Setting up prob
I1130 22:00:23.272398 11663 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:00:23.272403 11663 net.cpp:165] Memory required for data: 12536
I1130 22:00:23.272406 11663 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:00:23.272418 11663 net.cpp:100] Creating Layer bbox_pred
I1130 22:00:23.272423 11663 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 22:00:23.272428 11663 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:00:23.273473 11663 net.cpp:150] Setting up bbox_pred
I1130 22:00:23.273490 11663 net.cpp:157] Top shape: 1 4 1 1 (4)
I1130 22:00:23.273494 11663 net.cpp:165] Memory required for data: 12552
I1130 22:00:23.273502 11663 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:00:23.273512 11663 net.cpp:100] Creating Layer landmark_pred
I1130 22:00:23.273517 11663 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 22:00:23.273524 11663 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:00:23.274678 11663 net.cpp:150] Setting up landmark_pred
I1130 22:00:23.274698 11663 net.cpp:157] Top shape: 1 10 1 1 (10)
I1130 22:00:23.274703 11663 net.cpp:165] Memory required for data: 12592
I1130 22:00:23.274709 11663 net.cpp:228] landmark_pred does not need backward computation.
I1130 22:00:23.274714 11663 net.cpp:228] bbox_pred does not need backward computation.
I1130 22:00:23.274718 11663 net.cpp:228] prob does not need backward computation.
I1130 22:00:23.274721 11663 net.cpp:228] score does not need backward computation.
I1130 22:00:23.274725 11663 net.cpp:228] conv3_prelu3_0_split does not need backward computation.
I1130 22:00:23.274729 11663 net.cpp:228] prelu3 does not need backward computation.
I1130 22:00:23.274732 11663 net.cpp:228] conv3 does not need backward computation.
I1130 22:00:23.274735 11663 net.cpp:228] prelu2 does not need backward computation.
I1130 22:00:23.274739 11663 net.cpp:228] conv2 does not need backward computation.
I1130 22:00:23.274742 11663 net.cpp:228] pool1 does not need backward computation.
I1130 22:00:23.274745 11663 net.cpp:228] prelu1 does not need backward computation.
I1130 22:00:23.274749 11663 net.cpp:228] conv1 does not need backward computation.
I1130 22:00:23.274752 11663 net.cpp:228] data does not need backward computation.
I1130 22:00:23.274755 11663 net.cpp:270] This network produces output bbox_pred
I1130 22:00:23.274760 11663 net.cpp:270] This network produces output landmark_pred
I1130 22:00:23.274763 11663 net.cpp:270] This network produces output prob
I1130 22:00:23.274775 11663 net.cpp:283] Network initialization done.
I1130 22:00:23.275014 11663 net.cpp:761] Ignoring source layer loss
[2016-11-30 22:00:25,336][INFO] writes 615 positives, 7136 negatives, 2248 part
[2016-11-30 22:00:26,805][INFO] writes 1373 positives, 14075 negatives, 4551 part
[2016-11-30 22:00:28,613][INFO] writes 2038 positives, 21604 negatives, 6357 part
[2016-11-30 22:00:30,367][INFO] writes 2779 positives, 28595 negatives, 8625 part
[2016-11-30 22:00:32,081][INFO] writes 3408 positives, 36072 negatives, 10519 part
[2016-11-30 22:00:33,873][INFO] writes 4047 positives, 43461 negatives, 12491 part
[2016-11-30 22:00:35,706][INFO] writes 4892 positives, 49672 negatives, 15435 part
[2016-11-30 22:00:37,290][INFO] writes 5770 positives, 56253 negatives, 17976 part
[2016-11-30 22:00:38,992][INFO] writes 6108 positives, 64589 negatives, 19302 part
[2016-11-30 22:00:41,066][INFO] writes 6607 positives, 72404 negatives, 20988 part
[2016-11-30 22:00:42,901][INFO] writes 7096 positives, 80248 negatives, 22655 part
[2016-11-30 22:00:44,446][INFO] writes 7838 positives, 87227 negatives, 24934 part
[2016-11-30 22:00:45,940][INFO] writes 8807 positives, 93575 negatives, 27617 part
[2016-11-30 22:00:47,620][INFO] writes 9448 positives, 100586 negatives, 29965 part
[2016-11-30 22:00:49,168][INFO] writes 10191 positives, 107559 negatives, 32249 part
[2016-11-30 22:00:50,627][INFO] writes 10766 positives, 115186 negatives, 34047 part
[2016-11-30 22:00:52,037][INFO] writes 11728 positives, 121650 negatives, 36621 part
[2016-11-30 22:00:53,669][INFO] writes 12857 positives, 128072 negatives, 39070 part
[2016-11-30 22:00:55,341][INFO] writes 13700 positives, 134732 negatives, 41567 part
[2016-11-30 22:00:57,003][INFO] writes 14828 positives, 141152 negatives, 44019 part
[2016-11-30 22:00:58,401][INFO] writes 15856 positives, 147652 negatives, 46491 part
[2016-11-30 22:00:59,928][INFO] writes 16938 positives, 154004 negatives, 49057 part
[2016-11-30 22:01:01,358][INFO] writes 18018 positives, 160105 negatives, 51876 part
[2016-11-30 22:01:02,687][INFO] writes 18872 positives, 167265 negatives, 53862 part
[2016-11-30 22:01:04,039][INFO] writes 19941 positives, 173661 negatives, 56397 part
[2016-11-30 22:01:05,864][INFO] writes 20763 positives, 180693 negatives, 58543 part
[2016-11-30 22:01:07,794][INFO] writes 21917 positives, 186942 negatives, 61140 part
[2016-11-30 22:01:09,659][INFO] writes 22528 positives, 194706 negatives, 62765 part
[2016-11-30 22:01:11,713][INFO] writes 22811 positives, 203507 negatives, 63681 part
[2016-11-30 22:01:13,902][INFO] writes 23086 positives, 212363 negatives, 64550 part
[2016-11-30 22:01:16,023][INFO] writes 23284 positives, 221445 negatives, 65270 part
[2016-11-30 22:01:18,304][INFO] writes 23492 positives, 230484 negatives, 66023 part
[2016-11-30 22:01:20,192][INFO] writes 23716 positives, 239582 negatives, 66701 part
[2016-11-30 22:01:22,260][INFO] writes 23994 positives, 248414 negatives, 67591 part
[2016-11-30 22:01:24,536][INFO] writes 24227 positives, 257369 negatives, 68403 part
[2016-11-30 22:01:26,469][INFO] writes 24585 positives, 265908 negatives, 69506 part
[2016-11-30 22:01:28,578][INFO] writes 24903 positives, 274734 negatives, 70362 part
[2016-11-30 22:01:30,715][INFO] writes 25392 positives, 283119 negatives, 71488 part
[2016-11-30 22:01:33,660][INFO] writes 25651 positives, 292020 negatives, 72328 part
[2016-11-30 22:01:35,945][INFO] writes 26047 positives, 300512 negatives, 73440 part
[2016-11-30 22:01:37,898][INFO] writes 26499 positives, 308419 negatives, 75081 part
[2016-11-30 22:01:40,009][INFO] writes 27018 positives, 316318 negatives, 76663 part
[2016-11-30 22:01:42,323][INFO] writes 27505 positives, 324455 negatives, 78039 part
[2016-11-30 22:01:45,186][INFO] writes 27916 positives, 332512 negatives, 79571 part
[2016-11-30 22:01:47,127][INFO] writes 28238 positives, 341120 negatives, 80641 part
[2016-11-30 22:01:49,359][INFO] writes 28580 positives, 349557 negatives, 81862 part
[2016-11-30 22:01:51,626][INFO] writes 28967 positives, 357938 negatives, 83094 part
[2016-11-30 22:01:53,719][INFO] writes 29505 positives, 365403 negatives, 85091 part
[2016-11-30 22:01:55,573][INFO] writes 30371 positives, 371624 negatives, 88004 part
[2016-11-30 22:01:57,473][INFO] writes 30838 positives, 379378 negatives, 89783 part
[2016-11-30 22:01:59,293][INFO] writes 31436 positives, 386696 negatives, 91867 part
[2016-11-30 22:02:01,148][INFO] writes 32269 positives, 392712 negatives, 95018 part
[2016-11-30 22:02:03,232][INFO] writes 32870 positives, 399858 negatives, 97271 part
[2016-11-30 22:02:05,341][INFO] writes 33540 positives, 406596 negatives, 99863 part
[2016-11-30 22:02:07,019][INFO] writes 34461 positives, 412623 negatives, 102915 part
[2016-11-30 22:02:09,026][INFO] writes 35209 positives, 418809 negatives, 105981 part
[2016-11-30 22:02:10,990][INFO] writes 35970 positives, 425096 negatives, 108933 part
[2016-11-30 22:02:12,842][INFO] writes 36653 positives, 431624 negatives, 111722 part
[2016-11-30 22:02:14,740][INFO] writes 37359 positives, 437932 negatives, 114708 part
[2016-11-30 22:02:16,317][INFO] writes 38087 positives, 444846 negatives, 117066 part
[2016-11-30 22:02:18,145][INFO] writes 38710 positives, 451845 negatives, 119444 part
[2016-11-30 22:02:19,911][INFO] writes 39297 positives, 459016 negatives, 121686 part
[2016-11-30 22:02:21,848][INFO] writes 39933 positives, 466006 negatives, 124060 part
[2016-11-30 22:02:23,710][INFO] writes 40526 positives, 473261 negatives, 126212 part
[2016-11-30 22:02:25,434][INFO] writes 41209 positives, 479967 negatives, 128823 part
[2016-11-30 22:02:27,150][INFO] writes 42143 positives, 485899 negatives, 131957 part
[2016-11-30 22:02:28,928][INFO] writes 43001 positives, 492801 negatives, 134197 part
[2016-11-30 22:02:30,267][INFO] Process-1 reads 1000
[2016-11-30 22:02:30,605][INFO] writes 43777 positives, 499634 negatives, 136588 part
[2016-11-30 22:02:30,886][INFO] Process-2 reads 1000
[2016-11-30 22:02:32,281][INFO] writes 44799 positives, 506301 negatives, 138899 part
[2016-11-30 22:02:32,401][INFO] Process-4 reads 1000
[2016-11-30 22:02:34,123][INFO] writes 45876 positives, 512788 negatives, 141335 part
[2016-11-30 22:02:36,046][INFO] writes 46713 positives, 519842 negatives, 143444 part
[2016-11-30 22:02:36,148][INFO] Process-3 reads 1000
[2016-11-30 22:02:38,125][INFO] writes 47369 positives, 527162 negatives, 145468 part
[2016-11-30 22:02:40,016][INFO] writes 48023 positives, 534718 negatives, 147258 part
[2016-11-30 22:02:41,728][INFO] writes 48590 positives, 542100 negatives, 149309 part
[2016-11-30 22:02:44,060][INFO] writes 48948 positives, 550545 negatives, 150506 part
[2016-11-30 22:02:46,081][INFO] writes 49295 positives, 558910 negatives, 151794 part
[2016-11-30 22:02:48,640][INFO] writes 49545 positives, 567774 negatives, 152680 part
[2016-11-30 22:02:50,691][INFO] writes 49864 positives, 576382 negatives, 153753 part
[2016-11-30 22:02:52,840][INFO] writes 50153 positives, 585171 negatives, 154675 part
[2016-11-30 22:02:55,260][INFO] writes 50445 positives, 593967 negatives, 155587 part
[2016-11-30 22:02:57,759][INFO] writes 50635 positives, 603072 negatives, 156292 part
[2016-11-30 22:03:00,327][INFO] writes 51018 positives, 611496 negatives, 157485 part
[2016-11-30 22:03:02,731][INFO] writes 51226 positives, 620408 negatives, 158365 part
[2016-11-30 22:03:04,579][INFO] writes 51549 positives, 629265 negatives, 159185 part
[2016-11-30 22:03:06,885][INFO] writes 51821 positives, 637811 negatives, 160367 part
[2016-11-30 22:03:09,371][INFO] writes 52197 positives, 646156 negatives, 161646 part
[2016-11-30 22:03:12,051][INFO] writes 52650 positives, 654162 negatives, 163187 part
[2016-11-30 22:03:14,461][INFO] writes 52965 positives, 662772 negatives, 164262 part
[2016-11-30 22:03:17,348][INFO] writes 53354 positives, 671155 negatives, 165490 part
[2016-11-30 22:03:20,088][INFO] writes 53693 positives, 679603 negatives, 166703 part
[2016-11-30 22:03:22,434][INFO] writes 54126 positives, 687809 negatives, 168064 part
[2016-11-30 22:03:24,651][INFO] writes 54516 positives, 696072 negatives, 169411 part
[2016-11-30 22:03:26,757][INFO] writes 54991 positives, 704144 negatives, 170864 part
[2016-11-30 22:03:28,691][INFO] writes 55225 positives, 713055 negatives, 171719 part
[2016-11-30 22:03:30,629][INFO] writes 55461 positives, 721992 negatives, 172546 part
[2016-11-30 22:03:33,014][INFO] writes 55675 positives, 731012 negatives, 173312 part
[2016-11-30 22:03:34,887][INFO] writes 55983 positives, 739751 negatives, 174265 part
[2016-11-30 22:03:36,880][INFO] writes 56304 positives, 748246 negatives, 175449 part
[2016-11-30 22:03:39,028][INFO] writes 56663 positives, 756698 negatives, 176638 part
[2016-11-30 22:03:40,917][INFO] writes 57191 positives, 764758 negatives, 178050 part
[2016-11-30 22:03:42,860][INFO] writes 57594 positives, 773192 negatives, 179213 part
[2016-11-30 22:03:44,928][INFO] writes 58010 positives, 781423 negatives, 180566 part
[2016-11-30 22:03:46,864][INFO] writes 58435 positives, 789460 negatives, 182104 part
[2016-11-30 22:03:49,104][INFO] writes 58892 positives, 797631 negatives, 183476 part
[2016-11-30 22:03:50,739][INFO] writes 59454 positives, 805578 negatives, 184967 part
[2016-11-30 22:03:52,691][INFO] writes 60238 positives, 812615 negatives, 187146 part
[2016-11-30 22:03:55,423][INFO] writes 60726 positives, 820424 negatives, 188849 part
[2016-11-30 22:03:57,662][INFO] writes 61203 positives, 828352 negatives, 190444 part
[2016-11-30 22:03:59,830][INFO] writes 61542 positives, 836573 negatives, 191884 part
[2016-11-30 22:04:02,118][INFO] writes 61830 positives, 845302 negatives, 192867 part
[2016-11-30 22:04:04,014][INFO] writes 62189 positives, 853854 negatives, 193956 part
[2016-11-30 22:04:05,659][INFO] writes 62838 positives, 861473 negatives, 195688 part
[2016-11-30 22:04:07,585][INFO] writes 63339 positives, 869491 negatives, 197169 part
[2016-11-30 22:04:09,048][INFO] writes 64039 positives, 877185 negatives, 198775 part
[2016-11-30 22:04:10,677][INFO] writes 64413 positives, 885497 negatives, 200089 part
[2016-11-30 22:04:12,471][INFO] writes 64715 positives, 894077 negatives, 201207 part
[2016-11-30 22:04:14,333][INFO] writes 64974 positives, 902914 negatives, 202111 part
[2016-11-30 22:04:16,163][INFO] writes 65345 positives, 911549 negatives, 203105 part
[2016-11-30 22:04:17,974][INFO] writes 65962 positives, 918977 negatives, 205060 part
[2016-11-30 22:04:19,883][INFO] writes 66292 positives, 927466 negatives, 206241 part
[2016-11-30 22:04:21,868][INFO] writes 66685 positives, 935792 negatives, 207522 part
[2016-11-30 22:04:23,695][INFO] writes 66998 positives, 944294 negatives, 208707 part
[2016-11-30 22:04:25,516][INFO] writes 67442 positives, 952532 negatives, 210025 part
[2016-11-30 22:04:25,652][INFO] Process-1 reads 2000
[2016-11-30 22:04:26,570][INFO] Process-2 reads 2000
[2016-11-30 22:04:27,511][INFO] writes 68080 positives, 960414 negatives, 211505 part
[2016-11-30 22:04:29,190][INFO] writes 68689 positives, 968118 negatives, 213192 part
[2016-11-30 22:04:30,996][INFO] writes 69112 positives, 976616 negatives, 214271 part
[2016-11-30 22:04:32,716][INFO] writes 69478 positives, 985126 negatives, 215395 part
[2016-11-30 22:04:34,566][INFO] writes 69751 positives, 993959 negatives, 216289 part
[2016-11-30 22:04:36,147][INFO] writes 70319 positives, 1002110 negatives, 217570 part
[2016-11-30 22:04:37,874][INFO] writes 70707 positives, 1010736 negatives, 218556 part
[2016-11-30 22:04:38,210][INFO] Process-3 reads 2000
[2016-11-30 22:04:39,344][INFO] writes 71147 positives, 1019023 negatives, 219829 part
[2016-11-30 22:04:41,319][INFO] writes 71400 positives, 1027856 negatives, 220743 part
[2016-11-30 22:04:43,000][INFO] writes 71650 positives, 1036808 negatives, 221541 part
[2016-11-30 22:04:44,710][INFO] writes 71955 positives, 1045570 negatives, 222474 part
[2016-11-30 22:04:46,438][INFO] writes 72333 positives, 1054225 negatives, 223441 part
[2016-11-30 22:04:48,256][INFO] writes 72614 positives, 1063172 negatives, 224213 part
[2016-11-30 22:04:50,205][INFO] writes 72888 positives, 1072086 negatives, 225025 part
[2016-11-30 22:04:52,481][INFO] writes 73145 positives, 1081086 negatives, 225768 part
[2016-11-30 22:04:54,538][INFO] writes 73384 positives, 1089991 negatives, 226624 part
[2016-11-30 22:04:56,440][INFO] writes 73738 positives, 1098695 negatives, 227566 part
[2016-11-30 22:04:58,171][INFO] writes 74008 positives, 1107530 negatives, 228461 part
[2016-11-30 22:04:59,042][INFO] Process-4 reads 2000
[2016-11-30 22:04:59,906][INFO] writes 74370 positives, 1116095 negatives, 229534 part
[2016-11-30 22:05:01,643][INFO] writes 74846 positives, 1123979 negatives, 231174 part
[2016-11-30 22:05:03,677][INFO] writes 75239 positives, 1132333 negatives, 232427 part
[2016-11-30 22:05:05,790][INFO] writes 75489 positives, 1141186 negatives, 233324 part
[2016-11-30 22:05:07,736][INFO] writes 75722 positives, 1150186 negatives, 234091 part
[2016-11-30 22:05:09,480][INFO] writes 75932 positives, 1159214 negatives, 234853 part
[2016-11-30 22:05:11,605][INFO] writes 76210 positives, 1167750 negatives, 236039 part
[2016-11-30 22:05:13,410][INFO] writes 76606 positives, 1176220 negatives, 237173 part
[2016-11-30 22:05:15,208][INFO] writes 76800 positives, 1185363 negatives, 237836 part
[2016-11-30 22:05:17,164][INFO] writes 77076 positives, 1194002 negatives, 238921 part
[2016-11-30 22:05:19,050][INFO] writes 77539 positives, 1201963 negatives, 240497 part
[2016-11-30 22:05:21,111][INFO] writes 77927 positives, 1210241 negatives, 241831 part
[2016-11-30 22:05:23,376][INFO] writes 78311 positives, 1218636 negatives, 243052 part
[2016-11-30 22:05:25,702][INFO] writes 78570 positives, 1227648 negatives, 243781 part
[2016-11-30 22:05:28,244][INFO] writes 78814 positives, 1236673 negatives, 244512 part
[2016-11-30 22:05:30,635][INFO] writes 79162 positives, 1245252 negatives, 245585 part
[2016-11-30 22:05:33,353][INFO] writes 79540 positives, 1253651 negatives, 246808 part
[2016-11-30 22:05:35,719][INFO] writes 79784 positives, 1262476 negatives, 247739 part
[2016-11-30 22:05:37,816][INFO] writes 80104 positives, 1271189 negatives, 248706 part
[2016-11-30 22:05:40,153][INFO] writes 80372 positives, 1280140 negatives, 249487 part
[2016-11-30 22:05:42,144][INFO] writes 80654 positives, 1288899 negatives, 250446 part
[2016-11-30 22:05:44,500][INFO] writes 81000 positives, 1297332 negatives, 251667 part
[2016-11-30 22:05:46,765][INFO] writes 81284 positives, 1306018 negatives, 252697 part
[2016-11-30 22:05:49,112][INFO] writes 81618 positives, 1314662 negatives, 253719 part
[2016-11-30 22:05:51,797][INFO] writes 81901 positives, 1323510 negatives, 254588 part
[2016-11-30 22:05:54,653][INFO] writes 82222 positives, 1332246 negatives, 255531 part
[2016-11-30 22:05:57,009][INFO] writes 82525 positives, 1340874 negatives, 256600 part
[2016-11-30 22:05:58,880][INFO] writes 82884 positives, 1349341 negatives, 257774 part
[2016-11-30 22:06:00,795][INFO] writes 83285 positives, 1357249 negatives, 259465 part
[2016-11-30 22:06:02,904][INFO] writes 83623 positives, 1365861 negatives, 260515 part
[2016-11-30 22:06:04,886][INFO] writes 83906 positives, 1374558 negatives, 261535 part
[2016-11-30 22:06:07,271][INFO] writes 84194 positives, 1383181 negatives, 262624 part
[2016-11-30 22:06:09,593][INFO] writes 84664 positives, 1391468 negatives, 263867 part
[2016-11-30 22:06:11,702][INFO] writes 85004 positives, 1400142 negatives, 264853 part
[2016-11-30 22:06:13,519][INFO] writes 85344 positives, 1408882 negatives, 265773 part
[2016-11-30 22:06:15,452][INFO] writes 85749 positives, 1417324 negatives, 266926 part
[2016-11-30 22:06:16,495][INFO] Process-2 reads 3000
[2016-11-30 22:06:16,984][INFO] writes 86416 positives, 1424923 negatives, 268660 part
[2016-11-30 22:06:19,069][INFO] writes 86853 positives, 1432950 negatives, 270196 part
[2016-11-30 22:06:21,112][INFO] writes 87175 positives, 1441486 negatives, 271338 part
[2016-11-30 22:06:23,121][INFO] writes 87431 positives, 1450228 negatives, 272340 part
[2016-11-30 22:06:24,889][INFO] writes 87995 positives, 1457607 negatives, 274397 part
[2016-11-30 22:06:25,211][INFO] Process-1 reads 3000
[2016-11-30 22:06:26,905][INFO] writes 88782 positives, 1464538 negatives, 276679 part
[2016-11-30 22:06:29,036][INFO] writes 89500 positives, 1471737 negatives, 278762 part
[2016-11-30 22:06:30,931][INFO] writes 90127 positives, 1479362 negatives, 280510 part
[2016-11-30 22:06:32,496][INFO] writes 90681 positives, 1486999 negatives, 282319 part
[2016-11-30 22:06:34,169][INFO] writes 91246 positives, 1494339 negatives, 284414 part
[2016-11-30 22:06:35,938][INFO] writes 91727 positives, 1502392 negatives, 285880 part
[2016-11-30 22:06:37,916][INFO] writes 92232 positives, 1510324 negatives, 287443 part
[2016-11-30 22:06:39,820][INFO] writes 92768 positives, 1518045 negatives, 289186 part
[2016-11-30 22:06:40,100][INFO] Process-3 reads 3000
[2016-11-30 22:06:41,852][INFO] writes 93132 positives, 1526520 negatives, 290347 part
[2016-11-30 22:06:43,893][INFO] writes 93467 positives, 1535137 negatives, 291395 part
[2016-11-30 22:06:47,269][INFO] writes 93775 positives, 1543980 negatives, 292244 part
[2016-11-30 22:06:49,760][INFO] writes 94439 positives, 1551153 negatives, 294407 part
[2016-11-30 22:06:52,549][INFO] writes 95279 positives, 1557728 negatives, 296992 part
[2016-11-30 22:06:55,287][INFO] writes 95731 positives, 1565585 negatives, 298683 part
[2016-11-30 22:06:57,399][INFO] Process-4 reads 3000
[2016-11-30 22:06:58,577][INFO] writes 96176 positives, 1573725 negatives, 300098 part
[2016-11-30 22:07:02,713][INFO] writes 96533 positives, 1582244 negatives, 301222 part
[2016-11-30 22:07:08,436][INFO] writes 97209 positives, 1589314 negatives, 303476 part
[2016-11-30 22:07:14,230][INFO] writes 98041 positives, 1595745 negatives, 306213 part
[2016-11-30 22:07:34,523][INFO] Finish
[2016-11-30 22:07:34,669][INFO] writing val data, 3196 images
[2016-11-30 22:07:34,686][INFO] remove data/rnet_positive_val
[2016-11-30 22:07:34,687][INFO] remove data/rnet_negative_val
[2016-11-30 22:07:34,687][INFO] remove data/rnet_part_val
[2016-11-30 22:07:34,687][INFO] fill queues
WARNING: Logging before InitGoogleLogging() is written to STDERR
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 22:07:37.737805 11792 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
  }
}
I1130 22:07:37.737805 11791 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
  }
}
I1130 22:07:37.737948 11792 layer_factory.hpp:77] Creating layer data
I1130 22:07:37.737949 11791 layer_factory.hpp:77] Creating layer data
I1130 22:07:37.737967 11792 net.cpp:100] Creating Layer data
I1130 22:07:37.737967 11791 net.cpp:100] Creating Layer data
I1130 22:07:37.737975 11791 net.cpp:408] data -> data
I1130 22:07:37.737975 11792 net.cpp:408] data -> data
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 22:07:37.747819 11794 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
  }
}
I1130 22:07:37.747941 11794 layer_factory.hpp:77] Creating layer data
I1130 22:07:37.747958 11794 net.cpp:100] Creating Layer data
I1130 22:07:37.747967 11794 net.cpp:408] data -> data
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 22:07:37.751555 11793 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
  }
}
I1130 22:07:37.751677 11793 layer_factory.hpp:77] Creating layer data
I1130 22:07:37.751693 11793 net.cpp:100] Creating Layer data
I1130 22:07:37.751700 11793 net.cpp:408] data -> data
I1130 22:07:37.756412 11792 net.cpp:150] Setting up data
I1130 22:07:37.756441 11792 net.cpp:157] Top shape: 1 3 12 12 (432)
I1130 22:07:37.756446 11792 net.cpp:165] Memory required for data: 1728
I1130 22:07:37.756453 11792 layer_factory.hpp:77] Creating layer conv1
I1130 22:07:37.756467 11792 net.cpp:100] Creating Layer conv1
I1130 22:07:37.756471 11792 net.cpp:434] conv1 <- data
I1130 22:07:37.756479 11792 net.cpp:408] conv1 -> conv1
I1130 22:07:37.796609 11794 net.cpp:150] Setting up data
I1130 22:07:37.796643 11794 net.cpp:157] Top shape: 1 3 12 12 (432)
I1130 22:07:37.796648 11794 net.cpp:165] Memory required for data: 1728
I1130 22:07:37.796656 11794 layer_factory.hpp:77] Creating layer conv1
I1130 22:07:37.796670 11794 net.cpp:100] Creating Layer conv1
I1130 22:07:37.796676 11794 net.cpp:434] conv1 <- data
I1130 22:07:37.796684 11794 net.cpp:408] conv1 -> conv1
I1130 22:07:37.807620 11791 net.cpp:150] Setting up data
I1130 22:07:37.807683 11791 net.cpp:157] Top shape: 1 3 12 12 (432)
I1130 22:07:37.807693 11791 net.cpp:165] Memory required for data: 1728
I1130 22:07:37.807703 11791 layer_factory.hpp:77] Creating layer conv1
I1130 22:07:37.807730 11791 net.cpp:100] Creating Layer conv1
I1130 22:07:37.807737 11791 net.cpp:434] conv1 <- data
I1130 22:07:37.807749 11791 net.cpp:408] conv1 -> conv1
I1130 22:07:37.821506 11793 net.cpp:150] Setting up data
I1130 22:07:37.821564 11793 net.cpp:157] Top shape: 1 3 12 12 (432)
I1130 22:07:37.821569 11793 net.cpp:165] Memory required for data: 1728
I1130 22:07:37.821578 11793 layer_factory.hpp:77] Creating layer conv1
I1130 22:07:37.821599 11793 net.cpp:100] Creating Layer conv1
I1130 22:07:37.821604 11793 net.cpp:434] conv1 <- data
I1130 22:07:37.821612 11793 net.cpp:408] conv1 -> conv1
I1130 22:07:38.027218 11792 net.cpp:150] Setting up conv1
I1130 22:07:38.027271 11792 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:07:38.027277 11792 net.cpp:165] Memory required for data: 5728
I1130 22:07:38.027307 11792 layer_factory.hpp:77] Creating layer prelu1
I1130 22:07:38.027329 11792 net.cpp:100] Creating Layer prelu1
I1130 22:07:38.027336 11792 net.cpp:434] prelu1 <- conv1
I1130 22:07:38.027343 11792 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:07:38.027463 11792 net.cpp:150] Setting up prelu1
I1130 22:07:38.027472 11792 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:07:38.027477 11792 net.cpp:165] Memory required for data: 9728
I1130 22:07:38.027484 11792 layer_factory.hpp:77] Creating layer pool1
I1130 22:07:38.027498 11792 net.cpp:100] Creating Layer pool1
I1130 22:07:38.027503 11792 net.cpp:434] pool1 <- conv1
I1130 22:07:38.027508 11792 net.cpp:408] pool1 -> pool1
I1130 22:07:38.027554 11792 net.cpp:150] Setting up pool1
I1130 22:07:38.027560 11792 net.cpp:157] Top shape: 1 10 5 5 (250)
I1130 22:07:38.027565 11792 net.cpp:165] Memory required for data: 10728
I1130 22:07:38.027568 11792 layer_factory.hpp:77] Creating layer conv2
I1130 22:07:38.027582 11792 net.cpp:100] Creating Layer conv2
I1130 22:07:38.027586 11792 net.cpp:434] conv2 <- pool1
I1130 22:07:38.027591 11792 net.cpp:408] conv2 -> conv2
I1130 22:07:38.029909 11792 net.cpp:150] Setting up conv2
I1130 22:07:38.029940 11792 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:07:38.029945 11792 net.cpp:165] Memory required for data: 11304
I1130 22:07:38.029958 11792 layer_factory.hpp:77] Creating layer prelu2
I1130 22:07:38.029968 11792 net.cpp:100] Creating Layer prelu2
I1130 22:07:38.029973 11792 net.cpp:434] prelu2 <- conv2
I1130 22:07:38.029978 11792 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:07:38.030083 11792 net.cpp:150] Setting up prelu2
I1130 22:07:38.030095 11792 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:07:38.030098 11792 net.cpp:165] Memory required for data: 11880
I1130 22:07:38.030104 11792 layer_factory.hpp:77] Creating layer conv3
I1130 22:07:38.030117 11792 net.cpp:100] Creating Layer conv3
I1130 22:07:38.030130 11792 net.cpp:434] conv3 <- conv2
I1130 22:07:38.030138 11792 net.cpp:408] conv3 -> conv3
I1130 22:07:38.032413 11792 net.cpp:150] Setting up conv3
I1130 22:07:38.032436 11792 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.032441 11792 net.cpp:165] Memory required for data: 12008
I1130 22:07:38.032449 11792 layer_factory.hpp:77] Creating layer prelu3
I1130 22:07:38.032460 11792 net.cpp:100] Creating Layer prelu3
I1130 22:07:38.032464 11792 net.cpp:434] prelu3 <- conv3
I1130 22:07:38.032470 11792 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:07:38.032564 11792 net.cpp:150] Setting up prelu3
I1130 22:07:38.032572 11792 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.032575 11792 net.cpp:165] Memory required for data: 12136
I1130 22:07:38.032584 11792 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 22:07:38.032598 11792 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 22:07:38.032601 11792 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 22:07:38.032608 11792 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 22:07:38.032614 11792 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 22:07:38.032620 11792 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 22:07:38.032671 11792 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 22:07:38.032678 11792 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.032683 11792 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.032687 11792 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.032691 11792 net.cpp:165] Memory required for data: 12520
I1130 22:07:38.032694 11792 layer_factory.hpp:77] Creating layer score
I1130 22:07:38.032704 11792 net.cpp:100] Creating Layer score
I1130 22:07:38.032708 11792 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 22:07:38.032714 11792 net.cpp:408] score -> score
I1130 22:07:38.033776 11792 net.cpp:150] Setting up score
I1130 22:07:38.033799 11792 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:07:38.033804 11792 net.cpp:165] Memory required for data: 12528
I1130 22:07:38.033812 11792 layer_factory.hpp:77] Creating layer prob
I1130 22:07:38.033823 11792 net.cpp:100] Creating Layer prob
I1130 22:07:38.033828 11792 net.cpp:434] prob <- score
I1130 22:07:38.033833 11792 net.cpp:408] prob -> prob
I1130 22:07:38.034087 11792 net.cpp:150] Setting up prob
I1130 22:07:38.034102 11792 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:07:38.034106 11792 net.cpp:165] Memory required for data: 12536
I1130 22:07:38.034111 11792 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:07:38.034122 11792 net.cpp:100] Creating Layer bbox_pred
I1130 22:07:38.034127 11792 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 22:07:38.034135 11792 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:07:38.035200 11792 net.cpp:150] Setting up bbox_pred
I1130 22:07:38.035220 11792 net.cpp:157] Top shape: 1 4 1 1 (4)
I1130 22:07:38.035225 11792 net.cpp:165] Memory required for data: 12552
I1130 22:07:38.035233 11792 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:07:38.035243 11792 net.cpp:100] Creating Layer landmark_pred
I1130 22:07:38.035248 11792 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 22:07:38.035255 11792 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:07:38.036345 11792 net.cpp:150] Setting up landmark_pred
I1130 22:07:38.036363 11792 net.cpp:157] Top shape: 1 10 1 1 (10)
I1130 22:07:38.036367 11792 net.cpp:165] Memory required for data: 12592
I1130 22:07:38.036375 11792 net.cpp:228] landmark_pred does not need backward computation.
I1130 22:07:38.036381 11792 net.cpp:228] bbox_pred does not need backward computation.
I1130 22:07:38.036384 11792 net.cpp:228] prob does not need backward computation.
I1130 22:07:38.036388 11792 net.cpp:228] score does not need backward computation.
I1130 22:07:38.036392 11792 net.cpp:228] conv3_prelu3_0_split does not need backward computation.
I1130 22:07:38.036396 11792 net.cpp:228] prelu3 does not need backward computation.
I1130 22:07:38.036399 11792 net.cpp:228] conv3 does not need backward computation.
I1130 22:07:38.036412 11792 net.cpp:228] prelu2 does not need backward computation.
I1130 22:07:38.036417 11792 net.cpp:228] conv2 does not need backward computation.
I1130 22:07:38.036420 11792 net.cpp:228] pool1 does not need backward computation.
I1130 22:07:38.036424 11792 net.cpp:228] prelu1 does not need backward computation.
I1130 22:07:38.036428 11792 net.cpp:228] conv1 does not need backward computation.
I1130 22:07:38.036432 11792 net.cpp:228] data does not need backward computation.
I1130 22:07:38.036435 11792 net.cpp:270] This network produces output bbox_pred
I1130 22:07:38.036439 11792 net.cpp:270] This network produces output landmark_pred
I1130 22:07:38.036443 11792 net.cpp:270] This network produces output prob
I1130 22:07:38.036458 11792 net.cpp:283] Network initialization done.
I1130 22:07:38.036705 11792 net.cpp:761] Ignoring source layer loss
I1130 22:07:38.070610 11794 net.cpp:150] Setting up conv1
I1130 22:07:38.070659 11794 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:07:38.070665 11794 net.cpp:165] Memory required for data: 5728
I1130 22:07:38.070694 11794 layer_factory.hpp:77] Creating layer prelu1
I1130 22:07:38.070716 11794 net.cpp:100] Creating Layer prelu1
I1130 22:07:38.070724 11794 net.cpp:434] prelu1 <- conv1
I1130 22:07:38.070730 11794 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:07:38.070847 11794 net.cpp:150] Setting up prelu1
I1130 22:07:38.070857 11794 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:07:38.070859 11794 net.cpp:165] Memory required for data: 9728
I1130 22:07:38.070868 11794 layer_factory.hpp:77] Creating layer pool1
I1130 22:07:38.070880 11794 net.cpp:100] Creating Layer pool1
I1130 22:07:38.070884 11794 net.cpp:434] pool1 <- conv1
I1130 22:07:38.070890 11794 net.cpp:408] pool1 -> pool1
I1130 22:07:38.070935 11794 net.cpp:150] Setting up pool1
I1130 22:07:38.070942 11794 net.cpp:157] Top shape: 1 10 5 5 (250)
I1130 22:07:38.070946 11794 net.cpp:165] Memory required for data: 10728
I1130 22:07:38.070950 11794 layer_factory.hpp:77] Creating layer conv2
I1130 22:07:38.070962 11794 net.cpp:100] Creating Layer conv2
I1130 22:07:38.070966 11794 net.cpp:434] conv2 <- pool1
I1130 22:07:38.070971 11794 net.cpp:408] conv2 -> conv2
I1130 22:07:38.073313 11794 net.cpp:150] Setting up conv2
I1130 22:07:38.073333 11794 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:07:38.073338 11794 net.cpp:165] Memory required for data: 11304
I1130 22:07:38.073348 11794 layer_factory.hpp:77] Creating layer prelu2
I1130 22:07:38.073359 11794 net.cpp:100] Creating Layer prelu2
I1130 22:07:38.073362 11794 net.cpp:434] prelu2 <- conv2
I1130 22:07:38.073369 11794 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:07:38.073463 11794 net.cpp:150] Setting up prelu2
I1130 22:07:38.073472 11794 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:07:38.073475 11794 net.cpp:165] Memory required for data: 11880
I1130 22:07:38.073482 11794 layer_factory.hpp:77] Creating layer conv3
I1130 22:07:38.073490 11794 net.cpp:100] Creating Layer conv3
I1130 22:07:38.073495 11794 net.cpp:434] conv3 <- conv2
I1130 22:07:38.073503 11794 net.cpp:408] conv3 -> conv3
I1130 22:07:38.075763 11794 net.cpp:150] Setting up conv3
I1130 22:07:38.075783 11794 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.075788 11794 net.cpp:165] Memory required for data: 12008
I1130 22:07:38.075796 11794 layer_factory.hpp:77] Creating layer prelu3
I1130 22:07:38.075806 11794 net.cpp:100] Creating Layer prelu3
I1130 22:07:38.075811 11794 net.cpp:434] prelu3 <- conv3
I1130 22:07:38.075817 11794 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:07:38.075916 11794 net.cpp:150] Setting up prelu3
I1130 22:07:38.075923 11794 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.075927 11794 net.cpp:165] Memory required for data: 12136
I1130 22:07:38.075935 11794 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 22:07:38.075948 11794 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 22:07:38.075953 11794 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 22:07:38.075958 11794 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 22:07:38.075974 11794 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 22:07:38.075980 11794 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 22:07:38.076031 11794 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 22:07:38.076038 11794 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.076043 11794 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.076047 11794 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.076050 11794 net.cpp:165] Memory required for data: 12520
I1130 22:07:38.076055 11794 layer_factory.hpp:77] Creating layer score
I1130 22:07:38.076063 11794 net.cpp:100] Creating Layer score
I1130 22:07:38.076073 11794 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 22:07:38.076083 11794 net.cpp:408] score -> score
I1130 22:07:38.077162 11794 net.cpp:150] Setting up score
I1130 22:07:38.077183 11794 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:07:38.077188 11794 net.cpp:165] Memory required for data: 12528
I1130 22:07:38.077195 11794 layer_factory.hpp:77] Creating layer prob
I1130 22:07:38.077204 11794 net.cpp:100] Creating Layer prob
I1130 22:07:38.077209 11794 net.cpp:434] prob <- score
I1130 22:07:38.077215 11794 net.cpp:408] prob -> prob
I1130 22:07:38.077464 11794 net.cpp:150] Setting up prob
I1130 22:07:38.077476 11794 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:07:38.077479 11794 net.cpp:165] Memory required for data: 12536
I1130 22:07:38.077483 11794 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:07:38.077493 11794 net.cpp:100] Creating Layer bbox_pred
I1130 22:07:38.077497 11794 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 22:07:38.077507 11794 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:07:38.078582 11794 net.cpp:150] Setting up bbox_pred
I1130 22:07:38.078603 11794 net.cpp:157] Top shape: 1 4 1 1 (4)
I1130 22:07:38.078608 11794 net.cpp:165] Memory required for data: 12552
I1130 22:07:38.078615 11794 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:07:38.078624 11794 net.cpp:100] Creating Layer landmark_pred
I1130 22:07:38.078629 11794 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 22:07:38.078637 11794 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:07:38.079730 11794 net.cpp:150] Setting up landmark_pred
I1130 22:07:38.079747 11794 net.cpp:157] Top shape: 1 10 1 1 (10)
I1130 22:07:38.079752 11794 net.cpp:165] Memory required for data: 12592
I1130 22:07:38.079761 11794 net.cpp:228] landmark_pred does not need backward computation.
I1130 22:07:38.079764 11794 net.cpp:228] bbox_pred does not need backward computation.
I1130 22:07:38.079768 11794 net.cpp:228] prob does not need backward computation.
I1130 22:07:38.079772 11794 net.cpp:228] score does not need backward computation.
I1130 22:07:38.079777 11794 net.cpp:228] conv3_prelu3_0_split does not need backward computation.
I1130 22:07:38.079780 11794 net.cpp:228] prelu3 does not need backward computation.
I1130 22:07:38.079783 11794 net.cpp:228] conv3 does not need backward computation.
I1130 22:07:38.079787 11794 net.cpp:228] prelu2 does not need backward computation.
I1130 22:07:38.079790 11794 net.cpp:228] conv2 does not need backward computation.
I1130 22:07:38.079793 11794 net.cpp:228] pool1 does not need backward computation.
I1130 22:07:38.079797 11794 net.cpp:228] prelu1 does not need backward computation.
I1130 22:07:38.079800 11794 net.cpp:228] conv1 does not need backward computation.
I1130 22:07:38.079804 11794 net.cpp:228] data does not need backward computation.
I1130 22:07:38.079807 11794 net.cpp:270] This network produces output bbox_pred
I1130 22:07:38.079812 11794 net.cpp:270] This network produces output landmark_pred
I1130 22:07:38.079815 11794 net.cpp:270] This network produces output prob
I1130 22:07:38.079831 11794 net.cpp:283] Network initialization done.
I1130 22:07:38.080080 11794 net.cpp:761] Ignoring source layer loss
I1130 22:07:38.097054 11793 net.cpp:150] Setting up conv1
I1130 22:07:38.097110 11793 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:07:38.097115 11793 net.cpp:165] Memory required for data: 5728
I1130 22:07:38.097151 11793 layer_factory.hpp:77] Creating layer prelu1
I1130 22:07:38.097170 11793 net.cpp:100] Creating Layer prelu1
I1130 22:07:38.097177 11793 net.cpp:434] prelu1 <- conv1
I1130 22:07:38.097183 11793 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:07:38.097301 11793 net.cpp:150] Setting up prelu1
I1130 22:07:38.097311 11793 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:07:38.097314 11793 net.cpp:165] Memory required for data: 9728
I1130 22:07:38.097321 11793 layer_factory.hpp:77] Creating layer pool1
I1130 22:07:38.097333 11793 net.cpp:100] Creating Layer pool1
I1130 22:07:38.097337 11793 net.cpp:434] pool1 <- conv1
I1130 22:07:38.097343 11793 net.cpp:408] pool1 -> pool1
I1130 22:07:38.097386 11793 net.cpp:150] Setting up pool1
I1130 22:07:38.097393 11793 net.cpp:157] Top shape: 1 10 5 5 (250)
I1130 22:07:38.097396 11793 net.cpp:165] Memory required for data: 10728
I1130 22:07:38.097400 11793 layer_factory.hpp:77] Creating layer conv2
I1130 22:07:38.097417 11793 net.cpp:100] Creating Layer conv2
I1130 22:07:38.097421 11793 net.cpp:434] conv2 <- pool1
I1130 22:07:38.097426 11793 net.cpp:408] conv2 -> conv2
I1130 22:07:38.099706 11793 net.cpp:150] Setting up conv2
I1130 22:07:38.099730 11793 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:07:38.099735 11793 net.cpp:165] Memory required for data: 11304
I1130 22:07:38.099746 11793 layer_factory.hpp:77] Creating layer prelu2
I1130 22:07:38.099756 11793 net.cpp:100] Creating Layer prelu2
I1130 22:07:38.099761 11793 net.cpp:434] prelu2 <- conv2
I1130 22:07:38.099766 11793 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:07:38.099861 11793 net.cpp:150] Setting up prelu2
I1130 22:07:38.099869 11793 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:07:38.099872 11793 net.cpp:165] Memory required for data: 11880
I1130 22:07:38.099877 11793 layer_factory.hpp:77] Creating layer conv3
I1130 22:07:38.099887 11793 net.cpp:100] Creating Layer conv3
I1130 22:07:38.099891 11793 net.cpp:434] conv3 <- conv2
I1130 22:07:38.099900 11793 net.cpp:408] conv3 -> conv3
I1130 22:07:38.102186 11793 net.cpp:150] Setting up conv3
I1130 22:07:38.102212 11793 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.102217 11793 net.cpp:165] Memory required for data: 12008
I1130 22:07:38.102226 11793 layer_factory.hpp:77] Creating layer prelu3
I1130 22:07:38.102236 11793 net.cpp:100] Creating Layer prelu3
I1130 22:07:38.102239 11793 net.cpp:434] prelu3 <- conv3
I1130 22:07:38.102246 11793 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:07:38.102340 11793 net.cpp:150] Setting up prelu3
I1130 22:07:38.102349 11793 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.102351 11793 net.cpp:165] Memory required for data: 12136
I1130 22:07:38.102360 11793 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 22:07:38.102372 11793 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 22:07:38.102377 11793 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 22:07:38.102382 11793 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 22:07:38.102390 11793 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 22:07:38.102396 11793 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 22:07:38.102445 11793 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 22:07:38.102452 11793 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.102458 11793 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.102461 11793 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.102464 11793 net.cpp:165] Memory required for data: 12520
I1130 22:07:38.102468 11793 layer_factory.hpp:77] Creating layer score
I1130 22:07:38.102478 11793 net.cpp:100] Creating Layer score
I1130 22:07:38.102481 11793 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 22:07:38.102488 11793 net.cpp:408] score -> score
I1130 22:07:38.103543 11793 net.cpp:150] Setting up score
I1130 22:07:38.103566 11793 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:07:38.103570 11793 net.cpp:165] Memory required for data: 12528
I1130 22:07:38.103579 11793 layer_factory.hpp:77] Creating layer prob
I1130 22:07:38.103596 11793 net.cpp:100] Creating Layer prob
I1130 22:07:38.103601 11793 net.cpp:434] prob <- score
I1130 22:07:38.103607 11793 net.cpp:408] prob -> prob
I1130 22:07:38.103852 11793 net.cpp:150] Setting up prob
I1130 22:07:38.103863 11793 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:07:38.103868 11793 net.cpp:165] Memory required for data: 12536
I1130 22:07:38.103871 11793 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:07:38.103881 11793 net.cpp:100] Creating Layer bbox_pred
I1130 22:07:38.103885 11793 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 22:07:38.103895 11793 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:07:38.104961 11793 net.cpp:150] Setting up bbox_pred
I1130 22:07:38.104981 11793 net.cpp:157] Top shape: 1 4 1 1 (4)
I1130 22:07:38.104986 11793 net.cpp:165] Memory required for data: 12552
I1130 22:07:38.104995 11793 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:07:38.105003 11793 net.cpp:100] Creating Layer landmark_pred
I1130 22:07:38.105007 11793 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 22:07:38.105015 11793 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:07:38.106112 11793 net.cpp:150] Setting up landmark_pred
I1130 22:07:38.106130 11793 net.cpp:157] Top shape: 1 10 1 1 (10)
I1130 22:07:38.106135 11793 net.cpp:165] Memory required for data: 12592
I1130 22:07:38.106142 11793 net.cpp:228] landmark_pred does not need backward computation.
I1130 22:07:38.106148 11793 net.cpp:228] bbox_pred does not need backward computation.
I1130 22:07:38.106151 11793 net.cpp:228] prob does not need backward computation.
I1130 22:07:38.106154 11793 net.cpp:228] score does not need backward computation.
I1130 22:07:38.106158 11793 net.cpp:228] conv3_prelu3_0_split does not need backward computation.
I1130 22:07:38.106163 11793 net.cpp:228] prelu3 does not need backward computation.
I1130 22:07:38.106165 11793 net.cpp:228] conv3 does not need backward computation.
I1130 22:07:38.106169 11793 net.cpp:228] prelu2 does not need backward computation.
I1130 22:07:38.106173 11793 net.cpp:228] conv2 does not need backward computation.
I1130 22:07:38.106176 11793 net.cpp:228] pool1 does not need backward computation.
I1130 22:07:38.106179 11793 net.cpp:228] prelu1 does not need backward computation.
I1130 22:07:38.106183 11793 net.cpp:228] conv1 does not need backward computation.
I1130 22:07:38.106186 11793 net.cpp:228] data does not need backward computation.
I1130 22:07:38.106189 11793 net.cpp:270] This network produces output bbox_pred
I1130 22:07:38.106194 11793 net.cpp:270] This network produces output landmark_pred
I1130 22:07:38.106197 11793 net.cpp:270] This network produces output prob
I1130 22:07:38.106212 11793 net.cpp:283] Network initialization done.
I1130 22:07:38.106446 11793 net.cpp:761] Ignoring source layer loss
I1130 22:07:38.111183 11791 net.cpp:150] Setting up conv1
I1130 22:07:38.111208 11791 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:07:38.111213 11791 net.cpp:165] Memory required for data: 5728
I1130 22:07:38.111233 11791 layer_factory.hpp:77] Creating layer prelu1
I1130 22:07:38.111251 11791 net.cpp:100] Creating Layer prelu1
I1130 22:07:38.111256 11791 net.cpp:434] prelu1 <- conv1
I1130 22:07:38.111263 11791 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:07:38.111371 11791 net.cpp:150] Setting up prelu1
I1130 22:07:38.111379 11791 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:07:38.111382 11791 net.cpp:165] Memory required for data: 9728
I1130 22:07:38.111390 11791 layer_factory.hpp:77] Creating layer pool1
I1130 22:07:38.111402 11791 net.cpp:100] Creating Layer pool1
I1130 22:07:38.111407 11791 net.cpp:434] pool1 <- conv1
I1130 22:07:38.111412 11791 net.cpp:408] pool1 -> pool1
I1130 22:07:38.111452 11791 net.cpp:150] Setting up pool1
I1130 22:07:38.111459 11791 net.cpp:157] Top shape: 1 10 5 5 (250)
I1130 22:07:38.111464 11791 net.cpp:165] Memory required for data: 10728
I1130 22:07:38.111467 11791 layer_factory.hpp:77] Creating layer conv2
I1130 22:07:38.111477 11791 net.cpp:100] Creating Layer conv2
I1130 22:07:38.111496 11791 net.cpp:434] conv2 <- pool1
I1130 22:07:38.111508 11791 net.cpp:408] conv2 -> conv2
I1130 22:07:38.113607 11791 net.cpp:150] Setting up conv2
I1130 22:07:38.113626 11791 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:07:38.113631 11791 net.cpp:165] Memory required for data: 11304
I1130 22:07:38.113642 11791 layer_factory.hpp:77] Creating layer prelu2
I1130 22:07:38.113651 11791 net.cpp:100] Creating Layer prelu2
I1130 22:07:38.113656 11791 net.cpp:434] prelu2 <- conv2
I1130 22:07:38.113662 11791 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:07:38.113754 11791 net.cpp:150] Setting up prelu2
I1130 22:07:38.113762 11791 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:07:38.113766 11791 net.cpp:165] Memory required for data: 11880
I1130 22:07:38.113771 11791 layer_factory.hpp:77] Creating layer conv3
I1130 22:07:38.113780 11791 net.cpp:100] Creating Layer conv3
I1130 22:07:38.113785 11791 net.cpp:434] conv3 <- conv2
I1130 22:07:38.113791 11791 net.cpp:408] conv3 -> conv3
I1130 22:07:38.116016 11791 net.cpp:150] Setting up conv3
I1130 22:07:38.116036 11791 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.116041 11791 net.cpp:165] Memory required for data: 12008
I1130 22:07:38.116050 11791 layer_factory.hpp:77] Creating layer prelu3
I1130 22:07:38.116060 11791 net.cpp:100] Creating Layer prelu3
I1130 22:07:38.116063 11791 net.cpp:434] prelu3 <- conv3
I1130 22:07:38.116078 11791 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:07:38.116175 11791 net.cpp:150] Setting up prelu3
I1130 22:07:38.116183 11791 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.116188 11791 net.cpp:165] Memory required for data: 12136
I1130 22:07:38.116195 11791 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 22:07:38.116209 11791 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 22:07:38.116212 11791 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 22:07:38.116217 11791 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 22:07:38.116225 11791 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 22:07:38.116230 11791 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 22:07:38.116279 11791 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 22:07:38.116286 11791 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.116291 11791 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.116294 11791 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:07:38.116297 11791 net.cpp:165] Memory required for data: 12520
I1130 22:07:38.116302 11791 layer_factory.hpp:77] Creating layer score
I1130 22:07:38.116310 11791 net.cpp:100] Creating Layer score
I1130 22:07:38.116314 11791 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 22:07:38.116320 11791 net.cpp:408] score -> score
I1130 22:07:38.117362 11791 net.cpp:150] Setting up score
I1130 22:07:38.117383 11791 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:07:38.117386 11791 net.cpp:165] Memory required for data: 12528
I1130 22:07:38.117394 11791 layer_factory.hpp:77] Creating layer prob
I1130 22:07:38.117403 11791 net.cpp:100] Creating Layer prob
I1130 22:07:38.117408 11791 net.cpp:434] prob <- score
I1130 22:07:38.117414 11791 net.cpp:408] prob -> prob
I1130 22:07:38.117660 11791 net.cpp:150] Setting up prob
I1130 22:07:38.117671 11791 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:07:38.117676 11791 net.cpp:165] Memory required for data: 12536
I1130 22:07:38.117679 11791 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:07:38.117688 11791 net.cpp:100] Creating Layer bbox_pred
I1130 22:07:38.117692 11791 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 22:07:38.117700 11791 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:07:38.118868 11791 net.cpp:150] Setting up bbox_pred
I1130 22:07:38.118888 11791 net.cpp:157] Top shape: 1 4 1 1 (4)
I1130 22:07:38.118893 11791 net.cpp:165] Memory required for data: 12552
I1130 22:07:38.118902 11791 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:07:38.118911 11791 net.cpp:100] Creating Layer landmark_pred
I1130 22:07:38.118916 11791 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 22:07:38.118928 11791 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:07:38.120088 11791 net.cpp:150] Setting up landmark_pred
I1130 22:07:38.120106 11791 net.cpp:157] Top shape: 1 10 1 1 (10)
I1130 22:07:38.120111 11791 net.cpp:165] Memory required for data: 12592
I1130 22:07:38.120120 11791 net.cpp:228] landmark_pred does not need backward computation.
I1130 22:07:38.120124 11791 net.cpp:228] bbox_pred does not need backward computation.
I1130 22:07:38.120128 11791 net.cpp:228] prob does not need backward computation.
I1130 22:07:38.120131 11791 net.cpp:228] score does not need backward computation.
I1130 22:07:38.120136 11791 net.cpp:228] conv3_prelu3_0_split does not need backward computation.
I1130 22:07:38.120144 11791 net.cpp:228] prelu3 does not need backward computation.
I1130 22:07:38.120147 11791 net.cpp:228] conv3 does not need backward computation.
I1130 22:07:38.120151 11791 net.cpp:228] prelu2 does not need backward computation.
I1130 22:07:38.120154 11791 net.cpp:228] conv2 does not need backward computation.
I1130 22:07:38.120158 11791 net.cpp:228] pool1 does not need backward computation.
I1130 22:07:38.120162 11791 net.cpp:228] prelu1 does not need backward computation.
I1130 22:07:38.120164 11791 net.cpp:228] conv1 does not need backward computation.
I1130 22:07:38.120168 11791 net.cpp:228] data does not need backward computation.
I1130 22:07:38.120172 11791 net.cpp:270] This network produces output bbox_pred
I1130 22:07:38.120175 11791 net.cpp:270] This network produces output landmark_pred
I1130 22:07:38.120179 11791 net.cpp:270] This network produces output prob
I1130 22:07:38.120194 11791 net.cpp:283] Network initialization done.
I1130 22:07:38.120435 11791 net.cpp:761] Ignoring source layer loss
[2016-11-30 22:07:39,750][INFO] writes 548 positives, 7394 negatives, 2057 part
[2016-11-30 22:07:41,406][INFO] writes 1267 positives, 14560 negatives, 4172 part
[2016-11-30 22:07:43,066][INFO] writes 2039 positives, 21363 negatives, 6597 part
[2016-11-30 22:07:45,183][INFO] writes 2889 positives, 27984 negatives, 9126 part
[2016-11-30 22:07:46,795][INFO] writes 3695 positives, 34524 negatives, 11780 part
[2016-11-30 22:07:48,731][INFO] writes 4780 positives, 40474 negatives, 14745 part
[2016-11-30 22:07:50,227][INFO] writes 5759 positives, 47464 negatives, 16776 part
[2016-11-30 22:07:52,144][INFO] writes 6433 positives, 55137 negatives, 18429 part
[2016-11-30 22:07:54,356][INFO] writes 6667 positives, 64146 negatives, 19186 part
[2016-11-30 22:07:56,371][INFO] writes 6975 positives, 72832 negatives, 20192 part
[2016-11-30 22:07:58,935][INFO] writes 7469 positives, 80957 negatives, 21573 part
[2016-11-30 22:08:00,917][INFO] writes 7818 positives, 89420 negatives, 22761 part
[2016-11-30 22:08:02,903][INFO] writes 8384 positives, 96686 negatives, 24929 part
[2016-11-30 22:08:04,612][INFO] writes 9204 positives, 103086 negatives, 27709 part
[2016-11-30 22:08:06,140][INFO] writes 10084 positives, 108681 negatives, 31234 part
[2016-11-30 22:08:07,907][INFO] writes 10727 positives, 115673 negatives, 33599 part
[2016-11-30 22:08:09,737][INFO] writes 11494 positives, 122436 negatives, 36069 part
[2016-11-30 22:08:11,493][INFO] writes 12277 positives, 129441 negatives, 38281 part
[2016-11-30 22:08:13,841][INFO] writes 12745 positives, 137600 negatives, 39654 part
[2016-11-30 22:08:15,925][INFO] writes 13047 positives, 146283 negatives, 40669 part
[2016-11-30 22:08:17,869][INFO] writes 13337 positives, 155070 negatives, 41592 part
[2016-11-30 22:08:20,030][INFO] writes 13738 positives, 163278 negatives, 42983 part
[2016-11-30 22:08:22,067][INFO] writes 14205 positives, 171438 negatives, 44356 part
[2016-11-30 22:08:24,179][INFO] writes 14495 positives, 180174 negatives, 45330 part
[2016-11-30 22:08:26,381][INFO] writes 14767 positives, 188802 negatives, 46430 part
[2016-11-30 22:08:28,321][INFO] writes 15112 positives, 197533 negatives, 47354 part
[2016-11-30 22:08:30,355][INFO] writes 15544 positives, 205589 negatives, 48866 part
[2016-11-30 22:08:32,327][INFO] writes 15946 positives, 213647 negatives, 50406 part
[2016-11-30 22:08:34,063][INFO] writes 16407 positives, 221803 negatives, 51789 part
[2016-11-30 22:08:36,007][INFO] writes 16915 positives, 229874 negatives, 53210 part
[2016-11-30 22:08:37,986][INFO] writes 17264 positives, 238549 negatives, 54186 part
[2016-11-30 22:08:39,611][INFO] writes 17617 positives, 247040 negatives, 55342 part
[2016-11-30 22:08:41,419][INFO] writes 18153 positives, 255616 negatives, 56230 part
[2016-11-30 22:08:43,126][INFO] writes 18375 positives, 264438 negatives, 57186 part
[2016-11-30 22:08:44,914][INFO] writes 18772 positives, 272881 negatives, 58346 part
[2016-11-30 22:08:46,686][INFO] writes 19096 positives, 281494 negatives, 59409 part
[2016-11-30 22:08:48,674][INFO] writes 19322 positives, 290531 negatives, 60146 part
[2016-11-30 22:08:50,865][INFO] writes 19675 positives, 298998 negatives, 61326 part
[2016-11-30 22:08:53,089][INFO] writes 20011 positives, 307794 negatives, 62194 part
[2016-11-30 22:08:55,315][INFO] writes 20359 positives, 316329 negatives, 63311 part
[2016-11-30 22:08:57,327][INFO] writes 20729 positives, 324899 negatives, 64371 part
[2016-11-30 22:08:59,246][INFO] writes 20987 positives, 333750 negatives, 65262 part
[2016-11-30 22:09:01,469][INFO] writes 21289 positives, 342446 negatives, 66264 part
[2016-11-30 22:09:03,305][INFO] writes 21641 positives, 350899 negatives, 67459 part
[2016-11-30 22:09:05,404][INFO] writes 22102 positives, 358767 negatives, 69130 part
[2016-11-30 22:09:07,149][INFO] writes 22673 positives, 366525 negatives, 70801 part
[2016-11-30 22:09:09,074][INFO] writes 23157 positives, 374349 negatives, 72493 part
[2016-11-30 22:09:11,123][INFO] writes 23807 positives, 381701 negatives, 74491 part
[2016-11-30 22:09:13,632][INFO] writes 24328 positives, 389816 negatives, 75855 part
[2016-11-30 22:09:19,972][INFO] writes 24674 positives, 398301 negatives, 77024 part
[2016-11-30 22:09:31,837][INFO] Finish
Train rNet
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 22:09:34.955953 11845 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1679
test_interval: 6810
base_lr: 0.01
display: 500
max_iter: 272400
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 68100
snapshot: 6810
snapshot_prefix: "tmp/rnet"
solver_mode: GPU
net: "proto/r_train_val.prototxt"
test_initialization: false
average_loss: 500
I1130 22:09:34.956077 11845 solver.cpp:91] Creating training net from net file: proto/r_train_val.prototxt
I1130 22:09:34.956425 11845 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1130 22:09:34.956526 11845 net.cpp:58] Initializing net from parameters: 
name: "rNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "bbox_target"
  top: "landmark_target"
  top: "label"
  include {
    phase: TRAIN
  }
  python_param {
    module: "layers.data_layer"
    layer: "FaceDataLayer"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "conv3"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "fc"
  top: "fc"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "fc"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "bbox_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "landmark_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "landmark_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "JfdaLoss"
  bottom: "score"
  bottom: "bbox_pred"
  bottom: "landmark_pred"
  bottom: "bbox_target"
  bottom: "landmark_target"
  bottom: "label"
  top: "face_cls_loss"
  top: "bbox_reg_loss"
  top: "landmark_reg_loss"
  top: "face_cls_neg_acc"
  top: "face_cls_pos_acc"
  loss_weight: 1
  loss_weight: 0.5
  loss_weight: 1
  loss_weight: 0
  loss_weight: 0
  jfda_loss_param {
    drop_loss_rate: 0.3
  }
}
I1130 22:09:34.956604 11845 layer_factory.hpp:77] Creating layer data
I1130 22:09:34.956867 11845 net.cpp:100] Creating Layer data
I1130 22:09:34.956881 11845 net.cpp:408] data -> data
I1130 22:09:34.956893 11845 net.cpp:408] data -> bbox_target
I1130 22:09:34.956899 11845 net.cpp:408] data -> landmark_target
I1130 22:09:34.956904 11845 net.cpp:408] data -> label
I1130 22:09:34.971107 11845 net.cpp:150] Setting up data
I1130 22:09:34.971124 11845 net.cpp:157] Top shape: 4 3 24 24 (6912)
I1130 22:09:34.971129 11845 net.cpp:157] Top shape: 4 4 (16)
I1130 22:09:34.971132 11845 net.cpp:157] Top shape: 4 10 (40)
I1130 22:09:34.971135 11845 net.cpp:157] Top shape: 4 (4)
I1130 22:09:34.971138 11845 net.cpp:165] Memory required for data: 27888
I1130 22:09:34.971143 11845 layer_factory.hpp:77] Creating layer conv1
I1130 22:09:34.971155 11845 net.cpp:100] Creating Layer conv1
I1130 22:09:34.971159 11845 net.cpp:434] conv1 <- data
I1130 22:09:34.971168 11845 net.cpp:408] conv1 -> conv1
I1130 22:09:35.178894 11845 net.cpp:150] Setting up conv1
I1130 22:09:35.178935 11845 net.cpp:157] Top shape: 4 28 22 22 (54208)
I1130 22:09:35.178939 11845 net.cpp:165] Memory required for data: 244720
I1130 22:09:35.178957 11845 layer_factory.hpp:77] Creating layer prelu1
I1130 22:09:35.178972 11845 net.cpp:100] Creating Layer prelu1
I1130 22:09:35.178977 11845 net.cpp:434] prelu1 <- conv1
I1130 22:09:35.178983 11845 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:09:35.180052 11845 net.cpp:150] Setting up prelu1
I1130 22:09:35.180071 11845 net.cpp:157] Top shape: 4 28 22 22 (54208)
I1130 22:09:35.180076 11845 net.cpp:165] Memory required for data: 461552
I1130 22:09:35.180084 11845 layer_factory.hpp:77] Creating layer pool1
I1130 22:09:35.180095 11845 net.cpp:100] Creating Layer pool1
I1130 22:09:35.180099 11845 net.cpp:434] pool1 <- conv1
I1130 22:09:35.180106 11845 net.cpp:408] pool1 -> pool1
I1130 22:09:35.180151 11845 net.cpp:150] Setting up pool1
I1130 22:09:35.180157 11845 net.cpp:157] Top shape: 4 28 11 11 (13552)
I1130 22:09:35.180160 11845 net.cpp:165] Memory required for data: 515760
I1130 22:09:35.180162 11845 layer_factory.hpp:77] Creating layer conv2
I1130 22:09:35.180176 11845 net.cpp:100] Creating Layer conv2
I1130 22:09:35.180178 11845 net.cpp:434] conv2 <- pool1
I1130 22:09:35.180182 11845 net.cpp:408] conv2 -> conv2
I1130 22:09:35.181321 11845 net.cpp:150] Setting up conv2
I1130 22:09:35.181335 11845 net.cpp:157] Top shape: 4 48 9 9 (15552)
I1130 22:09:35.181339 11845 net.cpp:165] Memory required for data: 577968
I1130 22:09:35.181349 11845 layer_factory.hpp:77] Creating layer prelu2
I1130 22:09:35.181354 11845 net.cpp:100] Creating Layer prelu2
I1130 22:09:35.181357 11845 net.cpp:434] prelu2 <- conv2
I1130 22:09:35.181363 11845 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:09:35.182385 11845 net.cpp:150] Setting up prelu2
I1130 22:09:35.182399 11845 net.cpp:157] Top shape: 4 48 9 9 (15552)
I1130 22:09:35.182402 11845 net.cpp:165] Memory required for data: 640176
I1130 22:09:35.182407 11845 layer_factory.hpp:77] Creating layer pool2
I1130 22:09:35.182415 11845 net.cpp:100] Creating Layer pool2
I1130 22:09:35.182417 11845 net.cpp:434] pool2 <- conv2
I1130 22:09:35.182423 11845 net.cpp:408] pool2 -> pool2
I1130 22:09:35.182454 11845 net.cpp:150] Setting up pool2
I1130 22:09:35.182459 11845 net.cpp:157] Top shape: 4 48 4 4 (3072)
I1130 22:09:35.182461 11845 net.cpp:165] Memory required for data: 652464
I1130 22:09:35.182464 11845 layer_factory.hpp:77] Creating layer conv3
I1130 22:09:35.182476 11845 net.cpp:100] Creating Layer conv3
I1130 22:09:35.182478 11845 net.cpp:434] conv3 <- pool2
I1130 22:09:35.182482 11845 net.cpp:408] conv3 -> conv3
I1130 22:09:35.183404 11845 net.cpp:150] Setting up conv3
I1130 22:09:35.183418 11845 net.cpp:157] Top shape: 4 64 3 3 (2304)
I1130 22:09:35.183423 11845 net.cpp:165] Memory required for data: 661680
I1130 22:09:35.183429 11845 layer_factory.hpp:77] Creating layer prelu3
I1130 22:09:35.183436 11845 net.cpp:100] Creating Layer prelu3
I1130 22:09:35.183439 11845 net.cpp:434] prelu3 <- conv3
I1130 22:09:35.183444 11845 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:09:35.183519 11845 net.cpp:150] Setting up prelu3
I1130 22:09:35.183526 11845 net.cpp:157] Top shape: 4 64 3 3 (2304)
I1130 22:09:35.183527 11845 net.cpp:165] Memory required for data: 670896
I1130 22:09:35.183533 11845 layer_factory.hpp:77] Creating layer fc
I1130 22:09:35.183547 11845 net.cpp:100] Creating Layer fc
I1130 22:09:35.183550 11845 net.cpp:434] fc <- conv3
I1130 22:09:35.183557 11845 net.cpp:408] fc -> fc
I1130 22:09:35.184975 11845 net.cpp:150] Setting up fc
I1130 22:09:35.184989 11845 net.cpp:157] Top shape: 4 128 (512)
I1130 22:09:35.184993 11845 net.cpp:165] Memory required for data: 672944
I1130 22:09:35.184998 11845 layer_factory.hpp:77] Creating layer prelu4
I1130 22:09:35.185004 11845 net.cpp:100] Creating Layer prelu4
I1130 22:09:35.185008 11845 net.cpp:434] prelu4 <- fc
I1130 22:09:35.185011 11845 net.cpp:395] prelu4 -> fc (in-place)
I1130 22:09:35.185080 11845 net.cpp:150] Setting up prelu4
I1130 22:09:35.185087 11845 net.cpp:157] Top shape: 4 128 (512)
I1130 22:09:35.185091 11845 net.cpp:165] Memory required for data: 674992
I1130 22:09:35.185094 11845 layer_factory.hpp:77] Creating layer fc_prelu4_0_split
I1130 22:09:35.185101 11845 net.cpp:100] Creating Layer fc_prelu4_0_split
I1130 22:09:35.185103 11845 net.cpp:434] fc_prelu4_0_split <- fc
I1130 22:09:35.185107 11845 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_0
I1130 22:09:35.185115 11845 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_1
I1130 22:09:35.185120 11845 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_2
I1130 22:09:35.185158 11845 net.cpp:150] Setting up fc_prelu4_0_split
I1130 22:09:35.185163 11845 net.cpp:157] Top shape: 4 128 (512)
I1130 22:09:35.185166 11845 net.cpp:157] Top shape: 4 128 (512)
I1130 22:09:35.185169 11845 net.cpp:157] Top shape: 4 128 (512)
I1130 22:09:35.185173 11845 net.cpp:165] Memory required for data: 681136
I1130 22:09:35.185179 11845 layer_factory.hpp:77] Creating layer score
I1130 22:09:35.185185 11845 net.cpp:100] Creating Layer score
I1130 22:09:35.185189 11845 net.cpp:434] score <- fc_prelu4_0_split_0
I1130 22:09:35.185194 11845 net.cpp:408] score -> score
I1130 22:09:35.185263 11845 net.cpp:150] Setting up score
I1130 22:09:35.185269 11845 net.cpp:157] Top shape: 4 2 (8)
I1130 22:09:35.185271 11845 net.cpp:165] Memory required for data: 681168
I1130 22:09:35.185276 11845 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:09:35.185286 11845 net.cpp:100] Creating Layer bbox_pred
I1130 22:09:35.185289 11845 net.cpp:434] bbox_pred <- fc_prelu4_0_split_1
I1130 22:09:35.185295 11845 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:09:35.185370 11845 net.cpp:150] Setting up bbox_pred
I1130 22:09:35.185375 11845 net.cpp:157] Top shape: 4 4 (16)
I1130 22:09:35.185379 11845 net.cpp:165] Memory required for data: 681232
I1130 22:09:35.185382 11845 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:09:35.185387 11845 net.cpp:100] Creating Layer landmark_pred
I1130 22:09:35.185390 11845 net.cpp:434] landmark_pred <- fc_prelu4_0_split_2
I1130 22:09:35.185396 11845 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:09:35.185479 11845 net.cpp:150] Setting up landmark_pred
I1130 22:09:35.185485 11845 net.cpp:157] Top shape: 4 10 (40)
I1130 22:09:35.185487 11845 net.cpp:165] Memory required for data: 681392
I1130 22:09:35.185497 11845 layer_factory.hpp:77] Creating layer loss
I1130 22:09:35.185508 11845 net.cpp:100] Creating Layer loss
I1130 22:09:35.185511 11845 net.cpp:434] loss <- score
I1130 22:09:35.185514 11845 net.cpp:434] loss <- bbox_pred
I1130 22:09:35.185518 11845 net.cpp:434] loss <- landmark_pred
I1130 22:09:35.185520 11845 net.cpp:434] loss <- bbox_target
I1130 22:09:35.185523 11845 net.cpp:434] loss <- landmark_target
I1130 22:09:35.185526 11845 net.cpp:434] loss <- label
I1130 22:09:35.185530 11845 net.cpp:408] loss -> face_cls_loss
I1130 22:09:35.185539 11845 net.cpp:408] loss -> bbox_reg_loss
I1130 22:09:35.185545 11845 net.cpp:408] loss -> landmark_reg_loss
I1130 22:09:35.185550 11845 net.cpp:408] loss -> face_cls_neg_acc
I1130 22:09:35.185555 11845 net.cpp:408] loss -> face_cls_pos_acc
I1130 22:09:35.185629 11845 net.cpp:150] Setting up loss
I1130 22:09:35.185634 11845 net.cpp:157] Top shape: (1)
I1130 22:09:35.185636 11845 net.cpp:160]     with loss weight 1
I1130 22:09:35.185652 11845 net.cpp:157] Top shape: (1)
I1130 22:09:35.185653 11845 net.cpp:160]     with loss weight 0.5
I1130 22:09:35.185657 11845 net.cpp:157] Top shape: (1)
I1130 22:09:35.185660 11845 net.cpp:160]     with loss weight 1
I1130 22:09:35.185663 11845 net.cpp:157] Top shape: (1)
I1130 22:09:35.185667 11845 net.cpp:157] Top shape: (1)
I1130 22:09:35.185668 11845 net.cpp:165] Memory required for data: 681412
I1130 22:09:35.185672 11845 net.cpp:226] loss needs backward computation.
I1130 22:09:35.185675 11845 net.cpp:226] landmark_pred needs backward computation.
I1130 22:09:35.185678 11845 net.cpp:226] bbox_pred needs backward computation.
I1130 22:09:35.185681 11845 net.cpp:226] score needs backward computation.
I1130 22:09:35.185684 11845 net.cpp:226] fc_prelu4_0_split needs backward computation.
I1130 22:09:35.185688 11845 net.cpp:226] prelu4 needs backward computation.
I1130 22:09:35.185689 11845 net.cpp:226] fc needs backward computation.
I1130 22:09:35.185693 11845 net.cpp:226] prelu3 needs backward computation.
I1130 22:09:35.185694 11845 net.cpp:226] conv3 needs backward computation.
I1130 22:09:35.185698 11845 net.cpp:226] pool2 needs backward computation.
I1130 22:09:35.185700 11845 net.cpp:226] prelu2 needs backward computation.
I1130 22:09:35.185703 11845 net.cpp:226] conv2 needs backward computation.
I1130 22:09:35.185705 11845 net.cpp:226] pool1 needs backward computation.
I1130 22:09:35.185708 11845 net.cpp:226] prelu1 needs backward computation.
I1130 22:09:35.185710 11845 net.cpp:226] conv1 needs backward computation.
I1130 22:09:35.185714 11845 net.cpp:228] data does not need backward computation.
I1130 22:09:35.185719 11845 net.cpp:270] This network produces output bbox_reg_loss
I1130 22:09:35.185722 11845 net.cpp:270] This network produces output face_cls_loss
I1130 22:09:35.185725 11845 net.cpp:270] This network produces output face_cls_neg_acc
I1130 22:09:35.185729 11845 net.cpp:270] This network produces output face_cls_pos_acc
I1130 22:09:35.185730 11845 net.cpp:270] This network produces output landmark_reg_loss
I1130 22:09:35.185742 11845 net.cpp:283] Network initialization done.
I1130 22:09:35.186130 11845 solver.cpp:181] Creating test net (#0) specified by net file: proto/r_train_val.prototxt
I1130 22:09:35.186161 11845 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1130 22:09:35.186280 11845 net.cpp:58] Initializing net from parameters: 
name: "rNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "bbox_target"
  top: "landmark_target"
  top: "label"
  include {
    phase: TEST
  }
  python_param {
    module: "layers.data_layer"
    layer: "FaceDataLayer"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "conv3"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "fc"
  top: "fc"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "fc"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "bbox_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "landmark_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "landmark_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "JfdaLoss"
  bottom: "score"
  bottom: "bbox_pred"
  bottom: "landmark_pred"
  bottom: "bbox_target"
  bottom: "landmark_target"
  bottom: "label"
  top: "face_cls_loss"
  top: "bbox_reg_loss"
  top: "landmark_reg_loss"
  top: "face_cls_neg_acc"
  top: "face_cls_pos_acc"
  loss_weight: 1
  loss_weight: 0.5
  loss_weight: 1
  loss_weight: 0
  loss_weight: 0
  jfda_loss_param {
    drop_loss_rate: 0.3
  }
}
I1130 22:09:35.186349 11845 layer_factory.hpp:77] Creating layer data
I1130 22:09:35.186404 11845 net.cpp:100] Creating Layer data
I1130 22:09:35.186410 11845 net.cpp:408] data -> data
I1130 22:09:35.186417 11845 net.cpp:408] data -> bbox_target
I1130 22:09:35.186422 11845 net.cpp:408] data -> landmark_target
I1130 22:09:35.186426 11845 net.cpp:408] data -> label
I1130 22:09:35.186705 11845 net.cpp:150] Setting up data
I1130 22:09:35.186717 11845 net.cpp:157] Top shape: 4 3 24 24 (6912)
I1130 22:09:35.186720 11845 net.cpp:157] Top shape: 4 4 (16)
I1130 22:09:35.186723 11845 net.cpp:157] Top shape: 4 10 (40)
I1130 22:09:35.186727 11845 net.cpp:157] Top shape: 4 (4)
I1130 22:09:35.186729 11845 net.cpp:165] Memory required for data: 27888
I1130 22:09:35.186733 11845 layer_factory.hpp:77] Creating layer conv1
I1130 22:09:35.186741 11845 net.cpp:100] Creating Layer conv1
I1130 22:09:35.186744 11845 net.cpp:434] conv1 <- data
I1130 22:09:35.186749 11845 net.cpp:408] conv1 -> conv1
I1130 22:09:35.187613 11845 net.cpp:150] Setting up conv1
I1130 22:09:35.187629 11845 net.cpp:157] Top shape: 4 28 22 22 (54208)
I1130 22:09:35.187633 11845 net.cpp:165] Memory required for data: 244720
I1130 22:09:35.187641 11845 layer_factory.hpp:77] Creating layer prelu1
I1130 22:09:35.187647 11845 net.cpp:100] Creating Layer prelu1
I1130 22:09:35.187650 11845 net.cpp:434] prelu1 <- conv1
I1130 22:09:35.187654 11845 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:09:35.187736 11845 net.cpp:150] Setting up prelu1
I1130 22:09:35.187741 11845 net.cpp:157] Top shape: 4 28 22 22 (54208)
I1130 22:09:35.187743 11845 net.cpp:165] Memory required for data: 461552
I1130 22:09:35.187749 11845 layer_factory.hpp:77] Creating layer pool1
I1130 22:09:35.187755 11845 net.cpp:100] Creating Layer pool1
I1130 22:09:35.187758 11845 net.cpp:434] pool1 <- conv1
I1130 22:09:35.187762 11845 net.cpp:408] pool1 -> pool1
I1130 22:09:35.187791 11845 net.cpp:150] Setting up pool1
I1130 22:09:35.187796 11845 net.cpp:157] Top shape: 4 28 11 11 (13552)
I1130 22:09:35.187798 11845 net.cpp:165] Memory required for data: 515760
I1130 22:09:35.187801 11845 layer_factory.hpp:77] Creating layer conv2
I1130 22:09:35.187809 11845 net.cpp:100] Creating Layer conv2
I1130 22:09:35.187813 11845 net.cpp:434] conv2 <- pool1
I1130 22:09:35.187819 11845 net.cpp:408] conv2 -> conv2
I1130 22:09:35.188740 11845 net.cpp:150] Setting up conv2
I1130 22:09:35.188753 11845 net.cpp:157] Top shape: 4 48 9 9 (15552)
I1130 22:09:35.188757 11845 net.cpp:165] Memory required for data: 577968
I1130 22:09:35.188765 11845 layer_factory.hpp:77] Creating layer prelu2
I1130 22:09:35.188771 11845 net.cpp:100] Creating Layer prelu2
I1130 22:09:35.188776 11845 net.cpp:434] prelu2 <- conv2
I1130 22:09:35.188779 11845 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:09:35.188853 11845 net.cpp:150] Setting up prelu2
I1130 22:09:35.188859 11845 net.cpp:157] Top shape: 4 48 9 9 (15552)
I1130 22:09:35.188863 11845 net.cpp:165] Memory required for data: 640176
I1130 22:09:35.188866 11845 layer_factory.hpp:77] Creating layer pool2
I1130 22:09:35.188871 11845 net.cpp:100] Creating Layer pool2
I1130 22:09:35.188874 11845 net.cpp:434] pool2 <- conv2
I1130 22:09:35.188879 11845 net.cpp:408] pool2 -> pool2
I1130 22:09:35.188907 11845 net.cpp:150] Setting up pool2
I1130 22:09:35.188913 11845 net.cpp:157] Top shape: 4 48 4 4 (3072)
I1130 22:09:35.188916 11845 net.cpp:165] Memory required for data: 652464
I1130 22:09:35.188918 11845 layer_factory.hpp:77] Creating layer conv3
I1130 22:09:35.188926 11845 net.cpp:100] Creating Layer conv3
I1130 22:09:35.188930 11845 net.cpp:434] conv3 <- pool2
I1130 22:09:35.188933 11845 net.cpp:408] conv3 -> conv3
I1130 22:09:35.189839 11845 net.cpp:150] Setting up conv3
I1130 22:09:35.189857 11845 net.cpp:157] Top shape: 4 64 3 3 (2304)
I1130 22:09:35.189860 11845 net.cpp:165] Memory required for data: 661680
I1130 22:09:35.189867 11845 layer_factory.hpp:77] Creating layer prelu3
I1130 22:09:35.189875 11845 net.cpp:100] Creating Layer prelu3
I1130 22:09:35.189879 11845 net.cpp:434] prelu3 <- conv3
I1130 22:09:35.189884 11845 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:09:35.189960 11845 net.cpp:150] Setting up prelu3
I1130 22:09:35.189966 11845 net.cpp:157] Top shape: 4 64 3 3 (2304)
I1130 22:09:35.189968 11845 net.cpp:165] Memory required for data: 670896
I1130 22:09:35.189975 11845 layer_factory.hpp:77] Creating layer fc
I1130 22:09:35.189982 11845 net.cpp:100] Creating Layer fc
I1130 22:09:35.189985 11845 net.cpp:434] fc <- conv3
I1130 22:09:35.189991 11845 net.cpp:408] fc -> fc
I1130 22:09:35.190481 11845 net.cpp:150] Setting up fc
I1130 22:09:35.190490 11845 net.cpp:157] Top shape: 4 128 (512)
I1130 22:09:35.190493 11845 net.cpp:165] Memory required for data: 672944
I1130 22:09:35.190498 11845 layer_factory.hpp:77] Creating layer prelu4
I1130 22:09:35.190502 11845 net.cpp:100] Creating Layer prelu4
I1130 22:09:35.190505 11845 net.cpp:434] prelu4 <- fc
I1130 22:09:35.190510 11845 net.cpp:395] prelu4 -> fc (in-place)
I1130 22:09:35.190568 11845 net.cpp:150] Setting up prelu4
I1130 22:09:35.190573 11845 net.cpp:157] Top shape: 4 128 (512)
I1130 22:09:35.190575 11845 net.cpp:165] Memory required for data: 674992
I1130 22:09:35.190579 11845 layer_factory.hpp:77] Creating layer fc_prelu4_0_split
I1130 22:09:35.190584 11845 net.cpp:100] Creating Layer fc_prelu4_0_split
I1130 22:09:35.190587 11845 net.cpp:434] fc_prelu4_0_split <- fc
I1130 22:09:35.190590 11845 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_0
I1130 22:09:35.190595 11845 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_1
I1130 22:09:35.190599 11845 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_2
I1130 22:09:35.190634 11845 net.cpp:150] Setting up fc_prelu4_0_split
I1130 22:09:35.190637 11845 net.cpp:157] Top shape: 4 128 (512)
I1130 22:09:35.190641 11845 net.cpp:157] Top shape: 4 128 (512)
I1130 22:09:35.190644 11845 net.cpp:157] Top shape: 4 128 (512)
I1130 22:09:35.190646 11845 net.cpp:165] Memory required for data: 681136
I1130 22:09:35.190649 11845 layer_factory.hpp:77] Creating layer score
I1130 22:09:35.190654 11845 net.cpp:100] Creating Layer score
I1130 22:09:35.190657 11845 net.cpp:434] score <- fc_prelu4_0_split_0
I1130 22:09:35.190662 11845 net.cpp:408] score -> score
I1130 22:09:35.190734 11845 net.cpp:150] Setting up score
I1130 22:09:35.190739 11845 net.cpp:157] Top shape: 4 2 (8)
I1130 22:09:35.190742 11845 net.cpp:165] Memory required for data: 681168
I1130 22:09:35.190747 11845 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:09:35.190752 11845 net.cpp:100] Creating Layer bbox_pred
I1130 22:09:35.190754 11845 net.cpp:434] bbox_pred <- fc_prelu4_0_split_1
I1130 22:09:35.190758 11845 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:09:35.190836 11845 net.cpp:150] Setting up bbox_pred
I1130 22:09:35.190841 11845 net.cpp:157] Top shape: 4 4 (16)
I1130 22:09:35.190845 11845 net.cpp:165] Memory required for data: 681232
I1130 22:09:35.190848 11845 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:09:35.190853 11845 net.cpp:100] Creating Layer landmark_pred
I1130 22:09:35.190856 11845 net.cpp:434] landmark_pred <- fc_prelu4_0_split_2
I1130 22:09:35.190860 11845 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:09:35.190944 11845 net.cpp:150] Setting up landmark_pred
I1130 22:09:35.190949 11845 net.cpp:157] Top shape: 4 10 (40)
I1130 22:09:35.190951 11845 net.cpp:165] Memory required for data: 681392
I1130 22:09:35.190958 11845 layer_factory.hpp:77] Creating layer loss
I1130 22:09:35.190963 11845 net.cpp:100] Creating Layer loss
I1130 22:09:35.190966 11845 net.cpp:434] loss <- score
I1130 22:09:35.190969 11845 net.cpp:434] loss <- bbox_pred
I1130 22:09:35.190973 11845 net.cpp:434] loss <- landmark_pred
I1130 22:09:35.190976 11845 net.cpp:434] loss <- bbox_target
I1130 22:09:35.190982 11845 net.cpp:434] loss <- landmark_target
I1130 22:09:35.190985 11845 net.cpp:434] loss <- label
I1130 22:09:35.190991 11845 net.cpp:408] loss -> face_cls_loss
I1130 22:09:35.190997 11845 net.cpp:408] loss -> bbox_reg_loss
I1130 22:09:35.191002 11845 net.cpp:408] loss -> landmark_reg_loss
I1130 22:09:35.191009 11845 net.cpp:408] loss -> face_cls_neg_acc
I1130 22:09:35.191014 11845 net.cpp:408] loss -> face_cls_pos_acc
I1130 22:09:35.191089 11845 net.cpp:150] Setting up loss
I1130 22:09:35.191097 11845 net.cpp:157] Top shape: (1)
I1130 22:09:35.191100 11845 net.cpp:160]     with loss weight 1
I1130 22:09:35.191105 11845 net.cpp:157] Top shape: (1)
I1130 22:09:35.191107 11845 net.cpp:160]     with loss weight 0.5
I1130 22:09:35.191112 11845 net.cpp:157] Top shape: (1)
I1130 22:09:35.191113 11845 net.cpp:160]     with loss weight 1
I1130 22:09:35.191117 11845 net.cpp:157] Top shape: (1)
I1130 22:09:35.191119 11845 net.cpp:157] Top shape: (1)
I1130 22:09:35.191121 11845 net.cpp:165] Memory required for data: 681412
I1130 22:09:35.191124 11845 net.cpp:226] loss needs backward computation.
I1130 22:09:35.191129 11845 net.cpp:226] landmark_pred needs backward computation.
I1130 22:09:35.191133 11845 net.cpp:226] bbox_pred needs backward computation.
I1130 22:09:35.191134 11845 net.cpp:226] score needs backward computation.
I1130 22:09:35.191138 11845 net.cpp:226] fc_prelu4_0_split needs backward computation.
I1130 22:09:35.191140 11845 net.cpp:226] prelu4 needs backward computation.
I1130 22:09:35.191143 11845 net.cpp:226] fc needs backward computation.
I1130 22:09:35.191145 11845 net.cpp:226] prelu3 needs backward computation.
I1130 22:09:35.191148 11845 net.cpp:226] conv3 needs backward computation.
I1130 22:09:35.191150 11845 net.cpp:226] pool2 needs backward computation.
I1130 22:09:35.191154 11845 net.cpp:226] prelu2 needs backward computation.
I1130 22:09:35.191155 11845 net.cpp:226] conv2 needs backward computation.
I1130 22:09:35.191159 11845 net.cpp:226] pool1 needs backward computation.
I1130 22:09:35.191161 11845 net.cpp:226] prelu1 needs backward computation.
I1130 22:09:35.191164 11845 net.cpp:226] conv1 needs backward computation.
I1130 22:09:35.191167 11845 net.cpp:228] data does not need backward computation.
I1130 22:09:35.191169 11845 net.cpp:270] This network produces output bbox_reg_loss
I1130 22:09:35.191172 11845 net.cpp:270] This network produces output face_cls_loss
I1130 22:09:35.191175 11845 net.cpp:270] This network produces output face_cls_neg_acc
I1130 22:09:35.191179 11845 net.cpp:270] This network produces output face_cls_pos_acc
I1130 22:09:35.191180 11845 net.cpp:270] This network produces output landmark_reg_loss
I1130 22:09:35.191193 11845 net.cpp:283] Network initialization done.
I1130 22:09:35.191231 11845 solver.cpp:60] Solver scaffolding done.
Namespace(epoch=40, gpu=0, lr=0.01, lrp=10, lrw=0.1, net='r', size=64, snapshot=None)
I1130 22:09:35.208216 11845 solver.cpp:279] Solving rNet
I1130 22:09:35.208264 11845 solver.cpp:280] Learning Rate Policy: step
I1130 22:09:35.275794 11845 solver.cpp:228] Iteration 0, loss = 0.987914
I1130 22:09:35.275873 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0379053 (* 0.5 = 0.0189526 loss)
I1130 22:09:35.275892 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.390344 (* 1 = 0.390344 loss)
I1130 22:09:35.275903 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.473958
I1130 22:09:35.275913 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.6875
I1130 22:09:35.275925 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.578617 (* 1 = 0.578617 loss)
I1130 22:09:35.275943 11845 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I1130 22:09:39.242579 11845 solver.cpp:228] Iteration 500, loss = 0.255459
I1130 22:09:39.242642 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0144052 (* 0.5 = 0.00720259 loss)
I1130 22:09:39.242650 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.215688 (* 1 = 0.215688 loss)
I1130 22:09:39.242667 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:09:39.242671 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.421875
I1130 22:09:39.242676 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0117559 (* 1 = 0.0117559 loss)
I1130 22:09:39.242681 11845 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I1130 22:09:42.854316 11845 solver.cpp:228] Iteration 1000, loss = 0.166837
I1130 22:09:42.854380 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0121087 (* 0.5 = 0.00605434 loss)
I1130 22:09:42.854388 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.130828 (* 1 = 0.130828 loss)
I1130 22:09:42.854393 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.947917
I1130 22:09:42.854396 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 22:09:42.854400 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00764218 (* 1 = 0.00764218 loss)
I1130 22:09:42.854405 11845 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I1130 22:09:46.471806 11845 solver.cpp:228] Iteration 1500, loss = 0.132263
I1130 22:09:46.471868 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.01373 (* 0.5 = 0.00686501 loss)
I1130 22:09:46.471876 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.126098 (* 1 = 0.126098 loss)
I1130 22:09:46.471880 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:09:46.471884 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.75
I1130 22:09:46.471889 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00587785 (* 1 = 0.00587785 loss)
I1130 22:09:46.471894 11845 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I1130 22:09:50.081235 11845 solver.cpp:228] Iteration 2000, loss = 0.105525
I1130 22:09:50.081295 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0123729 (* 0.5 = 0.00618647 loss)
I1130 22:09:50.081303 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.103415 (* 1 = 0.103415 loss)
I1130 22:09:50.081307 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:09:50.081311 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.671875
I1130 22:09:50.081316 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00631512 (* 1 = 0.00631512 loss)
I1130 22:09:50.081321 11845 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I1130 22:09:53.691280 11845 solver.cpp:228] Iteration 2500, loss = 0.115305
I1130 22:09:53.691346 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0113818 (* 0.5 = 0.00569088 loss)
I1130 22:09:53.691354 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0748518 (* 1 = 0.0748518 loss)
I1130 22:09:53.691359 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:09:53.691362 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 22:09:53.691367 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00359984 (* 1 = 0.00359984 loss)
I1130 22:09:53.691373 11845 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I1130 22:09:57.301054 11845 solver.cpp:228] Iteration 3000, loss = 0.101211
I1130 22:09:57.301108 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0107284 (* 0.5 = 0.00536419 loss)
I1130 22:09:57.301115 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0889736 (* 1 = 0.0889736 loss)
I1130 22:09:57.301120 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:09:57.301123 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 22:09:57.301128 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00639304 (* 1 = 0.00639304 loss)
I1130 22:09:57.301133 11845 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I1130 22:10:00.929157 11845 solver.cpp:228] Iteration 3500, loss = 0.0822164
I1130 22:10:00.929219 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0109967 (* 0.5 = 0.00549837 loss)
I1130 22:10:00.929240 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0947462 (* 1 = 0.0947462 loss)
I1130 22:10:00.929245 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.953125
I1130 22:10:00.929250 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:10:00.929253 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00298601 (* 1 = 0.00298601 loss)
I1130 22:10:00.929258 11845 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I1130 22:10:04.536361 11845 solver.cpp:228] Iteration 4000, loss = 0.0943143
I1130 22:10:04.536427 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0109927 (* 0.5 = 0.00549636 loss)
I1130 22:10:04.536435 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0944023 (* 1 = 0.0944023 loss)
I1130 22:10:04.536439 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:10:04.536443 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.765625
I1130 22:10:04.536448 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00580103 (* 1 = 0.00580103 loss)
I1130 22:10:04.536453 11845 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I1130 22:10:08.160989 11845 solver.cpp:228] Iteration 4500, loss = 0.0879582
I1130 22:10:08.161042 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.011571 (* 0.5 = 0.00578548 loss)
I1130 22:10:08.161051 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.10621 (* 1 = 0.10621 loss)
I1130 22:10:08.161054 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:10:08.161059 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 22:10:08.161064 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00480512 (* 1 = 0.00480512 loss)
I1130 22:10:08.161077 11845 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I1130 22:10:12.121301 11845 solver.cpp:228] Iteration 5000, loss = 0.0766312
I1130 22:10:12.121373 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0106152 (* 0.5 = 0.00530761 loss)
I1130 22:10:12.121381 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0676261 (* 1 = 0.0676261 loss)
I1130 22:10:12.121387 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:10:12.121392 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:10:12.121397 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00363225 (* 1 = 0.00363225 loss)
I1130 22:10:12.121405 11845 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I1130 22:10:16.776020 11845 solver.cpp:228] Iteration 5500, loss = 0.0804181
I1130 22:10:16.776095 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00833449 (* 0.5 = 0.00416724 loss)
I1130 22:10:16.776105 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0610549 (* 1 = 0.0610549 loss)
I1130 22:10:16.776110 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:10:16.776114 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 22:10:16.776119 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0034303 (* 1 = 0.0034303 loss)
I1130 22:10:16.776135 11845 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I1130 22:10:20.789855 11845 solver.cpp:228] Iteration 6000, loss = 0.0790206
I1130 22:10:20.789918 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.01216 (* 0.5 = 0.00608002 loss)
I1130 22:10:20.789934 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0572109 (* 1 = 0.0572109 loss)
I1130 22:10:20.789939 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:10:20.789943 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:10:20.789948 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00342574 (* 1 = 0.00342574 loss)
I1130 22:10:20.789957 11845 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I1130 22:10:24.799716 11845 solver.cpp:228] Iteration 6500, loss = 0.0695419
I1130 22:10:24.799814 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0103181 (* 0.5 = 0.00515903 loss)
I1130 22:10:24.799823 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.05769 (* 1 = 0.05769 loss)
I1130 22:10:24.799826 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:10:24.799830 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:10:24.799835 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00213614 (* 1 = 0.00213614 loss)
I1130 22:10:24.799842 11845 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I1130 22:10:27.325644 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_6810.caffemodel
I1130 22:10:27.332226 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_6810.solverstate
I1130 22:10:27.332870 11845 solver.cpp:337] Iteration 6810, Testing net (#0)
I1130 22:10:40.504829 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0107099 (* 0.5 = 0.00535495 loss)
I1130 22:10:40.504887 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0756758 (* 1 = 0.0756758 loss)
I1130 22:10:40.504899 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.987917
I1130 22:10:40.504907 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.84951
I1130 22:10:40.504917 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00313847 (* 1 = 0.00313847 loss)
I1130 22:10:42.003330 11845 solver.cpp:228] Iteration 7000, loss = 0.0767489
I1130 22:10:42.003378 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00953359 (* 0.5 = 0.0047668 loss)
I1130 22:10:42.003387 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0633849 (* 1 = 0.0633849 loss)
I1130 22:10:42.003392 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:10:42.003397 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:10:42.003403 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00366967 (* 1 = 0.00366967 loss)
I1130 22:10:42.003408 11845 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I1130 22:10:45.657366 11845 solver.cpp:228] Iteration 7500, loss = 0.075522
I1130 22:10:45.657405 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00973008 (* 0.5 = 0.00486504 loss)
I1130 22:10:45.657413 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0514349 (* 1 = 0.0514349 loss)
I1130 22:10:45.657416 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:10:45.657420 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:10:45.657424 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00510029 (* 1 = 0.00510029 loss)
I1130 22:10:45.657429 11845 sgd_solver.cpp:106] Iteration 7500, lr = 0.01
I1130 22:10:49.280019 11845 solver.cpp:228] Iteration 8000, loss = 0.0692364
I1130 22:10:49.280057 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00799429 (* 0.5 = 0.00399714 loss)
I1130 22:10:49.280064 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0517371 (* 1 = 0.0517371 loss)
I1130 22:10:49.280073 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:10:49.280077 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:10:49.280082 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00252378 (* 1 = 0.00252378 loss)
I1130 22:10:49.280086 11845 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I1130 22:10:52.898789 11845 solver.cpp:228] Iteration 8500, loss = 0.0735482
I1130 22:10:52.898835 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0119785 (* 0.5 = 0.00598924 loss)
I1130 22:10:52.898843 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.11682 (* 1 = 0.11682 loss)
I1130 22:10:52.898846 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:10:52.898849 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.71875
I1130 22:10:52.898867 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00206609 (* 1 = 0.00206609 loss)
I1130 22:10:52.898872 11845 sgd_solver.cpp:106] Iteration 8500, lr = 0.01
I1130 22:10:56.522948 11845 solver.cpp:228] Iteration 9000, loss = 0.0744375
I1130 22:10:56.522989 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0115173 (* 0.5 = 0.00575867 loss)
I1130 22:10:56.522994 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.07234 (* 1 = 0.07234 loss)
I1130 22:10:56.522999 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:10:56.523002 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:10:56.523006 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00476383 (* 1 = 0.00476383 loss)
I1130 22:10:56.523010 11845 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I1130 22:11:00.336369 11845 solver.cpp:228] Iteration 9500, loss = 0.0673613
I1130 22:11:00.336465 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00861314 (* 0.5 = 0.00430657 loss)
I1130 22:11:00.336473 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0192756 (* 1 = 0.0192756 loss)
I1130 22:11:00.336477 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:11:00.336482 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:11:00.336486 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00222852 (* 1 = 0.00222852 loss)
I1130 22:11:00.336491 11845 sgd_solver.cpp:106] Iteration 9500, lr = 0.01
I1130 22:11:04.220767 11845 solver.cpp:228] Iteration 10000, loss = 0.0659413
I1130 22:11:04.220850 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00849378 (* 0.5 = 0.00424689 loss)
I1130 22:11:04.220857 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0780099 (* 1 = 0.0780099 loss)
I1130 22:11:04.220861 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:11:04.220865 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:11:04.220870 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00205383 (* 1 = 0.00205383 loss)
I1130 22:11:04.220875 11845 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I1130 22:11:07.897490 11845 solver.cpp:228] Iteration 10500, loss = 0.068013
I1130 22:11:07.897550 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00981094 (* 0.5 = 0.00490547 loss)
I1130 22:11:07.897557 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0784802 (* 1 = 0.0784802 loss)
I1130 22:11:07.897562 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:11:07.897565 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 22:11:07.897570 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0024461 (* 1 = 0.0024461 loss)
I1130 22:11:07.897575 11845 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I1130 22:11:12.079557 11845 solver.cpp:228] Iteration 11000, loss = 0.0721018
I1130 22:11:12.079624 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00960857 (* 0.5 = 0.00480428 loss)
I1130 22:11:12.079632 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0398433 (* 1 = 0.0398433 loss)
I1130 22:11:12.079638 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:11:12.079641 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:11:12.079646 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00239242 (* 1 = 0.00239242 loss)
I1130 22:11:12.079653 11845 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I1130 22:11:15.738731 11845 solver.cpp:228] Iteration 11500, loss = 0.0641818
I1130 22:11:15.738792 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00723826 (* 0.5 = 0.00361913 loss)
I1130 22:11:15.738800 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0703383 (* 1 = 0.0703383 loss)
I1130 22:11:15.738804 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:11:15.738821 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:11:15.738827 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00274619 (* 1 = 0.00274619 loss)
I1130 22:11:15.738833 11845 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I1130 22:11:19.404315 11845 solver.cpp:228] Iteration 12000, loss = 0.0645879
I1130 22:11:19.404376 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0105824 (* 0.5 = 0.00529121 loss)
I1130 22:11:19.404382 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0526726 (* 1 = 0.0526726 loss)
I1130 22:11:19.404386 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:11:19.404392 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:11:19.404397 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00189212 (* 1 = 0.00189212 loss)
I1130 22:11:19.404402 11845 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I1130 22:11:23.066229 11845 solver.cpp:228] Iteration 12500, loss = 0.0657339
I1130 22:11:23.066294 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00883007 (* 0.5 = 0.00441504 loss)
I1130 22:11:23.066303 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0246398 (* 1 = 0.0246398 loss)
I1130 22:11:23.066306 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:11:23.066311 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:11:23.066316 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00323939 (* 1 = 0.00323939 loss)
I1130 22:11:23.066323 11845 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I1130 22:11:26.737354 11845 solver.cpp:228] Iteration 13000, loss = 0.0617498
I1130 22:11:26.737419 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0093944 (* 0.5 = 0.0046972 loss)
I1130 22:11:26.737427 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0405367 (* 1 = 0.0405367 loss)
I1130 22:11:26.737432 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:11:26.737435 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:11:26.737440 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00453264 (* 1 = 0.00453264 loss)
I1130 22:11:26.737447 11845 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I1130 22:11:30.402729 11845 solver.cpp:228] Iteration 13500, loss = 0.064883
I1130 22:11:30.402801 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0085581 (* 0.5 = 0.00427905 loss)
I1130 22:11:30.402808 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0497938 (* 1 = 0.0497938 loss)
I1130 22:11:30.402812 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:11:30.402817 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:11:30.402822 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00238428 (* 1 = 0.00238428 loss)
I1130 22:11:30.402828 11845 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I1130 22:11:31.275403 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_13620.caffemodel
I1130 22:11:31.281081 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_13620.solverstate
I1130 22:11:31.281711 11845 solver.cpp:337] Iteration 13620, Testing net (#0)
I1130 22:11:43.700755 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00958163 (* 0.5 = 0.00479082 loss)
I1130 22:11:43.700824 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0635536 (* 1 = 0.0635536 loss)
I1130 22:11:43.700829 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.988276
I1130 22:11:43.700834 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.882659
I1130 22:11:43.700840 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.0026639 (* 1 = 0.0026639 loss)
I1130 22:11:46.576660 11845 solver.cpp:228] Iteration 14000, loss = 0.0630405
I1130 22:11:46.576719 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00943883 (* 0.5 = 0.00471941 loss)
I1130 22:11:46.576726 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0563175 (* 1 = 0.0563175 loss)
I1130 22:11:46.576730 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:11:46.576735 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:11:46.576738 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00352322 (* 1 = 0.00352322 loss)
I1130 22:11:46.576742 11845 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I1130 22:11:50.259596 11845 solver.cpp:228] Iteration 14500, loss = 0.0564747
I1130 22:11:50.259641 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0112037 (* 0.5 = 0.00560186 loss)
I1130 22:11:50.259649 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0387237 (* 1 = 0.0387237 loss)
I1130 22:11:50.259652 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:11:50.259656 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:11:50.259660 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00195016 (* 1 = 0.00195016 loss)
I1130 22:11:50.259665 11845 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I1130 22:11:53.944653 11845 solver.cpp:228] Iteration 15000, loss = 0.0597898
I1130 22:11:53.944711 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00786066 (* 0.5 = 0.00393033 loss)
I1130 22:11:53.944720 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0290541 (* 1 = 0.0290541 loss)
I1130 22:11:53.944723 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:11:53.944727 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:11:53.944733 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00219236 (* 1 = 0.00219236 loss)
I1130 22:11:53.944739 11845 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I1130 22:11:57.600101 11845 solver.cpp:228] Iteration 15500, loss = 0.0645598
I1130 22:11:57.600162 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0107266 (* 0.5 = 0.00536329 loss)
I1130 22:11:57.600170 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0504243 (* 1 = 0.0504243 loss)
I1130 22:11:57.600174 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:11:57.600179 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:11:57.600184 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00200179 (* 1 = 0.00200179 loss)
I1130 22:11:57.600190 11845 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I1130 22:12:01.259979 11845 solver.cpp:228] Iteration 16000, loss = 0.0572414
I1130 22:12:01.260048 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0102295 (* 0.5 = 0.00511473 loss)
I1130 22:12:01.260056 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0661876 (* 1 = 0.0661876 loss)
I1130 22:12:01.260061 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:12:01.260064 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:12:01.260077 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00190611 (* 1 = 0.00190611 loss)
I1130 22:12:01.260083 11845 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I1130 22:12:04.920312 11845 solver.cpp:228] Iteration 16500, loss = 0.0612713
I1130 22:12:04.920374 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00890884 (* 0.5 = 0.00445442 loss)
I1130 22:12:04.920382 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0496858 (* 1 = 0.0496858 loss)
I1130 22:12:04.920387 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:12:04.920390 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:12:04.920395 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00234691 (* 1 = 0.00234691 loss)
I1130 22:12:04.920415 11845 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I1130 22:12:08.580271 11845 solver.cpp:228] Iteration 17000, loss = 0.067859
I1130 22:12:08.580334 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00870475 (* 0.5 = 0.00435238 loss)
I1130 22:12:08.580343 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0776638 (* 1 = 0.0776638 loss)
I1130 22:12:08.580346 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:12:08.580350 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 22:12:08.580355 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00223802 (* 1 = 0.00223802 loss)
I1130 22:12:08.580361 11845 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I1130 22:12:12.236133 11845 solver.cpp:228] Iteration 17500, loss = 0.0572419
I1130 22:12:12.236196 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0109733 (* 0.5 = 0.00548663 loss)
I1130 22:12:12.236202 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.085298 (* 1 = 0.085298 loss)
I1130 22:12:12.236207 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:12:12.236212 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 22:12:12.236217 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00158236 (* 1 = 0.00158236 loss)
I1130 22:12:12.236222 11845 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I1130 22:12:15.892213 11845 solver.cpp:228] Iteration 18000, loss = 0.0580756
I1130 22:12:15.892280 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00940342 (* 0.5 = 0.00470171 loss)
I1130 22:12:15.892288 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0343715 (* 1 = 0.0343715 loss)
I1130 22:12:15.892292 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:12:15.892297 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:12:15.892302 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00245806 (* 1 = 0.00245806 loss)
I1130 22:12:15.892307 11845 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I1130 22:12:19.547523 11845 solver.cpp:228] Iteration 18500, loss = 0.0617332
I1130 22:12:19.547583 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00977834 (* 0.5 = 0.00488917 loss)
I1130 22:12:19.547591 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0226549 (* 1 = 0.0226549 loss)
I1130 22:12:19.547595 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:12:19.547600 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:12:19.547605 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0018076 (* 1 = 0.0018076 loss)
I1130 22:12:19.547610 11845 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I1130 22:12:23.203835 11845 solver.cpp:228] Iteration 19000, loss = 0.0555327
I1130 22:12:23.203897 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00876437 (* 0.5 = 0.00438218 loss)
I1130 22:12:23.203905 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0709485 (* 1 = 0.0709485 loss)
I1130 22:12:23.203909 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:12:23.203913 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:12:23.203918 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00238886 (* 1 = 0.00238886 loss)
I1130 22:12:23.203924 11845 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I1130 22:12:26.867710 11845 solver.cpp:228] Iteration 19500, loss = 0.0624354
I1130 22:12:26.867772 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00757096 (* 0.5 = 0.00378548 loss)
I1130 22:12:26.867779 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0543266 (* 1 = 0.0543266 loss)
I1130 22:12:26.867784 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:12:26.867787 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:12:26.867806 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00230405 (* 1 = 0.00230405 loss)
I1130 22:12:26.867812 11845 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I1130 22:12:30.541625 11845 solver.cpp:228] Iteration 20000, loss = 0.0606795
I1130 22:12:30.541695 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00975937 (* 0.5 = 0.00487968 loss)
I1130 22:12:30.541702 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0510689 (* 1 = 0.0510689 loss)
I1130 22:12:30.541707 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:12:30.541710 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:12:30.541715 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00322665 (* 1 = 0.00322665 loss)
I1130 22:12:30.541723 11845 sgd_solver.cpp:106] Iteration 20000, lr = 0.01
I1130 22:12:33.688556 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_20430.caffemodel
I1130 22:12:33.694257 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_20430.solverstate
I1130 22:12:33.694891 11845 solver.cpp:337] Iteration 20430, Testing net (#0)
I1130 22:12:44.435087 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00908341 (* 0.5 = 0.00454171 loss)
I1130 22:12:44.435127 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0609873 (* 1 = 0.0609873 loss)
I1130 22:12:44.435133 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.99416
I1130 22:12:44.435137 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.869091
I1130 22:12:44.435142 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00228393 (* 1 = 0.00228393 loss)
I1130 22:12:44.947625 11845 solver.cpp:228] Iteration 20500, loss = 0.0517186
I1130 22:12:44.947682 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0101883 (* 0.5 = 0.00509416 loss)
I1130 22:12:44.947690 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0670494 (* 1 = 0.0670494 loss)
I1130 22:12:44.947695 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:12:44.947698 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 22:12:44.947703 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00297057 (* 1 = 0.00297057 loss)
I1130 22:12:44.947710 11845 sgd_solver.cpp:106] Iteration 20500, lr = 0.01
I1130 22:12:48.640223 11845 solver.cpp:228] Iteration 21000, loss = 0.0605782
I1130 22:12:48.640285 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00928833 (* 0.5 = 0.00464416 loss)
I1130 22:12:48.640292 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0391458 (* 1 = 0.0391458 loss)
I1130 22:12:48.640296 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:12:48.640300 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:12:48.640305 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.001744 (* 1 = 0.001744 loss)
I1130 22:12:48.640311 11845 sgd_solver.cpp:106] Iteration 21000, lr = 0.01
I1130 22:12:52.276017 11845 solver.cpp:228] Iteration 21500, loss = 0.0626371
I1130 22:12:52.276113 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0100306 (* 0.5 = 0.0050153 loss)
I1130 22:12:52.276124 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0792867 (* 1 = 0.0792867 loss)
I1130 22:12:52.276127 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:12:52.276132 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 22:12:52.276137 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00185811 (* 1 = 0.00185811 loss)
I1130 22:12:52.276149 11845 sgd_solver.cpp:106] Iteration 21500, lr = 0.01
I1130 22:12:55.905124 11845 solver.cpp:228] Iteration 22000, loss = 0.0494373
I1130 22:12:55.905185 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0091553 (* 0.5 = 0.00457765 loss)
I1130 22:12:55.905208 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0609339 (* 1 = 0.0609339 loss)
I1130 22:12:55.905212 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:12:55.905216 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:12:55.905221 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00122498 (* 1 = 0.00122498 loss)
I1130 22:12:55.905227 11845 sgd_solver.cpp:106] Iteration 22000, lr = 0.01
I1130 22:12:59.532776 11845 solver.cpp:228] Iteration 22500, loss = 0.058203
I1130 22:12:59.532841 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00961305 (* 0.5 = 0.00480652 loss)
I1130 22:12:59.532848 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0442022 (* 1 = 0.0442022 loss)
I1130 22:12:59.532853 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:12:59.532857 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:12:59.532862 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00222444 (* 1 = 0.00222444 loss)
I1130 22:12:59.532868 11845 sgd_solver.cpp:106] Iteration 22500, lr = 0.01
I1130 22:13:03.159986 11845 solver.cpp:228] Iteration 23000, loss = 0.0593519
I1130 22:13:03.160048 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00804657 (* 0.5 = 0.00402328 loss)
I1130 22:13:03.160055 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0612485 (* 1 = 0.0612485 loss)
I1130 22:13:03.160059 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:13:03.160063 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:13:03.160073 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00245356 (* 1 = 0.00245356 loss)
I1130 22:13:03.160081 11845 sgd_solver.cpp:106] Iteration 23000, lr = 0.01
I1130 22:13:06.788077 11845 solver.cpp:228] Iteration 23500, loss = 0.0474484
I1130 22:13:06.788141 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00715147 (* 0.5 = 0.00357573 loss)
I1130 22:13:06.788148 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0410924 (* 1 = 0.0410924 loss)
I1130 22:13:06.788152 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:13:06.788156 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:13:06.788161 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00386087 (* 1 = 0.00386087 loss)
I1130 22:13:06.788168 11845 sgd_solver.cpp:106] Iteration 23500, lr = 0.01
I1130 22:13:10.407218 11845 solver.cpp:228] Iteration 24000, loss = 0.0609564
I1130 22:13:10.407281 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00736199 (* 0.5 = 0.00368099 loss)
I1130 22:13:10.407289 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0415978 (* 1 = 0.0415978 loss)
I1130 22:13:10.407294 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:13:10.407297 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:13:10.407302 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00162781 (* 1 = 0.00162781 loss)
I1130 22:13:10.407308 11845 sgd_solver.cpp:106] Iteration 24000, lr = 0.01
I1130 22:13:14.039245 11845 solver.cpp:228] Iteration 24500, loss = 0.0588704
I1130 22:13:14.039314 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00975369 (* 0.5 = 0.00487685 loss)
I1130 22:13:14.039321 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0725191 (* 1 = 0.0725191 loss)
I1130 22:13:14.039326 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:13:14.039330 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:13:14.039335 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00179487 (* 1 = 0.00179487 loss)
I1130 22:13:14.039341 11845 sgd_solver.cpp:106] Iteration 24500, lr = 0.01
I1130 22:13:17.664573 11845 solver.cpp:228] Iteration 25000, loss = 0.0494647
I1130 22:13:17.664638 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00948161 (* 0.5 = 0.0047408 loss)
I1130 22:13:17.664646 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0305945 (* 1 = 0.0305945 loss)
I1130 22:13:17.664650 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:13:17.664654 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:13:17.664659 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00158139 (* 1 = 0.00158139 loss)
I1130 22:13:17.664666 11845 sgd_solver.cpp:106] Iteration 25000, lr = 0.01
I1130 22:13:21.288329 11845 solver.cpp:228] Iteration 25500, loss = 0.0642148
I1130 22:13:21.288393 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00815819 (* 0.5 = 0.00407909 loss)
I1130 22:13:21.288400 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0644116 (* 1 = 0.0644116 loss)
I1130 22:13:21.288404 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:13:21.288408 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:13:21.288414 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0019292 (* 1 = 0.0019292 loss)
I1130 22:13:21.288419 11845 sgd_solver.cpp:106] Iteration 25500, lr = 0.01
I1130 22:13:24.913911 11845 solver.cpp:228] Iteration 26000, loss = 0.060767
I1130 22:13:24.913974 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00778933 (* 0.5 = 0.00389466 loss)
I1130 22:13:24.913981 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0450178 (* 1 = 0.0450178 loss)
I1130 22:13:24.913985 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:13:24.913990 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:13:24.913995 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00189195 (* 1 = 0.00189195 loss)
I1130 22:13:24.914000 11845 sgd_solver.cpp:106] Iteration 26000, lr = 0.01
I1130 22:13:28.538025 11845 solver.cpp:228] Iteration 26500, loss = 0.0478538
I1130 22:13:28.538094 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00823167 (* 0.5 = 0.00411584 loss)
I1130 22:13:28.538102 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0331331 (* 1 = 0.0331331 loss)
I1130 22:13:28.538106 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:13:28.538110 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:13:28.538115 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00105527 (* 1 = 0.00105527 loss)
I1130 22:13:28.538121 11845 sgd_solver.cpp:106] Iteration 26500, lr = 0.01
I1130 22:13:32.165633 11845 solver.cpp:228] Iteration 27000, loss = 0.0575202
I1130 22:13:32.165701 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00932018 (* 0.5 = 0.00466009 loss)
I1130 22:13:32.165709 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0640058 (* 1 = 0.0640058 loss)
I1130 22:13:32.165714 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:13:32.165717 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:13:32.165722 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00319258 (* 1 = 0.00319258 loss)
I1130 22:13:32.165729 11845 sgd_solver.cpp:106] Iteration 27000, lr = 0.01
I1130 22:13:33.897653 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_27240.caffemodel
I1130 22:13:33.903198 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_27240.solverstate
I1130 22:13:33.903833 11845 solver.cpp:337] Iteration 27240, Testing net (#0)
I1130 22:13:45.462491 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00891878 (* 0.5 = 0.00445939 loss)
I1130 22:13:45.462533 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0595324 (* 1 = 0.0595324 loss)
I1130 22:13:45.462553 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.987499
I1130 22:13:45.462558 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.897325
I1130 22:13:45.462561 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00227418 (* 1 = 0.00227418 loss)
I1130 22:13:47.442457 11845 solver.cpp:228] Iteration 27500, loss = 0.0615045
I1130 22:13:47.442519 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00983783 (* 0.5 = 0.00491891 loss)
I1130 22:13:47.442528 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0736524 (* 1 = 0.0736524 loss)
I1130 22:13:47.442531 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:13:47.442535 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:13:47.442540 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00163869 (* 1 = 0.00163869 loss)
I1130 22:13:47.442548 11845 sgd_solver.cpp:106] Iteration 27500, lr = 0.01
I1130 22:13:51.044824 11845 solver.cpp:228] Iteration 28000, loss = 0.0535769
I1130 22:13:51.044893 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00766584 (* 0.5 = 0.00383292 loss)
I1130 22:13:51.044901 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0199638 (* 1 = 0.0199638 loss)
I1130 22:13:51.044905 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:13:51.044910 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:13:51.044915 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00239046 (* 1 = 0.00239046 loss)
I1130 22:13:51.044921 11845 sgd_solver.cpp:106] Iteration 28000, lr = 0.01
I1130 22:13:54.656498 11845 solver.cpp:228] Iteration 28500, loss = 0.055845
I1130 22:13:54.656560 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.01028 (* 0.5 = 0.00514001 loss)
I1130 22:13:54.656569 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0674726 (* 1 = 0.0674726 loss)
I1130 22:13:54.656572 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:13:54.656577 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:13:54.656582 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00361883 (* 1 = 0.00361883 loss)
I1130 22:13:54.656589 11845 sgd_solver.cpp:106] Iteration 28500, lr = 0.01
I1130 22:13:58.258338 11845 solver.cpp:228] Iteration 29000, loss = 0.0542424
I1130 22:13:58.258400 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00707117 (* 0.5 = 0.00353559 loss)
I1130 22:13:58.258409 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0550108 (* 1 = 0.0550108 loss)
I1130 22:13:58.258412 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:13:58.258416 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:13:58.258421 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00181198 (* 1 = 0.00181198 loss)
I1130 22:13:58.258427 11845 sgd_solver.cpp:106] Iteration 29000, lr = 0.01
I1130 22:14:01.858191 11845 solver.cpp:228] Iteration 29500, loss = 0.0510954
I1130 22:14:01.858252 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00971304 (* 0.5 = 0.00485652 loss)
I1130 22:14:01.858259 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0193514 (* 1 = 0.0193514 loss)
I1130 22:14:01.858263 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:14:01.858268 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:14:01.858273 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00150146 (* 1 = 0.00150146 loss)
I1130 22:14:01.858279 11845 sgd_solver.cpp:106] Iteration 29500, lr = 0.01
I1130 22:14:05.469530 11845 solver.cpp:228] Iteration 30000, loss = 0.0578605
I1130 22:14:05.469595 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00822084 (* 0.5 = 0.00411042 loss)
I1130 22:14:05.469602 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0509186 (* 1 = 0.0509186 loss)
I1130 22:14:05.469621 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:14:05.469626 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:14:05.469631 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00172759 (* 1 = 0.00172759 loss)
I1130 22:14:05.469637 11845 sgd_solver.cpp:106] Iteration 30000, lr = 0.01
I1130 22:14:09.071660 11845 solver.cpp:228] Iteration 30500, loss = 0.0556343
I1130 22:14:09.071725 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00924296 (* 0.5 = 0.00462148 loss)
I1130 22:14:09.071733 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0365087 (* 1 = 0.0365087 loss)
I1130 22:14:09.071738 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:14:09.071743 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:14:09.071748 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00123394 (* 1 = 0.00123394 loss)
I1130 22:14:09.071753 11845 sgd_solver.cpp:106] Iteration 30500, lr = 0.01
I1130 22:14:12.669473 11845 solver.cpp:228] Iteration 31000, loss = 0.04995
I1130 22:14:12.669543 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00713542 (* 0.5 = 0.00356771 loss)
I1130 22:14:12.669551 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0144394 (* 1 = 0.0144394 loss)
I1130 22:14:12.669555 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:14:12.669559 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:14:12.669564 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00307484 (* 1 = 0.00307484 loss)
I1130 22:14:12.669570 11845 sgd_solver.cpp:106] Iteration 31000, lr = 0.01
I1130 22:14:16.271435 11845 solver.cpp:228] Iteration 31500, loss = 0.0521434
I1130 22:14:16.271498 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0061031 (* 0.5 = 0.00305155 loss)
I1130 22:14:16.271507 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0294933 (* 1 = 0.0294933 loss)
I1130 22:14:16.271510 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:14:16.271514 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:14:16.271519 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00458828 (* 1 = 0.00458828 loss)
I1130 22:14:16.271525 11845 sgd_solver.cpp:106] Iteration 31500, lr = 0.01
I1130 22:14:19.869755 11845 solver.cpp:228] Iteration 32000, loss = 0.0533733
I1130 22:14:19.869817 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0101425 (* 0.5 = 0.00507123 loss)
I1130 22:14:19.869824 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0418505 (* 1 = 0.0418505 loss)
I1130 22:14:19.869828 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:14:19.869832 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:14:19.869837 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00268808 (* 1 = 0.00268808 loss)
I1130 22:14:19.869843 11845 sgd_solver.cpp:106] Iteration 32000, lr = 0.01
I1130 22:14:23.476590 11845 solver.cpp:228] Iteration 32500, loss = 0.0544517
I1130 22:14:23.476657 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00820477 (* 0.5 = 0.00410238 loss)
I1130 22:14:23.476665 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0538755 (* 1 = 0.0538755 loss)
I1130 22:14:23.476670 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:14:23.476673 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:14:23.476678 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0023633 (* 1 = 0.0023633 loss)
I1130 22:14:23.476685 11845 sgd_solver.cpp:106] Iteration 32500, lr = 0.01
I1130 22:14:27.074061 11845 solver.cpp:228] Iteration 33000, loss = 0.0529274
I1130 22:14:27.074146 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00814894 (* 0.5 = 0.00407447 loss)
I1130 22:14:27.074153 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0260178 (* 1 = 0.0260178 loss)
I1130 22:14:27.074157 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:14:27.074162 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:14:27.074167 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00174409 (* 1 = 0.00174409 loss)
I1130 22:14:27.074172 11845 sgd_solver.cpp:106] Iteration 33000, lr = 0.01
I1130 22:14:30.678849 11845 solver.cpp:228] Iteration 33500, loss = 0.0541194
I1130 22:14:30.678927 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00757632 (* 0.5 = 0.00378816 loss)
I1130 22:14:30.678936 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0379395 (* 1 = 0.0379395 loss)
I1130 22:14:30.678939 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:14:30.678943 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:14:30.678948 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00232463 (* 1 = 0.00232463 loss)
I1130 22:14:30.678954 11845 sgd_solver.cpp:106] Iteration 33500, lr = 0.01
I1130 22:14:34.305892 11845 solver.cpp:228] Iteration 34000, loss = 0.060075
I1130 22:14:34.305955 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00777045 (* 0.5 = 0.00388522 loss)
I1130 22:14:34.305963 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0233469 (* 1 = 0.0233469 loss)
I1130 22:14:34.305966 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:14:34.305970 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:14:34.305975 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00137676 (* 1 = 0.00137676 loss)
I1130 22:14:34.305981 11845 sgd_solver.cpp:106] Iteration 34000, lr = 0.01
I1130 22:14:34.662149 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_34050.caffemodel
I1130 22:14:34.667752 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_34050.solverstate
I1130 22:14:34.668408 11845 solver.cpp:337] Iteration 34050, Testing net (#0)
I1130 22:14:45.495352 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00896976 (* 0.5 = 0.00448488 loss)
I1130 22:14:45.495391 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0620491 (* 1 = 0.0620491 loss)
I1130 22:14:45.495396 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.996096
I1130 22:14:45.495399 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.866466
I1130 22:14:45.495404 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00208278 (* 1 = 0.00208278 loss)
I1130 22:14:48.813598 11845 solver.cpp:228] Iteration 34500, loss = 0.0514569
I1130 22:14:48.813655 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00914413 (* 0.5 = 0.00457207 loss)
I1130 22:14:48.813663 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.056003 (* 1 = 0.056003 loss)
I1130 22:14:48.813668 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:14:48.813671 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:14:48.813675 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0016701 (* 1 = 0.0016701 loss)
I1130 22:14:48.813683 11845 sgd_solver.cpp:106] Iteration 34500, lr = 0.01
I1130 22:14:52.416270 11845 solver.cpp:228] Iteration 35000, loss = 0.0510515
I1130 22:14:52.416339 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00803192 (* 0.5 = 0.00401596 loss)
I1130 22:14:52.416347 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0388384 (* 1 = 0.0388384 loss)
I1130 22:14:52.416350 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:14:52.416354 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:14:52.416373 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00182101 (* 1 = 0.00182101 loss)
I1130 22:14:52.416380 11845 sgd_solver.cpp:106] Iteration 35000, lr = 0.01
I1130 22:14:56.016443 11845 solver.cpp:228] Iteration 35500, loss = 0.0574649
I1130 22:14:56.016507 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00739463 (* 0.5 = 0.00369731 loss)
I1130 22:14:56.016515 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0248933 (* 1 = 0.0248933 loss)
I1130 22:14:56.016520 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:14:56.016523 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:14:56.016528 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00199652 (* 1 = 0.00199652 loss)
I1130 22:14:56.016535 11845 sgd_solver.cpp:106] Iteration 35500, lr = 0.01
I1130 22:14:59.620616 11845 solver.cpp:228] Iteration 36000, loss = 0.0544115
I1130 22:14:59.620682 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00882775 (* 0.5 = 0.00441387 loss)
I1130 22:14:59.620689 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0501591 (* 1 = 0.0501591 loss)
I1130 22:14:59.620693 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:14:59.620697 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:14:59.620702 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00184848 (* 1 = 0.00184848 loss)
I1130 22:14:59.620709 11845 sgd_solver.cpp:106] Iteration 36000, lr = 0.01
I1130 22:15:03.220305 11845 solver.cpp:228] Iteration 36500, loss = 0.0529869
I1130 22:15:03.220369 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00977531 (* 0.5 = 0.00488766 loss)
I1130 22:15:03.220377 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0509388 (* 1 = 0.0509388 loss)
I1130 22:15:03.220381 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:15:03.220386 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:15:03.220391 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00162005 (* 1 = 0.00162005 loss)
I1130 22:15:03.220397 11845 sgd_solver.cpp:106] Iteration 36500, lr = 0.01
I1130 22:15:06.816129 11845 solver.cpp:228] Iteration 37000, loss = 0.0564907
I1130 22:15:06.816193 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00852512 (* 0.5 = 0.00426256 loss)
I1130 22:15:06.816201 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0256286 (* 1 = 0.0256286 loss)
I1130 22:15:06.816205 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:15:06.816210 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:15:06.816215 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0020771 (* 1 = 0.0020771 loss)
I1130 22:15:06.816221 11845 sgd_solver.cpp:106] Iteration 37000, lr = 0.01
I1130 22:15:10.416726 11845 solver.cpp:228] Iteration 37500, loss = 0.0476853
I1130 22:15:10.416796 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00857973 (* 0.5 = 0.00428987 loss)
I1130 22:15:10.416805 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0635517 (* 1 = 0.0635517 loss)
I1130 22:15:10.416808 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:15:10.416812 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:15:10.416817 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00194957 (* 1 = 0.00194957 loss)
I1130 22:15:10.416822 11845 sgd_solver.cpp:106] Iteration 37500, lr = 0.01
I1130 22:15:14.024318 11845 solver.cpp:228] Iteration 38000, loss = 0.0531994
I1130 22:15:14.024381 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00539561 (* 0.5 = 0.00269781 loss)
I1130 22:15:14.024389 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0406812 (* 1 = 0.0406812 loss)
I1130 22:15:14.024394 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:15:14.024412 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:15:14.024418 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00279071 (* 1 = 0.00279071 loss)
I1130 22:15:14.024423 11845 sgd_solver.cpp:106] Iteration 38000, lr = 0.01
I1130 22:15:17.620195 11845 solver.cpp:228] Iteration 38500, loss = 0.0570881
I1130 22:15:17.620259 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00687161 (* 0.5 = 0.0034358 loss)
I1130 22:15:17.620266 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0288099 (* 1 = 0.0288099 loss)
I1130 22:15:17.620270 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:15:17.620275 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:15:17.620280 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00188894 (* 1 = 0.00188894 loss)
I1130 22:15:17.620285 11845 sgd_solver.cpp:106] Iteration 38500, lr = 0.01
I1130 22:15:21.218124 11845 solver.cpp:228] Iteration 39000, loss = 0.0446572
I1130 22:15:21.218189 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0122407 (* 0.5 = 0.00612037 loss)
I1130 22:15:21.218195 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0585466 (* 1 = 0.0585466 loss)
I1130 22:15:21.218199 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:15:21.218204 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:15:21.218209 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00232525 (* 1 = 0.00232525 loss)
I1130 22:15:21.218214 11845 sgd_solver.cpp:106] Iteration 39000, lr = 0.01
I1130 22:15:24.844200 11845 solver.cpp:228] Iteration 39500, loss = 0.0524852
I1130 22:15:24.844283 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00871675 (* 0.5 = 0.00435837 loss)
I1130 22:15:24.844292 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0472122 (* 1 = 0.0472122 loss)
I1130 22:15:24.844297 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:15:24.844301 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:15:24.844308 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00142529 (* 1 = 0.00142529 loss)
I1130 22:15:24.844319 11845 sgd_solver.cpp:106] Iteration 39500, lr = 0.01
I1130 22:15:28.445536 11845 solver.cpp:228] Iteration 40000, loss = 0.0543054
I1130 22:15:28.445600 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00754742 (* 0.5 = 0.00377371 loss)
I1130 22:15:28.445606 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0499444 (* 1 = 0.0499444 loss)
I1130 22:15:28.445611 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:15:28.445614 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:15:28.445619 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00282409 (* 1 = 0.00282409 loss)
I1130 22:15:28.445626 11845 sgd_solver.cpp:106] Iteration 40000, lr = 0.01
I1130 22:15:32.060539 11845 solver.cpp:228] Iteration 40500, loss = 0.0458685
I1130 22:15:32.060613 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00853882 (* 0.5 = 0.00426941 loss)
I1130 22:15:32.060621 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0719225 (* 1 = 0.0719225 loss)
I1130 22:15:32.060626 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:15:32.060629 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:15:32.060634 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00198641 (* 1 = 0.00198641 loss)
I1130 22:15:32.060641 11845 sgd_solver.cpp:106] Iteration 40500, lr = 0.01
I1130 22:15:34.643419 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_40860.caffemodel
I1130 22:15:34.649389 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_40860.solverstate
I1130 22:15:34.650043 11845 solver.cpp:337] Iteration 40860, Testing net (#0)
I1130 22:15:45.425472 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00871279 (* 0.5 = 0.00435639 loss)
I1130 22:15:45.425523 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.056317 (* 1 = 0.056317 loss)
I1130 22:15:45.425529 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.994929
I1130 22:15:45.425534 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.879904
I1130 22:15:45.425539 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00212678 (* 1 = 0.00212678 loss)
I1130 22:15:46.497119 11845 solver.cpp:228] Iteration 41000, loss = 0.0543433
I1130 22:15:46.497170 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00790334 (* 0.5 = 0.00395167 loss)
I1130 22:15:46.497177 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0261428 (* 1 = 0.0261428 loss)
I1130 22:15:46.497181 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:15:46.497185 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:15:46.497190 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00155637 (* 1 = 0.00155637 loss)
I1130 22:15:46.497195 11845 sgd_solver.cpp:106] Iteration 41000, lr = 0.01
I1130 22:15:50.189509 11845 solver.cpp:228] Iteration 41500, loss = 0.0565143
I1130 22:15:50.189550 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0107335 (* 0.5 = 0.00536676 loss)
I1130 22:15:50.189558 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0557076 (* 1 = 0.0557076 loss)
I1130 22:15:50.189563 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:15:50.189565 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:15:50.189570 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00180608 (* 1 = 0.00180608 loss)
I1130 22:15:50.189575 11845 sgd_solver.cpp:106] Iteration 41500, lr = 0.01
I1130 22:15:54.137917 11845 solver.cpp:228] Iteration 42000, loss = 0.0475977
I1130 22:15:54.138000 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00891184 (* 0.5 = 0.00445592 loss)
I1130 22:15:54.138010 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0620631 (* 1 = 0.0620631 loss)
I1130 22:15:54.138015 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:15:54.138020 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:15:54.138025 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00165008 (* 1 = 0.00165008 loss)
I1130 22:15:54.138031 11845 sgd_solver.cpp:106] Iteration 42000, lr = 0.01
I1130 22:15:57.923102 11845 solver.cpp:228] Iteration 42500, loss = 0.0586194
I1130 22:15:57.923158 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00885871 (* 0.5 = 0.00442935 loss)
I1130 22:15:57.923166 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0382789 (* 1 = 0.0382789 loss)
I1130 22:15:57.923169 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:15:57.923173 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:15:57.923178 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00348844 (* 1 = 0.00348844 loss)
I1130 22:15:57.923184 11845 sgd_solver.cpp:106] Iteration 42500, lr = 0.01
I1130 22:16:01.556217 11845 solver.cpp:228] Iteration 43000, loss = 0.053329
I1130 22:16:01.556275 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00669693 (* 0.5 = 0.00334846 loss)
I1130 22:16:01.556283 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0357403 (* 1 = 0.0357403 loss)
I1130 22:16:01.556288 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:16:01.556293 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:16:01.556298 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00176789 (* 1 = 0.00176789 loss)
I1130 22:16:01.556318 11845 sgd_solver.cpp:106] Iteration 43000, lr = 0.01
I1130 22:16:05.191741 11845 solver.cpp:228] Iteration 43500, loss = 0.0431988
I1130 22:16:05.191802 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00856838 (* 0.5 = 0.00428419 loss)
I1130 22:16:05.191810 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0535651 (* 1 = 0.0535651 loss)
I1130 22:16:05.191814 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:16:05.191817 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:16:05.191823 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00231222 (* 1 = 0.00231222 loss)
I1130 22:16:05.191828 11845 sgd_solver.cpp:106] Iteration 43500, lr = 0.01
I1130 22:16:08.822129 11845 solver.cpp:228] Iteration 44000, loss = 0.0583412
I1130 22:16:08.822183 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0101486 (* 0.5 = 0.00507431 loss)
I1130 22:16:08.822190 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0531851 (* 1 = 0.0531851 loss)
I1130 22:16:08.822194 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:16:08.822198 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:16:08.822203 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00133723 (* 1 = 0.00133723 loss)
I1130 22:16:08.822208 11845 sgd_solver.cpp:106] Iteration 44000, lr = 0.01
I1130 22:16:12.528291 11845 solver.cpp:228] Iteration 44500, loss = 0.0565826
I1130 22:16:12.528370 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00698926 (* 0.5 = 0.00349463 loss)
I1130 22:16:12.528380 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0448578 (* 1 = 0.0448578 loss)
I1130 22:16:12.528385 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:16:12.528390 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:16:12.528396 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00258252 (* 1 = 0.00258252 loss)
I1130 22:16:12.528404 11845 sgd_solver.cpp:106] Iteration 44500, lr = 0.01
I1130 22:16:16.277107 11845 solver.cpp:228] Iteration 45000, loss = 0.0450112
I1130 22:16:16.277169 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0078648 (* 0.5 = 0.0039324 loss)
I1130 22:16:16.277179 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0365658 (* 1 = 0.0365658 loss)
I1130 22:16:16.277184 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:16:16.277189 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:16:16.277195 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00356821 (* 1 = 0.00356821 loss)
I1130 22:16:16.277204 11845 sgd_solver.cpp:106] Iteration 45000, lr = 0.01
I1130 22:16:20.013782 11845 solver.cpp:228] Iteration 45500, loss = 0.055938
I1130 22:16:20.013844 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00624197 (* 0.5 = 0.00312099 loss)
I1130 22:16:20.013851 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0519498 (* 1 = 0.0519498 loss)
I1130 22:16:20.013855 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:16:20.013859 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:16:20.013865 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00135364 (* 1 = 0.00135364 loss)
I1130 22:16:20.013872 11845 sgd_solver.cpp:106] Iteration 45500, lr = 0.01
I1130 22:16:23.950162 11845 solver.cpp:228] Iteration 46000, loss = 0.0529135
I1130 22:16:23.950234 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.010161 (* 0.5 = 0.00508048 loss)
I1130 22:16:23.950242 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0935697 (* 1 = 0.0935697 loss)
I1130 22:16:23.950247 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:16:23.950268 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:16:23.950281 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00157733 (* 1 = 0.00157733 loss)
I1130 22:16:23.950289 11845 sgd_solver.cpp:106] Iteration 46000, lr = 0.01
I1130 22:16:27.696065 11845 solver.cpp:228] Iteration 46500, loss = 0.0462666
I1130 22:16:27.696163 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00923975 (* 0.5 = 0.00461988 loss)
I1130 22:16:27.696171 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0393401 (* 1 = 0.0393401 loss)
I1130 22:16:27.696177 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:16:27.696182 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:16:27.696187 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00303477 (* 1 = 0.00303477 loss)
I1130 22:16:27.696194 11845 sgd_solver.cpp:106] Iteration 46500, lr = 0.01
I1130 22:16:31.400044 11845 solver.cpp:228] Iteration 47000, loss = 0.0549762
I1130 22:16:31.400137 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00779589 (* 0.5 = 0.00389794 loss)
I1130 22:16:31.400148 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0655217 (* 1 = 0.0655217 loss)
I1130 22:16:31.400154 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:16:31.400159 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 22:16:31.400166 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00223535 (* 1 = 0.00223535 loss)
I1130 22:16:31.400171 11845 sgd_solver.cpp:106] Iteration 47000, lr = 0.01
I1130 22:16:35.204727 11845 solver.cpp:228] Iteration 47500, loss = 0.0520975
I1130 22:16:35.204808 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00667925 (* 0.5 = 0.00333962 loss)
I1130 22:16:35.204818 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0517117 (* 1 = 0.0517117 loss)
I1130 22:16:35.204821 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:16:35.204825 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:16:35.204840 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00207838 (* 1 = 0.00207838 loss)
I1130 22:16:35.204846 11845 sgd_solver.cpp:106] Iteration 47500, lr = 0.01
I1130 22:16:36.592129 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_47670.caffemodel
I1130 22:16:36.598387 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_47670.solverstate
I1130 22:16:36.599170 11845 solver.cpp:337] Iteration 47670, Testing net (#0)
I1130 22:16:48.344159 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00864914 (* 0.5 = 0.00432457 loss)
I1130 22:16:48.344240 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0536524 (* 1 = 0.0536524 loss)
I1130 22:16:48.344247 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.991065
I1130 22:16:48.344256 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.897418
I1130 22:16:48.344266 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00200527 (* 1 = 0.00200527 loss)
I1130 22:16:50.939585 11845 solver.cpp:228] Iteration 48000, loss = 0.0441238
I1130 22:16:50.939663 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00604156 (* 0.5 = 0.00302078 loss)
I1130 22:16:50.939671 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0216222 (* 1 = 0.0216222 loss)
I1130 22:16:50.939676 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:16:50.939679 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:16:50.939692 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00181279 (* 1 = 0.00181279 loss)
I1130 22:16:50.939698 11845 sgd_solver.cpp:106] Iteration 48000, lr = 0.01
I1130 22:16:54.744112 11845 solver.cpp:228] Iteration 48500, loss = 0.0527905
I1130 22:16:54.744204 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00933781 (* 0.5 = 0.0046689 loss)
I1130 22:16:54.744212 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0568109 (* 1 = 0.0568109 loss)
I1130 22:16:54.744216 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:16:54.744220 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:16:54.744232 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00152805 (* 1 = 0.00152805 loss)
I1130 22:16:54.744240 11845 sgd_solver.cpp:106] Iteration 48500, lr = 0.01
I1130 22:16:58.486971 11845 solver.cpp:228] Iteration 49000, loss = 0.0527311
I1130 22:16:58.487048 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00660674 (* 0.5 = 0.00330337 loss)
I1130 22:16:58.487056 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0372969 (* 1 = 0.0372969 loss)
I1130 22:16:58.487061 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:16:58.487066 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:16:58.487085 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00202394 (* 1 = 0.00202394 loss)
I1130 22:16:58.487093 11845 sgd_solver.cpp:106] Iteration 49000, lr = 0.01
I1130 22:17:02.348918 11845 solver.cpp:228] Iteration 49500, loss = 0.0477573
I1130 22:17:02.349009 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00970361 (* 0.5 = 0.0048518 loss)
I1130 22:17:02.349016 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0294088 (* 1 = 0.0294088 loss)
I1130 22:17:02.349020 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:17:02.349025 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:17:02.349030 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00179756 (* 1 = 0.00179756 loss)
I1130 22:17:02.349037 11845 sgd_solver.cpp:106] Iteration 49500, lr = 0.01
I1130 22:17:06.088424 11845 solver.cpp:228] Iteration 50000, loss = 0.0532865
I1130 22:17:06.088505 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0080659 (* 0.5 = 0.00403295 loss)
I1130 22:17:06.088515 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0438941 (* 1 = 0.0438941 loss)
I1130 22:17:06.088520 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:17:06.088524 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:17:06.088538 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0017163 (* 1 = 0.0017163 loss)
I1130 22:17:06.088546 11845 sgd_solver.cpp:106] Iteration 50000, lr = 0.01
I1130 22:17:09.889211 11845 solver.cpp:228] Iteration 50500, loss = 0.053386
I1130 22:17:09.889261 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00990881 (* 0.5 = 0.00495441 loss)
I1130 22:17:09.889271 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0524487 (* 1 = 0.0524487 loss)
I1130 22:17:09.889276 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:17:09.889281 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:17:09.889286 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00119513 (* 1 = 0.00119513 loss)
I1130 22:17:09.889292 11845 sgd_solver.cpp:106] Iteration 50500, lr = 0.01
I1130 22:17:13.578147 11845 solver.cpp:228] Iteration 51000, loss = 0.0505765
I1130 22:17:13.578176 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00960228 (* 0.5 = 0.00480114 loss)
I1130 22:17:13.578184 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0386252 (* 1 = 0.0386252 loss)
I1130 22:17:13.578189 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:17:13.578194 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:17:13.578200 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00148754 (* 1 = 0.00148754 loss)
I1130 22:17:13.578207 11845 sgd_solver.cpp:106] Iteration 51000, lr = 0.01
I1130 22:17:17.249528 11845 solver.cpp:228] Iteration 51500, loss = 0.0490535
I1130 22:17:17.249567 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00861814 (* 0.5 = 0.00430907 loss)
I1130 22:17:17.249573 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.068827 (* 1 = 0.068827 loss)
I1130 22:17:17.249577 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:17:17.249580 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:17:17.249585 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00171986 (* 1 = 0.00171986 loss)
I1130 22:17:17.249589 11845 sgd_solver.cpp:106] Iteration 51500, lr = 0.01
I1130 22:17:20.872316 11845 solver.cpp:228] Iteration 52000, loss = 0.050424
I1130 22:17:20.872340 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0120179 (* 0.5 = 0.00600895 loss)
I1130 22:17:20.872346 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0572341 (* 1 = 0.0572341 loss)
I1130 22:17:20.872350 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:17:20.872354 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:17:20.872359 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00147463 (* 1 = 0.00147463 loss)
I1130 22:17:20.872364 11845 sgd_solver.cpp:106] Iteration 52000, lr = 0.01
I1130 22:17:24.495708 11845 solver.cpp:228] Iteration 52500, loss = 0.0524905
I1130 22:17:24.495772 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00863481 (* 0.5 = 0.0043174 loss)
I1130 22:17:24.495780 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0332353 (* 1 = 0.0332353 loss)
I1130 22:17:24.495784 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:17:24.495789 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:17:24.495792 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0028555 (* 1 = 0.0028555 loss)
I1130 22:17:24.495798 11845 sgd_solver.cpp:106] Iteration 52500, lr = 0.01
I1130 22:17:28.144495 11845 solver.cpp:228] Iteration 53000, loss = 0.0522085
I1130 22:17:28.144551 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0100045 (* 0.5 = 0.00500225 loss)
I1130 22:17:28.144558 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0247311 (* 1 = 0.0247311 loss)
I1130 22:17:28.144562 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:17:28.144567 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:17:28.144572 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00242806 (* 1 = 0.00242806 loss)
I1130 22:17:28.144577 11845 sgd_solver.cpp:106] Iteration 53000, lr = 0.01
I1130 22:17:31.969373 11845 solver.cpp:228] Iteration 53500, loss = 0.0520348
I1130 22:17:31.969481 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00792968 (* 0.5 = 0.00396484 loss)
I1130 22:17:31.969497 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0473286 (* 1 = 0.0473286 loss)
I1130 22:17:31.969501 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:17:31.969506 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:17:31.969511 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00416982 (* 1 = 0.00416982 loss)
I1130 22:17:31.969521 11845 sgd_solver.cpp:106] Iteration 53500, lr = 0.01
I1130 22:17:35.780510 11845 solver.cpp:228] Iteration 54000, loss = 0.0506886
I1130 22:17:35.780614 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00976468 (* 0.5 = 0.00488234 loss)
I1130 22:17:35.780622 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0272776 (* 1 = 0.0272776 loss)
I1130 22:17:35.780627 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:17:35.780632 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:17:35.780685 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00268473 (* 1 = 0.00268473 loss)
I1130 22:17:35.780694 11845 sgd_solver.cpp:106] Iteration 54000, lr = 0.01
I1130 22:17:39.421460 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_54480.caffemodel
I1130 22:17:39.427633 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_54480.solverstate
I1130 22:17:39.428304 11845 solver.cpp:337] Iteration 54480, Testing net (#0)
I1130 22:17:51.082960 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0084788 (* 0.5 = 0.0042394 loss)
I1130 22:17:51.083012 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0566698 (* 1 = 0.0566698 loss)
I1130 22:17:51.083019 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.992476
I1130 22:17:51.083024 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.887135
I1130 22:17:51.083029 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00199 (* 1 = 0.00199 loss)
I1130 22:17:51.238802 11845 solver.cpp:228] Iteration 54500, loss = 0.0492255
I1130 22:17:51.238872 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00818148 (* 0.5 = 0.00409074 loss)
I1130 22:17:51.238879 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0454439 (* 1 = 0.0454439 loss)
I1130 22:17:51.238883 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:17:51.238888 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:17:51.238893 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00120047 (* 1 = 0.00120047 loss)
I1130 22:17:51.238900 11845 sgd_solver.cpp:106] Iteration 54500, lr = 0.01
I1130 22:17:55.112908 11845 solver.cpp:228] Iteration 55000, loss = 0.0527439
I1130 22:17:55.112995 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00765032 (* 0.5 = 0.00382516 loss)
I1130 22:17:55.113003 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.064557 (* 1 = 0.064557 loss)
I1130 22:17:55.113008 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:17:55.113010 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:17:55.113015 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00134873 (* 1 = 0.00134873 loss)
I1130 22:17:55.113032 11845 sgd_solver.cpp:106] Iteration 55000, lr = 0.01
I1130 22:17:58.895684 11845 solver.cpp:228] Iteration 55500, loss = 0.0526789
I1130 22:17:58.895759 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00860226 (* 0.5 = 0.00430113 loss)
I1130 22:17:58.895766 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0349882 (* 1 = 0.0349882 loss)
I1130 22:17:58.895771 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:17:58.895774 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:17:58.895779 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00153963 (* 1 = 0.00153963 loss)
I1130 22:17:58.895787 11845 sgd_solver.cpp:106] Iteration 55500, lr = 0.01
I1130 22:18:02.610117 11845 solver.cpp:228] Iteration 56000, loss = 0.0457598
I1130 22:18:02.610185 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00709053 (* 0.5 = 0.00354527 loss)
I1130 22:18:02.610193 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0285362 (* 1 = 0.0285362 loss)
I1130 22:18:02.610198 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:18:02.610201 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:18:02.610206 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0014563 (* 1 = 0.0014563 loss)
I1130 22:18:02.610213 11845 sgd_solver.cpp:106] Iteration 56000, lr = 0.01
I1130 22:18:06.334079 11845 solver.cpp:228] Iteration 56500, loss = 0.0499086
I1130 22:18:06.334167 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00767014 (* 0.5 = 0.00383507 loss)
I1130 22:18:06.334190 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0146006 (* 1 = 0.0146006 loss)
I1130 22:18:06.334195 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:18:06.334199 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:18:06.334204 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00156609 (* 1 = 0.00156609 loss)
I1130 22:18:06.334211 11845 sgd_solver.cpp:106] Iteration 56500, lr = 0.01
I1130 22:18:10.067387 11845 solver.cpp:228] Iteration 57000, loss = 0.0521119
I1130 22:18:10.067466 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00548504 (* 0.5 = 0.00274252 loss)
I1130 22:18:10.067474 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0426416 (* 1 = 0.0426416 loss)
I1130 22:18:10.067479 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:18:10.067484 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:18:10.067490 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00246149 (* 1 = 0.00246149 loss)
I1130 22:18:10.067498 11845 sgd_solver.cpp:106] Iteration 57000, lr = 0.01
I1130 22:18:13.847964 11845 solver.cpp:228] Iteration 57500, loss = 0.0457107
I1130 22:18:13.848043 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0088786 (* 0.5 = 0.0044393 loss)
I1130 22:18:13.848052 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0474891 (* 1 = 0.0474891 loss)
I1130 22:18:13.848057 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:18:13.848062 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:18:13.848083 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00303693 (* 1 = 0.00303693 loss)
I1130 22:18:13.848093 11845 sgd_solver.cpp:106] Iteration 57500, lr = 0.01
I1130 22:18:17.678270 11845 solver.cpp:228] Iteration 58000, loss = 0.0522931
I1130 22:18:17.678344 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00788592 (* 0.5 = 0.00394296 loss)
I1130 22:18:17.678360 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0580154 (* 1 = 0.0580154 loss)
I1130 22:18:17.678365 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:18:17.678369 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:18:17.678375 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00228811 (* 1 = 0.00228811 loss)
I1130 22:18:17.678382 11845 sgd_solver.cpp:106] Iteration 58000, lr = 0.01
I1130 22:18:21.421898 11845 solver.cpp:228] Iteration 58500, loss = 0.0531441
I1130 22:18:21.421967 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00646312 (* 0.5 = 0.00323156 loss)
I1130 22:18:21.421973 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0298602 (* 1 = 0.0298602 loss)
I1130 22:18:21.421978 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:18:21.421983 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:18:21.421993 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00120156 (* 1 = 0.00120156 loss)
I1130 22:18:21.422000 11845 sgd_solver.cpp:106] Iteration 58500, lr = 0.01
I1130 22:18:25.143501 11845 solver.cpp:228] Iteration 59000, loss = 0.0503162
I1130 22:18:25.143568 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00901306 (* 0.5 = 0.00450653 loss)
I1130 22:18:25.143575 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0815935 (* 1 = 0.0815935 loss)
I1130 22:18:25.143579 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:18:25.143584 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.796875
I1130 22:18:25.143589 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00148626 (* 1 = 0.00148626 loss)
I1130 22:18:25.143595 11845 sgd_solver.cpp:106] Iteration 59000, lr = 0.01
I1130 22:18:28.897267 11845 solver.cpp:228] Iteration 59500, loss = 0.051196
I1130 22:18:28.897398 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00828756 (* 0.5 = 0.00414378 loss)
I1130 22:18:28.897414 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0452706 (* 1 = 0.0452706 loss)
I1130 22:18:28.897418 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:18:28.897423 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:18:28.897428 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00276382 (* 1 = 0.00276382 loss)
I1130 22:18:28.897433 11845 sgd_solver.cpp:106] Iteration 59500, lr = 0.01
I1130 22:18:32.680104 11845 solver.cpp:228] Iteration 60000, loss = 0.0506217
I1130 22:18:32.680176 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00935019 (* 0.5 = 0.0046751 loss)
I1130 22:18:32.680183 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.048458 (* 1 = 0.048458 loss)
I1130 22:18:32.680187 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:18:32.680191 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:18:32.680197 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00166262 (* 1 = 0.00166262 loss)
I1130 22:18:32.680212 11845 sgd_solver.cpp:106] Iteration 60000, lr = 0.01
I1130 22:18:36.497222 11845 solver.cpp:228] Iteration 60500, loss = 0.0468319
I1130 22:18:36.497337 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00792012 (* 0.5 = 0.00396006 loss)
I1130 22:18:36.497345 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0619646 (* 1 = 0.0619646 loss)
I1130 22:18:36.497351 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:18:36.497355 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:18:36.497362 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00126504 (* 1 = 0.00126504 loss)
I1130 22:18:36.497370 11845 sgd_solver.cpp:106] Iteration 60500, lr = 0.01
I1130 22:18:40.310101 11845 solver.cpp:228] Iteration 61000, loss = 0.0558903
I1130 22:18:40.310166 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00628688 (* 0.5 = 0.00314344 loss)
I1130 22:18:40.310173 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0298652 (* 1 = 0.0298652 loss)
I1130 22:18:40.310178 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:18:40.310183 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:18:40.310187 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00175988 (* 1 = 0.00175988 loss)
I1130 22:18:40.310194 11845 sgd_solver.cpp:106] Iteration 61000, lr = 0.01
I1130 22:18:42.526615 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_61290.caffemodel
I1130 22:18:42.532601 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_61290.solverstate
I1130 22:18:42.533313 11845 solver.cpp:337] Iteration 61290, Testing net (#0)
I1130 22:18:54.495010 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00874893 (* 0.5 = 0.00437446 loss)
I1130 22:18:54.495075 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0517239 (* 1 = 0.0517239 loss)
I1130 22:18:54.495082 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.987911
I1130 22:18:54.495087 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.911973
I1130 22:18:54.495093 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00194083 (* 1 = 0.00194083 loss)
I1130 22:18:56.056269 11845 solver.cpp:228] Iteration 61500, loss = 0.0553028
I1130 22:18:56.056385 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00710526 (* 0.5 = 0.00355263 loss)
I1130 22:18:56.056394 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0439246 (* 1 = 0.0439246 loss)
I1130 22:18:56.056398 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:18:56.056402 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:18:56.056443 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00135932 (* 1 = 0.00135932 loss)
I1130 22:18:56.056452 11845 sgd_solver.cpp:106] Iteration 61500, lr = 0.01
I1130 22:18:59.860086 11845 solver.cpp:228] Iteration 62000, loss = 0.0435148
I1130 22:18:59.860177 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00850666 (* 0.5 = 0.00425333 loss)
I1130 22:18:59.860184 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0671979 (* 1 = 0.0671979 loss)
I1130 22:18:59.860188 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:18:59.860193 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:18:59.860198 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00130287 (* 1 = 0.00130287 loss)
I1130 22:18:59.860206 11845 sgd_solver.cpp:106] Iteration 62000, lr = 0.01
I1130 22:19:03.647949 11845 solver.cpp:228] Iteration 62500, loss = 0.0507232
I1130 22:19:03.648015 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00890115 (* 0.5 = 0.00445057 loss)
I1130 22:19:03.648022 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0526717 (* 1 = 0.0526717 loss)
I1130 22:19:03.648026 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:19:03.648030 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:19:03.648036 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00137457 (* 1 = 0.00137457 loss)
I1130 22:19:03.648042 11845 sgd_solver.cpp:106] Iteration 62500, lr = 0.01
I1130 22:19:07.444552 11845 solver.cpp:228] Iteration 63000, loss = 0.0545764
I1130 22:19:07.444658 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00782725 (* 0.5 = 0.00391362 loss)
I1130 22:19:07.444667 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0698104 (* 1 = 0.0698104 loss)
I1130 22:19:07.444681 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:19:07.444685 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 22:19:07.444691 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0023915 (* 1 = 0.0023915 loss)
I1130 22:19:07.444699 11845 sgd_solver.cpp:106] Iteration 63000, lr = 0.01
I1130 22:19:11.155109 11845 solver.cpp:228] Iteration 63500, loss = 0.0447623
I1130 22:19:11.155174 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00906205 (* 0.5 = 0.00453103 loss)
I1130 22:19:11.155181 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0464006 (* 1 = 0.0464006 loss)
I1130 22:19:11.155185 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:19:11.155189 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:19:11.155194 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00142494 (* 1 = 0.00142494 loss)
I1130 22:19:11.155201 11845 sgd_solver.cpp:106] Iteration 63500, lr = 0.01
I1130 22:19:14.965605 11845 solver.cpp:228] Iteration 64000, loss = 0.0517559
I1130 22:19:14.965675 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00923565 (* 0.5 = 0.00461783 loss)
I1130 22:19:14.965688 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0248461 (* 1 = 0.0248461 loss)
I1130 22:19:14.965695 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:19:14.965703 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:19:14.965710 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0026467 (* 1 = 0.0026467 loss)
I1130 22:19:14.965718 11845 sgd_solver.cpp:106] Iteration 64000, lr = 0.01
I1130 22:19:18.640467 11845 solver.cpp:228] Iteration 64500, loss = 0.0506572
I1130 22:19:18.640509 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00940694 (* 0.5 = 0.00470347 loss)
I1130 22:19:18.640518 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0597832 (* 1 = 0.0597832 loss)
I1130 22:19:18.640534 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:19:18.640539 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:19:18.640545 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00153857 (* 1 = 0.00153857 loss)
I1130 22:19:18.640552 11845 sgd_solver.cpp:106] Iteration 64500, lr = 0.01
I1130 22:19:22.383226 11845 solver.cpp:228] Iteration 65000, loss = 0.0417324
I1130 22:19:22.383283 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00951219 (* 0.5 = 0.00475609 loss)
I1130 22:19:22.383299 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0864737 (* 1 = 0.0864737 loss)
I1130 22:19:22.383303 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:19:22.383307 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.796875
I1130 22:19:22.383312 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00175222 (* 1 = 0.00175222 loss)
I1130 22:19:22.383319 11845 sgd_solver.cpp:106] Iteration 65000, lr = 0.01
I1130 22:19:26.101220 11845 solver.cpp:228] Iteration 65500, loss = 0.0536236
I1130 22:19:26.101289 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00680493 (* 0.5 = 0.00340246 loss)
I1130 22:19:26.101296 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0474269 (* 1 = 0.0474269 loss)
I1130 22:19:26.101300 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:19:26.101305 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:19:26.101310 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00156727 (* 1 = 0.00156727 loss)
I1130 22:19:26.101316 11845 sgd_solver.cpp:106] Iteration 65500, lr = 0.01
I1130 22:19:29.830494 11845 solver.cpp:228] Iteration 66000, loss = 0.0521926
I1130 22:19:29.830556 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00947807 (* 0.5 = 0.00473903 loss)
I1130 22:19:29.830564 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0590515 (* 1 = 0.0590515 loss)
I1130 22:19:29.830569 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:19:29.830579 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:19:29.830585 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00186417 (* 1 = 0.00186417 loss)
I1130 22:19:29.830593 11845 sgd_solver.cpp:106] Iteration 66000, lr = 0.01
I1130 22:19:33.563225 11845 solver.cpp:228] Iteration 66500, loss = 0.0435267
I1130 22:19:33.563313 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0065019 (* 0.5 = 0.00325095 loss)
I1130 22:19:33.563319 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0369804 (* 1 = 0.0369804 loss)
I1130 22:19:33.563324 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:19:33.563328 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:19:33.563333 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00241836 (* 1 = 0.00241836 loss)
I1130 22:19:33.563350 11845 sgd_solver.cpp:106] Iteration 66500, lr = 0.01
I1130 22:19:37.517166 11845 solver.cpp:228] Iteration 67000, loss = 0.0542758
I1130 22:19:37.517266 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00795275 (* 0.5 = 0.00397638 loss)
I1130 22:19:37.517274 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0388144 (* 1 = 0.0388144 loss)
I1130 22:19:37.517278 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:19:37.517283 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:19:37.517288 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00302719 (* 1 = 0.00302719 loss)
I1130 22:19:37.517297 11845 sgd_solver.cpp:106] Iteration 67000, lr = 0.01
I1130 22:19:41.364941 11845 solver.cpp:228] Iteration 67500, loss = 0.0547078
I1130 22:19:41.365066 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00951647 (* 0.5 = 0.00475823 loss)
I1130 22:19:41.365106 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0254063 (* 1 = 0.0254063 loss)
I1130 22:19:41.365113 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:19:41.365120 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:19:41.365126 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00121921 (* 1 = 0.00121921 loss)
I1130 22:19:41.365136 11845 sgd_solver.cpp:106] Iteration 67500, lr = 0.01
I1130 22:19:45.119390 11845 solver.cpp:228] Iteration 68000, loss = 0.043596
I1130 22:19:45.119449 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00734082 (* 0.5 = 0.00367041 loss)
I1130 22:19:45.119457 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0133865 (* 1 = 0.0133865 loss)
I1130 22:19:45.119462 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:19:45.119465 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:19:45.119470 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.002374 (* 1 = 0.002374 loss)
I1130 22:19:45.119477 11845 sgd_solver.cpp:106] Iteration 68000, lr = 0.01
I1130 22:19:45.853755 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_68100.caffemodel
I1130 22:19:45.859637 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_68100.solverstate
I1130 22:19:45.860342 11845 solver.cpp:337] Iteration 68100, Testing net (#0)
I1130 22:19:57.847430 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00846186 (* 0.5 = 0.00423093 loss)
I1130 22:19:57.847478 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0568727 (* 1 = 0.0568727 loss)
I1130 22:19:57.847486 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.975025
I1130 22:19:57.847489 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.939585
I1130 22:19:57.847494 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00196639 (* 1 = 0.00196639 loss)
I1130 22:20:00.913650 11845 solver.cpp:228] Iteration 68500, loss = 0.0491427
I1130 22:20:00.913765 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00834685 (* 0.5 = 0.00417343 loss)
I1130 22:20:00.913774 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0694204 (* 1 = 0.0694204 loss)
I1130 22:20:00.913777 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:20:00.913782 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:20:00.913787 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00150781 (* 1 = 0.00150781 loss)
I1130 22:20:00.913805 11845 sgd_solver.cpp:106] Iteration 68500, lr = 0.001
I1130 22:20:04.620517 11845 solver.cpp:228] Iteration 69000, loss = 0.0492612
I1130 22:20:04.620584 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00698941 (* 0.5 = 0.0034947 loss)
I1130 22:20:04.620591 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0543889 (* 1 = 0.0543889 loss)
I1130 22:20:04.620595 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:20:04.620599 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:20:04.620605 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00105584 (* 1 = 0.00105584 loss)
I1130 22:20:04.620612 11845 sgd_solver.cpp:106] Iteration 69000, lr = 0.001
I1130 22:20:08.329490 11845 solver.cpp:228] Iteration 69500, loss = 0.045454
I1130 22:20:08.329588 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0069212 (* 0.5 = 0.0034606 loss)
I1130 22:20:08.329605 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0247278 (* 1 = 0.0247278 loss)
I1130 22:20:08.329609 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:20:08.329613 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:20:08.329655 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00248565 (* 1 = 0.00248565 loss)
I1130 22:20:08.329663 11845 sgd_solver.cpp:106] Iteration 69500, lr = 0.001
I1130 22:20:12.151365 11845 solver.cpp:228] Iteration 70000, loss = 0.0486444
I1130 22:20:12.151484 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00775789 (* 0.5 = 0.00387894 loss)
I1130 22:20:12.151492 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0451181 (* 1 = 0.0451181 loss)
I1130 22:20:12.151496 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:20:12.151500 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:20:12.151505 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00215943 (* 1 = 0.00215943 loss)
I1130 22:20:12.151515 11845 sgd_solver.cpp:106] Iteration 70000, lr = 0.001
I1130 22:20:15.889951 11845 solver.cpp:228] Iteration 70500, loss = 0.0461672
I1130 22:20:15.890056 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00712431 (* 0.5 = 0.00356215 loss)
I1130 22:20:15.890064 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.045747 (* 1 = 0.045747 loss)
I1130 22:20:15.890074 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:20:15.890079 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:20:15.890084 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00219716 (* 1 = 0.00219716 loss)
I1130 22:20:15.890090 11845 sgd_solver.cpp:106] Iteration 70500, lr = 0.001
I1130 22:20:19.603214 11845 solver.cpp:228] Iteration 71000, loss = 0.0404133
I1130 22:20:19.603330 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00656216 (* 0.5 = 0.00328108 loss)
I1130 22:20:19.603338 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0343817 (* 1 = 0.0343817 loss)
I1130 22:20:19.603343 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:20:19.603348 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:20:19.603361 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00225518 (* 1 = 0.00225518 loss)
I1130 22:20:19.603368 11845 sgd_solver.cpp:106] Iteration 71000, lr = 0.001
I1130 22:20:23.310698 11845 solver.cpp:228] Iteration 71500, loss = 0.0478202
I1130 22:20:23.310796 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0068228 (* 0.5 = 0.0034114 loss)
I1130 22:20:23.310806 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0712467 (* 1 = 0.0712467 loss)
I1130 22:20:23.310811 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:20:23.310823 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:20:23.310830 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00233769 (* 1 = 0.00233769 loss)
I1130 22:20:23.310837 11845 sgd_solver.cpp:106] Iteration 71500, lr = 0.001
I1130 22:20:27.064594 11845 solver.cpp:228] Iteration 72000, loss = 0.0476441
I1130 22:20:27.064666 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00826894 (* 0.5 = 0.00413447 loss)
I1130 22:20:27.064672 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0240814 (* 1 = 0.0240814 loss)
I1130 22:20:27.064677 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:20:27.064682 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:20:27.064687 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00264759 (* 1 = 0.00264759 loss)
I1130 22:20:27.064693 11845 sgd_solver.cpp:106] Iteration 72000, lr = 0.001
I1130 22:20:30.782492 11845 solver.cpp:228] Iteration 72500, loss = 0.0409997
I1130 22:20:30.782563 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00644666 (* 0.5 = 0.00322333 loss)
I1130 22:20:30.782570 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0148375 (* 1 = 0.0148375 loss)
I1130 22:20:30.782574 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:20:30.782603 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:20:30.782609 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00138202 (* 1 = 0.00138202 loss)
I1130 22:20:30.782616 11845 sgd_solver.cpp:106] Iteration 72500, lr = 0.001
I1130 22:20:34.636494 11845 solver.cpp:228] Iteration 73000, loss = 0.0446624
I1130 22:20:34.636577 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00815384 (* 0.5 = 0.00407692 loss)
I1130 22:20:34.636585 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0337437 (* 1 = 0.0337437 loss)
I1130 22:20:34.636590 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:20:34.636595 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:20:34.636610 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00157518 (* 1 = 0.00157518 loss)
I1130 22:20:34.636616 11845 sgd_solver.cpp:106] Iteration 73000, lr = 0.001
I1130 22:20:38.493968 11845 solver.cpp:228] Iteration 73500, loss = 0.0449504
I1130 22:20:38.494087 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00855289 (* 0.5 = 0.00427645 loss)
I1130 22:20:38.494097 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0419986 (* 1 = 0.0419986 loss)
I1130 22:20:38.494102 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:20:38.494107 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:20:38.494112 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00155055 (* 1 = 0.00155055 loss)
I1130 22:20:38.494119 11845 sgd_solver.cpp:106] Iteration 73500, lr = 0.001
I1130 22:20:42.312595 11845 solver.cpp:228] Iteration 74000, loss = 0.0433369
I1130 22:20:42.312682 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00662299 (* 0.5 = 0.0033115 loss)
I1130 22:20:42.312692 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0138426 (* 1 = 0.0138426 loss)
I1130 22:20:42.312698 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:20:42.312703 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:20:42.312710 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00165189 (* 1 = 0.00165189 loss)
I1130 22:20:42.312717 11845 sgd_solver.cpp:106] Iteration 74000, lr = 0.001
I1130 22:20:46.092319 11845 solver.cpp:228] Iteration 74500, loss = 0.0455144
I1130 22:20:46.092589 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0070568 (* 0.5 = 0.0035284 loss)
I1130 22:20:46.092598 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0264065 (* 1 = 0.0264065 loss)
I1130 22:20:46.092602 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:20:46.092609 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:20:46.092622 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00161092 (* 1 = 0.00161092 loss)
I1130 22:20:46.092628 11845 sgd_solver.cpp:106] Iteration 74500, lr = 0.001
I1130 22:20:49.148038 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_74910.caffemodel
I1130 22:20:49.153651 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_74910.solverstate
I1130 22:20:49.154297 11845 solver.cpp:337] Iteration 74910, Testing net (#0)
I1130 22:21:01.097700 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00839436 (* 0.5 = 0.00419718 loss)
I1130 22:21:01.097753 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0468573 (* 1 = 0.0468573 loss)
I1130 22:21:01.097759 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.992767
I1130 22:21:01.097764 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.910857
I1130 22:21:01.097769 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.0018802 (* 1 = 0.0018802 loss)
I1130 22:21:01.752542 11845 solver.cpp:228] Iteration 75000, loss = 0.0466435
I1130 22:21:01.752609 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.008341 (* 0.5 = 0.0041705 loss)
I1130 22:21:01.752616 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0640792 (* 1 = 0.0640792 loss)
I1130 22:21:01.752620 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:21:01.752624 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:21:01.752629 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00122603 (* 1 = 0.00122603 loss)
I1130 22:21:01.752634 11845 sgd_solver.cpp:106] Iteration 75000, lr = 0.001
I1130 22:21:05.387305 11845 solver.cpp:228] Iteration 75500, loss = 0.0481883
I1130 22:21:05.387346 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00533384 (* 0.5 = 0.00266692 loss)
I1130 22:21:05.387352 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0103123 (* 1 = 0.0103123 loss)
I1130 22:21:05.387356 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:21:05.387361 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:21:05.387364 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00185093 (* 1 = 0.00185093 loss)
I1130 22:21:05.387368 11845 sgd_solver.cpp:106] Iteration 75500, lr = 0.001
I1130 22:21:08.957803 11845 solver.cpp:228] Iteration 76000, loss = 0.0441785
I1130 22:21:08.957844 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00614917 (* 0.5 = 0.00307459 loss)
I1130 22:21:08.957851 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0295873 (* 1 = 0.0295873 loss)
I1130 22:21:08.957855 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:21:08.957859 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:21:08.957864 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0012202 (* 1 = 0.0012202 loss)
I1130 22:21:08.957868 11845 sgd_solver.cpp:106] Iteration 76000, lr = 0.001
I1130 22:21:12.534651 11845 solver.cpp:228] Iteration 76500, loss = 0.0440693
I1130 22:21:12.534688 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00791084 (* 0.5 = 0.00395542 loss)
I1130 22:21:12.534695 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0207633 (* 1 = 0.0207633 loss)
I1130 22:21:12.534699 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:21:12.534703 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:21:12.534708 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00151704 (* 1 = 0.00151704 loss)
I1130 22:21:12.534713 11845 sgd_solver.cpp:106] Iteration 76500, lr = 0.001
I1130 22:21:16.199638 11845 solver.cpp:228] Iteration 77000, loss = 0.0459975
I1130 22:21:16.199702 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00872828 (* 0.5 = 0.00436414 loss)
I1130 22:21:16.199709 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0129958 (* 1 = 0.0129958 loss)
I1130 22:21:16.199714 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:21:16.199718 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:21:16.199723 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00138601 (* 1 = 0.00138601 loss)
I1130 22:21:16.199729 11845 sgd_solver.cpp:106] Iteration 77000, lr = 0.001
I1130 22:21:19.811975 11845 solver.cpp:228] Iteration 77500, loss = 0.0466548
I1130 22:21:19.812043 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00892979 (* 0.5 = 0.00446489 loss)
I1130 22:21:19.812052 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0252134 (* 1 = 0.0252134 loss)
I1130 22:21:19.812057 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:21:19.812060 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:21:19.812065 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00131569 (* 1 = 0.00131569 loss)
I1130 22:21:19.812093 11845 sgd_solver.cpp:106] Iteration 77500, lr = 0.001
I1130 22:21:23.452966 11845 solver.cpp:228] Iteration 78000, loss = 0.0477463
I1130 22:21:23.453045 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00702315 (* 0.5 = 0.00351158 loss)
I1130 22:21:23.453054 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0404607 (* 1 = 0.0404607 loss)
I1130 22:21:23.453058 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:21:23.453063 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:21:23.453073 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00185935 (* 1 = 0.00185935 loss)
I1130 22:21:23.453081 11845 sgd_solver.cpp:106] Iteration 78000, lr = 0.001
I1130 22:21:27.071630 11845 solver.cpp:228] Iteration 78500, loss = 0.0469439
I1130 22:21:27.071694 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00805743 (* 0.5 = 0.00402871 loss)
I1130 22:21:27.071702 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0531686 (* 1 = 0.0531686 loss)
I1130 22:21:27.071707 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:21:27.071712 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:21:27.071717 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00130668 (* 1 = 0.00130668 loss)
I1130 22:21:27.071722 11845 sgd_solver.cpp:106] Iteration 78500, lr = 0.001
I1130 22:21:30.686910 11845 solver.cpp:228] Iteration 79000, loss = 0.040367
I1130 22:21:30.686992 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00797922 (* 0.5 = 0.00398961 loss)
I1130 22:21:30.687000 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0259319 (* 1 = 0.0259319 loss)
I1130 22:21:30.687005 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:21:30.687010 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:21:30.687014 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00141557 (* 1 = 0.00141557 loss)
I1130 22:21:30.687021 11845 sgd_solver.cpp:106] Iteration 79000, lr = 0.001
I1130 22:21:34.291960 11845 solver.cpp:228] Iteration 79500, loss = 0.045333
I1130 22:21:34.292024 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00806435 (* 0.5 = 0.00403217 loss)
I1130 22:21:34.292032 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0390277 (* 1 = 0.0390277 loss)
I1130 22:21:34.292035 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:21:34.292040 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:21:34.292044 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00222914 (* 1 = 0.00222914 loss)
I1130 22:21:34.292050 11845 sgd_solver.cpp:106] Iteration 79500, lr = 0.001
I1130 22:21:37.907932 11845 solver.cpp:228] Iteration 80000, loss = 0.048824
I1130 22:21:37.907996 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00828191 (* 0.5 = 0.00414095 loss)
I1130 22:21:37.908004 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.035108 (* 1 = 0.035108 loss)
I1130 22:21:37.908007 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:21:37.908012 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:21:37.908017 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00183449 (* 1 = 0.00183449 loss)
I1130 22:21:37.908022 11845 sgd_solver.cpp:106] Iteration 80000, lr = 0.001
I1130 22:21:41.506381 11845 solver.cpp:228] Iteration 80500, loss = 0.039926
I1130 22:21:41.506486 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00719715 (* 0.5 = 0.00359857 loss)
I1130 22:21:41.506494 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0623682 (* 1 = 0.0623682 loss)
I1130 22:21:41.506499 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:21:41.506502 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:21:41.506516 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00121833 (* 1 = 0.00121833 loss)
I1130 22:21:41.506522 11845 sgd_solver.cpp:106] Iteration 80500, lr = 0.001
I1130 22:21:45.104331 11845 solver.cpp:228] Iteration 81000, loss = 0.0430003
I1130 22:21:45.104398 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00831529 (* 0.5 = 0.00415765 loss)
I1130 22:21:45.104405 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0348259 (* 1 = 0.0348259 loss)
I1130 22:21:45.104410 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:21:45.104414 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:21:45.104419 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00203432 (* 1 = 0.00203432 loss)
I1130 22:21:45.104425 11845 sgd_solver.cpp:106] Iteration 81000, lr = 0.001
I1130 22:21:48.749788 11845 solver.cpp:228] Iteration 81500, loss = 0.0474167
I1130 22:21:48.749855 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00877301 (* 0.5 = 0.0043865 loss)
I1130 22:21:48.749864 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0368099 (* 1 = 0.0368099 loss)
I1130 22:21:48.749868 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:21:48.749873 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:21:48.749879 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00459707 (* 1 = 0.00459707 loss)
I1130 22:21:48.749886 11845 sgd_solver.cpp:106] Iteration 81500, lr = 0.001
I1130 22:21:50.391563 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_81720.caffemodel
I1130 22:21:50.397593 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_81720.solverstate
I1130 22:21:50.398252 11845 solver.cpp:337] Iteration 81720, Testing net (#0)
I1130 22:22:01.875588 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00819557 (* 0.5 = 0.00409779 loss)
I1130 22:22:01.875638 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0473924 (* 1 = 0.0473924 loss)
I1130 22:22:01.875643 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.993927
I1130 22:22:01.875648 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.90585
I1130 22:22:01.875653 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00185046 (* 1 = 0.00185046 loss)
I1130 22:22:03.928110 11845 solver.cpp:228] Iteration 82000, loss = 0.0386007
I1130 22:22:03.928171 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00748271 (* 0.5 = 0.00374135 loss)
I1130 22:22:03.928179 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0340393 (* 1 = 0.0340393 loss)
I1130 22:22:03.928184 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:22:03.928186 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:22:03.928191 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00175946 (* 1 = 0.00175946 loss)
I1130 22:22:03.928198 11845 sgd_solver.cpp:106] Iteration 82000, lr = 0.001
I1130 22:22:07.565371 11845 solver.cpp:228] Iteration 82500, loss = 0.045719
I1130 22:22:07.565439 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00647713 (* 0.5 = 0.00323857 loss)
I1130 22:22:07.565448 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0455938 (* 1 = 0.0455938 loss)
I1130 22:22:07.565451 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:22:07.565455 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:22:07.565460 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0019549 (* 1 = 0.0019549 loss)
I1130 22:22:07.565466 11845 sgd_solver.cpp:106] Iteration 82500, lr = 0.001
I1130 22:22:11.206127 11845 solver.cpp:228] Iteration 83000, loss = 0.0485063
I1130 22:22:11.206226 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00680717 (* 0.5 = 0.00340359 loss)
I1130 22:22:11.206259 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0412602 (* 1 = 0.0412602 loss)
I1130 22:22:11.206264 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:22:11.206269 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:22:11.206274 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00173979 (* 1 = 0.00173979 loss)
I1130 22:22:11.206284 11845 sgd_solver.cpp:106] Iteration 83000, lr = 0.001
I1130 22:22:14.844647 11845 solver.cpp:228] Iteration 83500, loss = 0.0392863
I1130 22:22:14.844712 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00893291 (* 0.5 = 0.00446645 loss)
I1130 22:22:14.844718 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0515235 (* 1 = 0.0515235 loss)
I1130 22:22:14.844723 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:22:14.844727 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:22:14.844732 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00235171 (* 1 = 0.00235171 loss)
I1130 22:22:14.844738 11845 sgd_solver.cpp:106] Iteration 83500, lr = 0.001
I1130 22:22:18.476455 11845 solver.cpp:228] Iteration 84000, loss = 0.0495918
I1130 22:22:18.476523 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0088732 (* 0.5 = 0.0044366 loss)
I1130 22:22:18.476531 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0351741 (* 1 = 0.0351741 loss)
I1130 22:22:18.476536 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:22:18.476539 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:22:18.476544 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0014975 (* 1 = 0.0014975 loss)
I1130 22:22:18.476550 11845 sgd_solver.cpp:106] Iteration 84000, lr = 0.001
I1130 22:22:22.112864 11845 solver.cpp:228] Iteration 84500, loss = 0.0487189
I1130 22:22:22.112926 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00841492 (* 0.5 = 0.00420746 loss)
I1130 22:22:22.112933 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0373164 (* 1 = 0.0373164 loss)
I1130 22:22:22.112937 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:22:22.112941 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:22:22.112946 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00173859 (* 1 = 0.00173859 loss)
I1130 22:22:22.112952 11845 sgd_solver.cpp:106] Iteration 84500, lr = 0.001
I1130 22:22:25.753096 11845 solver.cpp:228] Iteration 85000, loss = 0.0372708
I1130 22:22:25.753163 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00638808 (* 0.5 = 0.00319404 loss)
I1130 22:22:25.753171 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0306178 (* 1 = 0.0306178 loss)
I1130 22:22:25.753175 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:22:25.753180 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:22:25.753185 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00179845 (* 1 = 0.00179845 loss)
I1130 22:22:25.753190 11845 sgd_solver.cpp:106] Iteration 85000, lr = 0.001
I1130 22:22:29.389055 11845 solver.cpp:228] Iteration 85500, loss = 0.0458613
I1130 22:22:29.389124 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0074565 (* 0.5 = 0.00372825 loss)
I1130 22:22:29.389132 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0468868 (* 1 = 0.0468868 loss)
I1130 22:22:29.389137 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:22:29.389140 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:22:29.389145 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00113156 (* 1 = 0.00113156 loss)
I1130 22:22:29.389152 11845 sgd_solver.cpp:106] Iteration 85500, lr = 0.001
I1130 22:22:33.045374 11845 solver.cpp:228] Iteration 86000, loss = 0.0507771
I1130 22:22:33.045442 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00902227 (* 0.5 = 0.00451113 loss)
I1130 22:22:33.045450 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0356484 (* 1 = 0.0356484 loss)
I1130 22:22:33.045455 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:22:33.045459 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:22:33.045464 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00737161 (* 1 = 0.00737161 loss)
I1130 22:22:33.045470 11845 sgd_solver.cpp:106] Iteration 86000, lr = 0.001
I1130 22:22:36.676609 11845 solver.cpp:228] Iteration 86500, loss = 0.0400046
I1130 22:22:36.676677 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00671537 (* 0.5 = 0.00335768 loss)
I1130 22:22:36.676686 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0235594 (* 1 = 0.0235594 loss)
I1130 22:22:36.676689 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:22:36.676693 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:22:36.676698 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00134781 (* 1 = 0.00134781 loss)
I1130 22:22:36.676704 11845 sgd_solver.cpp:106] Iteration 86500, lr = 0.001
I1130 22:22:40.304569 11845 solver.cpp:228] Iteration 87000, loss = 0.0487686
I1130 22:22:40.304631 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0076513 (* 0.5 = 0.00382565 loss)
I1130 22:22:40.304638 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0247903 (* 1 = 0.0247903 loss)
I1130 22:22:40.304642 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:22:40.304646 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:22:40.304651 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00169224 (* 1 = 0.00169224 loss)
I1130 22:22:40.304657 11845 sgd_solver.cpp:106] Iteration 87000, lr = 0.001
I1130 22:22:43.933316 11845 solver.cpp:228] Iteration 87500, loss = 0.044959
I1130 22:22:43.933382 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00655309 (* 0.5 = 0.00327655 loss)
I1130 22:22:43.933390 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.029672 (* 1 = 0.029672 loss)
I1130 22:22:43.933395 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:22:43.933399 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:22:43.933404 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00128945 (* 1 = 0.00128945 loss)
I1130 22:22:43.933410 11845 sgd_solver.cpp:106] Iteration 87500, lr = 0.001
I1130 22:22:47.588335 11845 solver.cpp:228] Iteration 88000, loss = 0.0389197
I1130 22:22:47.588398 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00665817 (* 0.5 = 0.00332909 loss)
I1130 22:22:47.588407 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0154918 (* 1 = 0.0154918 loss)
I1130 22:22:47.588410 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:22:47.588414 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:22:47.588419 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00123305 (* 1 = 0.00123305 loss)
I1130 22:22:47.588425 11845 sgd_solver.cpp:106] Iteration 88000, lr = 0.001
I1130 22:22:51.225355 11845 solver.cpp:228] Iteration 88500, loss = 0.0500348
I1130 22:22:51.225416 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00957986 (* 0.5 = 0.00478993 loss)
I1130 22:22:51.225424 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0407547 (* 1 = 0.0407547 loss)
I1130 22:22:51.225427 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:22:51.225431 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:22:51.225436 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00208354 (* 1 = 0.00208354 loss)
I1130 22:22:51.225458 11845 sgd_solver.cpp:106] Iteration 88500, lr = 0.001
I1130 22:22:51.435297 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_88530.caffemodel
I1130 22:22:51.441694 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_88530.solverstate
I1130 22:22:51.442342 11845 solver.cpp:337] Iteration 88530, Testing net (#0)
I1130 22:23:03.160249 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00834254 (* 0.5 = 0.00417127 loss)
I1130 22:23:03.160301 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0457594 (* 1 = 0.0457594 loss)
I1130 22:23:03.160307 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.991765
I1130 22:23:03.160311 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.916152
I1130 22:23:03.160317 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00191406 (* 1 = 0.00191406 loss)
I1130 22:23:06.659579 11845 solver.cpp:228] Iteration 89000, loss = 0.0446618
I1130 22:23:06.659626 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00752967 (* 0.5 = 0.00376484 loss)
I1130 22:23:06.659632 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0420438 (* 1 = 0.0420438 loss)
I1130 22:23:06.659636 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:23:06.659641 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:23:06.659646 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00197256 (* 1 = 0.00197256 loss)
I1130 22:23:06.659649 11845 sgd_solver.cpp:106] Iteration 89000, lr = 0.001
I1130 22:23:10.322115 11845 solver.cpp:228] Iteration 89500, loss = 0.0379048
I1130 22:23:10.322146 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0077319 (* 0.5 = 0.00386595 loss)
I1130 22:23:10.322154 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.00880209 (* 1 = 0.00880209 loss)
I1130 22:23:10.322157 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:23:10.322161 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:23:10.322165 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00179978 (* 1 = 0.00179978 loss)
I1130 22:23:10.322170 11845 sgd_solver.cpp:106] Iteration 89500, lr = 0.001
I1130 22:23:14.016743 11845 solver.cpp:228] Iteration 90000, loss = 0.045221
I1130 22:23:14.016794 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00876301 (* 0.5 = 0.0043815 loss)
I1130 22:23:14.016801 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0370415 (* 1 = 0.0370415 loss)
I1130 22:23:14.016805 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:23:14.016809 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:23:14.016814 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0018646 (* 1 = 0.0018646 loss)
I1130 22:23:14.016819 11845 sgd_solver.cpp:106] Iteration 90000, lr = 0.001
I1130 22:23:17.692240 11845 solver.cpp:228] Iteration 90500, loss = 0.0450229
I1130 22:23:17.692296 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00820782 (* 0.5 = 0.00410391 loss)
I1130 22:23:17.692302 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0516985 (* 1 = 0.0516985 loss)
I1130 22:23:17.692306 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:23:17.692311 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:23:17.692315 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00261957 (* 1 = 0.00261957 loss)
I1130 22:23:17.692322 11845 sgd_solver.cpp:106] Iteration 90500, lr = 0.001
I1130 22:23:21.357341 11845 solver.cpp:228] Iteration 91000, loss = 0.0408165
I1130 22:23:21.357400 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00809993 (* 0.5 = 0.00404996 loss)
I1130 22:23:21.357409 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0242055 (* 1 = 0.0242055 loss)
I1130 22:23:21.357434 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:23:21.357439 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:23:21.357445 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00469031 (* 1 = 0.00469031 loss)
I1130 22:23:21.357450 11845 sgd_solver.cpp:106] Iteration 91000, lr = 0.001
I1130 22:23:25.020845 11845 solver.cpp:228] Iteration 91500, loss = 0.0477348
I1130 22:23:25.020913 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00910585 (* 0.5 = 0.00455293 loss)
I1130 22:23:25.020921 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0303354 (* 1 = 0.0303354 loss)
I1130 22:23:25.020925 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:23:25.020930 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:23:25.020934 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00205475 (* 1 = 0.00205475 loss)
I1130 22:23:25.020941 11845 sgd_solver.cpp:106] Iteration 91500, lr = 0.001
I1130 22:23:28.681839 11845 solver.cpp:228] Iteration 92000, loss = 0.0463017
I1130 22:23:28.681901 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00789007 (* 0.5 = 0.00394504 loss)
I1130 22:23:28.681908 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0679386 (* 1 = 0.0679386 loss)
I1130 22:23:28.681913 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:23:28.681917 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:23:28.681922 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00115896 (* 1 = 0.00115896 loss)
I1130 22:23:28.681927 11845 sgd_solver.cpp:106] Iteration 92000, lr = 0.001
I1130 22:23:32.345541 11845 solver.cpp:228] Iteration 92500, loss = 0.043629
I1130 22:23:32.345604 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0080952 (* 0.5 = 0.0040476 loss)
I1130 22:23:32.345613 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0173468 (* 1 = 0.0173468 loss)
I1130 22:23:32.345616 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:23:32.345620 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:23:32.345625 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00191058 (* 1 = 0.00191058 loss)
I1130 22:23:32.345631 11845 sgd_solver.cpp:106] Iteration 92500, lr = 0.001
I1130 22:23:36.003927 11845 solver.cpp:228] Iteration 93000, loss = 0.0464317
I1130 22:23:36.003989 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00841514 (* 0.5 = 0.00420757 loss)
I1130 22:23:36.003998 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0330311 (* 1 = 0.0330311 loss)
I1130 22:23:36.004003 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:23:36.004006 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:23:36.004011 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00143304 (* 1 = 0.00143304 loss)
I1130 22:23:36.004017 11845 sgd_solver.cpp:106] Iteration 93000, lr = 0.001
I1130 22:23:39.668524 11845 solver.cpp:228] Iteration 93500, loss = 0.043609
I1130 22:23:39.668589 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00896248 (* 0.5 = 0.00448124 loss)
I1130 22:23:39.668597 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0572012 (* 1 = 0.0572012 loss)
I1130 22:23:39.668601 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:23:39.668606 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 22:23:39.668611 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00369887 (* 1 = 0.00369887 loss)
I1130 22:23:39.668615 11845 sgd_solver.cpp:106] Iteration 93500, lr = 0.001
I1130 22:23:43.326894 11845 solver.cpp:228] Iteration 94000, loss = 0.0425398
I1130 22:23:43.326958 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00764148 (* 0.5 = 0.00382074 loss)
I1130 22:23:43.326980 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0333021 (* 1 = 0.0333021 loss)
I1130 22:23:43.326985 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:23:43.326989 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:23:43.326994 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0014578 (* 1 = 0.0014578 loss)
I1130 22:23:43.327000 11845 sgd_solver.cpp:106] Iteration 94000, lr = 0.001
I1130 22:23:46.995045 11845 solver.cpp:228] Iteration 94500, loss = 0.0492641
I1130 22:23:46.995112 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00575646 (* 0.5 = 0.00287823 loss)
I1130 22:23:46.995121 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.03228 (* 1 = 0.03228 loss)
I1130 22:23:46.995124 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:23:46.995128 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:23:46.995133 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00114628 (* 1 = 0.00114628 loss)
I1130 22:23:46.995139 11845 sgd_solver.cpp:106] Iteration 94500, lr = 0.001
I1130 22:23:50.668074 11845 solver.cpp:228] Iteration 95000, loss = 0.0451383
I1130 22:23:50.668138 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00919031 (* 0.5 = 0.00459515 loss)
I1130 22:23:50.668145 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0478899 (* 1 = 0.0478899 loss)
I1130 22:23:50.668149 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:23:50.668154 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:23:50.668159 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00108208 (* 1 = 0.00108208 loss)
I1130 22:23:50.668165 11845 sgd_solver.cpp:106] Iteration 95000, lr = 0.001
I1130 22:23:53.150135 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_95340.caffemodel
I1130 22:23:53.155789 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_95340.solverstate
I1130 22:23:53.156452 11845 solver.cpp:337] Iteration 95340, Testing net (#0)
I1130 22:24:04.412094 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00824484 (* 0.5 = 0.00412242 loss)
I1130 22:24:04.412147 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0478238 (* 1 = 0.0478238 loss)
I1130 22:24:04.412153 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.986997
I1130 22:24:04.412158 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.925262
I1130 22:24:04.412163 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.0018545 (* 1 = 0.0018545 loss)
I1130 22:24:05.636636 11845 solver.cpp:228] Iteration 95500, loss = 0.0438621
I1130 22:24:05.636693 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00828159 (* 0.5 = 0.0041408 loss)
I1130 22:24:05.636701 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0111296 (* 1 = 0.0111296 loss)
I1130 22:24:05.636705 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:24:05.636709 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:24:05.636714 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00176954 (* 1 = 0.00176954 loss)
I1130 22:24:05.636718 11845 sgd_solver.cpp:106] Iteration 95500, lr = 0.001
I1130 22:24:09.323562 11845 solver.cpp:228] Iteration 96000, loss = 0.0419068
I1130 22:24:09.323598 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00678149 (* 0.5 = 0.00339075 loss)
I1130 22:24:09.323606 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.025816 (* 1 = 0.025816 loss)
I1130 22:24:09.323609 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:24:09.323613 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:24:09.323635 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00118506 (* 1 = 0.00118506 loss)
I1130 22:24:09.323640 11845 sgd_solver.cpp:106] Iteration 96000, lr = 0.001
I1130 22:24:12.991847 11845 solver.cpp:228] Iteration 96500, loss = 0.0464131
I1130 22:24:12.991878 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0070007 (* 0.5 = 0.00350035 loss)
I1130 22:24:12.991885 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0306061 (* 1 = 0.0306061 loss)
I1130 22:24:12.991889 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:24:12.991894 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:24:12.991897 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00132353 (* 1 = 0.00132353 loss)
I1130 22:24:12.991901 11845 sgd_solver.cpp:106] Iteration 96500, lr = 0.001
I1130 22:24:16.649685 11845 solver.cpp:228] Iteration 97000, loss = 0.0453997
I1130 22:24:16.649715 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00792721 (* 0.5 = 0.00396361 loss)
I1130 22:24:16.649722 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0304442 (* 1 = 0.0304442 loss)
I1130 22:24:16.649725 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:24:16.649729 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:24:16.649734 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00273147 (* 1 = 0.00273147 loss)
I1130 22:24:16.649739 11845 sgd_solver.cpp:106] Iteration 97000, lr = 0.001
I1130 22:24:20.571779 11845 solver.cpp:228] Iteration 97500, loss = 0.0398912
I1130 22:24:20.571828 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.008766 (* 0.5 = 0.004383 loss)
I1130 22:24:20.571835 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0365173 (* 1 = 0.0365173 loss)
I1130 22:24:20.571840 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:24:20.571843 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:24:20.571848 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00340513 (* 1 = 0.00340513 loss)
I1130 22:24:20.571852 11845 sgd_solver.cpp:106] Iteration 97500, lr = 0.001
I1130 22:24:24.314903 11845 solver.cpp:228] Iteration 98000, loss = 0.0442481
I1130 22:24:24.314951 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00815576 (* 0.5 = 0.00407788 loss)
I1130 22:24:24.314959 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0243217 (* 1 = 0.0243217 loss)
I1130 22:24:24.314962 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:24:24.314965 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:24:24.314970 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00238523 (* 1 = 0.00238523 loss)
I1130 22:24:24.314975 11845 sgd_solver.cpp:106] Iteration 98000, lr = 0.001
I1130 22:24:27.933147 11845 solver.cpp:228] Iteration 98500, loss = 0.0445875
I1130 22:24:27.933183 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00833515 (* 0.5 = 0.00416757 loss)
I1130 22:24:27.933192 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0572612 (* 1 = 0.0572612 loss)
I1130 22:24:27.933194 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:24:27.933198 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:24:27.933202 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00223928 (* 1 = 0.00223928 loss)
I1130 22:24:27.933207 11845 sgd_solver.cpp:106] Iteration 98500, lr = 0.001
I1130 22:24:31.642721 11845 solver.cpp:228] Iteration 99000, loss = 0.0406875
I1130 22:24:31.642844 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00734698 (* 0.5 = 0.00367349 loss)
I1130 22:24:31.642853 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0278654 (* 1 = 0.0278654 loss)
I1130 22:24:31.642856 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:24:31.642874 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:24:31.642880 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00344984 (* 1 = 0.00344984 loss)
I1130 22:24:31.642884 11845 sgd_solver.cpp:106] Iteration 99000, lr = 0.001
I1130 22:24:35.439769 11845 solver.cpp:228] Iteration 99500, loss = 0.0441097
I1130 22:24:35.439832 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00779779 (* 0.5 = 0.0038989 loss)
I1130 22:24:35.439841 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0467362 (* 1 = 0.0467362 loss)
I1130 22:24:35.439844 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:24:35.439848 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:24:35.439853 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00229235 (* 1 = 0.00229235 loss)
I1130 22:24:35.439859 11845 sgd_solver.cpp:106] Iteration 99500, lr = 0.001
I1130 22:24:39.103595 11845 solver.cpp:228] Iteration 100000, loss = 0.0479172
I1130 22:24:39.103657 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00870058 (* 0.5 = 0.00435029 loss)
I1130 22:24:39.103665 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0215831 (* 1 = 0.0215831 loss)
I1130 22:24:39.103669 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:24:39.103673 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:24:39.103678 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00282761 (* 1 = 0.00282761 loss)
I1130 22:24:39.103684 11845 sgd_solver.cpp:106] Iteration 100000, lr = 0.001
I1130 22:24:42.771831 11845 solver.cpp:228] Iteration 100500, loss = 0.04274
I1130 22:24:42.771901 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00739218 (* 0.5 = 0.00369609 loss)
I1130 22:24:42.771909 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0515245 (* 1 = 0.0515245 loss)
I1130 22:24:42.771914 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:24:42.771919 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:24:42.771924 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.003388 (* 1 = 0.003388 loss)
I1130 22:24:42.771929 11845 sgd_solver.cpp:106] Iteration 100500, lr = 0.001
I1130 22:24:46.442128 11845 solver.cpp:228] Iteration 101000, loss = 0.0464538
I1130 22:24:46.442201 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00739855 (* 0.5 = 0.00369927 loss)
I1130 22:24:46.442209 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0512988 (* 1 = 0.0512988 loss)
I1130 22:24:46.442214 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:24:46.442217 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:24:46.442222 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00140571 (* 1 = 0.00140571 loss)
I1130 22:24:46.442229 11845 sgd_solver.cpp:106] Iteration 101000, lr = 0.001
I1130 22:24:50.101941 11845 solver.cpp:228] Iteration 101500, loss = 0.0459635
I1130 22:24:50.102010 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00746337 (* 0.5 = 0.00373169 loss)
I1130 22:24:50.102017 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0548652 (* 1 = 0.0548652 loss)
I1130 22:24:50.102021 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:24:50.102025 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:24:50.102030 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00319407 (* 1 = 0.00319407 loss)
I1130 22:24:50.102036 11845 sgd_solver.cpp:106] Iteration 101500, lr = 0.001
I1130 22:24:53.762413 11845 solver.cpp:228] Iteration 102000, loss = 0.0393419
I1130 22:24:53.762481 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0102666 (* 0.5 = 0.00513331 loss)
I1130 22:24:53.762506 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0521032 (* 1 = 0.0521032 loss)
I1130 22:24:53.762511 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:24:53.762516 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:24:53.762519 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00149049 (* 1 = 0.00149049 loss)
I1130 22:24:53.762526 11845 sgd_solver.cpp:106] Iteration 102000, lr = 0.001
I1130 22:24:54.852777 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_102150.caffemodel
I1130 22:24:54.858681 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_102150.solverstate
I1130 22:24:54.859313 11845 solver.cpp:337] Iteration 102150, Testing net (#0)
I1130 22:25:06.173789 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00832878 (* 0.5 = 0.00416439 loss)
I1130 22:25:06.173856 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0449475 (* 1 = 0.0449475 loss)
I1130 22:25:06.173863 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.99234
I1130 22:25:06.173868 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.915482
I1130 22:25:06.173874 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00191216 (* 1 = 0.00191216 loss)
I1130 22:25:08.793503 11845 solver.cpp:228] Iteration 102500, loss = 0.0466845
I1130 22:25:08.793573 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00791497 (* 0.5 = 0.00395749 loss)
I1130 22:25:08.793581 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0459486 (* 1 = 0.0459486 loss)
I1130 22:25:08.793586 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:25:08.793589 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:25:08.793594 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00220178 (* 1 = 0.00220178 loss)
I1130 22:25:08.793601 11845 sgd_solver.cpp:106] Iteration 102500, lr = 0.001
I1130 22:25:12.424577 11845 solver.cpp:228] Iteration 103000, loss = 0.0510786
I1130 22:25:12.424639 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00829912 (* 0.5 = 0.00414956 loss)
I1130 22:25:12.424646 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0250858 (* 1 = 0.0250858 loss)
I1130 22:25:12.424651 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:25:12.424654 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:25:12.424659 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00265731 (* 1 = 0.00265731 loss)
I1130 22:25:12.424664 11845 sgd_solver.cpp:106] Iteration 103000, lr = 0.001
I1130 22:25:16.037701 11845 solver.cpp:228] Iteration 103500, loss = 0.0394092
I1130 22:25:16.037768 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00799513 (* 0.5 = 0.00399757 loss)
I1130 22:25:16.037775 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0424453 (* 1 = 0.0424453 loss)
I1130 22:25:16.037780 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:25:16.037783 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:25:16.037788 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00131871 (* 1 = 0.00131871 loss)
I1130 22:25:16.037793 11845 sgd_solver.cpp:106] Iteration 103500, lr = 0.001
I1130 22:25:19.640491 11845 solver.cpp:228] Iteration 104000, loss = 0.0443225
I1130 22:25:19.640558 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0055718 (* 0.5 = 0.0027859 loss)
I1130 22:25:19.640566 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.034019 (* 1 = 0.034019 loss)
I1130 22:25:19.640570 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:25:19.640574 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:25:19.640579 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00209936 (* 1 = 0.00209936 loss)
I1130 22:25:19.640597 11845 sgd_solver.cpp:106] Iteration 104000, lr = 0.001
I1130 22:25:23.243289 11845 solver.cpp:228] Iteration 104500, loss = 0.0460207
I1130 22:25:23.243355 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00904374 (* 0.5 = 0.00452187 loss)
I1130 22:25:23.243361 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0436092 (* 1 = 0.0436092 loss)
I1130 22:25:23.243366 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:25:23.243369 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:25:23.243374 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00109134 (* 1 = 0.00109134 loss)
I1130 22:25:23.243379 11845 sgd_solver.cpp:106] Iteration 104500, lr = 0.001
I1130 22:25:26.842097 11845 solver.cpp:228] Iteration 105000, loss = 0.0406737
I1130 22:25:26.842161 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0103555 (* 0.5 = 0.00517777 loss)
I1130 22:25:26.842169 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0547056 (* 1 = 0.0547056 loss)
I1130 22:25:26.842172 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:25:26.842176 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:25:26.842181 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00225976 (* 1 = 0.00225976 loss)
I1130 22:25:26.842185 11845 sgd_solver.cpp:106] Iteration 105000, lr = 0.001
I1130 22:25:30.449371 11845 solver.cpp:228] Iteration 105500, loss = 0.0463191
I1130 22:25:30.449425 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00958483 (* 0.5 = 0.00479241 loss)
I1130 22:25:30.449432 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0233093 (* 1 = 0.0233093 loss)
I1130 22:25:30.449436 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:25:30.449440 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:25:30.449445 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00144854 (* 1 = 0.00144854 loss)
I1130 22:25:30.449450 11845 sgd_solver.cpp:106] Iteration 105500, lr = 0.001
I1130 22:25:34.049273 11845 solver.cpp:228] Iteration 106000, loss = 0.0449318
I1130 22:25:34.049335 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00727301 (* 0.5 = 0.00363651 loss)
I1130 22:25:34.049343 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0332185 (* 1 = 0.0332185 loss)
I1130 22:25:34.049347 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:25:34.049351 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:25:34.049355 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00117992 (* 1 = 0.00117992 loss)
I1130 22:25:34.049360 11845 sgd_solver.cpp:106] Iteration 106000, lr = 0.001
I1130 22:25:37.655629 11845 solver.cpp:228] Iteration 106500, loss = 0.0371884
I1130 22:25:37.655694 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00691266 (* 0.5 = 0.00345633 loss)
I1130 22:25:37.655700 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0578195 (* 1 = 0.0578195 loss)
I1130 22:25:37.655704 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:25:37.655709 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:25:37.655712 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00206923 (* 1 = 0.00206923 loss)
I1130 22:25:37.655717 11845 sgd_solver.cpp:106] Iteration 106500, lr = 0.001
I1130 22:25:41.256197 11845 solver.cpp:228] Iteration 107000, loss = 0.0456833
I1130 22:25:41.256255 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00664123 (* 0.5 = 0.00332062 loss)
I1130 22:25:41.256263 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0315037 (* 1 = 0.0315037 loss)
I1130 22:25:41.256266 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:25:41.256283 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:25:41.256289 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00244487 (* 1 = 0.00244487 loss)
I1130 22:25:41.256294 11845 sgd_solver.cpp:106] Iteration 107000, lr = 0.001
I1130 22:25:44.854324 11845 solver.cpp:228] Iteration 107500, loss = 0.0461785
I1130 22:25:44.854387 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00837595 (* 0.5 = 0.00418797 loss)
I1130 22:25:44.854395 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0511852 (* 1 = 0.0511852 loss)
I1130 22:25:44.854399 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:25:44.854403 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:25:44.854408 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00150402 (* 1 = 0.00150402 loss)
I1130 22:25:44.854413 11845 sgd_solver.cpp:106] Iteration 107500, lr = 0.001
I1130 22:25:48.471438 11845 solver.cpp:228] Iteration 108000, loss = 0.0380483
I1130 22:25:48.471498 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00882244 (* 0.5 = 0.00441122 loss)
I1130 22:25:48.471505 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0211943 (* 1 = 0.0211943 loss)
I1130 22:25:48.471509 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:25:48.471514 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:25:48.471518 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00166952 (* 1 = 0.00166952 loss)
I1130 22:25:48.471524 11845 sgd_solver.cpp:106] Iteration 108000, lr = 0.001
I1130 22:25:52.081233 11845 solver.cpp:228] Iteration 108500, loss = 0.0482588
I1130 22:25:52.081298 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00531658 (* 0.5 = 0.00265829 loss)
I1130 22:25:52.081305 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0570971 (* 1 = 0.0570971 loss)
I1130 22:25:52.081310 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:25:52.081313 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:25:52.081318 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00104261 (* 1 = 0.00104261 loss)
I1130 22:25:52.081323 11845 sgd_solver.cpp:106] Iteration 108500, lr = 0.001
I1130 22:25:55.389853 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_108960.caffemodel
I1130 22:25:55.395671 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_108960.solverstate
I1130 22:25:55.396292 11845 solver.cpp:337] Iteration 108960, Testing net (#0)
I1130 22:26:06.887163 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00831566 (* 0.5 = 0.00415783 loss)
I1130 22:26:06.887202 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.045986 (* 1 = 0.045986 loss)
I1130 22:26:06.887207 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.989317
I1130 22:26:06.887209 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.924844
I1130 22:26:06.887214 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00185874 (* 1 = 0.00185874 loss)
I1130 22:26:07.188575 11845 solver.cpp:228] Iteration 109000, loss = 0.047144
I1130 22:26:07.188634 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00635851 (* 0.5 = 0.00317926 loss)
I1130 22:26:07.188642 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0472583 (* 1 = 0.0472583 loss)
I1130 22:26:07.188645 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:26:07.188649 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:26:07.188653 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00245184 (* 1 = 0.00245184 loss)
I1130 22:26:07.188658 11845 sgd_solver.cpp:106] Iteration 109000, lr = 0.001
I1130 22:26:10.926277 11845 solver.cpp:228] Iteration 109500, loss = 0.0408119
I1130 22:26:10.926348 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0102307 (* 0.5 = 0.00511535 loss)
I1130 22:26:10.926357 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.036822 (* 1 = 0.036822 loss)
I1130 22:26:10.926359 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:26:10.926363 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:26:10.926367 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0030264 (* 1 = 0.0030264 loss)
I1130 22:26:10.926373 11845 sgd_solver.cpp:106] Iteration 109500, lr = 0.001
I1130 22:26:14.500226 11845 solver.cpp:228] Iteration 110000, loss = 0.0455291
I1130 22:26:14.500291 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0063357 (* 0.5 = 0.00316785 loss)
I1130 22:26:14.500298 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0452456 (* 1 = 0.0452456 loss)
I1130 22:26:14.500303 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:26:14.500306 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:26:14.500311 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00225974 (* 1 = 0.00225974 loss)
I1130 22:26:14.500316 11845 sgd_solver.cpp:106] Iteration 110000, lr = 0.001
I1130 22:26:18.098819 11845 solver.cpp:228] Iteration 110500, loss = 0.0441741
I1130 22:26:18.098879 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00759294 (* 0.5 = 0.00379647 loss)
I1130 22:26:18.098886 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0361331 (* 1 = 0.0361331 loss)
I1130 22:26:18.098891 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:26:18.098894 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:26:18.098899 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00182015 (* 1 = 0.00182015 loss)
I1130 22:26:18.098903 11845 sgd_solver.cpp:106] Iteration 110500, lr = 0.001
I1130 22:26:21.674710 11845 solver.cpp:228] Iteration 111000, loss = 0.0429486
I1130 22:26:21.674762 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00799776 (* 0.5 = 0.00399888 loss)
I1130 22:26:21.674769 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0319669 (* 1 = 0.0319669 loss)
I1130 22:26:21.674773 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:26:21.674777 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:26:21.674782 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00187323 (* 1 = 0.00187323 loss)
I1130 22:26:21.674787 11845 sgd_solver.cpp:106] Iteration 111000, lr = 0.001
I1130 22:26:25.252146 11845 solver.cpp:228] Iteration 111500, loss = 0.0497518
I1130 22:26:25.252203 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00909872 (* 0.5 = 0.00454936 loss)
I1130 22:26:25.252212 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0292481 (* 1 = 0.0292481 loss)
I1130 22:26:25.252215 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:26:25.252218 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:26:25.252223 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00119664 (* 1 = 0.00119664 loss)
I1130 22:26:25.252228 11845 sgd_solver.cpp:106] Iteration 111500, lr = 0.001
I1130 22:26:28.828534 11845 solver.cpp:228] Iteration 112000, loss = 0.0444173
I1130 22:26:28.828591 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00810816 (* 0.5 = 0.00405408 loss)
I1130 22:26:28.828599 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0519758 (* 1 = 0.0519758 loss)
I1130 22:26:28.828603 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:26:28.828606 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:26:28.828611 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00146789 (* 1 = 0.00146789 loss)
I1130 22:26:28.828631 11845 sgd_solver.cpp:106] Iteration 112000, lr = 0.001
I1130 22:26:32.415493 11845 solver.cpp:228] Iteration 112500, loss = 0.0391407
I1130 22:26:32.415556 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0076444 (* 0.5 = 0.0038222 loss)
I1130 22:26:32.415565 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.022963 (* 1 = 0.022963 loss)
I1130 22:26:32.415568 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:26:32.415571 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:26:32.415576 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00191761 (* 1 = 0.00191761 loss)
I1130 22:26:32.415581 11845 sgd_solver.cpp:106] Iteration 112500, lr = 0.001
I1130 22:26:35.992573 11845 solver.cpp:228] Iteration 113000, loss = 0.0465587
I1130 22:26:35.992631 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00592301 (* 0.5 = 0.0029615 loss)
I1130 22:26:35.992638 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0487509 (* 1 = 0.0487509 loss)
I1130 22:26:35.992642 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:26:35.992646 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:26:35.992651 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00110969 (* 1 = 0.00110969 loss)
I1130 22:26:35.992655 11845 sgd_solver.cpp:106] Iteration 113000, lr = 0.001
I1130 22:26:39.570462 11845 solver.cpp:228] Iteration 113500, loss = 0.0459509
I1130 22:26:39.570521 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00677056 (* 0.5 = 0.00338528 loss)
I1130 22:26:39.570528 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0459807 (* 1 = 0.0459807 loss)
I1130 22:26:39.570533 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:26:39.570536 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:26:39.570540 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00120584 (* 1 = 0.00120584 loss)
I1130 22:26:39.570545 11845 sgd_solver.cpp:106] Iteration 113500, lr = 0.001
I1130 22:26:43.155014 11845 solver.cpp:228] Iteration 114000, loss = 0.0399168
I1130 22:26:43.155076 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00863681 (* 0.5 = 0.0043184 loss)
I1130 22:26:43.155086 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0158523 (* 1 = 0.0158523 loss)
I1130 22:26:43.155089 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:26:43.155093 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:26:43.155098 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.001283 (* 1 = 0.001283 loss)
I1130 22:26:43.155102 11845 sgd_solver.cpp:106] Iteration 114000, lr = 0.001
I1130 22:26:46.731149 11845 solver.cpp:228] Iteration 114500, loss = 0.044118
I1130 22:26:46.731211 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00818081 (* 0.5 = 0.00409041 loss)
I1130 22:26:46.731220 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0268841 (* 1 = 0.0268841 loss)
I1130 22:26:46.731223 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:26:46.731226 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:26:46.731231 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00167569 (* 1 = 0.00167569 loss)
I1130 22:26:46.731236 11845 sgd_solver.cpp:106] Iteration 114500, lr = 0.001
I1130 22:26:50.318639 11845 solver.cpp:228] Iteration 115000, loss = 0.0441925
I1130 22:26:50.318699 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0104675 (* 0.5 = 0.00523377 loss)
I1130 22:26:50.318707 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0576191 (* 1 = 0.0576191 loss)
I1130 22:26:50.318711 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:26:50.318714 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:26:50.318733 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0013966 (* 1 = 0.0013966 loss)
I1130 22:26:50.318739 11845 sgd_solver.cpp:106] Iteration 115000, lr = 0.001
I1130 22:26:53.890820 11845 solver.cpp:228] Iteration 115500, loss = 0.041052
I1130 22:26:53.890879 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00599549 (* 0.5 = 0.00299775 loss)
I1130 22:26:53.890887 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0237855 (* 1 = 0.0237855 loss)
I1130 22:26:53.890890 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:26:53.890893 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:26:53.890898 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00150826 (* 1 = 0.00150826 loss)
I1130 22:26:53.890903 11845 sgd_solver.cpp:106] Iteration 115500, lr = 0.001
I1130 22:26:55.815259 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_115770.caffemodel
I1130 22:26:55.820765 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_115770.solverstate
I1130 22:26:55.821367 11845 solver.cpp:337] Iteration 115770, Testing net (#0)
I1130 22:27:06.542424 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00827561 (* 0.5 = 0.00413781 loss)
I1130 22:27:06.542459 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0481791 (* 1 = 0.0481791 loss)
I1130 22:27:06.542464 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.982862
I1130 22:27:06.542467 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.935239
I1130 22:27:06.542471 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00193322 (* 1 = 0.00193322 loss)
I1130 22:27:08.317924 11845 solver.cpp:228] Iteration 116000, loss = 0.0435885
I1130 22:27:08.317991 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00902082 (* 0.5 = 0.00451041 loss)
I1130 22:27:08.317998 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0405659 (* 1 = 0.0405659 loss)
I1130 22:27:08.318003 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:27:08.318006 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:27:08.318011 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00179774 (* 1 = 0.00179774 loss)
I1130 22:27:08.318017 11845 sgd_solver.cpp:106] Iteration 116000, lr = 0.001
I1130 22:27:11.918467 11845 solver.cpp:228] Iteration 116500, loss = 0.0466011
I1130 22:27:11.918529 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00895845 (* 0.5 = 0.00447923 loss)
I1130 22:27:11.918536 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0638296 (* 1 = 0.0638296 loss)
I1130 22:27:11.918540 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:27:11.918545 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:27:11.918550 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00103871 (* 1 = 0.00103871 loss)
I1130 22:27:11.918555 11845 sgd_solver.cpp:106] Iteration 116500, lr = 0.001
I1130 22:27:15.502270 11845 solver.cpp:228] Iteration 117000, loss = 0.043348
I1130 22:27:15.502332 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00612488 (* 0.5 = 0.00306244 loss)
I1130 22:27:15.502339 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0273169 (* 1 = 0.0273169 loss)
I1130 22:27:15.502343 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:27:15.502347 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:27:15.502352 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00124141 (* 1 = 0.00124141 loss)
I1130 22:27:15.502357 11845 sgd_solver.cpp:106] Iteration 117000, lr = 0.001
I1130 22:27:19.077662 11845 solver.cpp:228] Iteration 117500, loss = 0.0456893
I1130 22:27:19.077719 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00705308 (* 0.5 = 0.00352654 loss)
I1130 22:27:19.077740 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0186313 (* 1 = 0.0186313 loss)
I1130 22:27:19.077745 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:27:19.077749 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:27:19.077754 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.004564 (* 1 = 0.004564 loss)
I1130 22:27:19.077759 11845 sgd_solver.cpp:106] Iteration 117500, lr = 0.001
I1130 22:27:22.653779 11845 solver.cpp:228] Iteration 118000, loss = 0.0447362
I1130 22:27:22.653836 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00512222 (* 0.5 = 0.00256111 loss)
I1130 22:27:22.653844 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0542471 (* 1 = 0.0542471 loss)
I1130 22:27:22.653848 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:27:22.653851 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:27:22.653856 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000989393 (* 1 = 0.000989393 loss)
I1130 22:27:22.653861 11845 sgd_solver.cpp:106] Iteration 118000, lr = 0.001
I1130 22:27:26.224839 11845 solver.cpp:228] Iteration 118500, loss = 0.0419447
I1130 22:27:26.224897 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00913118 (* 0.5 = 0.00456559 loss)
I1130 22:27:26.224905 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0274471 (* 1 = 0.0274471 loss)
I1130 22:27:26.224910 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:27:26.224912 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:27:26.224917 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00124989 (* 1 = 0.00124989 loss)
I1130 22:27:26.224921 11845 sgd_solver.cpp:106] Iteration 118500, lr = 0.001
I1130 22:27:29.803081 11845 solver.cpp:228] Iteration 119000, loss = 0.0430501
I1130 22:27:29.803141 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00787203 (* 0.5 = 0.00393602 loss)
I1130 22:27:29.803149 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.032683 (* 1 = 0.032683 loss)
I1130 22:27:29.803153 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:27:29.803158 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:27:29.803163 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0032311 (* 1 = 0.0032311 loss)
I1130 22:27:29.803167 11845 sgd_solver.cpp:106] Iteration 119000, lr = 0.001
I1130 22:27:33.376032 11845 solver.cpp:228] Iteration 119500, loss = 0.0483453
I1130 22:27:33.376094 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00714602 (* 0.5 = 0.00357301 loss)
I1130 22:27:33.376102 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0158594 (* 1 = 0.0158594 loss)
I1130 22:27:33.376106 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:27:33.376111 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:27:33.376116 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00217803 (* 1 = 0.00217803 loss)
I1130 22:27:33.376119 11845 sgd_solver.cpp:106] Iteration 119500, lr = 0.001
I1130 22:27:36.945817 11845 solver.cpp:228] Iteration 120000, loss = 0.0483097
I1130 22:27:36.945874 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00811396 (* 0.5 = 0.00405698 loss)
I1130 22:27:36.945881 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0224075 (* 1 = 0.0224075 loss)
I1130 22:27:36.945885 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:27:36.945889 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:27:36.945894 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00137136 (* 1 = 0.00137136 loss)
I1130 22:27:36.945899 11845 sgd_solver.cpp:106] Iteration 120000, lr = 0.001
I1130 22:27:40.527930 11845 solver.cpp:228] Iteration 120500, loss = 0.039831
I1130 22:27:40.527994 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00691904 (* 0.5 = 0.00345952 loss)
I1130 22:27:40.528002 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0307136 (* 1 = 0.0307136 loss)
I1130 22:27:40.528007 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:27:40.528010 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:27:40.528015 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00151274 (* 1 = 0.00151274 loss)
I1130 22:27:40.528020 11845 sgd_solver.cpp:106] Iteration 120500, lr = 0.001
I1130 22:27:44.107362 11845 solver.cpp:228] Iteration 121000, loss = 0.0431426
I1130 22:27:44.107419 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00646522 (* 0.5 = 0.00323261 loss)
I1130 22:27:44.107426 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0357664 (* 1 = 0.0357664 loss)
I1130 22:27:44.107430 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:27:44.107434 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:27:44.107439 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00104494 (* 1 = 0.00104494 loss)
I1130 22:27:44.107445 11845 sgd_solver.cpp:106] Iteration 121000, lr = 0.001
I1130 22:27:47.678661 11845 solver.cpp:228] Iteration 121500, loss = 0.0474561
I1130 22:27:47.678727 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00922978 (* 0.5 = 0.00461489 loss)
I1130 22:27:47.678735 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0186353 (* 1 = 0.0186353 loss)
I1130 22:27:47.678738 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:27:47.678742 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:27:47.678747 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00147482 (* 1 = 0.00147482 loss)
I1130 22:27:47.678751 11845 sgd_solver.cpp:106] Iteration 121500, lr = 0.001
I1130 22:27:51.254668 11845 solver.cpp:228] Iteration 122000, loss = 0.0408219
I1130 22:27:51.254726 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00751885 (* 0.5 = 0.00375942 loss)
I1130 22:27:51.254734 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0250932 (* 1 = 0.0250932 loss)
I1130 22:27:51.254737 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:27:51.254741 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:27:51.254746 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00135059 (* 1 = 0.00135059 loss)
I1130 22:27:51.254751 11845 sgd_solver.cpp:106] Iteration 122000, lr = 0.001
I1130 22:27:54.835636 11845 solver.cpp:228] Iteration 122500, loss = 0.0427793
I1130 22:27:54.835695 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00508347 (* 0.5 = 0.00254174 loss)
I1130 22:27:54.835702 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0341088 (* 1 = 0.0341088 loss)
I1130 22:27:54.835706 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:27:54.835710 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:27:54.835714 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00143612 (* 1 = 0.00143612 loss)
I1130 22:27:54.835721 11845 sgd_solver.cpp:106] Iteration 122500, lr = 0.001
I1130 22:27:55.399909 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_122580.caffemodel
I1130 22:27:55.405489 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_122580.solverstate
I1130 22:27:55.406093 11845 solver.cpp:337] Iteration 122580, Testing net (#0)
I1130 22:28:06.175145 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00828619 (* 0.5 = 0.0041431 loss)
I1130 22:28:06.175179 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0462253 (* 1 = 0.0462253 loss)
I1130 22:28:06.175192 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.991606
I1130 22:28:06.175196 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.915007
I1130 22:28:06.175201 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00183892 (* 1 = 0.00183892 loss)
I1130 22:28:09.309411 11845 solver.cpp:228] Iteration 123000, loss = 0.0440739
I1130 22:28:09.309476 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00768807 (* 0.5 = 0.00384403 loss)
I1130 22:28:09.309484 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.038599 (* 1 = 0.038599 loss)
I1130 22:28:09.309487 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:28:09.309491 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:28:09.309495 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00188341 (* 1 = 0.00188341 loss)
I1130 22:28:09.309500 11845 sgd_solver.cpp:106] Iteration 123000, lr = 0.001
I1130 22:28:12.913991 11845 solver.cpp:228] Iteration 123500, loss = 0.0391386
I1130 22:28:12.914050 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00937062 (* 0.5 = 0.00468531 loss)
I1130 22:28:12.914057 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.04274 (* 1 = 0.04274 loss)
I1130 22:28:12.914062 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:28:12.914065 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:28:12.914077 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00153855 (* 1 = 0.00153855 loss)
I1130 22:28:12.914083 11845 sgd_solver.cpp:106] Iteration 123500, lr = 0.001
I1130 22:28:16.518592 11845 solver.cpp:228] Iteration 124000, loss = 0.0440812
I1130 22:28:16.518649 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00662292 (* 0.5 = 0.00331146 loss)
I1130 22:28:16.518657 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0367713 (* 1 = 0.0367713 loss)
I1130 22:28:16.518661 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:28:16.518664 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:28:16.518669 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00170601 (* 1 = 0.00170601 loss)
I1130 22:28:16.518674 11845 sgd_solver.cpp:106] Iteration 124000, lr = 0.001
I1130 22:28:20.139729 11845 solver.cpp:228] Iteration 124500, loss = 0.0474072
I1130 22:28:20.139788 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00871771 (* 0.5 = 0.00435885 loss)
I1130 22:28:20.139796 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0445019 (* 1 = 0.0445019 loss)
I1130 22:28:20.139801 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:28:20.139804 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:28:20.139809 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00109168 (* 1 = 0.00109168 loss)
I1130 22:28:20.139814 11845 sgd_solver.cpp:106] Iteration 124500, lr = 0.001
I1130 22:28:23.751075 11845 solver.cpp:228] Iteration 125000, loss = 0.0395635
I1130 22:28:23.751133 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00788266 (* 0.5 = 0.00394133 loss)
I1130 22:28:23.751140 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0509849 (* 1 = 0.0509849 loss)
I1130 22:28:23.751144 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:28:23.751148 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:28:23.751153 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00352412 (* 1 = 0.00352412 loss)
I1130 22:28:23.751158 11845 sgd_solver.cpp:106] Iteration 125000, lr = 0.001
I1130 22:28:27.349963 11845 solver.cpp:228] Iteration 125500, loss = 0.0460239
I1130 22:28:27.350025 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00830369 (* 0.5 = 0.00415185 loss)
I1130 22:28:27.350047 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0250371 (* 1 = 0.0250371 loss)
I1130 22:28:27.350054 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:28:27.350057 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:28:27.350062 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00148716 (* 1 = 0.00148716 loss)
I1130 22:28:27.350072 11845 sgd_solver.cpp:106] Iteration 125500, lr = 0.001
I1130 22:28:30.959887 11845 solver.cpp:228] Iteration 126000, loss = 0.0494464
I1130 22:28:30.959944 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00905089 (* 0.5 = 0.00452545 loss)
I1130 22:28:30.959951 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0199581 (* 1 = 0.0199581 loss)
I1130 22:28:30.959956 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:28:30.959959 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:28:30.959964 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00277402 (* 1 = 0.00277402 loss)
I1130 22:28:30.959969 11845 sgd_solver.cpp:106] Iteration 126000, lr = 0.001
I1130 22:28:34.566138 11845 solver.cpp:228] Iteration 126500, loss = 0.0387259
I1130 22:28:34.566198 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00791889 (* 0.5 = 0.00395944 loss)
I1130 22:28:34.566205 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0617436 (* 1 = 0.0617436 loss)
I1130 22:28:34.566210 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:28:34.566213 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:28:34.566217 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00224383 (* 1 = 0.00224383 loss)
I1130 22:28:34.566222 11845 sgd_solver.cpp:106] Iteration 126500, lr = 0.001
I1130 22:28:38.183182 11845 solver.cpp:228] Iteration 127000, loss = 0.0439076
I1130 22:28:38.183241 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00921464 (* 0.5 = 0.00460732 loss)
I1130 22:28:38.183248 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0128253 (* 1 = 0.0128253 loss)
I1130 22:28:38.183253 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:28:38.183256 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:28:38.183261 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00285727 (* 1 = 0.00285727 loss)
I1130 22:28:38.183265 11845 sgd_solver.cpp:106] Iteration 127000, lr = 0.001
I1130 22:28:41.793674 11845 solver.cpp:228] Iteration 127500, loss = 0.0470772
I1130 22:28:41.793733 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00788114 (* 0.5 = 0.00394057 loss)
I1130 22:28:41.793740 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0570562 (* 1 = 0.0570562 loss)
I1130 22:28:41.793745 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:28:41.793748 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:28:41.793753 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00160862 (* 1 = 0.00160862 loss)
I1130 22:28:41.793758 11845 sgd_solver.cpp:106] Iteration 127500, lr = 0.001
I1130 22:28:45.402912 11845 solver.cpp:228] Iteration 128000, loss = 0.041259
I1130 22:28:45.402971 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0107419 (* 0.5 = 0.00537097 loss)
I1130 22:28:45.402977 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0352821 (* 1 = 0.0352821 loss)
I1130 22:28:45.402981 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:28:45.402986 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:28:45.402990 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00158468 (* 1 = 0.00158468 loss)
I1130 22:28:45.402994 11845 sgd_solver.cpp:106] Iteration 128000, lr = 0.001
I1130 22:28:49.010819 11845 solver.cpp:228] Iteration 128500, loss = 0.0486851
I1130 22:28:49.010903 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0106185 (* 0.5 = 0.00530924 loss)
I1130 22:28:49.010911 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0510198 (* 1 = 0.0510198 loss)
I1130 22:28:49.010915 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:28:49.010918 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:28:49.010923 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00234899 (* 1 = 0.00234899 loss)
I1130 22:28:49.010927 11845 sgd_solver.cpp:106] Iteration 128500, lr = 0.001
I1130 22:28:52.624413 11845 solver.cpp:228] Iteration 129000, loss = 0.0450294
I1130 22:28:52.624471 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00864487 (* 0.5 = 0.00432244 loss)
I1130 22:28:52.624478 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0313473 (* 1 = 0.0313473 loss)
I1130 22:28:52.624482 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:28:52.624486 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:28:52.624490 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00302248 (* 1 = 0.00302248 loss)
I1130 22:28:52.624495 11845 sgd_solver.cpp:106] Iteration 129000, lr = 0.001
I1130 22:28:55.434361 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_129390.caffemodel
I1130 22:28:55.440135 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_129390.solverstate
I1130 22:28:55.440774 11845 solver.cpp:337] Iteration 129390, Testing net (#0)
I1130 22:29:07.056206 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0081635 (* 0.5 = 0.00408175 loss)
I1130 22:29:07.056255 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0471447 (* 1 = 0.0471447 loss)
I1130 22:29:07.056262 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.990381
I1130 22:29:07.056267 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.915342
I1130 22:29:07.056272 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00189873 (* 1 = 0.00189873 loss)
I1130 22:29:07.944110 11845 solver.cpp:228] Iteration 129500, loss = 0.0369579
I1130 22:29:07.944170 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00794388 (* 0.5 = 0.00397194 loss)
I1130 22:29:07.944178 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0264382 (* 1 = 0.0264382 loss)
I1130 22:29:07.944183 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:29:07.944187 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:29:07.944193 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.002218 (* 1 = 0.002218 loss)
I1130 22:29:07.944197 11845 sgd_solver.cpp:106] Iteration 129500, lr = 0.001
I1130 22:29:11.946002 11845 solver.cpp:228] Iteration 130000, loss = 0.0495498
I1130 22:29:11.946060 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00673458 (* 0.5 = 0.00336729 loss)
I1130 22:29:11.946074 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0226369 (* 1 = 0.0226369 loss)
I1130 22:29:11.946079 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:29:11.946084 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:29:11.946089 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00231746 (* 1 = 0.00231746 loss)
I1130 22:29:11.946094 11845 sgd_solver.cpp:106] Iteration 130000, lr = 0.001
I1130 22:29:15.893962 11845 solver.cpp:228] Iteration 130500, loss = 0.0447683
I1130 22:29:15.894045 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00916981 (* 0.5 = 0.00458491 loss)
I1130 22:29:15.894054 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0393023 (* 1 = 0.0393023 loss)
I1130 22:29:15.894060 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:29:15.894094 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:29:15.894103 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00169897 (* 1 = 0.00169897 loss)
I1130 22:29:15.894110 11845 sgd_solver.cpp:106] Iteration 130500, lr = 0.001
I1130 22:29:19.773632 11845 solver.cpp:228] Iteration 131000, loss = 0.0366806
I1130 22:29:19.773677 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00710103 (* 0.5 = 0.00355052 loss)
I1130 22:29:19.773686 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0228622 (* 1 = 0.0228622 loss)
I1130 22:29:19.773691 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:29:19.773696 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:29:19.773701 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0028756 (* 1 = 0.0028756 loss)
I1130 22:29:19.773707 11845 sgd_solver.cpp:106] Iteration 131000, lr = 0.001
I1130 22:29:23.418936 11845 solver.cpp:228] Iteration 131500, loss = 0.045953
I1130 22:29:23.418979 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00937579 (* 0.5 = 0.0046879 loss)
I1130 22:29:23.418988 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0412482 (* 1 = 0.0412482 loss)
I1130 22:29:23.418992 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:29:23.418998 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:29:23.419003 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00163641 (* 1 = 0.00163641 loss)
I1130 22:29:23.419008 11845 sgd_solver.cpp:106] Iteration 131500, lr = 0.001
I1130 22:29:27.319999 11845 solver.cpp:228] Iteration 132000, loss = 0.0431564
I1130 22:29:27.320057 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00561776 (* 0.5 = 0.00280888 loss)
I1130 22:29:27.320065 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0436737 (* 1 = 0.0436737 loss)
I1130 22:29:27.320075 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:29:27.320080 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:29:27.320086 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00241231 (* 1 = 0.00241231 loss)
I1130 22:29:27.320092 11845 sgd_solver.cpp:106] Iteration 132000, lr = 0.001
I1130 22:29:31.187389 11845 solver.cpp:228] Iteration 132500, loss = 0.0379963
I1130 22:29:31.187435 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0101037 (* 0.5 = 0.00505183 loss)
I1130 22:29:31.187443 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0290313 (* 1 = 0.0290313 loss)
I1130 22:29:31.187448 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:29:31.187453 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:29:31.187459 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00219544 (* 1 = 0.00219544 loss)
I1130 22:29:31.187464 11845 sgd_solver.cpp:106] Iteration 132500, lr = 0.001
I1130 22:29:34.809967 11845 solver.cpp:228] Iteration 133000, loss = 0.0471991
I1130 22:29:34.810003 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00933883 (* 0.5 = 0.00466941 loss)
I1130 22:29:34.810009 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.033933 (* 1 = 0.033933 loss)
I1130 22:29:34.810014 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:29:34.810017 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:29:34.810021 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00153682 (* 1 = 0.00153682 loss)
I1130 22:29:34.810025 11845 sgd_solver.cpp:106] Iteration 133000, lr = 0.001
I1130 22:29:38.433382 11845 solver.cpp:228] Iteration 133500, loss = 0.0453614
I1130 22:29:38.433418 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00767869 (* 0.5 = 0.00383935 loss)
I1130 22:29:38.433424 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0329753 (* 1 = 0.0329753 loss)
I1130 22:29:38.433437 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:29:38.433441 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:29:38.433446 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00123463 (* 1 = 0.00123463 loss)
I1130 22:29:38.433450 11845 sgd_solver.cpp:106] Iteration 133500, lr = 0.001
I1130 22:29:42.054630 11845 solver.cpp:228] Iteration 134000, loss = 0.0424022
I1130 22:29:42.054667 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00835302 (* 0.5 = 0.00417651 loss)
I1130 22:29:42.054673 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0353926 (* 1 = 0.0353926 loss)
I1130 22:29:42.054677 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:29:42.054682 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:29:42.054685 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0012529 (* 1 = 0.0012529 loss)
I1130 22:29:42.054690 11845 sgd_solver.cpp:106] Iteration 134000, lr = 0.001
I1130 22:29:45.677777 11845 solver.cpp:228] Iteration 134500, loss = 0.0474714
I1130 22:29:45.677812 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00756148 (* 0.5 = 0.00378074 loss)
I1130 22:29:45.677819 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0371382 (* 1 = 0.0371382 loss)
I1130 22:29:45.677822 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:29:45.677826 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:29:45.677830 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00110893 (* 1 = 0.00110893 loss)
I1130 22:29:45.677834 11845 sgd_solver.cpp:106] Iteration 134500, lr = 0.001
I1130 22:29:49.299470 11845 solver.cpp:228] Iteration 135000, loss = 0.0432857
I1130 22:29:49.299513 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0088276 (* 0.5 = 0.0044138 loss)
I1130 22:29:49.299521 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0282572 (* 1 = 0.0282572 loss)
I1130 22:29:49.299525 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:29:49.299528 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:29:49.299533 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00186187 (* 1 = 0.00186187 loss)
I1130 22:29:49.299537 11845 sgd_solver.cpp:106] Iteration 135000, lr = 0.001
I1130 22:29:52.919091 11845 solver.cpp:228] Iteration 135500, loss = 0.0399429
I1130 22:29:52.919127 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00630488 (* 0.5 = 0.00315244 loss)
I1130 22:29:52.919134 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0134374 (* 1 = 0.0134374 loss)
I1130 22:29:52.919137 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:29:52.919142 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:29:52.919145 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00976968 (* 1 = 0.00976968 loss)
I1130 22:29:52.919149 11845 sgd_solver.cpp:106] Iteration 135500, lr = 0.001
I1130 22:29:56.536289 11845 solver.cpp:228] Iteration 136000, loss = 0.0494912
I1130 22:29:56.536327 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00855819 (* 0.5 = 0.00427909 loss)
I1130 22:29:56.536334 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0370271 (* 1 = 0.0370271 loss)
I1130 22:29:56.536339 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:29:56.536341 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:29:56.536346 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00193124 (* 1 = 0.00193124 loss)
I1130 22:29:56.536350 11845 sgd_solver.cpp:106] Iteration 136000, lr = 0.001
I1130 22:29:57.977758 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_136200.caffemodel
I1130 22:29:57.983362 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_136200.solverstate
I1130 22:29:57.983960 11845 solver.cpp:337] Iteration 136200, Testing net (#0)
I1130 22:30:10.064894 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00831591 (* 0.5 = 0.00415796 loss)
I1130 22:30:10.065001 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0471848 (* 1 = 0.0471848 loss)
I1130 22:30:10.065006 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.993884
I1130 22:30:10.065016 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.906083
I1130 22:30:10.065031 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00184213 (* 1 = 0.00184213 loss)
I1130 22:30:12.488083 11845 solver.cpp:228] Iteration 136500, loss = 0.0475453
I1130 22:30:12.488145 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.007498 (* 0.5 = 0.003749 loss)
I1130 22:30:12.488153 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0401952 (* 1 = 0.0401952 loss)
I1130 22:30:12.488158 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:30:12.488162 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:30:12.488168 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00125829 (* 1 = 0.00125829 loss)
I1130 22:30:12.488174 11845 sgd_solver.cpp:106] Iteration 136500, lr = 0.0001
I1130 22:30:16.509857 11845 solver.cpp:228] Iteration 137000, loss = 0.0418902
I1130 22:30:16.509929 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00882143 (* 0.5 = 0.00441072 loss)
I1130 22:30:16.509938 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.00472237 (* 1 = 0.00472237 loss)
I1130 22:30:16.509943 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:30:16.509946 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:30:16.509951 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00188993 (* 1 = 0.00188993 loss)
I1130 22:30:16.509966 11845 sgd_solver.cpp:106] Iteration 137000, lr = 0.0001
I1130 22:30:20.516943 11845 solver.cpp:228] Iteration 137500, loss = 0.0432013
I1130 22:30:20.517021 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00930969 (* 0.5 = 0.00465485 loss)
I1130 22:30:20.517030 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0274084 (* 1 = 0.0274084 loss)
I1130 22:30:20.517035 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:30:20.517038 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:30:20.517045 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00146597 (* 1 = 0.00146597 loss)
I1130 22:30:20.517051 11845 sgd_solver.cpp:106] Iteration 137500, lr = 0.0001
I1130 22:30:24.566102 11845 solver.cpp:228] Iteration 138000, loss = 0.0449173
I1130 22:30:24.566172 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00622134 (* 0.5 = 0.00311067 loss)
I1130 22:30:24.566180 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0380003 (* 1 = 0.0380003 loss)
I1130 22:30:24.566185 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:30:24.566190 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:30:24.566195 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00748732 (* 1 = 0.00748732 loss)
I1130 22:30:24.566201 11845 sgd_solver.cpp:106] Iteration 138000, lr = 0.0001
I1130 22:30:28.552610 11845 solver.cpp:228] Iteration 138500, loss = 0.045126
I1130 22:30:28.552670 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00766473 (* 0.5 = 0.00383236 loss)
I1130 22:30:28.552678 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0159001 (* 1 = 0.0159001 loss)
I1130 22:30:28.552682 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:30:28.552686 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:30:28.552709 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00285631 (* 1 = 0.00285631 loss)
I1130 22:30:28.552726 11845 sgd_solver.cpp:106] Iteration 138500, lr = 0.0001
I1130 22:30:32.527711 11845 solver.cpp:228] Iteration 139000, loss = 0.0422384
I1130 22:30:32.527791 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00768333 (* 0.5 = 0.00384167 loss)
I1130 22:30:32.527798 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0154785 (* 1 = 0.0154785 loss)
I1130 22:30:32.527802 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:30:32.527806 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:30:32.527812 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00425427 (* 1 = 0.00425427 loss)
I1130 22:30:32.527819 11845 sgd_solver.cpp:106] Iteration 139000, lr = 0.0001
I1130 22:30:36.539718 11845 solver.cpp:228] Iteration 139500, loss = 0.0419113
I1130 22:30:36.539801 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00951204 (* 0.5 = 0.00475602 loss)
I1130 22:30:36.539809 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0268956 (* 1 = 0.0268956 loss)
I1130 22:30:36.539813 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:30:36.539818 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:30:36.539822 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00107497 (* 1 = 0.00107497 loss)
I1130 22:30:36.539839 11845 sgd_solver.cpp:106] Iteration 139500, lr = 0.0001
I1130 22:30:40.498005 11845 solver.cpp:228] Iteration 140000, loss = 0.0446939
I1130 22:30:40.498075 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00916563 (* 0.5 = 0.00458281 loss)
I1130 22:30:40.498085 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0151394 (* 1 = 0.0151394 loss)
I1130 22:30:40.498090 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:30:40.498092 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:30:40.498097 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00189175 (* 1 = 0.00189175 loss)
I1130 22:30:40.498106 11845 sgd_solver.cpp:106] Iteration 140000, lr = 0.0001
I1130 22:30:44.470377 11845 solver.cpp:228] Iteration 140500, loss = 0.0401186
I1130 22:30:44.470448 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00878805 (* 0.5 = 0.00439403 loss)
I1130 22:30:44.470456 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0367715 (* 1 = 0.0367715 loss)
I1130 22:30:44.470461 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:30:44.470465 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:30:44.470470 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00209711 (* 1 = 0.00209711 loss)
I1130 22:30:44.470477 11845 sgd_solver.cpp:106] Iteration 140500, lr = 0.0001
I1130 22:30:48.450816 11845 solver.cpp:228] Iteration 141000, loss = 0.0436061
I1130 22:30:48.450877 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00826278 (* 0.5 = 0.00413139 loss)
I1130 22:30:48.450884 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0198983 (* 1 = 0.0198983 loss)
I1130 22:30:48.450888 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:30:48.450892 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:30:48.450897 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00131005 (* 1 = 0.00131005 loss)
I1130 22:30:48.450906 11845 sgd_solver.cpp:106] Iteration 141000, lr = 0.0001
I1130 22:30:52.424865 11845 solver.cpp:228] Iteration 141500, loss = 0.0466501
I1130 22:30:52.424926 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00728267 (* 0.5 = 0.00364134 loss)
I1130 22:30:52.424933 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0184737 (* 1 = 0.0184737 loss)
I1130 22:30:52.424937 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:30:52.424958 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:30:52.424964 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00368889 (* 1 = 0.00368889 loss)
I1130 22:30:52.424971 11845 sgd_solver.cpp:106] Iteration 141500, lr = 0.0001
I1130 22:30:56.404209 11845 solver.cpp:228] Iteration 142000, loss = 0.0398169
I1130 22:30:56.404299 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00779449 (* 0.5 = 0.00389724 loss)
I1130 22:30:56.404307 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0402491 (* 1 = 0.0402491 loss)
I1130 22:30:56.404312 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:30:56.404316 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:30:56.404321 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00118059 (* 1 = 0.00118059 loss)
I1130 22:30:56.404336 11845 sgd_solver.cpp:106] Iteration 142000, lr = 0.0001
I1130 22:31:00.345048 11845 solver.cpp:228] Iteration 142500, loss = 0.0467489
I1130 22:31:00.345129 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00775163 (* 0.5 = 0.00387582 loss)
I1130 22:31:00.345137 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.027297 (* 1 = 0.027297 loss)
I1130 22:31:00.345141 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:31:00.345145 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:31:00.345150 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00206072 (* 1 = 0.00206072 loss)
I1130 22:31:00.345156 11845 sgd_solver.cpp:106] Iteration 142500, lr = 0.0001
I1130 22:31:04.301515 11845 solver.cpp:228] Iteration 143000, loss = 0.0480983
I1130 22:31:04.301589 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00894266 (* 0.5 = 0.00447133 loss)
I1130 22:31:04.301597 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0343797 (* 1 = 0.0343797 loss)
I1130 22:31:04.301601 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:31:04.301605 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:31:04.301620 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00258671 (* 1 = 0.00258671 loss)
I1130 22:31:04.301625 11845 sgd_solver.cpp:106] Iteration 143000, lr = 0.0001
I1130 22:31:04.371783 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_143010.caffemodel
I1130 22:31:04.377507 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_143010.solverstate
I1130 22:31:04.378206 11845 solver.cpp:337] Iteration 143010, Testing net (#0)
I1130 22:31:15.830252 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00806062 (* 0.5 = 0.00403031 loss)
I1130 22:31:15.830296 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.043813 (* 1 = 0.043813 loss)
I1130 22:31:15.830302 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.992409
I1130 22:31:15.830305 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.920144
I1130 22:31:15.830312 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00191531 (* 1 = 0.00191531 loss)
I1130 22:31:19.524772 11845 solver.cpp:228] Iteration 143500, loss = 0.0385348
I1130 22:31:19.524821 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00774042 (* 0.5 = 0.00387021 loss)
I1130 22:31:19.524828 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0223578 (* 1 = 0.0223578 loss)
I1130 22:31:19.524832 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:31:19.524837 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:31:19.524842 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00274893 (* 1 = 0.00274893 loss)
I1130 22:31:19.524845 11845 sgd_solver.cpp:106] Iteration 143500, lr = 0.0001
I1130 22:31:23.200464 11845 solver.cpp:228] Iteration 144000, loss = 0.042584
I1130 22:31:23.200500 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00745183 (* 0.5 = 0.00372591 loss)
I1130 22:31:23.200507 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0366322 (* 1 = 0.0366322 loss)
I1130 22:31:23.200511 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:31:23.200515 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:31:23.200520 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00124803 (* 1 = 0.00124803 loss)
I1130 22:31:23.200523 11845 sgd_solver.cpp:106] Iteration 144000, lr = 0.0001
I1130 22:31:26.790838 11845 solver.cpp:228] Iteration 144500, loss = 0.0515566
I1130 22:31:26.790871 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00770511 (* 0.5 = 0.00385255 loss)
I1130 22:31:26.790879 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0518866 (* 1 = 0.0518866 loss)
I1130 22:31:26.790882 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:31:26.790885 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:31:26.790890 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00172366 (* 1 = 0.00172366 loss)
I1130 22:31:26.790894 11845 sgd_solver.cpp:106] Iteration 144500, lr = 0.0001
I1130 22:31:30.382191 11845 solver.cpp:228] Iteration 145000, loss = 0.0411458
I1130 22:31:30.382235 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00905064 (* 0.5 = 0.00452532 loss)
I1130 22:31:30.382241 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.049433 (* 1 = 0.049433 loss)
I1130 22:31:30.382246 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:31:30.382248 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:31:30.382253 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00259398 (* 1 = 0.00259398 loss)
I1130 22:31:30.382257 11845 sgd_solver.cpp:106] Iteration 145000, lr = 0.0001
I1130 22:31:33.972589 11845 solver.cpp:228] Iteration 145500, loss = 0.0440879
I1130 22:31:33.972636 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00727928 (* 0.5 = 0.00363964 loss)
I1130 22:31:33.972645 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0151633 (* 1 = 0.0151633 loss)
I1130 22:31:33.972648 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:31:33.972651 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:31:33.972656 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00164474 (* 1 = 0.00164474 loss)
I1130 22:31:33.972661 11845 sgd_solver.cpp:106] Iteration 145500, lr = 0.0001
I1130 22:31:37.562432 11845 solver.cpp:228] Iteration 146000, loss = 0.0446609
I1130 22:31:37.562469 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00554068 (* 0.5 = 0.00277034 loss)
I1130 22:31:37.562475 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0411564 (* 1 = 0.0411564 loss)
I1130 22:31:37.562479 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:31:37.562484 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:31:37.562487 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00273548 (* 1 = 0.00273548 loss)
I1130 22:31:37.562491 11845 sgd_solver.cpp:106] Iteration 146000, lr = 0.0001
I1130 22:31:41.280421 11845 solver.cpp:228] Iteration 146500, loss = 0.0392959
I1130 22:31:41.280473 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00647739 (* 0.5 = 0.00323869 loss)
I1130 22:31:41.280480 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0471434 (* 1 = 0.0471434 loss)
I1130 22:31:41.280485 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:31:41.280489 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:31:41.280494 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00181017 (* 1 = 0.00181017 loss)
I1130 22:31:41.280514 11845 sgd_solver.cpp:106] Iteration 146500, lr = 0.0001
I1130 22:31:44.870097 11845 solver.cpp:228] Iteration 147000, loss = 0.0472632
I1130 22:31:44.870146 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00895178 (* 0.5 = 0.00447589 loss)
I1130 22:31:44.870153 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0343243 (* 1 = 0.0343243 loss)
I1130 22:31:44.870158 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:31:44.870162 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:31:44.870167 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00186599 (* 1 = 0.00186599 loss)
I1130 22:31:44.870170 11845 sgd_solver.cpp:106] Iteration 147000, lr = 0.0001
I1130 22:31:48.458411 11845 solver.cpp:228] Iteration 147500, loss = 0.0446777
I1130 22:31:48.458444 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00825696 (* 0.5 = 0.00412848 loss)
I1130 22:31:48.458451 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0448231 (* 1 = 0.0448231 loss)
I1130 22:31:48.458456 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:31:48.458459 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:31:48.458463 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000948809 (* 1 = 0.000948809 loss)
I1130 22:31:48.458468 11845 sgd_solver.cpp:106] Iteration 147500, lr = 0.0001
I1130 22:31:52.043097 11845 solver.cpp:228] Iteration 148000, loss = 0.0373653
I1130 22:31:52.043157 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0089769 (* 0.5 = 0.00448845 loss)
I1130 22:31:52.043164 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0346117 (* 1 = 0.0346117 loss)
I1130 22:31:52.043169 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:31:52.043171 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:31:52.043176 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00212752 (* 1 = 0.00212752 loss)
I1130 22:31:52.043180 11845 sgd_solver.cpp:106] Iteration 148000, lr = 0.0001
I1130 22:31:55.730242 11845 solver.cpp:228] Iteration 148500, loss = 0.0447878
I1130 22:31:55.730303 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00738362 (* 0.5 = 0.00369181 loss)
I1130 22:31:55.730309 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0289148 (* 1 = 0.0289148 loss)
I1130 22:31:55.730314 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:31:55.730317 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:31:55.730322 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00116157 (* 1 = 0.00116157 loss)
I1130 22:31:55.730327 11845 sgd_solver.cpp:106] Iteration 148500, lr = 0.0001
I1130 22:31:59.345278 11845 solver.cpp:228] Iteration 149000, loss = 0.0446448
I1130 22:31:59.345340 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00957463 (* 0.5 = 0.00478731 loss)
I1130 22:31:59.345346 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0281919 (* 1 = 0.0281919 loss)
I1130 22:31:59.345350 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:31:59.345355 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:31:59.345360 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00150244 (* 1 = 0.00150244 loss)
I1130 22:31:59.345365 11845 sgd_solver.cpp:106] Iteration 149000, lr = 0.0001
I1130 22:32:02.967155 11845 solver.cpp:228] Iteration 149500, loss = 0.0377407
I1130 22:32:02.967211 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00980918 (* 0.5 = 0.00490459 loss)
I1130 22:32:02.967217 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0407924 (* 1 = 0.0407924 loss)
I1130 22:32:02.967221 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:32:02.967239 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:32:02.967244 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00232749 (* 1 = 0.00232749 loss)
I1130 22:32:02.967249 11845 sgd_solver.cpp:106] Iteration 149500, lr = 0.0001
I1130 22:32:05.259999 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_149820.caffemodel
I1130 22:32:05.265792 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_149820.solverstate
I1130 22:32:05.266391 11845 solver.cpp:337] Iteration 149820, Testing net (#0)
I1130 22:32:16.078768 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00836422 (* 0.5 = 0.00418211 loss)
I1130 22:32:16.078845 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0448062 (* 1 = 0.0448062 loss)
I1130 22:32:16.078850 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.989924
I1130 22:32:16.078855 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.923997
I1130 22:32:16.078860 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00184655 (* 1 = 0.00184655 loss)
I1130 22:32:17.367383 11845 solver.cpp:228] Iteration 150000, loss = 0.0484367
I1130 22:32:17.367441 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00757969 (* 0.5 = 0.00378984 loss)
I1130 22:32:17.367449 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0420292 (* 1 = 0.0420292 loss)
I1130 22:32:17.367452 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:32:17.367456 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:32:17.367460 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00248364 (* 1 = 0.00248364 loss)
I1130 22:32:17.367465 11845 sgd_solver.cpp:106] Iteration 150000, lr = 0.0001
I1130 22:32:20.931357 11845 solver.cpp:228] Iteration 150500, loss = 0.0455409
I1130 22:32:20.931401 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00610439 (* 0.5 = 0.0030522 loss)
I1130 22:32:20.931408 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0561114 (* 1 = 0.0561114 loss)
I1130 22:32:20.931412 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:32:20.931416 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:32:20.931421 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00131157 (* 1 = 0.00131157 loss)
I1130 22:32:20.931424 11845 sgd_solver.cpp:106] Iteration 150500, lr = 0.0001
I1130 22:32:24.494412 11845 solver.cpp:228] Iteration 151000, loss = 0.0401051
I1130 22:32:24.494446 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0063524 (* 0.5 = 0.0031762 loss)
I1130 22:32:24.494452 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0241561 (* 1 = 0.0241561 loss)
I1130 22:32:24.494457 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:32:24.494459 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:32:24.494464 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00226813 (* 1 = 0.00226813 loss)
I1130 22:32:24.494468 11845 sgd_solver.cpp:106] Iteration 151000, lr = 0.0001
I1130 22:32:28.056813 11845 solver.cpp:228] Iteration 151500, loss = 0.0480933
I1130 22:32:28.056850 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00865888 (* 0.5 = 0.00432944 loss)
I1130 22:32:28.056857 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0344944 (* 1 = 0.0344944 loss)
I1130 22:32:28.056861 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:32:28.056864 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:32:28.056869 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00160133 (* 1 = 0.00160133 loss)
I1130 22:32:28.056874 11845 sgd_solver.cpp:106] Iteration 151500, lr = 0.0001
I1130 22:32:31.615538 11845 solver.cpp:228] Iteration 152000, loss = 0.0427809
I1130 22:32:31.615592 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00745884 (* 0.5 = 0.00372942 loss)
I1130 22:32:31.615599 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0325608 (* 1 = 0.0325608 loss)
I1130 22:32:31.615602 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:32:31.615607 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:32:31.615610 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00215453 (* 1 = 0.00215453 loss)
I1130 22:32:31.615614 11845 sgd_solver.cpp:106] Iteration 152000, lr = 0.0001
I1130 22:32:35.176308 11845 solver.cpp:228] Iteration 152500, loss = 0.039212
I1130 22:32:35.176357 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00892398 (* 0.5 = 0.00446199 loss)
I1130 22:32:35.176363 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0434421 (* 1 = 0.0434421 loss)
I1130 22:32:35.176367 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:32:35.176372 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:32:35.176375 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00115265 (* 1 = 0.00115265 loss)
I1130 22:32:35.176380 11845 sgd_solver.cpp:106] Iteration 152500, lr = 0.0001
I1130 22:32:38.736557 11845 solver.cpp:228] Iteration 153000, loss = 0.0521114
I1130 22:32:38.736594 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00609188 (* 0.5 = 0.00304594 loss)
I1130 22:32:38.736600 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.029637 (* 1 = 0.029637 loss)
I1130 22:32:38.736604 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:32:38.736608 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:32:38.736613 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00135064 (* 1 = 0.00135064 loss)
I1130 22:32:38.736616 11845 sgd_solver.cpp:106] Iteration 153000, lr = 0.0001
I1130 22:32:42.297570 11845 solver.cpp:228] Iteration 153500, loss = 0.0446689
I1130 22:32:42.297605 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0076857 (* 0.5 = 0.00384285 loss)
I1130 22:32:42.297611 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0266123 (* 1 = 0.0266123 loss)
I1130 22:32:42.297616 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:32:42.297618 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:32:42.297623 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00108755 (* 1 = 0.00108755 loss)
I1130 22:32:42.297627 11845 sgd_solver.cpp:106] Iteration 153500, lr = 0.0001
I1130 22:32:45.857906 11845 solver.cpp:228] Iteration 154000, loss = 0.0388642
I1130 22:32:45.857941 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00821672 (* 0.5 = 0.00410836 loss)
I1130 22:32:45.857947 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.028359 (* 1 = 0.028359 loss)
I1130 22:32:45.857951 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:32:45.857955 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:32:45.857959 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00252566 (* 1 = 0.00252566 loss)
I1130 22:32:45.857964 11845 sgd_solver.cpp:106] Iteration 154000, lr = 0.0001
I1130 22:32:49.414507 11845 solver.cpp:228] Iteration 154500, loss = 0.0448664
I1130 22:32:49.414543 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00946199 (* 0.5 = 0.004731 loss)
I1130 22:32:49.414549 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0228211 (* 1 = 0.0228211 loss)
I1130 22:32:49.414553 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:32:49.414557 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:32:49.414561 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00213916 (* 1 = 0.00213916 loss)
I1130 22:32:49.414573 11845 sgd_solver.cpp:106] Iteration 154500, lr = 0.0001
I1130 22:32:52.974649 11845 solver.cpp:228] Iteration 155000, loss = 0.0458755
I1130 22:32:52.974694 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00811719 (* 0.5 = 0.00405859 loss)
I1130 22:32:52.974701 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0327616 (* 1 = 0.0327616 loss)
I1130 22:32:52.974705 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:32:52.974709 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:32:52.974714 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0030318 (* 1 = 0.0030318 loss)
I1130 22:32:52.974717 11845 sgd_solver.cpp:106] Iteration 155000, lr = 0.0001
I1130 22:32:56.538167 11845 solver.cpp:228] Iteration 155500, loss = 0.0398415
I1130 22:32:56.538203 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00501653 (* 0.5 = 0.00250827 loss)
I1130 22:32:56.538208 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0325907 (* 1 = 0.0325907 loss)
I1130 22:32:56.538213 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:32:56.538216 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:32:56.538220 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00169329 (* 1 = 0.00169329 loss)
I1130 22:32:56.538225 11845 sgd_solver.cpp:106] Iteration 155500, lr = 0.0001
I1130 22:33:00.098211 11845 solver.cpp:228] Iteration 156000, loss = 0.0431756
I1130 22:33:00.098248 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0086088 (* 0.5 = 0.0043044 loss)
I1130 22:33:00.098254 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0461606 (* 1 = 0.0461606 loss)
I1130 22:33:00.098258 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:33:00.098263 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:33:00.098266 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00393384 (* 1 = 0.00393384 loss)
I1130 22:33:00.098271 11845 sgd_solver.cpp:106] Iteration 156000, lr = 0.0001
I1130 22:33:03.656420 11845 solver.cpp:228] Iteration 156500, loss = 0.0448871
I1130 22:33:03.656455 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00962708 (* 0.5 = 0.00481354 loss)
I1130 22:33:03.656462 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0341017 (* 1 = 0.0341017 loss)
I1130 22:33:03.656466 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:33:03.656469 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:33:03.656474 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00181962 (* 1 = 0.00181962 loss)
I1130 22:33:03.656478 11845 sgd_solver.cpp:106] Iteration 156500, lr = 0.0001
I1130 22:33:04.575304 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_156630.caffemodel
I1130 22:33:04.580807 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_156630.solverstate
I1130 22:33:04.581403 11845 solver.cpp:337] Iteration 156630, Testing net (#0)
I1130 22:33:17.157035 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00807741 (* 0.5 = 0.0040387 loss)
I1130 22:33:17.157100 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0442039 (* 1 = 0.0442039 loss)
I1130 22:33:17.157112 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.990553
I1130 22:33:17.157119 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.923336
I1130 22:33:17.157129 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.0018895 (* 1 = 0.0018895 loss)
I1130 22:33:19.934052 11845 solver.cpp:228] Iteration 157000, loss = 0.0393908
I1130 22:33:19.934109 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00844268 (* 0.5 = 0.00422134 loss)
I1130 22:33:19.934118 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.025879 (* 1 = 0.025879 loss)
I1130 22:33:19.934139 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:33:19.934144 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:33:19.934150 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00167041 (* 1 = 0.00167041 loss)
I1130 22:33:19.934155 11845 sgd_solver.cpp:106] Iteration 157000, lr = 0.0001
I1130 22:33:23.560803 11845 solver.cpp:228] Iteration 157500, loss = 0.0440667
I1130 22:33:23.560835 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00907269 (* 0.5 = 0.00453635 loss)
I1130 22:33:23.560842 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0480935 (* 1 = 0.0480935 loss)
I1130 22:33:23.560847 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:33:23.560849 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:33:23.560854 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00271303 (* 1 = 0.00271303 loss)
I1130 22:33:23.560858 11845 sgd_solver.cpp:106] Iteration 157500, lr = 0.0001
I1130 22:33:27.144727 11845 solver.cpp:228] Iteration 158000, loss = 0.0447695
I1130 22:33:27.144815 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00688716 (* 0.5 = 0.00344358 loss)
I1130 22:33:27.144824 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0339866 (* 1 = 0.0339866 loss)
I1130 22:33:27.144827 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:33:27.144831 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:33:27.144836 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00204117 (* 1 = 0.00204117 loss)
I1130 22:33:27.144842 11845 sgd_solver.cpp:106] Iteration 158000, lr = 0.0001
I1130 22:33:30.933266 11845 solver.cpp:228] Iteration 158500, loss = 0.0426862
I1130 22:33:30.933323 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00836152 (* 0.5 = 0.00418076 loss)
I1130 22:33:30.933331 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0387214 (* 1 = 0.0387214 loss)
I1130 22:33:30.933334 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:33:30.933338 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:33:30.933343 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00203396 (* 1 = 0.00203396 loss)
I1130 22:33:30.933347 11845 sgd_solver.cpp:106] Iteration 158500, lr = 0.0001
I1130 22:33:35.251521 11845 solver.cpp:228] Iteration 159000, loss = 0.044948
I1130 22:33:35.251682 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.010461 (* 0.5 = 0.00523051 loss)
I1130 22:33:35.251689 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0282965 (* 1 = 0.0282965 loss)
I1130 22:33:35.251694 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:33:35.251698 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:33:35.251703 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00149259 (* 1 = 0.00149259 loss)
I1130 22:33:35.251713 11845 sgd_solver.cpp:106] Iteration 159000, lr = 0.0001
I1130 22:33:39.111958 11845 solver.cpp:228] Iteration 159500, loss = 0.046506
I1130 22:33:39.112228 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00749853 (* 0.5 = 0.00374926 loss)
I1130 22:33:39.112237 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0454597 (* 1 = 0.0454597 loss)
I1130 22:33:39.112241 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:33:39.112246 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:33:39.112251 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00236295 (* 1 = 0.00236295 loss)
I1130 22:33:39.112258 11845 sgd_solver.cpp:106] Iteration 159500, lr = 0.0001
I1130 22:33:42.963371 11845 solver.cpp:228] Iteration 160000, loss = 0.0426294
I1130 22:33:42.963512 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00498602 (* 0.5 = 0.00249301 loss)
I1130 22:33:42.963522 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0104597 (* 1 = 0.0104597 loss)
I1130 22:33:42.963526 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:33:42.963531 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:33:42.963536 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0015857 (* 1 = 0.0015857 loss)
I1130 22:33:42.963543 11845 sgd_solver.cpp:106] Iteration 160000, lr = 0.0001
I1130 22:33:46.808308 11845 solver.cpp:228] Iteration 160500, loss = 0.0407399
I1130 22:33:46.808524 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00833783 (* 0.5 = 0.00416892 loss)
I1130 22:33:46.808531 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0384029 (* 1 = 0.0384029 loss)
I1130 22:33:46.808537 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:33:46.808542 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:33:46.808547 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00210979 (* 1 = 0.00210979 loss)
I1130 22:33:46.808553 11845 sgd_solver.cpp:106] Iteration 160500, lr = 0.0001
I1130 22:33:50.642269 11845 solver.cpp:228] Iteration 161000, loss = 0.0464983
I1130 22:33:50.642386 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00819885 (* 0.5 = 0.00409943 loss)
I1130 22:33:50.642395 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0451395 (* 1 = 0.0451395 loss)
I1130 22:33:50.642398 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:33:50.642402 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:33:50.642407 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00152727 (* 1 = 0.00152727 loss)
I1130 22:33:50.642415 11845 sgd_solver.cpp:106] Iteration 161000, lr = 0.0001
I1130 22:33:54.498033 11845 solver.cpp:228] Iteration 161500, loss = 0.0491884
I1130 22:33:54.498111 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00681792 (* 0.5 = 0.00340896 loss)
I1130 22:33:54.498117 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.00919693 (* 1 = 0.00919693 loss)
I1130 22:33:54.498122 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:33:54.498126 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:33:54.498131 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0014429 (* 1 = 0.0014429 loss)
I1130 22:33:54.498136 11845 sgd_solver.cpp:106] Iteration 161500, lr = 0.0001
I1130 22:33:58.343283 11845 solver.cpp:228] Iteration 162000, loss = 0.0408005
I1130 22:33:58.343351 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00878274 (* 0.5 = 0.00439137 loss)
I1130 22:33:58.343358 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0253554 (* 1 = 0.0253554 loss)
I1130 22:33:58.343364 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:33:58.343367 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:33:58.343372 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00217765 (* 1 = 0.00217765 loss)
I1130 22:33:58.343379 11845 sgd_solver.cpp:106] Iteration 162000, lr = 0.0001
I1130 22:34:02.192997 11845 solver.cpp:228] Iteration 162500, loss = 0.0438479
I1130 22:34:02.193063 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00823615 (* 0.5 = 0.00411808 loss)
I1130 22:34:02.193076 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.033503 (* 1 = 0.033503 loss)
I1130 22:34:02.193080 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:34:02.193084 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:34:02.193089 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0015307 (* 1 = 0.0015307 loss)
I1130 22:34:02.193110 11845 sgd_solver.cpp:106] Iteration 162500, lr = 0.0001
I1130 22:34:06.041750 11845 solver.cpp:228] Iteration 163000, loss = 0.0453505
I1130 22:34:06.041815 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00929656 (* 0.5 = 0.00464828 loss)
I1130 22:34:06.041823 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0443267 (* 1 = 0.0443267 loss)
I1130 22:34:06.041827 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:34:06.041831 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:34:06.041836 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0013939 (* 1 = 0.0013939 loss)
I1130 22:34:06.041842 11845 sgd_solver.cpp:106] Iteration 163000, lr = 0.0001
I1130 22:34:09.465764 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_163440.caffemodel
I1130 22:34:09.471282 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_163440.solverstate
I1130 22:34:09.471909 11845 solver.cpp:337] Iteration 163440, Testing net (#0)
I1130 22:34:21.698217 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00830522 (* 0.5 = 0.00415261 loss)
I1130 22:34:21.698276 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.044735 (* 1 = 0.044735 loss)
I1130 22:34:21.698281 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.988877
I1130 22:34:21.698284 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.926817
I1130 22:34:21.698289 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00186779 (* 1 = 0.00186779 loss)
I1130 22:34:22.151615 11845 solver.cpp:228] Iteration 163500, loss = 0.0419328
I1130 22:34:22.151676 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00824366 (* 0.5 = 0.00412183 loss)
I1130 22:34:22.151684 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0417145 (* 1 = 0.0417145 loss)
I1130 22:34:22.151688 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:34:22.151692 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:34:22.151697 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00106418 (* 1 = 0.00106418 loss)
I1130 22:34:22.151705 11845 sgd_solver.cpp:106] Iteration 163500, lr = 0.0001
I1130 22:34:25.932003 11845 solver.cpp:228] Iteration 164000, loss = 0.0435321
I1130 22:34:25.932072 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0069372 (* 0.5 = 0.0034686 loss)
I1130 22:34:25.932082 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0335015 (* 1 = 0.0335015 loss)
I1130 22:34:25.932086 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:34:25.932090 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:34:25.932096 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00102381 (* 1 = 0.00102381 loss)
I1130 22:34:25.932101 11845 sgd_solver.cpp:106] Iteration 164000, lr = 0.0001
I1130 22:34:29.730274 11845 solver.cpp:228] Iteration 164500, loss = 0.0445132
I1130 22:34:29.730432 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00710113 (* 0.5 = 0.00355057 loss)
I1130 22:34:29.730442 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0509605 (* 1 = 0.0509605 loss)
I1130 22:34:29.730446 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:34:29.730451 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:34:29.730458 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00146264 (* 1 = 0.00146264 loss)
I1130 22:34:29.730465 11845 sgd_solver.cpp:106] Iteration 164500, lr = 0.0001
I1130 22:34:33.491294 11845 solver.cpp:228] Iteration 165000, loss = 0.03847
I1130 22:34:33.491370 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00717795 (* 0.5 = 0.00358898 loss)
I1130 22:34:33.491379 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.046955 (* 1 = 0.046955 loss)
I1130 22:34:33.491407 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:34:33.491413 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:34:33.491418 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00296653 (* 1 = 0.00296653 loss)
I1130 22:34:33.491425 11845 sgd_solver.cpp:106] Iteration 165000, lr = 0.0001
I1130 22:34:37.198635 11845 solver.cpp:228] Iteration 165500, loss = 0.0418651
I1130 22:34:37.198711 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00848387 (* 0.5 = 0.00424193 loss)
I1130 22:34:37.198719 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0414103 (* 1 = 0.0414103 loss)
I1130 22:34:37.198724 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:34:37.198727 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:34:37.198734 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00195924 (* 1 = 0.00195924 loss)
I1130 22:34:37.198740 11845 sgd_solver.cpp:106] Iteration 165500, lr = 0.0001
I1130 22:34:40.885948 11845 solver.cpp:228] Iteration 166000, loss = 0.0462768
I1130 22:34:40.886123 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00885146 (* 0.5 = 0.00442573 loss)
I1130 22:34:40.886133 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0410877 (* 1 = 0.0410877 loss)
I1130 22:34:40.886137 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:34:40.886142 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:34:40.886147 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00108531 (* 1 = 0.00108531 loss)
I1130 22:34:40.886153 11845 sgd_solver.cpp:106] Iteration 166000, lr = 0.0001
I1130 22:34:44.581820 11845 solver.cpp:228] Iteration 166500, loss = 0.0399553
I1130 22:34:44.581954 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0087907 (* 0.5 = 0.00439535 loss)
I1130 22:34:44.581961 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0348438 (* 1 = 0.0348438 loss)
I1130 22:34:44.581966 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:34:44.581970 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:34:44.581975 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00214934 (* 1 = 0.00214934 loss)
I1130 22:34:44.581984 11845 sgd_solver.cpp:106] Iteration 166500, lr = 0.0001
I1130 22:34:48.308725 11845 solver.cpp:228] Iteration 167000, loss = 0.0443915
I1130 22:34:48.308797 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0077496 (* 0.5 = 0.0038748 loss)
I1130 22:34:48.308805 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0253751 (* 1 = 0.0253751 loss)
I1130 22:34:48.308809 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:34:48.308814 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:34:48.308820 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00105146 (* 1 = 0.00105146 loss)
I1130 22:34:48.308826 11845 sgd_solver.cpp:106] Iteration 167000, lr = 0.0001
I1130 22:34:52.109195 11845 solver.cpp:228] Iteration 167500, loss = 0.0483941
I1130 22:34:52.109330 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00812667 (* 0.5 = 0.00406334 loss)
I1130 22:34:52.109338 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.044163 (* 1 = 0.044163 loss)
I1130 22:34:52.109343 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:34:52.109346 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:34:52.109351 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00106309 (* 1 = 0.00106309 loss)
I1130 22:34:52.109357 11845 sgd_solver.cpp:106] Iteration 167500, lr = 0.0001
I1130 22:34:55.799926 11845 solver.cpp:228] Iteration 168000, loss = 0.0406261
I1130 22:34:55.800040 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0082614 (* 0.5 = 0.0041307 loss)
I1130 22:34:55.800082 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0426475 (* 1 = 0.0426475 loss)
I1130 22:34:55.800088 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:34:55.800093 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:34:55.800098 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00108929 (* 1 = 0.00108929 loss)
I1130 22:34:55.800104 11845 sgd_solver.cpp:106] Iteration 168000, lr = 0.0001
I1130 22:34:59.495518 11845 solver.cpp:228] Iteration 168500, loss = 0.0434698
I1130 22:34:59.495584 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00737193 (* 0.5 = 0.00368596 loss)
I1130 22:34:59.495592 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0335455 (* 1 = 0.0335455 loss)
I1130 22:34:59.495596 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:34:59.495600 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:34:59.495605 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00174985 (* 1 = 0.00174985 loss)
I1130 22:34:59.495611 11845 sgd_solver.cpp:106] Iteration 168500, lr = 0.0001
I1130 22:35:03.209146 11845 solver.cpp:228] Iteration 169000, loss = 0.0447933
I1130 22:35:03.209228 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00771599 (* 0.5 = 0.003858 loss)
I1130 22:35:03.209236 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0447214 (* 1 = 0.0447214 loss)
I1130 22:35:03.209242 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:35:03.209247 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:35:03.209254 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00333378 (* 1 = 0.00333378 loss)
I1130 22:35:03.209261 11845 sgd_solver.cpp:106] Iteration 169000, lr = 0.0001
I1130 22:35:06.981699 11845 solver.cpp:228] Iteration 169500, loss = 0.0415739
I1130 22:35:06.981854 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00641203 (* 0.5 = 0.00320602 loss)
I1130 22:35:06.981863 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0829594 (* 1 = 0.0829594 loss)
I1130 22:35:06.981866 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 22:35:06.981870 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 22:35:06.981875 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00133268 (* 1 = 0.00133268 loss)
I1130 22:35:06.981881 11845 sgd_solver.cpp:106] Iteration 169500, lr = 0.0001
I1130 22:35:10.812508 11845 solver.cpp:228] Iteration 170000, loss = 0.0485291
I1130 22:35:10.812577 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00905869 (* 0.5 = 0.00452934 loss)
I1130 22:35:10.812583 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0354227 (* 1 = 0.0354227 loss)
I1130 22:35:10.812588 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:35:10.812592 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:35:10.812598 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00131968 (* 1 = 0.00131968 loss)
I1130 22:35:10.812604 11845 sgd_solver.cpp:106] Iteration 170000, lr = 0.0001
I1130 22:35:12.666931 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_170250.caffemodel
I1130 22:35:12.672436 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_170250.solverstate
I1130 22:35:12.673081 11845 solver.cpp:337] Iteration 170250, Testing net (#0)
I1130 22:35:25.064827 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00814991 (* 0.5 = 0.00407496 loss)
I1130 22:35:25.064890 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0454366 (* 1 = 0.0454366 loss)
I1130 22:35:25.064896 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.992313
I1130 22:35:25.064919 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.915184
I1130 22:35:25.064924 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00187816 (* 1 = 0.00187816 loss)
I1130 22:35:26.938666 11845 solver.cpp:228] Iteration 170500, loss = 0.0452081
I1130 22:35:26.938750 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00951788 (* 0.5 = 0.00475894 loss)
I1130 22:35:26.938757 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.03353 (* 1 = 0.03353 loss)
I1130 22:35:26.938761 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:35:26.938766 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:35:26.938771 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00173076 (* 1 = 0.00173076 loss)
I1130 22:35:26.938777 11845 sgd_solver.cpp:106] Iteration 170500, lr = 0.0001
I1130 22:35:30.709868 11845 solver.cpp:228] Iteration 171000, loss = 0.0364305
I1130 22:35:30.709977 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00756717 (* 0.5 = 0.00378358 loss)
I1130 22:35:30.709986 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0372198 (* 1 = 0.0372198 loss)
I1130 22:35:30.709990 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:35:30.709995 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:35:30.710000 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00137775 (* 1 = 0.00137775 loss)
I1130 22:35:30.710008 11845 sgd_solver.cpp:106] Iteration 171000, lr = 0.0001
I1130 22:35:34.400743 11845 solver.cpp:228] Iteration 171500, loss = 0.0478583
I1130 22:35:34.400898 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00790147 (* 0.5 = 0.00395073 loss)
I1130 22:35:34.400907 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.033095 (* 1 = 0.033095 loss)
I1130 22:35:34.400910 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:35:34.400914 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:35:34.400920 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00146362 (* 1 = 0.00146362 loss)
I1130 22:35:34.400926 11845 sgd_solver.cpp:106] Iteration 171500, lr = 0.0001
I1130 22:35:38.106158 11845 solver.cpp:228] Iteration 172000, loss = 0.0455546
I1130 22:35:38.106246 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00558773 (* 0.5 = 0.00279387 loss)
I1130 22:35:38.106256 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0265908 (* 1 = 0.0265908 loss)
I1130 22:35:38.106262 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:35:38.106268 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:35:38.106276 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00211182 (* 1 = 0.00211182 loss)
I1130 22:35:38.106282 11845 sgd_solver.cpp:106] Iteration 172000, lr = 0.0001
I1130 22:35:41.860853 11845 solver.cpp:228] Iteration 172500, loss = 0.0371288
I1130 22:35:41.860930 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00727955 (* 0.5 = 0.00363977 loss)
I1130 22:35:41.860939 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0320767 (* 1 = 0.0320767 loss)
I1130 22:35:41.860944 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:35:41.860947 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:35:41.860954 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00150776 (* 1 = 0.00150776 loss)
I1130 22:35:41.860960 11845 sgd_solver.cpp:106] Iteration 172500, lr = 0.0001
I1130 22:35:45.558279 11845 solver.cpp:228] Iteration 173000, loss = 0.045849
I1130 22:35:45.558379 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00862327 (* 0.5 = 0.00431164 loss)
I1130 22:35:45.558387 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0294828 (* 1 = 0.0294828 loss)
I1130 22:35:45.558410 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:35:45.558415 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:35:45.558420 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00144252 (* 1 = 0.00144252 loss)
I1130 22:35:45.558425 11845 sgd_solver.cpp:106] Iteration 173000, lr = 0.0001
I1130 22:35:49.252475 11845 solver.cpp:228] Iteration 173500, loss = 0.043572
I1130 22:35:49.252593 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00819873 (* 0.5 = 0.00409936 loss)
I1130 22:35:49.252600 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.042061 (* 1 = 0.042061 loss)
I1130 22:35:49.252604 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:35:49.252609 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:35:49.252614 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00203833 (* 1 = 0.00203833 loss)
I1130 22:35:49.252622 11845 sgd_solver.cpp:106] Iteration 173500, lr = 0.0001
I1130 22:35:52.937402 11845 solver.cpp:228] Iteration 174000, loss = 0.037562
I1130 22:35:52.937474 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00768262 (* 0.5 = 0.00384131 loss)
I1130 22:35:52.937482 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0321907 (* 1 = 0.0321907 loss)
I1130 22:35:52.937487 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:35:52.937491 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:35:52.937496 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00891783 (* 1 = 0.00891783 loss)
I1130 22:35:52.937505 11845 sgd_solver.cpp:106] Iteration 174000, lr = 0.0001
I1130 22:35:56.635277 11845 solver.cpp:228] Iteration 174500, loss = 0.0455238
I1130 22:35:56.635396 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00722445 (* 0.5 = 0.00361223 loss)
I1130 22:35:56.635402 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0334337 (* 1 = 0.0334337 loss)
I1130 22:35:56.635406 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:35:56.635411 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:35:56.635416 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00116607 (* 1 = 0.00116607 loss)
I1130 22:35:56.635422 11845 sgd_solver.cpp:106] Iteration 174500, lr = 0.0001
I1130 22:36:00.320217 11845 solver.cpp:228] Iteration 175000, loss = 0.0461201
I1130 22:36:00.320282 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0085066 (* 0.5 = 0.0042533 loss)
I1130 22:36:00.320289 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0294838 (* 1 = 0.0294838 loss)
I1130 22:36:00.320294 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:36:00.320298 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:36:00.320303 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00137922 (* 1 = 0.00137922 loss)
I1130 22:36:00.320309 11845 sgd_solver.cpp:106] Iteration 175000, lr = 0.0001
I1130 22:36:04.038228 11845 solver.cpp:228] Iteration 175500, loss = 0.0392178
I1130 22:36:04.038313 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00583508 (* 0.5 = 0.00291754 loss)
I1130 22:36:04.038322 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0222734 (* 1 = 0.0222734 loss)
I1130 22:36:04.038326 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:36:04.038331 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:36:04.038336 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00139449 (* 1 = 0.00139449 loss)
I1130 22:36:04.038341 11845 sgd_solver.cpp:106] Iteration 175500, lr = 0.0001
I1130 22:36:07.732591 11845 solver.cpp:228] Iteration 176000, loss = 0.0491365
I1130 22:36:07.732717 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00829803 (* 0.5 = 0.00414902 loss)
I1130 22:36:07.732753 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.039896 (* 1 = 0.039896 loss)
I1130 22:36:07.732756 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:36:07.732760 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:36:07.732765 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00131816 (* 1 = 0.00131816 loss)
I1130 22:36:07.732774 11845 sgd_solver.cpp:106] Iteration 176000, lr = 0.0001
I1130 22:36:11.449793 11845 solver.cpp:228] Iteration 176500, loss = 0.0455349
I1130 22:36:11.449908 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00638897 (* 0.5 = 0.00319449 loss)
I1130 22:36:11.449915 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0474262 (* 1 = 0.0474262 loss)
I1130 22:36:11.449920 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:36:11.449924 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:36:11.449929 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00143112 (* 1 = 0.00143112 loss)
I1130 22:36:11.449936 11845 sgd_solver.cpp:106] Iteration 176500, lr = 0.0001
I1130 22:36:15.142606 11845 solver.cpp:228] Iteration 177000, loss = 0.0374711
I1130 22:36:15.142714 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00855259 (* 0.5 = 0.00427629 loss)
I1130 22:36:15.142724 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0365268 (* 1 = 0.0365268 loss)
I1130 22:36:15.142727 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:36:15.142732 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:36:15.142737 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00126479 (* 1 = 0.00126479 loss)
I1130 22:36:15.142746 11845 sgd_solver.cpp:106] Iteration 177000, lr = 0.0001
I1130 22:36:15.578088 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_177060.caffemodel
I1130 22:36:15.583617 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_177060.solverstate
I1130 22:36:15.584261 11845 solver.cpp:337] Iteration 177060, Testing net (#0)
I1130 22:36:27.644502 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0082742 (* 0.5 = 0.0041371 loss)
I1130 22:36:27.644556 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0447503 (* 1 = 0.0447503 loss)
I1130 22:36:27.644562 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.994439
I1130 22:36:27.644565 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.910131
I1130 22:36:27.644570 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00185897 (* 1 = 0.00185897 loss)
I1130 22:36:31.015431 11845 solver.cpp:228] Iteration 177500, loss = 0.0454982
I1130 22:36:31.015477 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00684979 (* 0.5 = 0.00342489 loss)
I1130 22:36:31.015485 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0385046 (* 1 = 0.0385046 loss)
I1130 22:36:31.015488 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:36:31.015491 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:36:31.015496 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00189741 (* 1 = 0.00189741 loss)
I1130 22:36:31.015501 11845 sgd_solver.cpp:106] Iteration 177500, lr = 0.0001
I1130 22:36:34.640633 11845 solver.cpp:228] Iteration 178000, loss = 0.0492407
I1130 22:36:34.640668 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00728679 (* 0.5 = 0.00364339 loss)
I1130 22:36:34.640674 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0415102 (* 1 = 0.0415102 loss)
I1130 22:36:34.640678 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:36:34.640682 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:36:34.640696 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00214134 (* 1 = 0.00214134 loss)
I1130 22:36:34.640699 11845 sgd_solver.cpp:106] Iteration 178000, lr = 0.0001
I1130 22:36:38.346339 11845 solver.cpp:228] Iteration 178500, loss = 0.0423577
I1130 22:36:38.346421 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00879009 (* 0.5 = 0.00439504 loss)
I1130 22:36:38.346429 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0338341 (* 1 = 0.0338341 loss)
I1130 22:36:38.346433 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:36:38.346438 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:36:38.346452 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00125702 (* 1 = 0.00125702 loss)
I1130 22:36:38.346460 11845 sgd_solver.cpp:106] Iteration 178500, lr = 0.0001
I1130 22:36:42.314290 11845 solver.cpp:228] Iteration 179000, loss = 0.0427614
I1130 22:36:42.314368 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00643389 (* 0.5 = 0.00321695 loss)
I1130 22:36:42.314376 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0557141 (* 1 = 0.0557141 loss)
I1130 22:36:42.314380 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:36:42.314384 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 22:36:42.314390 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00116735 (* 1 = 0.00116735 loss)
I1130 22:36:42.314398 11845 sgd_solver.cpp:106] Iteration 179000, lr = 0.0001
I1130 22:36:46.347818 11845 solver.cpp:228] Iteration 179500, loss = 0.0436906
I1130 22:36:46.347910 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00937882 (* 0.5 = 0.00468941 loss)
I1130 22:36:46.347920 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0370539 (* 1 = 0.0370539 loss)
I1130 22:36:46.347926 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:36:46.347931 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:36:46.347949 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00151387 (* 1 = 0.00151387 loss)
I1130 22:36:46.347957 11845 sgd_solver.cpp:106] Iteration 179500, lr = 0.0001
I1130 22:36:50.399166 11845 solver.cpp:228] Iteration 180000, loss = 0.043815
I1130 22:36:50.399252 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0096808 (* 0.5 = 0.0048404 loss)
I1130 22:36:50.399260 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0214588 (* 1 = 0.0214588 loss)
I1130 22:36:50.399265 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:36:50.399268 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:36:50.399282 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00587515 (* 1 = 0.00587515 loss)
I1130 22:36:50.399291 11845 sgd_solver.cpp:106] Iteration 180000, lr = 0.0001
I1130 22:36:54.372182 11845 solver.cpp:228] Iteration 180500, loss = 0.0434025
I1130 22:36:54.372242 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00807025 (* 0.5 = 0.00403512 loss)
I1130 22:36:54.372251 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0279831 (* 1 = 0.0279831 loss)
I1130 22:36:54.372254 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:36:54.372258 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:36:54.372273 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00966098 (* 1 = 0.00966098 loss)
I1130 22:36:54.372280 11845 sgd_solver.cpp:106] Iteration 180500, lr = 0.0001
I1130 22:36:58.431254 11845 solver.cpp:228] Iteration 181000, loss = 0.043219
I1130 22:36:58.431339 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0073072 (* 0.5 = 0.0036536 loss)
I1130 22:36:58.431346 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0351752 (* 1 = 0.0351752 loss)
I1130 22:36:58.431367 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:36:58.431372 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:36:58.431378 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00156438 (* 1 = 0.00156438 loss)
I1130 22:36:58.431385 11845 sgd_solver.cpp:106] Iteration 181000, lr = 0.0001
I1130 22:37:02.462733 11845 solver.cpp:228] Iteration 181500, loss = 0.0423367
I1130 22:37:02.462806 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00749386 (* 0.5 = 0.00374693 loss)
I1130 22:37:02.462815 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0183698 (* 1 = 0.0183698 loss)
I1130 22:37:02.462819 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:37:02.462823 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:37:02.462828 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00132719 (* 1 = 0.00132719 loss)
I1130 22:37:02.462836 11845 sgd_solver.cpp:106] Iteration 181500, lr = 0.0001
I1130 22:37:06.402019 11845 solver.cpp:228] Iteration 182000, loss = 0.0403806
I1130 22:37:06.402102 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00892074 (* 0.5 = 0.00446037 loss)
I1130 22:37:06.402112 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0291807 (* 1 = 0.0291807 loss)
I1130 22:37:06.402117 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:37:06.402120 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:37:06.402125 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00178682 (* 1 = 0.00178682 loss)
I1130 22:37:06.402132 11845 sgd_solver.cpp:106] Iteration 182000, lr = 0.0001
I1130 22:37:10.334667 11845 solver.cpp:228] Iteration 182500, loss = 0.043445
I1130 22:37:10.334738 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00934843 (* 0.5 = 0.00467422 loss)
I1130 22:37:10.334746 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0398174 (* 1 = 0.0398174 loss)
I1130 22:37:10.334750 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:37:10.334754 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:37:10.334760 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00130181 (* 1 = 0.00130181 loss)
I1130 22:37:10.334767 11845 sgd_solver.cpp:106] Iteration 182500, lr = 0.0001
I1130 22:37:14.271525 11845 solver.cpp:228] Iteration 183000, loss = 0.0457472
I1130 22:37:14.271586 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00640947 (* 0.5 = 0.00320473 loss)
I1130 22:37:14.271595 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0417562 (* 1 = 0.0417562 loss)
I1130 22:37:14.271598 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:37:14.271602 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:37:14.271608 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00159431 (* 1 = 0.00159431 loss)
I1130 22:37:14.271615 11845 sgd_solver.cpp:106] Iteration 183000, lr = 0.0001
I1130 22:37:18.220055 11845 solver.cpp:228] Iteration 183500, loss = 0.0401835
I1130 22:37:18.220140 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00479384 (* 0.5 = 0.00239692 loss)
I1130 22:37:18.220149 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0222206 (* 1 = 0.0222206 loss)
I1130 22:37:18.220152 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:37:18.220156 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:37:18.220162 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00204111 (* 1 = 0.00204111 loss)
I1130 22:37:18.220170 11845 sgd_solver.cpp:106] Iteration 183500, lr = 0.0001
I1130 22:37:21.130374 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_183870.caffemodel
I1130 22:37:21.135990 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_183870.solverstate
I1130 22:37:21.136662 11845 solver.cpp:337] Iteration 183870, Testing net (#0)
I1130 22:37:32.376873 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00817042 (* 0.5 = 0.00408521 loss)
I1130 22:37:32.376940 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0464717 (* 1 = 0.0464717 loss)
I1130 22:37:32.376946 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.995218
I1130 22:37:32.376951 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.903235
I1130 22:37:32.376957 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.0018835 (* 1 = 0.0018835 loss)
I1130 22:37:33.343176 11845 solver.cpp:228] Iteration 184000, loss = 0.0442258
I1130 22:37:33.343224 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00782181 (* 0.5 = 0.00391091 loss)
I1130 22:37:33.343230 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0701528 (* 1 = 0.0701528 loss)
I1130 22:37:33.343235 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:37:33.343238 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:37:33.343243 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00101221 (* 1 = 0.00101221 loss)
I1130 22:37:33.343247 11845 sgd_solver.cpp:106] Iteration 184000, lr = 0.0001
I1130 22:37:36.994225 11845 solver.cpp:228] Iteration 184500, loss = 0.0498505
I1130 22:37:36.994262 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00938979 (* 0.5 = 0.00469489 loss)
I1130 22:37:36.994269 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0286896 (* 1 = 0.0286896 loss)
I1130 22:37:36.994273 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:37:36.994277 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:37:36.994282 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00222687 (* 1 = 0.00222687 loss)
I1130 22:37:36.994285 11845 sgd_solver.cpp:106] Iteration 184500, lr = 0.0001
I1130 22:37:40.653579 11845 solver.cpp:228] Iteration 185000, loss = 0.0396139
I1130 22:37:40.653630 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00797469 (* 0.5 = 0.00398735 loss)
I1130 22:37:40.653641 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0318435 (* 1 = 0.0318435 loss)
I1130 22:37:40.653648 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:37:40.653656 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:37:40.653663 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00318983 (* 1 = 0.00318983 loss)
I1130 22:37:40.653671 11845 sgd_solver.cpp:106] Iteration 185000, lr = 0.0001
I1130 22:37:44.300861 11845 solver.cpp:228] Iteration 185500, loss = 0.0421485
I1130 22:37:44.300925 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00988141 (* 0.5 = 0.0049407 loss)
I1130 22:37:44.300935 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0354662 (* 1 = 0.0354662 loss)
I1130 22:37:44.300940 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:37:44.300945 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:37:44.300951 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00313007 (* 1 = 0.00313007 loss)
I1130 22:37:44.300959 11845 sgd_solver.cpp:106] Iteration 185500, lr = 0.0001
I1130 22:37:48.239166 11845 solver.cpp:228] Iteration 186000, loss = 0.0485556
I1130 22:37:48.239259 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00953856 (* 0.5 = 0.00476928 loss)
I1130 22:37:48.239276 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0439278 (* 1 = 0.0439278 loss)
I1130 22:37:48.239280 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:37:48.239285 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:37:48.239300 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00303662 (* 1 = 0.00303662 loss)
I1130 22:37:48.239308 11845 sgd_solver.cpp:106] Iteration 186000, lr = 0.0001
I1130 22:37:52.423753 11845 solver.cpp:228] Iteration 186500, loss = 0.0430153
I1130 22:37:52.423822 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0085191 (* 0.5 = 0.00425955 loss)
I1130 22:37:52.423831 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0483968 (* 1 = 0.0483968 loss)
I1130 22:37:52.423835 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:37:52.423840 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:37:52.423844 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00260985 (* 1 = 0.00260985 loss)
I1130 22:37:52.423849 11845 sgd_solver.cpp:106] Iteration 186500, lr = 0.0001
I1130 22:37:56.096134 11845 solver.cpp:228] Iteration 187000, loss = 0.0440492
I1130 22:37:56.096216 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00789424 (* 0.5 = 0.00394712 loss)
I1130 22:37:56.096225 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0356105 (* 1 = 0.0356105 loss)
I1130 22:37:56.096228 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:37:56.096232 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:37:56.096237 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00120055 (* 1 = 0.00120055 loss)
I1130 22:37:56.096243 11845 sgd_solver.cpp:106] Iteration 187000, lr = 0.0001
I1130 22:37:59.749706 11845 solver.cpp:228] Iteration 187500, loss = 0.0456083
I1130 22:37:59.749770 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00768554 (* 0.5 = 0.00384277 loss)
I1130 22:37:59.749778 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0245509 (* 1 = 0.0245509 loss)
I1130 22:37:59.749781 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:37:59.749785 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:37:59.749790 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000994529 (* 1 = 0.000994529 loss)
I1130 22:37:59.749795 11845 sgd_solver.cpp:106] Iteration 187500, lr = 0.0001
I1130 22:38:03.367576 11845 solver.cpp:228] Iteration 188000, loss = 0.0385883
I1130 22:38:03.367671 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00578949 (* 0.5 = 0.00289474 loss)
I1130 22:38:03.367679 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0432271 (* 1 = 0.0432271 loss)
I1130 22:38:03.367684 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:38:03.367687 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:38:03.367692 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00192094 (* 1 = 0.00192094 loss)
I1130 22:38:03.367697 11845 sgd_solver.cpp:106] Iteration 188000, lr = 0.0001
I1130 22:38:06.985538 11845 solver.cpp:228] Iteration 188500, loss = 0.0448888
I1130 22:38:06.985604 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00549355 (* 0.5 = 0.00274678 loss)
I1130 22:38:06.985610 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0469006 (* 1 = 0.0469006 loss)
I1130 22:38:06.985615 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:38:06.985618 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:38:06.985623 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00115099 (* 1 = 0.00115099 loss)
I1130 22:38:06.985628 11845 sgd_solver.cpp:106] Iteration 188500, lr = 0.0001
I1130 22:38:10.607292 11845 solver.cpp:228] Iteration 189000, loss = 0.0457117
I1130 22:38:10.607352 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00738607 (* 0.5 = 0.00369303 loss)
I1130 22:38:10.607360 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0342885 (* 1 = 0.0342885 loss)
I1130 22:38:10.607364 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:38:10.607383 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:38:10.607389 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00265107 (* 1 = 0.00265107 loss)
I1130 22:38:10.607394 11845 sgd_solver.cpp:106] Iteration 189000, lr = 0.0001
I1130 22:38:14.310892 11845 solver.cpp:228] Iteration 189500, loss = 0.0375858
I1130 22:38:14.311023 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00748913 (* 0.5 = 0.00374457 loss)
I1130 22:38:14.311031 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0304151 (* 1 = 0.0304151 loss)
I1130 22:38:14.311035 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:38:14.311039 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:38:14.311053 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00152805 (* 1 = 0.00152805 loss)
I1130 22:38:14.311059 11845 sgd_solver.cpp:106] Iteration 189500, lr = 0.0001
I1130 22:38:18.127146 11845 solver.cpp:228] Iteration 190000, loss = 0.0443495
I1130 22:38:18.127220 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00595413 (* 0.5 = 0.00297707 loss)
I1130 22:38:18.127228 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0226917 (* 1 = 0.0226917 loss)
I1130 22:38:18.127231 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:38:18.127235 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:38:18.127240 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00208301 (* 1 = 0.00208301 loss)
I1130 22:38:18.127248 11845 sgd_solver.cpp:106] Iteration 190000, lr = 0.0001
I1130 22:38:21.897210 11845 solver.cpp:228] Iteration 190500, loss = 0.0439948
I1130 22:38:21.897330 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00823509 (* 0.5 = 0.00411755 loss)
I1130 22:38:21.897338 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0467608 (* 1 = 0.0467608 loss)
I1130 22:38:21.897343 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:38:21.897347 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:38:21.897354 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00125998 (* 1 = 0.00125998 loss)
I1130 22:38:21.897362 11845 sgd_solver.cpp:106] Iteration 190500, lr = 0.0001
I1130 22:38:23.253602 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_190680.caffemodel
I1130 22:38:23.259816 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_190680.solverstate
I1130 22:38:23.260478 11845 solver.cpp:337] Iteration 190680, Testing net (#0)
I1130 22:38:35.897410 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00828498 (* 0.5 = 0.00414249 loss)
I1130 22:38:35.897456 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0462958 (* 1 = 0.0462958 loss)
I1130 22:38:35.897462 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.993949
I1130 22:38:35.897466 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.906278
I1130 22:38:35.897472 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00188999 (* 1 = 0.00188999 loss)
I1130 22:38:38.374868 11845 solver.cpp:228] Iteration 191000, loss = 0.0371575
I1130 22:38:38.374929 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00998722 (* 0.5 = 0.00499361 loss)
I1130 22:38:38.374936 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0616003 (* 1 = 0.0616003 loss)
I1130 22:38:38.374940 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:38:38.374944 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:38:38.374949 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00223662 (* 1 = 0.00223662 loss)
I1130 22:38:38.374956 11845 sgd_solver.cpp:106] Iteration 191000, lr = 0.0001
I1130 22:38:42.088420 11845 solver.cpp:228] Iteration 191500, loss = 0.0475406
I1130 22:38:42.088490 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00725202 (* 0.5 = 0.00362601 loss)
I1130 22:38:42.088500 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0474643 (* 1 = 0.0474643 loss)
I1130 22:38:42.088505 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:38:42.088510 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:38:42.088517 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00273033 (* 1 = 0.00273033 loss)
I1130 22:38:42.088526 11845 sgd_solver.cpp:106] Iteration 191500, lr = 0.0001
I1130 22:38:45.804649 11845 solver.cpp:228] Iteration 192000, loss = 0.0455218
I1130 22:38:45.804738 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00856607 (* 0.5 = 0.00428303 loss)
I1130 22:38:45.804746 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0464716 (* 1 = 0.0464716 loss)
I1130 22:38:45.804751 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:38:45.804755 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:38:45.804761 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00156813 (* 1 = 0.00156813 loss)
I1130 22:38:45.804769 11845 sgd_solver.cpp:106] Iteration 192000, lr = 0.0001
I1130 22:38:49.495774 11845 solver.cpp:228] Iteration 192500, loss = 0.0392109
I1130 22:38:49.495827 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0087032 (* 0.5 = 0.0043516 loss)
I1130 22:38:49.495836 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0352812 (* 1 = 0.0352812 loss)
I1130 22:38:49.495841 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:38:49.495846 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:38:49.495851 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00153912 (* 1 = 0.00153912 loss)
I1130 22:38:49.495857 11845 sgd_solver.cpp:106] Iteration 192500, lr = 0.0001
I1130 22:38:53.058996 11845 solver.cpp:228] Iteration 193000, loss = 0.0491747
I1130 22:38:53.059032 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00583276 (* 0.5 = 0.00291638 loss)
I1130 22:38:53.059041 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0279331 (* 1 = 0.0279331 loss)
I1130 22:38:53.059044 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:38:53.059048 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:38:53.059053 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00299052 (* 1 = 0.00299052 loss)
I1130 22:38:53.059058 11845 sgd_solver.cpp:106] Iteration 193000, lr = 0.0001
I1130 22:38:56.644546 11845 solver.cpp:228] Iteration 193500, loss = 0.042434
I1130 22:38:56.644608 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00937686 (* 0.5 = 0.00468843 loss)
I1130 22:38:56.644616 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0541864 (* 1 = 0.0541864 loss)
I1130 22:38:56.644623 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:38:56.644628 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:38:56.644634 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00217846 (* 1 = 0.00217846 loss)
I1130 22:38:56.644644 11845 sgd_solver.cpp:106] Iteration 193500, lr = 0.0001
I1130 22:39:00.374934 11845 solver.cpp:228] Iteration 194000, loss = 0.0372985
I1130 22:39:00.375005 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00776776 (* 0.5 = 0.00388388 loss)
I1130 22:39:00.375013 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0257258 (* 1 = 0.0257258 loss)
I1130 22:39:00.375018 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:39:00.375023 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:39:00.375028 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000902479 (* 1 = 0.000902479 loss)
I1130 22:39:00.375052 11845 sgd_solver.cpp:106] Iteration 194000, lr = 0.0001
I1130 22:39:04.068287 11845 solver.cpp:228] Iteration 194500, loss = 0.0516134
I1130 22:39:04.068397 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00974837 (* 0.5 = 0.00487418 loss)
I1130 22:39:04.068406 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0606622 (* 1 = 0.0606622 loss)
I1130 22:39:04.068411 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:39:04.068416 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:39:04.068423 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00404322 (* 1 = 0.00404322 loss)
I1130 22:39:04.068430 11845 sgd_solver.cpp:106] Iteration 194500, lr = 0.0001
I1130 22:39:07.779263 11845 solver.cpp:228] Iteration 195000, loss = 0.0469448
I1130 22:39:07.779307 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0072073 (* 0.5 = 0.00360365 loss)
I1130 22:39:07.779316 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0386213 (* 1 = 0.0386213 loss)
I1130 22:39:07.779322 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:39:07.779327 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:39:07.779333 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00128494 (* 1 = 0.00128494 loss)
I1130 22:39:07.779338 11845 sgd_solver.cpp:106] Iteration 195000, lr = 0.0001
I1130 22:39:11.470847 11845 solver.cpp:228] Iteration 195500, loss = 0.0383052
I1130 22:39:11.470927 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00648436 (* 0.5 = 0.00324218 loss)
I1130 22:39:11.470934 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0244566 (* 1 = 0.0244566 loss)
I1130 22:39:11.470939 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:39:11.470952 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:39:11.470957 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00188672 (* 1 = 0.00188672 loss)
I1130 22:39:11.470964 11845 sgd_solver.cpp:106] Iteration 195500, lr = 0.0001
I1130 22:39:15.179050 11845 solver.cpp:228] Iteration 196000, loss = 0.0454259
I1130 22:39:15.179183 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00876597 (* 0.5 = 0.00438298 loss)
I1130 22:39:15.179193 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0446897 (* 1 = 0.0446897 loss)
I1130 22:39:15.179196 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:39:15.179203 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:39:15.179208 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00188895 (* 1 = 0.00188895 loss)
I1130 22:39:15.179217 11845 sgd_solver.cpp:106] Iteration 196000, lr = 0.0001
I1130 22:39:18.879791 11845 solver.cpp:228] Iteration 196500, loss = 0.0449667
I1130 22:39:18.879871 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00803801 (* 0.5 = 0.004019 loss)
I1130 22:39:18.879879 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.046654 (* 1 = 0.046654 loss)
I1130 22:39:18.879884 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:39:18.879889 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:39:18.879894 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00174761 (* 1 = 0.00174761 loss)
I1130 22:39:18.879901 11845 sgd_solver.cpp:106] Iteration 196500, lr = 0.0001
I1130 22:39:22.675284 11845 solver.cpp:228] Iteration 197000, loss = 0.0403751
I1130 22:39:22.675407 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00816507 (* 0.5 = 0.00408254 loss)
I1130 22:39:22.675416 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0155501 (* 1 = 0.0155501 loss)
I1130 22:39:22.675420 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:39:22.675463 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:39:22.675472 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00183629 (* 1 = 0.00183629 loss)
I1130 22:39:22.675479 11845 sgd_solver.cpp:106] Iteration 197000, lr = 0.0001
I1130 22:39:26.472663 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_197490.caffemodel
I1130 22:39:26.478612 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_197490.solverstate
I1130 22:39:26.479302 11845 solver.cpp:337] Iteration 197490, Testing net (#0)
I1130 22:39:37.206885 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00822239 (* 0.5 = 0.0041112 loss)
I1130 22:39:37.206918 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.044373 (* 1 = 0.044373 loss)
I1130 22:39:37.206923 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.98967
I1130 22:39:37.206928 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.926891
I1130 22:39:37.206933 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00184597 (* 1 = 0.00184597 loss)
I1130 22:39:37.285097 11845 solver.cpp:228] Iteration 197500, loss = 0.0448987
I1130 22:39:37.285152 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00663646 (* 0.5 = 0.00331823 loss)
I1130 22:39:37.285159 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0343895 (* 1 = 0.0343895 loss)
I1130 22:39:37.285164 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:39:37.285168 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:39:37.285172 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00172658 (* 1 = 0.00172658 loss)
I1130 22:39:37.285178 11845 sgd_solver.cpp:106] Iteration 197500, lr = 0.0001
I1130 22:39:41.072808 11845 solver.cpp:228] Iteration 198000, loss = 0.0419564
I1130 22:39:41.072918 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00735601 (* 0.5 = 0.003678 loss)
I1130 22:39:41.072927 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0315686 (* 1 = 0.0315686 loss)
I1130 22:39:41.072932 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:39:41.072935 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:39:41.072942 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.001102 (* 1 = 0.001102 loss)
I1130 22:39:41.072949 11845 sgd_solver.cpp:106] Iteration 198000, lr = 0.0001
I1130 22:39:44.889513 11845 solver.cpp:228] Iteration 198500, loss = 0.0400026
I1130 22:39:44.889575 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00874799 (* 0.5 = 0.00437399 loss)
I1130 22:39:44.889583 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0211097 (* 1 = 0.0211097 loss)
I1130 22:39:44.889587 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:39:44.889592 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:39:44.889598 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00351722 (* 1 = 0.00351722 loss)
I1130 22:39:44.889606 11845 sgd_solver.cpp:106] Iteration 198500, lr = 0.0001
I1130 22:39:48.616920 11845 solver.cpp:228] Iteration 199000, loss = 0.0432633
I1130 22:39:48.617029 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0067135 (* 0.5 = 0.00335675 loss)
I1130 22:39:48.617048 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.044607 (* 1 = 0.044607 loss)
I1130 22:39:48.617053 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:39:48.617056 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:39:48.617061 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00251836 (* 1 = 0.00251836 loss)
I1130 22:39:48.617074 11845 sgd_solver.cpp:106] Iteration 199000, lr = 0.0001
I1130 22:39:52.271998 11845 solver.cpp:228] Iteration 199500, loss = 0.0441162
I1130 22:39:52.272071 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00922857 (* 0.5 = 0.00461428 loss)
I1130 22:39:52.272083 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0416381 (* 1 = 0.0416381 loss)
I1130 22:39:52.272089 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:39:52.272094 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:39:52.272099 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00429498 (* 1 = 0.00429498 loss)
I1130 22:39:52.272104 11845 sgd_solver.cpp:106] Iteration 199500, lr = 0.0001
I1130 22:39:55.942368 11845 solver.cpp:228] Iteration 200000, loss = 0.0424248
I1130 22:39:55.942466 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00838935 (* 0.5 = 0.00419468 loss)
I1130 22:39:55.942473 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0153673 (* 1 = 0.0153673 loss)
I1130 22:39:55.942478 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:39:55.942482 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:39:55.942487 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00133423 (* 1 = 0.00133423 loss)
I1130 22:39:55.942493 11845 sgd_solver.cpp:106] Iteration 200000, lr = 0.0001
I1130 22:39:59.618685 11845 solver.cpp:228] Iteration 200500, loss = 0.0424321
I1130 22:39:59.618752 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00898489 (* 0.5 = 0.00449244 loss)
I1130 22:39:59.618760 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0311481 (* 1 = 0.0311481 loss)
I1130 22:39:59.618764 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:39:59.618767 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:39:59.618772 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00275775 (* 1 = 0.00275775 loss)
I1130 22:39:59.618777 11845 sgd_solver.cpp:106] Iteration 200500, lr = 0.0001
I1130 22:40:03.231163 11845 solver.cpp:228] Iteration 201000, loss = 0.0475794
I1130 22:40:03.231225 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00879341 (* 0.5 = 0.0043967 loss)
I1130 22:40:03.231232 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0488925 (* 1 = 0.0488925 loss)
I1130 22:40:03.231236 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:40:03.231240 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:40:03.231245 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.001098 (* 1 = 0.001098 loss)
I1130 22:40:03.231251 11845 sgd_solver.cpp:106] Iteration 201000, lr = 0.0001
I1130 22:40:07.269289 11845 solver.cpp:228] Iteration 201500, loss = 0.0451942
I1130 22:40:07.269393 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00849355 (* 0.5 = 0.00424678 loss)
I1130 22:40:07.269402 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.017891 (* 1 = 0.017891 loss)
I1130 22:40:07.269407 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:40:07.269410 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:40:07.269418 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00113279 (* 1 = 0.00113279 loss)
I1130 22:40:07.269425 11845 sgd_solver.cpp:106] Iteration 201500, lr = 0.0001
I1130 22:40:11.250370 11845 solver.cpp:228] Iteration 202000, loss = 0.0403548
I1130 22:40:11.250480 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00680672 (* 0.5 = 0.00340336 loss)
I1130 22:40:11.250490 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0269545 (* 1 = 0.0269545 loss)
I1130 22:40:11.250494 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:40:11.250499 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:40:11.250505 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00167316 (* 1 = 0.00167316 loss)
I1130 22:40:11.250536 11845 sgd_solver.cpp:106] Iteration 202000, lr = 0.0001
I1130 22:40:15.222718 11845 solver.cpp:228] Iteration 202500, loss = 0.0430486
I1130 22:40:15.222826 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00545356 (* 0.5 = 0.00272678 loss)
I1130 22:40:15.222836 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0260349 (* 1 = 0.0260349 loss)
I1130 22:40:15.222841 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:40:15.222846 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:40:15.222852 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00124705 (* 1 = 0.00124705 loss)
I1130 22:40:15.222859 11845 sgd_solver.cpp:106] Iteration 202500, lr = 0.0001
I1130 22:40:19.216785 11845 solver.cpp:228] Iteration 203000, loss = 0.0497898
I1130 22:40:19.216893 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00953925 (* 0.5 = 0.00476962 loss)
I1130 22:40:19.216902 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0218829 (* 1 = 0.0218829 loss)
I1130 22:40:19.216907 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:40:19.216910 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:40:19.216917 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00826 (* 1 = 0.00826 loss)
I1130 22:40:19.216923 11845 sgd_solver.cpp:106] Iteration 203000, lr = 0.0001
I1130 22:40:23.195492 11845 solver.cpp:228] Iteration 203500, loss = 0.0431617
I1130 22:40:23.195601 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00712684 (* 0.5 = 0.00356342 loss)
I1130 22:40:23.195610 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0403291 (* 1 = 0.0403291 loss)
I1130 22:40:23.195614 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:40:23.195618 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:40:23.195623 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00223378 (* 1 = 0.00223378 loss)
I1130 22:40:23.195631 11845 sgd_solver.cpp:106] Iteration 203500, lr = 0.0001
I1130 22:40:27.143395 11845 solver.cpp:228] Iteration 204000, loss = 0.0434588
I1130 22:40:27.143514 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00772252 (* 0.5 = 0.00386126 loss)
I1130 22:40:27.143522 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0302121 (* 1 = 0.0302121 loss)
I1130 22:40:27.143527 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:40:27.143532 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:40:27.143537 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0014517 (* 1 = 0.0014517 loss)
I1130 22:40:27.143543 11845 sgd_solver.cpp:106] Iteration 204000, lr = 0.0001
I1130 22:40:29.530664 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_204300.caffemodel
I1130 22:40:29.536327 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_204300.solverstate
I1130 22:40:29.537026 11845 solver.cpp:337] Iteration 204300, Testing net (#0)
I1130 22:40:41.168642 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00823892 (* 0.5 = 0.00411946 loss)
I1130 22:40:41.168696 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0450633 (* 1 = 0.0450633 loss)
I1130 22:40:41.168702 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.989629
I1130 22:40:41.168706 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.924155
I1130 22:40:41.168712 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00191235 (* 1 = 0.00191235 loss)
I1130 22:40:42.664371 11845 solver.cpp:228] Iteration 204500, loss = 0.0448787
I1130 22:40:42.664427 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0066823 (* 0.5 = 0.00334115 loss)
I1130 22:40:42.664434 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0265915 (* 1 = 0.0265915 loss)
I1130 22:40:42.664453 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:40:42.664459 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:40:42.664464 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00120523 (* 1 = 0.00120523 loss)
I1130 22:40:42.664471 11845 sgd_solver.cpp:106] Iteration 204500, lr = 1e-05
I1130 22:40:46.351899 11845 solver.cpp:228] Iteration 205000, loss = 0.0418019
I1130 22:40:46.352001 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0080218 (* 0.5 = 0.0040109 loss)
I1130 22:40:46.352010 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0307571 (* 1 = 0.0307571 loss)
I1130 22:40:46.352021 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:40:46.352025 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:40:46.352030 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0023997 (* 1 = 0.0023997 loss)
I1130 22:40:46.352038 11845 sgd_solver.cpp:106] Iteration 205000, lr = 1e-05
I1130 22:40:50.069239 11845 solver.cpp:228] Iteration 205500, loss = 0.0455574
I1130 22:40:50.069308 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00835012 (* 0.5 = 0.00417506 loss)
I1130 22:40:50.069319 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0297828 (* 1 = 0.0297828 loss)
I1130 22:40:50.069325 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:40:50.069332 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:40:50.069339 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00278403 (* 1 = 0.00278403 loss)
I1130 22:40:50.069350 11845 sgd_solver.cpp:106] Iteration 205500, lr = 1e-05
I1130 22:40:53.927903 11845 solver.cpp:228] Iteration 206000, loss = 0.0452676
I1130 22:40:53.927991 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00837218 (* 0.5 = 0.00418609 loss)
I1130 22:40:53.927999 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0387093 (* 1 = 0.0387093 loss)
I1130 22:40:53.928004 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:40:53.928007 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:40:53.928012 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00235514 (* 1 = 0.00235514 loss)
I1130 22:40:53.928020 11845 sgd_solver.cpp:106] Iteration 206000, lr = 1e-05
I1130 22:40:57.669823 11845 solver.cpp:228] Iteration 206500, loss = 0.0394345
I1130 22:40:57.669958 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00831159 (* 0.5 = 0.0041558 loss)
I1130 22:40:57.669975 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.050125 (* 1 = 0.050125 loss)
I1130 22:40:57.669980 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:40:57.669983 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:40:57.669988 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0015694 (* 1 = 0.0015694 loss)
I1130 22:40:57.669996 11845 sgd_solver.cpp:106] Iteration 206500, lr = 1e-05
I1130 22:41:01.382483 11845 solver.cpp:228] Iteration 207000, loss = 0.0422486
I1130 22:41:01.382556 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0066394 (* 0.5 = 0.0033197 loss)
I1130 22:41:01.382565 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0448327 (* 1 = 0.0448327 loss)
I1130 22:41:01.382570 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:41:01.382572 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:41:01.382578 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00136116 (* 1 = 0.00136116 loss)
I1130 22:41:01.382586 11845 sgd_solver.cpp:106] Iteration 207000, lr = 1e-05
I1130 22:41:05.057255 11845 solver.cpp:228] Iteration 207500, loss = 0.0445272
I1130 22:41:05.057317 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00904473 (* 0.5 = 0.00452237 loss)
I1130 22:41:05.057339 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0405947 (* 1 = 0.0405947 loss)
I1130 22:41:05.057345 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:41:05.057350 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:41:05.057356 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00113173 (* 1 = 0.00113173 loss)
I1130 22:41:05.057361 11845 sgd_solver.cpp:106] Iteration 207500, lr = 1e-05
I1130 22:41:08.797261 11845 solver.cpp:228] Iteration 208000, loss = 0.0411285
I1130 22:41:08.797359 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00934602 (* 0.5 = 0.00467301 loss)
I1130 22:41:08.797366 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0909835 (* 1 = 0.0909835 loss)
I1130 22:41:08.797371 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:41:08.797375 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.796875
I1130 22:41:08.797380 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00222404 (* 1 = 0.00222404 loss)
I1130 22:41:08.797385 11845 sgd_solver.cpp:106] Iteration 208000, lr = 1e-05
I1130 22:41:12.567800 11845 solver.cpp:228] Iteration 208500, loss = 0.0447857
I1130 22:41:12.567862 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00658446 (* 0.5 = 0.00329223 loss)
I1130 22:41:12.567870 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0306606 (* 1 = 0.0306606 loss)
I1130 22:41:12.567875 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:41:12.567880 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:41:12.567886 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00135951 (* 1 = 0.00135951 loss)
I1130 22:41:12.567894 11845 sgd_solver.cpp:106] Iteration 208500, lr = 1e-05
I1130 22:41:16.182018 11845 solver.cpp:228] Iteration 209000, loss = 0.0475787
I1130 22:41:16.182086 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0080042 (* 0.5 = 0.0040021 loss)
I1130 22:41:16.182096 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0153605 (* 1 = 0.0153605 loss)
I1130 22:41:16.182099 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:41:16.182103 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:41:16.182108 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0014878 (* 1 = 0.0014878 loss)
I1130 22:41:16.182114 11845 sgd_solver.cpp:106] Iteration 209000, lr = 1e-05
I1130 22:41:19.808224 11845 solver.cpp:228] Iteration 209500, loss = 0.042644
I1130 22:41:19.808287 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0067608 (* 0.5 = 0.0033804 loss)
I1130 22:41:19.808295 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0572016 (* 1 = 0.0572016 loss)
I1130 22:41:19.808300 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:41:19.808303 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:41:19.808308 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00330913 (* 1 = 0.00330913 loss)
I1130 22:41:19.808315 11845 sgd_solver.cpp:106] Iteration 209500, lr = 1e-05
I1130 22:41:23.438356 11845 solver.cpp:228] Iteration 210000, loss = 0.0450795
I1130 22:41:23.438418 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00826065 (* 0.5 = 0.00413033 loss)
I1130 22:41:23.438426 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.034701 (* 1 = 0.034701 loss)
I1130 22:41:23.438429 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:41:23.438433 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:41:23.438438 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00224969 (* 1 = 0.00224969 loss)
I1130 22:41:23.438443 11845 sgd_solver.cpp:106] Iteration 210000, lr = 1e-05
I1130 22:41:27.077575 11845 solver.cpp:228] Iteration 210500, loss = 0.0444125
I1130 22:41:27.077675 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00855375 (* 0.5 = 0.00427688 loss)
I1130 22:41:27.077682 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0322667 (* 1 = 0.0322667 loss)
I1130 22:41:27.077687 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:41:27.077690 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:41:27.077694 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00128271 (* 1 = 0.00128271 loss)
I1130 22:41:27.077700 11845 sgd_solver.cpp:106] Iteration 210500, lr = 1e-05
I1130 22:41:30.696774 11845 solver.cpp:228] Iteration 211000, loss = 0.0406114
I1130 22:41:30.696835 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00781217 (* 0.5 = 0.00390608 loss)
I1130 22:41:30.696841 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.034902 (* 1 = 0.034902 loss)
I1130 22:41:30.696846 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:41:30.696849 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:41:30.696854 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00378028 (* 1 = 0.00378028 loss)
I1130 22:41:30.696861 11845 sgd_solver.cpp:106] Iteration 211000, lr = 1e-05
I1130 22:41:31.487442 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_211110.caffemodel
I1130 22:41:31.493266 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_211110.solverstate
I1130 22:41:31.493886 11845 solver.cpp:337] Iteration 211110, Testing net (#0)
I1130 22:41:43.641160 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00819063 (* 0.5 = 0.00409532 loss)
I1130 22:41:43.641225 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0434559 (* 1 = 0.0434559 loss)
I1130 22:41:43.641232 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.992978
I1130 22:41:43.641237 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.918199
I1130 22:41:43.641243 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00184883 (* 1 = 0.00184883 loss)
I1130 22:41:46.533454 11845 solver.cpp:228] Iteration 211500, loss = 0.0508505
I1130 22:41:46.533519 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0059496 (* 0.5 = 0.0029748 loss)
I1130 22:41:46.533525 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0352563 (* 1 = 0.0352563 loss)
I1130 22:41:46.533529 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:41:46.533534 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:41:46.533538 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0016976 (* 1 = 0.0016976 loss)
I1130 22:41:46.533545 11845 sgd_solver.cpp:106] Iteration 211500, lr = 1e-05
I1130 22:41:50.191262 11845 solver.cpp:228] Iteration 212000, loss = 0.0450149
I1130 22:41:50.191324 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0079565 (* 0.5 = 0.00397825 loss)
I1130 22:41:50.191332 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0243097 (* 1 = 0.0243097 loss)
I1130 22:41:50.191336 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:41:50.191340 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:41:50.191344 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00155696 (* 1 = 0.00155696 loss)
I1130 22:41:50.191350 11845 sgd_solver.cpp:106] Iteration 212000, lr = 1e-05
I1130 22:41:53.858408 11845 solver.cpp:228] Iteration 212500, loss = 0.0384697
I1130 22:41:53.858472 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00966737 (* 0.5 = 0.00483368 loss)
I1130 22:41:53.858480 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0439932 (* 1 = 0.0439932 loss)
I1130 22:41:53.858484 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:41:53.858502 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:41:53.858507 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00184131 (* 1 = 0.00184131 loss)
I1130 22:41:53.858513 11845 sgd_solver.cpp:106] Iteration 212500, lr = 1e-05
I1130 22:41:57.503356 11845 solver.cpp:228] Iteration 213000, loss = 0.0469194
I1130 22:41:57.503417 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00633209 (* 0.5 = 0.00316604 loss)
I1130 22:41:57.503424 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0314649 (* 1 = 0.0314649 loss)
I1130 22:41:57.503428 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:41:57.503432 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:41:57.503437 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00274595 (* 1 = 0.00274595 loss)
I1130 22:41:57.503443 11845 sgd_solver.cpp:106] Iteration 213000, lr = 1e-05
I1130 22:42:01.154268 11845 solver.cpp:228] Iteration 213500, loss = 0.0461904
I1130 22:42:01.154330 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00849339 (* 0.5 = 0.0042467 loss)
I1130 22:42:01.154337 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0474495 (* 1 = 0.0474495 loss)
I1130 22:42:01.154342 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:42:01.154345 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:42:01.154350 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00216852 (* 1 = 0.00216852 loss)
I1130 22:42:01.154356 11845 sgd_solver.cpp:106] Iteration 213500, lr = 1e-05
I1130 22:42:04.819749 11845 solver.cpp:228] Iteration 214000, loss = 0.0387032
I1130 22:42:04.819813 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00773778 (* 0.5 = 0.00386889 loss)
I1130 22:42:04.819820 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0486874 (* 1 = 0.0486874 loss)
I1130 22:42:04.819825 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:42:04.819829 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:42:04.819833 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00471059 (* 1 = 0.00471059 loss)
I1130 22:42:04.819839 11845 sgd_solver.cpp:106] Iteration 214000, lr = 1e-05
I1130 22:42:08.471915 11845 solver.cpp:228] Iteration 214500, loss = 0.0460197
I1130 22:42:08.471971 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0102236 (* 0.5 = 0.00511182 loss)
I1130 22:42:08.471978 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0400202 (* 1 = 0.0400202 loss)
I1130 22:42:08.471982 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:42:08.471987 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:42:08.471992 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00235199 (* 1 = 0.00235199 loss)
I1130 22:42:08.471997 11845 sgd_solver.cpp:106] Iteration 214500, lr = 1e-05
I1130 22:42:12.123525 11845 solver.cpp:228] Iteration 215000, loss = 0.0438906
I1130 22:42:12.123580 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00840436 (* 0.5 = 0.00420218 loss)
I1130 22:42:12.123589 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0298523 (* 1 = 0.0298523 loss)
I1130 22:42:12.123592 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:42:12.123596 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:42:12.123601 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00140964 (* 1 = 0.00140964 loss)
I1130 22:42:12.123607 11845 sgd_solver.cpp:106] Iteration 215000, lr = 1e-05
I1130 22:42:15.784418 11845 solver.cpp:228] Iteration 215500, loss = 0.0371856
I1130 22:42:15.784478 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00810231 (* 0.5 = 0.00405115 loss)
I1130 22:42:15.784502 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0250001 (* 1 = 0.0250001 loss)
I1130 22:42:15.784507 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:42:15.784509 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:42:15.784514 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00100923 (* 1 = 0.00100923 loss)
I1130 22:42:15.784519 11845 sgd_solver.cpp:106] Iteration 215500, lr = 1e-05
I1130 22:42:19.436422 11845 solver.cpp:228] Iteration 216000, loss = 0.0468004
I1130 22:42:19.436477 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00891719 (* 0.5 = 0.0044586 loss)
I1130 22:42:19.436485 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0305694 (* 1 = 0.0305694 loss)
I1130 22:42:19.436488 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:42:19.436491 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:42:19.436496 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00294979 (* 1 = 0.00294979 loss)
I1130 22:42:19.436501 11845 sgd_solver.cpp:106] Iteration 216000, lr = 1e-05
I1130 22:42:23.088192 11845 solver.cpp:228] Iteration 216500, loss = 0.0441421
I1130 22:42:23.088253 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00630814 (* 0.5 = 0.00315407 loss)
I1130 22:42:23.088261 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0371204 (* 1 = 0.0371204 loss)
I1130 22:42:23.088265 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:42:23.088269 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:42:23.088274 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000852592 (* 1 = 0.000852592 loss)
I1130 22:42:23.088280 11845 sgd_solver.cpp:106] Iteration 216500, lr = 1e-05
I1130 22:42:26.740267 11845 solver.cpp:228] Iteration 217000, loss = 0.0397618
I1130 22:42:26.740320 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00866934 (* 0.5 = 0.00433467 loss)
I1130 22:42:26.740327 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0358009 (* 1 = 0.0358009 loss)
I1130 22:42:26.740331 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:42:26.740334 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:42:26.740339 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00238498 (* 1 = 0.00238498 loss)
I1130 22:42:26.740345 11845 sgd_solver.cpp:106] Iteration 217000, lr = 1e-05
I1130 22:42:30.388350 11845 solver.cpp:228] Iteration 217500, loss = 0.0499
I1130 22:42:30.388423 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00833339 (* 0.5 = 0.00416669 loss)
I1130 22:42:30.388430 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0514854 (* 1 = 0.0514854 loss)
I1130 22:42:30.388434 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:42:30.388437 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:42:30.388442 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0016887 (* 1 = 0.0016887 loss)
I1130 22:42:30.388449 11845 sgd_solver.cpp:106] Iteration 217500, lr = 1e-05
I1130 22:42:33.449633 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_217920.caffemodel
I1130 22:42:33.455346 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_217920.solverstate
I1130 22:42:33.455991 11845 solver.cpp:337] Iteration 217920, Testing net (#0)
I1130 22:42:44.354518 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00819011 (* 0.5 = 0.00409505 loss)
I1130 22:42:44.354586 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0440915 (* 1 = 0.0440915 loss)
I1130 22:42:44.354593 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.992505
I1130 22:42:44.354599 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.919325
I1130 22:42:44.354629 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00190834 (* 1 = 0.00190834 loss)
I1130 22:42:44.960193 11845 solver.cpp:228] Iteration 218000, loss = 0.0465237
I1130 22:42:44.960253 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0105773 (* 0.5 = 0.00528863 loss)
I1130 22:42:44.960263 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0683895 (* 1 = 0.0683895 loss)
I1130 22:42:44.960268 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:42:44.960273 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 22:42:44.960279 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00163135 (* 1 = 0.00163135 loss)
I1130 22:42:44.960286 11845 sgd_solver.cpp:106] Iteration 218000, lr = 1e-05
I1130 22:42:48.828971 11845 solver.cpp:228] Iteration 218500, loss = 0.0396376
I1130 22:42:48.829062 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00745868 (* 0.5 = 0.00372934 loss)
I1130 22:42:48.829077 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0236086 (* 1 = 0.0236086 loss)
I1130 22:42:48.829082 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:42:48.829085 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:42:48.829092 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00310752 (* 1 = 0.00310752 loss)
I1130 22:42:48.829102 11845 sgd_solver.cpp:106] Iteration 218500, lr = 1e-05
I1130 22:42:52.835235 11845 solver.cpp:228] Iteration 219000, loss = 0.044205
I1130 22:42:52.835290 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00589059 (* 0.5 = 0.0029453 loss)
I1130 22:42:52.835297 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0496121 (* 1 = 0.0496121 loss)
I1130 22:42:52.835301 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:42:52.835306 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:42:52.835310 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00103025 (* 1 = 0.00103025 loss)
I1130 22:42:52.835316 11845 sgd_solver.cpp:106] Iteration 219000, lr = 1e-05
I1130 22:42:56.493883 11845 solver.cpp:228] Iteration 219500, loss = 0.0480289
I1130 22:42:56.493938 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0105778 (* 0.5 = 0.00528888 loss)
I1130 22:42:56.493945 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0696226 (* 1 = 0.0696226 loss)
I1130 22:42:56.493950 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:42:56.493954 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:42:56.493959 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00320201 (* 1 = 0.00320201 loss)
I1130 22:42:56.493965 11845 sgd_solver.cpp:106] Iteration 219500, lr = 1e-05
I1130 22:43:00.145220 11845 solver.cpp:228] Iteration 220000, loss = 0.0446543
I1130 22:43:00.145273 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0072437 (* 0.5 = 0.00362185 loss)
I1130 22:43:00.145280 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0203703 (* 1 = 0.0203703 loss)
I1130 22:43:00.145284 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:43:00.145288 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:43:00.145293 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00104035 (* 1 = 0.00104035 loss)
I1130 22:43:00.145299 11845 sgd_solver.cpp:106] Iteration 220000, lr = 1e-05
I1130 22:43:03.805765 11845 solver.cpp:228] Iteration 220500, loss = 0.0448987
I1130 22:43:03.805829 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00873111 (* 0.5 = 0.00436555 loss)
I1130 22:43:03.805836 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0630729 (* 1 = 0.0630729 loss)
I1130 22:43:03.805840 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:43:03.805861 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:43:03.805867 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00212397 (* 1 = 0.00212397 loss)
I1130 22:43:03.805872 11845 sgd_solver.cpp:106] Iteration 220500, lr = 1e-05
I1130 22:43:07.455476 11845 solver.cpp:228] Iteration 221000, loss = 0.0436298
I1130 22:43:07.455533 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00571783 (* 0.5 = 0.00285891 loss)
I1130 22:43:07.455539 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0668449 (* 1 = 0.0668449 loss)
I1130 22:43:07.455543 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:43:07.455548 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:43:07.455551 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0018691 (* 1 = 0.0018691 loss)
I1130 22:43:07.455557 11845 sgd_solver.cpp:106] Iteration 221000, lr = 1e-05
I1130 22:43:11.108886 11845 solver.cpp:228] Iteration 221500, loss = 0.0413733
I1130 22:43:11.108944 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00825398 (* 0.5 = 0.00412699 loss)
I1130 22:43:11.108952 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0229006 (* 1 = 0.0229006 loss)
I1130 22:43:11.108955 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:43:11.108959 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:43:11.108963 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0014887 (* 1 = 0.0014887 loss)
I1130 22:43:11.108968 11845 sgd_solver.cpp:106] Iteration 221500, lr = 1e-05
I1130 22:43:14.760474 11845 solver.cpp:228] Iteration 222000, loss = 0.0455667
I1130 22:43:14.760529 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00858392 (* 0.5 = 0.00429196 loss)
I1130 22:43:14.760536 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0445477 (* 1 = 0.0445477 loss)
I1130 22:43:14.760540 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:43:14.760545 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:43:14.760550 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00261761 (* 1 = 0.00261761 loss)
I1130 22:43:14.760555 11845 sgd_solver.cpp:106] Iteration 222000, lr = 1e-05
I1130 22:43:18.413643 11845 solver.cpp:228] Iteration 222500, loss = 0.0446182
I1130 22:43:18.413710 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0070713 (* 0.5 = 0.00353565 loss)
I1130 22:43:18.413718 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0539756 (* 1 = 0.0539756 loss)
I1130 22:43:18.413722 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:43:18.413727 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:43:18.413732 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00152756 (* 1 = 0.00152756 loss)
I1130 22:43:18.413736 11845 sgd_solver.cpp:106] Iteration 222500, lr = 1e-05
I1130 22:43:22.076536 11845 solver.cpp:228] Iteration 223000, loss = 0.0421657
I1130 22:43:22.076597 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00859982 (* 0.5 = 0.00429991 loss)
I1130 22:43:22.076607 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0254214 (* 1 = 0.0254214 loss)
I1130 22:43:22.076612 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:43:22.076617 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:43:22.076623 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00253898 (* 1 = 0.00253898 loss)
I1130 22:43:22.076630 11845 sgd_solver.cpp:106] Iteration 223000, lr = 1e-05
I1130 22:43:25.732792 11845 solver.cpp:228] Iteration 223500, loss = 0.0419168
I1130 22:43:25.732846 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0066516 (* 0.5 = 0.0033258 loss)
I1130 22:43:25.732869 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0238233 (* 1 = 0.0238233 loss)
I1130 22:43:25.732874 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:43:25.732877 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:43:25.732882 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00154103 (* 1 = 0.00154103 loss)
I1130 22:43:25.732887 11845 sgd_solver.cpp:106] Iteration 223500, lr = 1e-05
I1130 22:43:29.382043 11845 solver.cpp:228] Iteration 224000, loss = 0.042582
I1130 22:43:29.382103 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00806346 (* 0.5 = 0.00403173 loss)
I1130 22:43:29.382110 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0285592 (* 1 = 0.0285592 loss)
I1130 22:43:29.382115 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:43:29.382118 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:43:29.382123 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00196786 (* 1 = 0.00196786 loss)
I1130 22:43:29.382129 11845 sgd_solver.cpp:106] Iteration 224000, lr = 1e-05
I1130 22:43:33.032112 11845 solver.cpp:228] Iteration 224500, loss = 0.0447999
I1130 22:43:33.032166 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00800527 (* 0.5 = 0.00400264 loss)
I1130 22:43:33.032173 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0260815 (* 1 = 0.0260815 loss)
I1130 22:43:33.032177 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:43:33.032181 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:43:33.032186 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00295434 (* 1 = 0.00295434 loss)
I1130 22:43:33.032191 11845 sgd_solver.cpp:106] Iteration 224500, lr = 1e-05
I1130 22:43:34.704865 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_224730.caffemodel
I1130 22:43:34.710500 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_224730.solverstate
I1130 22:43:34.711122 11845 solver.cpp:337] Iteration 224730, Testing net (#0)
I1130 22:43:45.978083 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00825768 (* 0.5 = 0.00412884 loss)
I1130 22:43:45.978135 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0458666 (* 1 = 0.0458666 loss)
I1130 22:43:45.978142 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.994029
I1130 22:43:45.978147 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.907553
I1130 22:43:45.978152 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00184082 (* 1 = 0.00184082 loss)
I1130 22:43:48.137750 11845 solver.cpp:228] Iteration 225000, loss = 0.0422225
I1130 22:43:48.137812 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00741745 (* 0.5 = 0.00370872 loss)
I1130 22:43:48.137820 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0341823 (* 1 = 0.0341823 loss)
I1130 22:43:48.137825 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:43:48.137828 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:43:48.137833 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00128669 (* 1 = 0.00128669 loss)
I1130 22:43:48.137838 11845 sgd_solver.cpp:106] Iteration 225000, lr = 1e-05
I1130 22:43:51.823076 11845 solver.cpp:228] Iteration 225500, loss = 0.0436632
I1130 22:43:51.823154 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00609626 (* 0.5 = 0.00304813 loss)
I1130 22:43:51.823163 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.020072 (* 1 = 0.020072 loss)
I1130 22:43:51.823168 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:43:51.823170 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:43:51.823175 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00113722 (* 1 = 0.00113722 loss)
I1130 22:43:51.823200 11845 sgd_solver.cpp:106] Iteration 225500, lr = 1e-05
I1130 22:43:55.536314 11845 solver.cpp:228] Iteration 226000, loss = 0.0486478
I1130 22:43:55.536377 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00806797 (* 0.5 = 0.00403399 loss)
I1130 22:43:55.536386 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0284583 (* 1 = 0.0284583 loss)
I1130 22:43:55.536391 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:43:55.536394 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:43:55.536399 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00145762 (* 1 = 0.00145762 loss)
I1130 22:43:55.536406 11845 sgd_solver.cpp:106] Iteration 226000, lr = 1e-05
I1130 22:43:59.240401 11845 solver.cpp:228] Iteration 226500, loss = 0.0426997
I1130 22:43:59.240468 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00997145 (* 0.5 = 0.00498572 loss)
I1130 22:43:59.240474 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0230457 (* 1 = 0.0230457 loss)
I1130 22:43:59.240478 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:43:59.240483 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:43:59.240487 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00230509 (* 1 = 0.00230509 loss)
I1130 22:43:59.240494 11845 sgd_solver.cpp:106] Iteration 226500, lr = 1e-05
I1130 22:44:02.887148 11845 solver.cpp:228] Iteration 227000, loss = 0.0422324
I1130 22:44:02.887200 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00621817 (* 0.5 = 0.00310908 loss)
I1130 22:44:02.887208 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0579371 (* 1 = 0.0579371 loss)
I1130 22:44:02.887212 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:44:02.887217 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:44:02.887222 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00199822 (* 1 = 0.00199822 loss)
I1130 22:44:02.887228 11845 sgd_solver.cpp:106] Iteration 227000, lr = 1e-05
I1130 22:44:06.504577 11845 solver.cpp:228] Iteration 227500, loss = 0.0453959
I1130 22:44:06.504632 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00842568 (* 0.5 = 0.00421284 loss)
I1130 22:44:06.504640 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0372923 (* 1 = 0.0372923 loss)
I1130 22:44:06.504644 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:44:06.504647 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:44:06.504652 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00159375 (* 1 = 0.00159375 loss)
I1130 22:44:06.504658 11845 sgd_solver.cpp:106] Iteration 227500, lr = 1e-05
I1130 22:44:10.119711 11845 solver.cpp:228] Iteration 228000, loss = 0.0455006
I1130 22:44:10.119768 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00770905 (* 0.5 = 0.00385452 loss)
I1130 22:44:10.119776 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.042782 (* 1 = 0.042782 loss)
I1130 22:44:10.119779 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:44:10.119783 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:44:10.119788 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00148331 (* 1 = 0.00148331 loss)
I1130 22:44:10.119793 11845 sgd_solver.cpp:106] Iteration 228000, lr = 1e-05
I1130 22:44:13.727732 11845 solver.cpp:228] Iteration 228500, loss = 0.0455304
I1130 22:44:13.727787 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00805194 (* 0.5 = 0.00402597 loss)
I1130 22:44:13.727795 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0372946 (* 1 = 0.0372946 loss)
I1130 22:44:13.727799 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:44:13.727818 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:44:13.727823 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00100781 (* 1 = 0.00100781 loss)
I1130 22:44:13.727828 11845 sgd_solver.cpp:106] Iteration 228500, lr = 1e-05
I1130 22:44:17.347131 11845 solver.cpp:228] Iteration 229000, loss = 0.0460975
I1130 22:44:17.347187 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00988598 (* 0.5 = 0.00494299 loss)
I1130 22:44:17.347194 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0227004 (* 1 = 0.0227004 loss)
I1130 22:44:17.347198 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:44:17.347203 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:44:17.347208 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00215397 (* 1 = 0.00215397 loss)
I1130 22:44:17.347213 11845 sgd_solver.cpp:106] Iteration 229000, lr = 1e-05
I1130 22:44:20.964445 11845 solver.cpp:228] Iteration 229500, loss = 0.0396275
I1130 22:44:20.964509 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00853309 (* 0.5 = 0.00426655 loss)
I1130 22:44:20.964515 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0518142 (* 1 = 0.0518142 loss)
I1130 22:44:20.964519 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:44:20.964524 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:44:20.964529 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00267343 (* 1 = 0.00267343 loss)
I1130 22:44:20.964534 11845 sgd_solver.cpp:106] Iteration 229500, lr = 1e-05
I1130 22:44:24.582586 11845 solver.cpp:228] Iteration 230000, loss = 0.044258
I1130 22:44:24.582643 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0089942 (* 0.5 = 0.0044971 loss)
I1130 22:44:24.582649 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0181385 (* 1 = 0.0181385 loss)
I1130 22:44:24.582653 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:44:24.582657 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:44:24.582661 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00147722 (* 1 = 0.00147722 loss)
I1130 22:44:24.582667 11845 sgd_solver.cpp:106] Iteration 230000, lr = 1e-05
I1130 22:44:28.198586 11845 solver.cpp:228] Iteration 230500, loss = 0.0464555
I1130 22:44:28.198640 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00743425 (* 0.5 = 0.00371713 loss)
I1130 22:44:28.198647 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0432527 (* 1 = 0.0432527 loss)
I1130 22:44:28.198652 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:44:28.198655 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:44:28.198660 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00160966 (* 1 = 0.00160966 loss)
I1130 22:44:28.198667 11845 sgd_solver.cpp:106] Iteration 230500, lr = 1e-05
I1130 22:44:31.816217 11845 solver.cpp:228] Iteration 231000, loss = 0.0385382
I1130 22:44:31.816270 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00843179 (* 0.5 = 0.0042159 loss)
I1130 22:44:31.816277 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0421202 (* 1 = 0.0421202 loss)
I1130 22:44:31.816282 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:44:31.816285 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:44:31.816290 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00141316 (* 1 = 0.00141316 loss)
I1130 22:44:31.816295 11845 sgd_solver.cpp:106] Iteration 231000, lr = 1e-05
I1130 22:44:35.433600 11845 solver.cpp:228] Iteration 231500, loss = 0.0439843
I1130 22:44:35.433655 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0090425 (* 0.5 = 0.00452125 loss)
I1130 22:44:35.433662 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0292505 (* 1 = 0.0292505 loss)
I1130 22:44:35.433681 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:44:35.433684 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:44:35.433689 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00192785 (* 1 = 0.00192785 loss)
I1130 22:44:35.433694 11845 sgd_solver.cpp:106] Iteration 231500, lr = 1e-05
I1130 22:44:35.716270 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_231540.caffemodel
I1130 22:44:35.722156 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_231540.solverstate
I1130 22:44:35.722772 11845 solver.cpp:337] Iteration 231540, Testing net (#0)
I1130 22:44:47.542129 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00806382 (* 0.5 = 0.00403191 loss)
I1130 22:44:47.542225 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0436012 (* 1 = 0.0436012 loss)
I1130 22:44:47.542232 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.99193
I1130 22:44:47.542242 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.921186
I1130 22:44:47.542253 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00191487 (* 1 = 0.00191487 loss)
I1130 22:44:50.978626 11845 solver.cpp:228] Iteration 232000, loss = 0.0445357
I1130 22:44:50.978683 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00973597 (* 0.5 = 0.00486798 loss)
I1130 22:44:50.978690 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0258444 (* 1 = 0.0258444 loss)
I1130 22:44:50.978694 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:44:50.978698 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:44:50.978703 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00113489 (* 1 = 0.00113489 loss)
I1130 22:44:50.978708 11845 sgd_solver.cpp:106] Iteration 232000, lr = 1e-05
I1130 22:44:54.568892 11845 solver.cpp:228] Iteration 232500, loss = 0.0379814
I1130 22:44:54.568950 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00741157 (* 0.5 = 0.00370578 loss)
I1130 22:44:54.568958 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0499718 (* 1 = 0.0499718 loss)
I1130 22:44:54.568963 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:44:54.568966 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:44:54.568971 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00159019 (* 1 = 0.00159019 loss)
I1130 22:44:54.568977 11845 sgd_solver.cpp:106] Iteration 232500, lr = 1e-05
I1130 22:44:58.156322 11845 solver.cpp:228] Iteration 233000, loss = 0.046172
I1130 22:44:58.156385 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00699295 (* 0.5 = 0.00349647 loss)
I1130 22:44:58.156393 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0229982 (* 1 = 0.0229982 loss)
I1130 22:44:58.156396 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:44:58.156400 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:44:58.156405 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00112445 (* 1 = 0.00112445 loss)
I1130 22:44:58.156410 11845 sgd_solver.cpp:106] Iteration 233000, lr = 1e-05
I1130 22:45:01.764400 11845 solver.cpp:228] Iteration 233500, loss = 0.0465376
I1130 22:45:01.764456 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00817206 (* 0.5 = 0.00408603 loss)
I1130 22:45:01.764462 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0371084 (* 1 = 0.0371084 loss)
I1130 22:45:01.764467 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:45:01.764470 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:45:01.764475 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00229219 (* 1 = 0.00229219 loss)
I1130 22:45:01.764480 11845 sgd_solver.cpp:106] Iteration 233500, lr = 1e-05
I1130 22:45:05.355559 11845 solver.cpp:228] Iteration 234000, loss = 0.0380567
I1130 22:45:05.355615 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00837961 (* 0.5 = 0.00418981 loss)
I1130 22:45:05.355623 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0341917 (* 1 = 0.0341917 loss)
I1130 22:45:05.355626 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:45:05.355630 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:45:05.355635 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00169812 (* 1 = 0.00169812 loss)
I1130 22:45:05.355641 11845 sgd_solver.cpp:106] Iteration 234000, lr = 1e-05
I1130 22:45:08.943447 11845 solver.cpp:228] Iteration 234500, loss = 0.0516506
I1130 22:45:08.943503 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00804917 (* 0.5 = 0.00402459 loss)
I1130 22:45:08.943511 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0254808 (* 1 = 0.0254808 loss)
I1130 22:45:08.943514 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:45:08.943518 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:45:08.943523 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00427705 (* 1 = 0.00427705 loss)
I1130 22:45:08.943528 11845 sgd_solver.cpp:106] Iteration 234500, lr = 1e-05
I1130 22:45:12.527446 11845 solver.cpp:228] Iteration 235000, loss = 0.0451194
I1130 22:45:12.527500 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00638227 (* 0.5 = 0.00319113 loss)
I1130 22:45:12.527508 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0321385 (* 1 = 0.0321385 loss)
I1130 22:45:12.527513 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:45:12.527515 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:45:12.527520 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00165396 (* 1 = 0.00165396 loss)
I1130 22:45:12.527526 11845 sgd_solver.cpp:106] Iteration 235000, lr = 1e-05
I1130 22:45:16.122275 11845 solver.cpp:228] Iteration 235500, loss = 0.0352045
I1130 22:45:16.122333 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00736828 (* 0.5 = 0.00368414 loss)
I1130 22:45:16.122339 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0293816 (* 1 = 0.0293816 loss)
I1130 22:45:16.122344 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:45:16.122347 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:45:16.122352 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00138413 (* 1 = 0.00138413 loss)
I1130 22:45:16.122359 11845 sgd_solver.cpp:106] Iteration 235500, lr = 1e-05
I1130 22:45:19.712831 11845 solver.cpp:228] Iteration 236000, loss = 0.0490283
I1130 22:45:19.712895 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00797958 (* 0.5 = 0.00398979 loss)
I1130 22:45:19.712903 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0460955 (* 1 = 0.0460955 loss)
I1130 22:45:19.712906 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:45:19.712910 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:45:19.712915 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00161065 (* 1 = 0.00161065 loss)
I1130 22:45:19.712920 11845 sgd_solver.cpp:106] Iteration 236000, lr = 1e-05
I1130 22:45:23.304378 11845 solver.cpp:228] Iteration 236500, loss = 0.0498157
I1130 22:45:23.304435 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00758369 (* 0.5 = 0.00379184 loss)
I1130 22:45:23.304441 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0627782 (* 1 = 0.0627782 loss)
I1130 22:45:23.304445 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:45:23.304450 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:45:23.304469 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00227674 (* 1 = 0.00227674 loss)
I1130 22:45:23.304476 11845 sgd_solver.cpp:106] Iteration 236500, lr = 1e-05
I1130 22:45:26.903764 11845 solver.cpp:228] Iteration 237000, loss = 0.0398114
I1130 22:45:26.903820 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00821526 (* 0.5 = 0.00410763 loss)
I1130 22:45:26.903826 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0590035 (* 1 = 0.0590035 loss)
I1130 22:45:26.903831 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:45:26.903834 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:45:26.903839 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00193733 (* 1 = 0.00193733 loss)
I1130 22:45:26.903844 11845 sgd_solver.cpp:106] Iteration 237000, lr = 1e-05
I1130 22:45:30.489707 11845 solver.cpp:228] Iteration 237500, loss = 0.0472394
I1130 22:45:30.489765 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0104478 (* 0.5 = 0.00522391 loss)
I1130 22:45:30.489773 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.035264 (* 1 = 0.035264 loss)
I1130 22:45:30.489776 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:45:30.489780 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:45:30.489785 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00151079 (* 1 = 0.00151079 loss)
I1130 22:45:30.489790 11845 sgd_solver.cpp:106] Iteration 237500, lr = 1e-05
I1130 22:45:34.104684 11845 solver.cpp:228] Iteration 238000, loss = 0.0435266
I1130 22:45:34.104742 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00707144 (* 0.5 = 0.00353572 loss)
I1130 22:45:34.104749 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0405471 (* 1 = 0.0405471 loss)
I1130 22:45:34.104753 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:45:34.104758 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:45:34.104763 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00155689 (* 1 = 0.00155689 loss)
I1130 22:45:34.104769 11845 sgd_solver.cpp:106] Iteration 238000, lr = 1e-05
I1130 22:45:36.864918 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_238350.caffemodel
I1130 22:45:36.870443 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_238350.solverstate
I1130 22:45:36.871122 11845 solver.cpp:337] Iteration 238350, Testing net (#0)
I1130 22:45:47.717437 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00832252 (* 0.5 = 0.00416126 loss)
I1130 22:45:47.717489 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.044802 (* 1 = 0.044802 loss)
I1130 22:45:47.717495 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.993519
I1130 22:45:47.717499 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.912718
I1130 22:45:47.717504 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00184388 (* 1 = 0.00184388 loss)
I1130 22:45:48.861186 11845 solver.cpp:228] Iteration 238500, loss = 0.040254
I1130 22:45:48.861239 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00751571 (* 0.5 = 0.00375785 loss)
I1130 22:45:48.861246 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0173426 (* 1 = 0.0173426 loss)
I1130 22:45:48.861250 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:45:48.861253 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:45:48.861258 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00137022 (* 1 = 0.00137022 loss)
I1130 22:45:48.861263 11845 sgd_solver.cpp:106] Iteration 238500, lr = 1e-05
I1130 22:45:52.467608 11845 solver.cpp:228] Iteration 239000, loss = 0.047686
I1130 22:45:52.467689 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00762963 (* 0.5 = 0.00381481 loss)
I1130 22:45:52.467716 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0861885 (* 1 = 0.0861885 loss)
I1130 22:45:52.467722 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:45:52.467727 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 22:45:52.467733 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0092876 (* 1 = 0.0092876 loss)
I1130 22:45:52.467741 11845 sgd_solver.cpp:106] Iteration 239000, lr = 1e-05
I1130 22:45:56.173596 11845 solver.cpp:228] Iteration 239500, loss = 0.0432362
I1130 22:45:56.173671 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00672442 (* 0.5 = 0.00336221 loss)
I1130 22:45:56.173679 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0317636 (* 1 = 0.0317636 loss)
I1130 22:45:56.173684 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:45:56.173689 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:45:56.173696 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00157383 (* 1 = 0.00157383 loss)
I1130 22:45:56.173713 11845 sgd_solver.cpp:106] Iteration 239500, lr = 1e-05
I1130 22:45:59.970438 11845 solver.cpp:228] Iteration 240000, loss = 0.0382516
I1130 22:45:59.970613 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00713439 (* 0.5 = 0.00356719 loss)
I1130 22:45:59.970621 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0542073 (* 1 = 0.0542073 loss)
I1130 22:45:59.970625 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:45:59.970639 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:45:59.970644 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00222981 (* 1 = 0.00222981 loss)
I1130 22:45:59.970652 11845 sgd_solver.cpp:106] Iteration 240000, lr = 1e-05
I1130 22:46:03.691468 11845 solver.cpp:228] Iteration 240500, loss = 0.0442369
I1130 22:46:03.691562 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0100913 (* 0.5 = 0.00504565 loss)
I1130 22:46:03.691570 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0226657 (* 1 = 0.0226657 loss)
I1130 22:46:03.691576 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:46:03.691588 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:46:03.691593 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00200665 (* 1 = 0.00200665 loss)
I1130 22:46:03.691601 11845 sgd_solver.cpp:106] Iteration 240500, lr = 1e-05
I1130 22:46:07.368621 11845 solver.cpp:228] Iteration 241000, loss = 0.0444831
I1130 22:46:07.368700 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00879674 (* 0.5 = 0.00439837 loss)
I1130 22:46:07.368706 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0238677 (* 1 = 0.0238677 loss)
I1130 22:46:07.368711 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:46:07.368716 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:46:07.368721 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00180112 (* 1 = 0.00180112 loss)
I1130 22:46:07.368728 11845 sgd_solver.cpp:106] Iteration 241000, lr = 1e-05
I1130 22:46:11.018049 11845 solver.cpp:228] Iteration 241500, loss = 0.0411676
I1130 22:46:11.018148 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00842939 (* 0.5 = 0.00421469 loss)
I1130 22:46:11.018157 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0122283 (* 1 = 0.0122283 loss)
I1130 22:46:11.018162 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:46:11.018165 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:46:11.018170 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00375102 (* 1 = 0.00375102 loss)
I1130 22:46:11.018177 11845 sgd_solver.cpp:106] Iteration 241500, lr = 1e-05
I1130 22:46:14.697960 11845 solver.cpp:228] Iteration 242000, loss = 0.0452195
I1130 22:46:14.698025 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0065074 (* 0.5 = 0.0032537 loss)
I1130 22:46:14.698032 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.047525 (* 1 = 0.047525 loss)
I1130 22:46:14.698036 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:46:14.698040 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:46:14.698053 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00140926 (* 1 = 0.00140926 loss)
I1130 22:46:14.698060 11845 sgd_solver.cpp:106] Iteration 242000, lr = 1e-05
I1130 22:46:18.395813 11845 solver.cpp:228] Iteration 242500, loss = 0.0460798
I1130 22:46:18.395895 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00794463 (* 0.5 = 0.00397232 loss)
I1130 22:46:18.395903 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0519064 (* 1 = 0.0519064 loss)
I1130 22:46:18.395907 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:46:18.395920 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:46:18.395925 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00344503 (* 1 = 0.00344503 loss)
I1130 22:46:18.395933 11845 sgd_solver.cpp:106] Iteration 242500, lr = 1e-05
I1130 22:46:22.082983 11845 solver.cpp:228] Iteration 243000, loss = 0.0454295
I1130 22:46:22.083044 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00957899 (* 0.5 = 0.00478949 loss)
I1130 22:46:22.083051 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.00873976 (* 1 = 0.00873976 loss)
I1130 22:46:22.083055 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:46:22.083060 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 22:46:22.083065 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00147454 (* 1 = 0.00147454 loss)
I1130 22:46:22.083078 11845 sgd_solver.cpp:106] Iteration 243000, lr = 1e-05
I1130 22:46:25.749615 11845 solver.cpp:228] Iteration 243500, loss = 0.0430802
I1130 22:46:25.749675 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00855381 (* 0.5 = 0.0042769 loss)
I1130 22:46:25.749683 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.030248 (* 1 = 0.030248 loss)
I1130 22:46:25.749687 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:46:25.749691 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:46:25.749696 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00205668 (* 1 = 0.00205668 loss)
I1130 22:46:25.749704 11845 sgd_solver.cpp:106] Iteration 243500, lr = 1e-05
I1130 22:46:29.423997 11845 solver.cpp:228] Iteration 244000, loss = 0.0431993
I1130 22:46:29.424070 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00710951 (* 0.5 = 0.00355475 loss)
I1130 22:46:29.424087 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0312783 (* 1 = 0.0312783 loss)
I1130 22:46:29.424090 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:46:29.424103 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:46:29.424108 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00421974 (* 1 = 0.00421974 loss)
I1130 22:46:29.424115 11845 sgd_solver.cpp:106] Iteration 244000, lr = 1e-05
I1130 22:46:33.152366 11845 solver.cpp:228] Iteration 244500, loss = 0.0457136
I1130 22:46:33.152436 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00556401 (* 0.5 = 0.002782 loss)
I1130 22:46:33.152442 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0208567 (* 1 = 0.0208567 loss)
I1130 22:46:33.152446 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:46:33.152451 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:46:33.152456 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00266594 (* 1 = 0.00266594 loss)
I1130 22:46:33.152478 11845 sgd_solver.cpp:106] Iteration 244500, lr = 1e-05
I1130 22:46:36.838217 11845 solver.cpp:228] Iteration 245000, loss = 0.0460129
I1130 22:46:36.838301 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00987286 (* 0.5 = 0.00493643 loss)
I1130 22:46:36.838310 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0410964 (* 1 = 0.0410964 loss)
I1130 22:46:36.838315 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:46:36.838318 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:46:36.838325 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00326093 (* 1 = 0.00326093 loss)
I1130 22:46:36.838332 11845 sgd_solver.cpp:106] Iteration 245000, lr = 1e-05
I1130 22:46:38.009599 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_245160.caffemodel
I1130 22:46:38.015163 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_245160.solverstate
I1130 22:46:38.015836 11845 solver.cpp:337] Iteration 245160, Testing net (#0)
I1130 22:46:49.496124 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00806409 (* 0.5 = 0.00403205 loss)
I1130 22:46:49.496198 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0439924 (* 1 = 0.0439924 loss)
I1130 22:46:49.496206 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.992221
I1130 22:46:49.496212 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.920358
I1130 22:46:49.496218 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00191509 (* 1 = 0.00191509 loss)
I1130 22:46:52.154371 11845 solver.cpp:228] Iteration 245500, loss = 0.0442928
I1130 22:46:52.154474 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00682092 (* 0.5 = 0.00341046 loss)
I1130 22:46:52.154489 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0455378 (* 1 = 0.0455378 loss)
I1130 22:46:52.154494 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:46:52.154497 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:46:52.154503 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00151816 (* 1 = 0.00151816 loss)
I1130 22:46:52.154510 11845 sgd_solver.cpp:106] Iteration 245500, lr = 1e-05
I1130 22:46:55.854122 11845 solver.cpp:228] Iteration 246000, loss = 0.0451154
I1130 22:46:55.854182 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00568434 (* 0.5 = 0.00284217 loss)
I1130 22:46:55.854197 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.023623 (* 1 = 0.023623 loss)
I1130 22:46:55.854202 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:46:55.854205 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:46:55.854210 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00117069 (* 1 = 0.00117069 loss)
I1130 22:46:55.854218 11845 sgd_solver.cpp:106] Iteration 246000, lr = 1e-05
I1130 22:46:59.577293 11845 solver.cpp:228] Iteration 246500, loss = 0.0409922
I1130 22:46:59.577395 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00684384 (* 0.5 = 0.00342192 loss)
I1130 22:46:59.577405 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0424379 (* 1 = 0.0424379 loss)
I1130 22:46:59.577411 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:46:59.577416 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:46:59.577424 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00152355 (* 1 = 0.00152355 loss)
I1130 22:46:59.577433 11845 sgd_solver.cpp:106] Iteration 246500, lr = 1e-05
I1130 22:47:03.303020 11845 solver.cpp:228] Iteration 247000, loss = 0.0453382
I1130 22:47:03.303123 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00756358 (* 0.5 = 0.00378179 loss)
I1130 22:47:03.303131 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0199514 (* 1 = 0.0199514 loss)
I1130 22:47:03.303167 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:47:03.303174 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:47:03.303179 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00121733 (* 1 = 0.00121733 loss)
I1130 22:47:03.303187 11845 sgd_solver.cpp:106] Iteration 247000, lr = 1e-05
I1130 22:47:07.048703 11845 solver.cpp:228] Iteration 247500, loss = 0.0459008
I1130 22:47:07.048789 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00666988 (* 0.5 = 0.00333494 loss)
I1130 22:47:07.048797 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0250832 (* 1 = 0.0250832 loss)
I1130 22:47:07.048802 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:47:07.048806 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:47:07.048812 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00136513 (* 1 = 0.00136513 loss)
I1130 22:47:07.048821 11845 sgd_solver.cpp:106] Iteration 247500, lr = 1e-05
I1130 22:47:10.747638 11845 solver.cpp:228] Iteration 248000, loss = 0.0393474
I1130 22:47:10.747731 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00816844 (* 0.5 = 0.00408422 loss)
I1130 22:47:10.747740 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0332528 (* 1 = 0.0332528 loss)
I1130 22:47:10.747743 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:47:10.747748 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:47:10.747755 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00161704 (* 1 = 0.00161704 loss)
I1130 22:47:10.747762 11845 sgd_solver.cpp:106] Iteration 248000, lr = 1e-05
I1130 22:47:14.462543 11845 solver.cpp:228] Iteration 248500, loss = 0.0431774
I1130 22:47:14.462649 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00763789 (* 0.5 = 0.00381895 loss)
I1130 22:47:14.462656 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0320478 (* 1 = 0.0320478 loss)
I1130 22:47:14.462661 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:47:14.462666 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:47:14.462679 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00139605 (* 1 = 0.00139605 loss)
I1130 22:47:14.462687 11845 sgd_solver.cpp:106] Iteration 248500, lr = 1e-05
I1130 22:47:18.177691 11845 solver.cpp:228] Iteration 249000, loss = 0.0443306
I1130 22:47:18.177778 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00738539 (* 0.5 = 0.00369269 loss)
I1130 22:47:18.177784 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0331714 (* 1 = 0.0331714 loss)
I1130 22:47:18.177788 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:47:18.177793 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:47:18.177798 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00133378 (* 1 = 0.00133378 loss)
I1130 22:47:18.177804 11845 sgd_solver.cpp:106] Iteration 249000, lr = 1e-05
I1130 22:47:21.901327 11845 solver.cpp:228] Iteration 249500, loss = 0.0394876
I1130 22:47:21.901427 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00930328 (* 0.5 = 0.00465164 loss)
I1130 22:47:21.901437 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.046888 (* 1 = 0.046888 loss)
I1130 22:47:21.901440 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:47:21.901445 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:47:21.901450 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00357059 (* 1 = 0.00357059 loss)
I1130 22:47:21.901458 11845 sgd_solver.cpp:106] Iteration 249500, lr = 1e-05
I1130 22:47:25.654160 11845 solver.cpp:228] Iteration 250000, loss = 0.0447189
I1130 22:47:25.654242 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.009238 (* 0.5 = 0.004619 loss)
I1130 22:47:25.654255 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.094224 (* 1 = 0.094224 loss)
I1130 22:47:25.654263 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:47:25.654270 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 22:47:25.654279 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00196085 (* 1 = 0.00196085 loss)
I1130 22:47:25.654287 11845 sgd_solver.cpp:106] Iteration 250000, lr = 1e-05
I1130 22:47:29.280831 11845 solver.cpp:228] Iteration 250500, loss = 0.0464932
I1130 22:47:29.280879 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00701926 (* 0.5 = 0.00350963 loss)
I1130 22:47:29.280886 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0300853 (* 1 = 0.0300853 loss)
I1130 22:47:29.280891 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:47:29.280896 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:47:29.280902 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00174353 (* 1 = 0.00174353 loss)
I1130 22:47:29.280907 11845 sgd_solver.cpp:106] Iteration 250500, lr = 1e-05
I1130 22:47:33.135401 11845 solver.cpp:228] Iteration 251000, loss = 0.0431104
I1130 22:47:33.135462 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00796265 (* 0.5 = 0.00398132 loss)
I1130 22:47:33.135469 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0400508 (* 1 = 0.0400508 loss)
I1130 22:47:33.135473 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:47:33.135478 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:47:33.135483 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00366176 (* 1 = 0.00366176 loss)
I1130 22:47:33.135488 11845 sgd_solver.cpp:106] Iteration 251000, lr = 1e-05
I1130 22:47:36.757859 11845 solver.cpp:228] Iteration 251500, loss = 0.0464461
I1130 22:47:36.757921 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00713205 (* 0.5 = 0.00356603 loss)
I1130 22:47:36.757928 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0411798 (* 1 = 0.0411798 loss)
I1130 22:47:36.757932 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:47:36.757936 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:47:36.757941 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00142309 (* 1 = 0.00142309 loss)
I1130 22:47:36.757946 11845 sgd_solver.cpp:106] Iteration 251500, lr = 1e-05
I1130 22:47:40.152775 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_251970.caffemodel
I1130 22:47:40.158565 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_251970.solverstate
I1130 22:47:40.159200 11845 solver.cpp:337] Iteration 251970, Testing net (#0)
I1130 22:47:51.961207 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00831976 (* 0.5 = 0.00415988 loss)
I1130 22:47:51.961264 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0434235 (* 1 = 0.0434235 loss)
I1130 22:47:51.961271 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.990777
I1130 22:47:51.961274 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.925374
I1130 22:47:51.961280 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00184528 (* 1 = 0.00184528 loss)
I1130 22:47:52.206864 11845 solver.cpp:228] Iteration 252000, loss = 0.0442187
I1130 22:47:52.206918 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00711897 (* 0.5 = 0.00355949 loss)
I1130 22:47:52.206926 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0365512 (* 1 = 0.0365512 loss)
I1130 22:47:52.206930 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:47:52.206934 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:47:52.206957 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000822451 (* 1 = 0.000822451 loss)
I1130 22:47:52.206962 11845 sgd_solver.cpp:106] Iteration 252000, lr = 1e-05
I1130 22:47:56.263175 11845 solver.cpp:228] Iteration 252500, loss = 0.0388608
I1130 22:47:56.263231 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0105507 (* 0.5 = 0.00527535 loss)
I1130 22:47:56.263237 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0554176 (* 1 = 0.0554176 loss)
I1130 22:47:56.263242 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:47:56.263245 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 22:47:56.263250 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00276094 (* 1 = 0.00276094 loss)
I1130 22:47:56.263255 11845 sgd_solver.cpp:106] Iteration 252500, lr = 1e-05
I1130 22:47:59.979918 11845 solver.cpp:228] Iteration 253000, loss = 0.0498941
I1130 22:47:59.979982 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0072283 (* 0.5 = 0.00361415 loss)
I1130 22:47:59.979990 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0544373 (* 1 = 0.0544373 loss)
I1130 22:47:59.979995 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:47:59.979998 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:47:59.980003 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00214683 (* 1 = 0.00214683 loss)
I1130 22:47:59.980010 11845 sgd_solver.cpp:106] Iteration 253000, lr = 1e-05
I1130 22:48:03.735518 11845 solver.cpp:228] Iteration 253500, loss = 0.0487712
I1130 22:48:03.735585 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00896318 (* 0.5 = 0.00448159 loss)
I1130 22:48:03.735594 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0506824 (* 1 = 0.0506824 loss)
I1130 22:48:03.735597 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:48:03.735601 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:48:03.735605 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00225469 (* 1 = 0.00225469 loss)
I1130 22:48:03.735611 11845 sgd_solver.cpp:106] Iteration 253500, lr = 1e-05
I1130 22:48:07.387300 11845 solver.cpp:228] Iteration 254000, loss = 0.0379649
I1130 22:48:07.387362 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00663125 (* 0.5 = 0.00331563 loss)
I1130 22:48:07.387369 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0547824 (* 1 = 0.0547824 loss)
I1130 22:48:07.387374 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:48:07.387377 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 22:48:07.387382 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00156015 (* 1 = 0.00156015 loss)
I1130 22:48:07.387388 11845 sgd_solver.cpp:106] Iteration 254000, lr = 1e-05
I1130 22:48:11.034248 11845 solver.cpp:228] Iteration 254500, loss = 0.0455504
I1130 22:48:11.034312 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00979091 (* 0.5 = 0.00489545 loss)
I1130 22:48:11.034319 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0281524 (* 1 = 0.0281524 loss)
I1130 22:48:11.034323 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:48:11.034327 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:48:11.034332 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00165952 (* 1 = 0.00165952 loss)
I1130 22:48:11.034338 11845 sgd_solver.cpp:106] Iteration 254500, lr = 1e-05
I1130 22:48:14.705677 11845 solver.cpp:228] Iteration 255000, loss = 0.0457101
I1130 22:48:14.705749 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00815536 (* 0.5 = 0.00407768 loss)
I1130 22:48:14.705759 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0473798 (* 1 = 0.0473798 loss)
I1130 22:48:14.705773 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:48:14.705778 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:48:14.705785 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00331914 (* 1 = 0.00331914 loss)
I1130 22:48:14.705792 11845 sgd_solver.cpp:106] Iteration 255000, lr = 1e-05
I1130 22:48:18.363787 11845 solver.cpp:228] Iteration 255500, loss = 0.0386415
I1130 22:48:18.363854 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00860955 (* 0.5 = 0.00430478 loss)
I1130 22:48:18.363862 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0728331 (* 1 = 0.0728331 loss)
I1130 22:48:18.363867 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:48:18.363872 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:48:18.363876 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00178013 (* 1 = 0.00178013 loss)
I1130 22:48:18.363883 11845 sgd_solver.cpp:106] Iteration 255500, lr = 1e-05
I1130 22:48:22.040165 11845 solver.cpp:228] Iteration 256000, loss = 0.0480587
I1130 22:48:22.040235 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00897777 (* 0.5 = 0.00448889 loss)
I1130 22:48:22.040241 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0359928 (* 1 = 0.0359928 loss)
I1130 22:48:22.040246 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:48:22.040249 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:48:22.040254 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000990473 (* 1 = 0.000990473 loss)
I1130 22:48:22.040261 11845 sgd_solver.cpp:106] Iteration 256000, lr = 1e-05
I1130 22:48:25.696924 11845 solver.cpp:228] Iteration 256500, loss = 0.0428737
I1130 22:48:25.696980 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00730102 (* 0.5 = 0.00365051 loss)
I1130 22:48:25.696987 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0270288 (* 1 = 0.0270288 loss)
I1130 22:48:25.696991 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:48:25.696995 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:48:25.697000 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0013531 (* 1 = 0.0013531 loss)
I1130 22:48:25.697005 11845 sgd_solver.cpp:106] Iteration 256500, lr = 1e-05
I1130 22:48:29.355525 11845 solver.cpp:228] Iteration 257000, loss = 0.0373096
I1130 22:48:29.355590 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00701176 (* 0.5 = 0.00350588 loss)
I1130 22:48:29.355598 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0412987 (* 1 = 0.0412987 loss)
I1130 22:48:29.355602 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:48:29.355607 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:48:29.355612 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00169012 (* 1 = 0.00169012 loss)
I1130 22:48:29.355618 11845 sgd_solver.cpp:106] Iteration 257000, lr = 1e-05
I1130 22:48:33.192006 11845 solver.cpp:228] Iteration 257500, loss = 0.0465875
I1130 22:48:33.192060 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00758468 (* 0.5 = 0.00379234 loss)
I1130 22:48:33.192072 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0263329 (* 1 = 0.0263329 loss)
I1130 22:48:33.192078 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:48:33.192082 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:48:33.192086 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00115173 (* 1 = 0.00115173 loss)
I1130 22:48:33.192092 11845 sgd_solver.cpp:106] Iteration 257500, lr = 1e-05
I1130 22:48:37.215391 11845 solver.cpp:228] Iteration 258000, loss = 0.0439941
I1130 22:48:37.215477 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00750476 (* 0.5 = 0.00375238 loss)
I1130 22:48:37.215502 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.050184 (* 1 = 0.050184 loss)
I1130 22:48:37.215507 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.979167
I1130 22:48:37.215512 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:48:37.215526 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00198684 (* 1 = 0.00198684 loss)
I1130 22:48:37.215533 11845 sgd_solver.cpp:106] Iteration 258000, lr = 1e-05
I1130 22:48:40.933356 11845 solver.cpp:228] Iteration 258500, loss = 0.0393306
I1130 22:48:40.933442 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00544402 (* 0.5 = 0.00272201 loss)
I1130 22:48:40.933450 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0339277 (* 1 = 0.0339277 loss)
I1130 22:48:40.933454 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:48:40.933459 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:48:40.933465 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00309816 (* 1 = 0.00309816 loss)
I1130 22:48:40.933471 11845 sgd_solver.cpp:106] Iteration 258500, lr = 1e-05
I1130 22:48:43.031782 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_258780.caffemodel
I1130 22:48:43.037327 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_258780.solverstate
I1130 22:48:43.038000 11845 solver.cpp:337] Iteration 258780, Testing net (#0)
I1130 22:48:55.358481 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00810867 (* 0.5 = 0.00405433 loss)
I1130 22:48:55.358546 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0446214 (* 1 = 0.0446214 loss)
I1130 22:48:55.358551 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.990457
I1130 22:48:55.358556 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.923522
I1130 22:48:55.358561 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.001899 (* 1 = 0.001899 loss)
I1130 22:48:57.127766 11845 solver.cpp:228] Iteration 259000, loss = 0.0458618
I1130 22:48:57.127825 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00718832 (* 0.5 = 0.00359416 loss)
I1130 22:48:57.127832 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0686381 (* 1 = 0.0686381 loss)
I1130 22:48:57.127836 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:48:57.127840 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:48:57.127846 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0027217 (* 1 = 0.0027217 loss)
I1130 22:48:57.127853 11845 sgd_solver.cpp:106] Iteration 259000, lr = 1e-05
I1130 22:49:00.947365 11845 solver.cpp:228] Iteration 259500, loss = 0.0493469
I1130 22:49:00.947448 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00876898 (* 0.5 = 0.00438449 loss)
I1130 22:49:00.947456 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0691084 (* 1 = 0.0691084 loss)
I1130 22:49:00.947461 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 22:49:00.947465 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 22:49:00.947471 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00138062 (* 1 = 0.00138062 loss)
I1130 22:49:00.947489 11845 sgd_solver.cpp:106] Iteration 259500, lr = 1e-05
I1130 22:49:04.671329 11845 solver.cpp:228] Iteration 260000, loss = 0.0405594
I1130 22:49:04.671402 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00686253 (* 0.5 = 0.00343127 loss)
I1130 22:49:04.671409 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0203169 (* 1 = 0.0203169 loss)
I1130 22:49:04.671414 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:49:04.671417 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 22:49:04.671449 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00100148 (* 1 = 0.00100148 loss)
I1130 22:49:04.671458 11845 sgd_solver.cpp:106] Iteration 260000, lr = 1e-05
I1130 22:49:08.383575 11845 solver.cpp:228] Iteration 260500, loss = 0.0441508
I1130 22:49:08.383646 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0083384 (* 0.5 = 0.0041692 loss)
I1130 22:49:08.383652 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0333745 (* 1 = 0.0333745 loss)
I1130 22:49:08.383657 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:49:08.383661 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:49:08.383666 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00145016 (* 1 = 0.00145016 loss)
I1130 22:49:08.383674 11845 sgd_solver.cpp:106] Iteration 260500, lr = 1e-05
I1130 22:49:12.100955 11845 solver.cpp:228] Iteration 261000, loss = 0.044302
I1130 22:49:12.101039 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00700502 (* 0.5 = 0.00350251 loss)
I1130 22:49:12.101047 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0394512 (* 1 = 0.0394512 loss)
I1130 22:49:12.101052 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:49:12.101055 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:49:12.101060 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00145445 (* 1 = 0.00145445 loss)
I1130 22:49:12.101073 11845 sgd_solver.cpp:106] Iteration 261000, lr = 1e-05
I1130 22:49:15.861708 11845 solver.cpp:228] Iteration 261500, loss = 0.0454175
I1130 22:49:15.861806 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00816937 (* 0.5 = 0.00408468 loss)
I1130 22:49:15.861814 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0465257 (* 1 = 0.0465257 loss)
I1130 22:49:15.861819 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:49:15.861824 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:49:15.861829 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00102334 (* 1 = 0.00102334 loss)
I1130 22:49:15.861838 11845 sgd_solver.cpp:106] Iteration 261500, lr = 1e-05
I1130 22:49:19.679843 11845 solver.cpp:228] Iteration 262000, loss = 0.0471491
I1130 22:49:19.679918 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00759851 (* 0.5 = 0.00379925 loss)
I1130 22:49:19.679924 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0305083 (* 1 = 0.0305083 loss)
I1130 22:49:19.679929 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:49:19.679934 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:49:19.679939 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00154874 (* 1 = 0.00154874 loss)
I1130 22:49:19.679956 11845 sgd_solver.cpp:106] Iteration 262000, lr = 1e-05
I1130 22:49:23.445380 11845 solver.cpp:228] Iteration 262500, loss = 0.0445962
I1130 22:49:23.445477 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00712729 (* 0.5 = 0.00356365 loss)
I1130 22:49:23.445484 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0194665 (* 1 = 0.0194665 loss)
I1130 22:49:23.445489 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:49:23.445493 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:49:23.445498 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0023818 (* 1 = 0.0023818 loss)
I1130 22:49:23.445508 11845 sgd_solver.cpp:106] Iteration 262500, lr = 1e-05
I1130 22:49:27.165220 11845 solver.cpp:228] Iteration 263000, loss = 0.0404948
I1130 22:49:27.165283 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00630173 (* 0.5 = 0.00315087 loss)
I1130 22:49:27.165292 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0299994 (* 1 = 0.0299994 loss)
I1130 22:49:27.165295 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:49:27.165325 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:49:27.165331 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00161897 (* 1 = 0.00161897 loss)
I1130 22:49:27.165338 11845 sgd_solver.cpp:106] Iteration 263000, lr = 1e-05
I1130 22:49:30.953356 11845 solver.cpp:228] Iteration 263500, loss = 0.0440538
I1130 22:49:30.953444 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00644712 (* 0.5 = 0.00322356 loss)
I1130 22:49:30.953452 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0190593 (* 1 = 0.0190593 loss)
I1130 22:49:30.953457 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:49:30.953461 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:49:30.953467 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00229886 (* 1 = 0.00229886 loss)
I1130 22:49:30.953483 11845 sgd_solver.cpp:106] Iteration 263500, lr = 1e-05
I1130 22:49:34.806962 11845 solver.cpp:228] Iteration 264000, loss = 0.046195
I1130 22:49:34.807025 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00938706 (* 0.5 = 0.00469353 loss)
I1130 22:49:34.807034 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0413124 (* 1 = 0.0413124 loss)
I1130 22:49:34.807037 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:49:34.807042 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:49:34.807047 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00115047 (* 1 = 0.00115047 loss)
I1130 22:49:34.807055 11845 sgd_solver.cpp:106] Iteration 264000, lr = 1e-05
I1130 22:49:38.660773 11845 solver.cpp:228] Iteration 264500, loss = 0.0417694
I1130 22:49:38.660840 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00614724 (* 0.5 = 0.00307362 loss)
I1130 22:49:38.660850 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.019737 (* 1 = 0.019737 loss)
I1130 22:49:38.660854 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:49:38.660859 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:49:38.660866 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00303547 (* 1 = 0.00303547 loss)
I1130 22:49:38.660871 11845 sgd_solver.cpp:106] Iteration 264500, lr = 1e-05
I1130 22:49:42.311558 11845 solver.cpp:228] Iteration 265000, loss = 0.0416481
I1130 22:49:42.311615 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00856348 (* 0.5 = 0.00428174 loss)
I1130 22:49:42.311622 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0310981 (* 1 = 0.0310981 loss)
I1130 22:49:42.311626 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:49:42.311630 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:49:42.311635 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0014732 (* 1 = 0.0014732 loss)
I1130 22:49:42.311640 11845 sgd_solver.cpp:106] Iteration 265000, lr = 1e-05
I1130 22:49:45.960253 11845 solver.cpp:228] Iteration 265500, loss = 0.0431821
I1130 22:49:45.960307 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00688725 (* 0.5 = 0.00344363 loss)
I1130 22:49:45.960314 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0469205 (* 1 = 0.0469205 loss)
I1130 22:49:45.960317 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:49:45.960321 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:49:45.960326 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00193542 (* 1 = 0.00193542 loss)
I1130 22:49:45.960331 11845 sgd_solver.cpp:106] Iteration 265500, lr = 1e-05
I1130 22:49:46.610960 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_265590.caffemodel
I1130 22:49:46.616940 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_265590.solverstate
I1130 22:49:46.617560 11845 solver.cpp:337] Iteration 265590, Testing net (#0)
I1130 22:49:57.593617 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00826929 (* 0.5 = 0.00413465 loss)
I1130 22:49:57.593670 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0440613 (* 1 = 0.0440613 loss)
I1130 22:49:57.593677 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.990303
I1130 22:49:57.593682 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.925039
I1130 22:49:57.593688 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00184436 (* 1 = 0.00184436 loss)
I1130 22:50:00.797341 11845 solver.cpp:228] Iteration 266000, loss = 0.0432316
I1130 22:50:00.797415 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00697722 (* 0.5 = 0.00348861 loss)
I1130 22:50:00.797423 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0198082 (* 1 = 0.0198082 loss)
I1130 22:50:00.797427 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:50:00.797431 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 22:50:00.797446 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0017937 (* 1 = 0.0017937 loss)
I1130 22:50:00.797452 11845 sgd_solver.cpp:106] Iteration 266000, lr = 1e-05
I1130 22:50:04.551273 11845 solver.cpp:228] Iteration 266500, loss = 0.042394
I1130 22:50:04.551383 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00790591 (* 0.5 = 0.00395295 loss)
I1130 22:50:04.551391 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0331499 (* 1 = 0.0331499 loss)
I1130 22:50:04.551395 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:50:04.551400 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:50:04.551406 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00131326 (* 1 = 0.00131326 loss)
I1130 22:50:04.551414 11845 sgd_solver.cpp:106] Iteration 266500, lr = 1e-05
I1130 22:50:08.278928 11845 solver.cpp:228] Iteration 267000, loss = 0.0444273
I1130 22:50:08.279011 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0084885 (* 0.5 = 0.00424425 loss)
I1130 22:50:08.279018 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0512288 (* 1 = 0.0512288 loss)
I1130 22:50:08.279022 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:50:08.279026 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 22:50:08.279031 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00139456 (* 1 = 0.00139456 loss)
I1130 22:50:08.279039 11845 sgd_solver.cpp:106] Iteration 267000, lr = 1e-05
I1130 22:50:12.077325 11845 solver.cpp:228] Iteration 267500, loss = 0.0463273
I1130 22:50:12.077435 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00883641 (* 0.5 = 0.00441821 loss)
I1130 22:50:12.077445 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0326172 (* 1 = 0.0326172 loss)
I1130 22:50:12.077450 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:50:12.077453 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:50:12.077458 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00242165 (* 1 = 0.00242165 loss)
I1130 22:50:12.077476 11845 sgd_solver.cpp:106] Iteration 267500, lr = 1e-05
I1130 22:50:15.929759 11845 solver.cpp:228] Iteration 268000, loss = 0.043767
I1130 22:50:15.929852 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00646705 (* 0.5 = 0.00323352 loss)
I1130 22:50:15.929860 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0448353 (* 1 = 0.0448353 loss)
I1130 22:50:15.929865 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:50:15.929872 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:50:15.929877 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00151252 (* 1 = 0.00151252 loss)
I1130 22:50:15.929940 11845 sgd_solver.cpp:106] Iteration 268000, lr = 1e-05
I1130 22:50:19.682021 11845 solver.cpp:228] Iteration 268500, loss = 0.0436122
I1130 22:50:19.682127 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0106675 (* 0.5 = 0.00533376 loss)
I1130 22:50:19.682135 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0488898 (* 1 = 0.0488898 loss)
I1130 22:50:19.682140 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:50:19.682144 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 22:50:19.682150 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00168228 (* 1 = 0.00168228 loss)
I1130 22:50:19.682158 11845 sgd_solver.cpp:106] Iteration 268500, lr = 1e-05
I1130 22:50:23.399729 11845 solver.cpp:228] Iteration 269000, loss = 0.0451437
I1130 22:50:23.399844 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00936131 (* 0.5 = 0.00468066 loss)
I1130 22:50:23.399852 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0305335 (* 1 = 0.0305335 loss)
I1130 22:50:23.399858 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:50:23.399863 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 22:50:23.399868 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00181433 (* 1 = 0.00181433 loss)
I1130 22:50:23.399878 11845 sgd_solver.cpp:106] Iteration 269000, lr = 1e-05
I1130 22:50:27.104595 11845 solver.cpp:228] Iteration 269500, loss = 0.0428189
I1130 22:50:27.104710 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0109412 (* 0.5 = 0.0054706 loss)
I1130 22:50:27.104718 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0681089 (* 1 = 0.0681089 loss)
I1130 22:50:27.104723 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.973958
I1130 22:50:27.104727 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 22:50:27.104733 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00219837 (* 1 = 0.00219837 loss)
I1130 22:50:27.104743 11845 sgd_solver.cpp:106] Iteration 269500, lr = 1e-05
I1130 22:50:30.809522 11845 solver.cpp:228] Iteration 270000, loss = 0.0481976
I1130 22:50:30.809589 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00964515 (* 0.5 = 0.00482258 loss)
I1130 22:50:30.809597 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0363734 (* 1 = 0.0363734 loss)
I1130 22:50:30.809600 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 22:50:30.809604 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:50:30.809609 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00139996 (* 1 = 0.00139996 loss)
I1130 22:50:30.809617 11845 sgd_solver.cpp:106] Iteration 270000, lr = 1e-05
I1130 22:50:34.504811 11845 solver.cpp:228] Iteration 270500, loss = 0.046759
I1130 22:50:34.504883 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00660101 (* 0.5 = 0.00330051 loss)
I1130 22:50:34.504890 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0399097 (* 1 = 0.0399097 loss)
I1130 22:50:34.504894 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:50:34.504899 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:50:34.504904 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00104858 (* 1 = 0.00104858 loss)
I1130 22:50:34.504910 11845 sgd_solver.cpp:106] Iteration 270500, lr = 1e-05
I1130 22:50:38.269285 11845 solver.cpp:228] Iteration 271000, loss = 0.0398698
I1130 22:50:38.269350 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00797687 (* 0.5 = 0.00398843 loss)
I1130 22:50:38.269367 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0400578 (* 1 = 0.0400578 loss)
I1130 22:50:38.269372 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:50:38.269414 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:50:38.269421 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00129185 (* 1 = 0.00129185 loss)
I1130 22:50:38.269430 11845 sgd_solver.cpp:106] Iteration 271000, lr = 1e-05
I1130 22:50:42.084349 11845 solver.cpp:228] Iteration 271500, loss = 0.0430496
I1130 22:50:42.084439 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00808602 (* 0.5 = 0.00404301 loss)
I1130 22:50:42.084457 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0314101 (* 1 = 0.0314101 loss)
I1130 22:50:42.084462 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.994792
I1130 22:50:42.084466 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:50:42.084472 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00183658 (* 1 = 0.00183658 loss)
I1130 22:50:42.084481 11845 sgd_solver.cpp:106] Iteration 271500, lr = 1e-05
I1130 22:50:45.876994 11845 solver.cpp:228] Iteration 272000, loss = 0.0474808
I1130 22:50:45.877060 11845 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00868088 (* 0.5 = 0.00434044 loss)
I1130 22:50:45.877074 11845 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0484131 (* 1 = 0.0484131 loss)
I1130 22:50:45.877091 11845 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.989583
I1130 22:50:45.877096 11845 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 22:50:45.877101 11845 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00116116 (* 1 = 0.00116116 loss)
I1130 22:50:45.877110 11845 sgd_solver.cpp:106] Iteration 272000, lr = 1e-05
I1130 22:50:48.902793 11845 solver.cpp:454] Snapshotting to binary proto file tmp/rnet_iter_272400.caffemodel
I1130 22:50:48.908670 11845 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/rnet_iter_272400.solverstate
I1130 22:50:48.909255 11845 solver.cpp:337] Iteration 272400, Testing net (#0)
I1130 22:50:59.960093 11845 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0081554 (* 0.5 = 0.0040777 loss)
I1130 22:50:59.960135 11845 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0447745 (* 1 = 0.0447745 loss)
I1130 22:50:59.960140 11845 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.993844
I1130 22:50:59.960144 11845 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.911061
I1130 22:50:59.960149 11845 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00189443 (* 1 = 0.00189443 loss)
I1130 22:50:59.960155 11845 solver.cpp:322] Optimization Done.
Generate Data for oNet
[2016-11-30 22:51:02,170][INFO] loading CelebA
[2016-11-30 22:51:08,396][INFO] total images, train: 162079, val: 40520
[2016-11-30 22:51:08,397][INFO] writing train data, 162079 images
[2016-11-30 22:51:08,397][INFO] remove data/onet_landmark_train
[2016-11-30 22:51:08,397][INFO] fill queues
[2016-11-30 22:51:09,253][INFO] writes 1000 landmark faces
[2016-11-30 22:51:09,542][INFO] writes 2000 landmark faces
[2016-11-30 22:51:09,789][INFO] writes 3000 landmark faces
[2016-11-30 22:51:10,030][INFO] writes 4000 landmark faces
[2016-11-30 22:51:10,261][INFO] writes 5000 landmark faces
[2016-11-30 22:51:10,501][INFO] writes 6000 landmark faces
[2016-11-30 22:51:10,747][INFO] writes 7000 landmark faces
[2016-11-30 22:51:10,997][INFO] writes 8000 landmark faces
[2016-11-30 22:51:11,244][INFO] writes 9000 landmark faces
[2016-11-30 22:51:11,456][INFO] writes 10000 landmark faces
[2016-11-30 22:51:11,711][INFO] writes 11000 landmark faces
[2016-11-30 22:51:11,947][INFO] writes 12000 landmark faces
[2016-11-30 22:51:12,162][INFO] writes 13000 landmark faces
[2016-11-30 22:51:12,420][INFO] writes 14000 landmark faces
[2016-11-30 22:51:12,660][INFO] writes 15000 landmark faces
[2016-11-30 22:51:12,921][INFO] writes 16000 landmark faces
[2016-11-30 22:51:13,167][INFO] writes 17000 landmark faces
[2016-11-30 22:51:13,395][INFO] writes 18000 landmark faces
[2016-11-30 22:51:13,628][INFO] writes 19000 landmark faces
[2016-11-30 22:51:13,878][INFO] writes 20000 landmark faces
[2016-11-30 22:51:14,122][INFO] writes 21000 landmark faces
[2016-11-30 22:51:14,360][INFO] writes 22000 landmark faces
[2016-11-30 22:51:14,577][INFO] writes 23000 landmark faces
[2016-11-30 22:51:14,779][INFO] writes 24000 landmark faces
[2016-11-30 22:51:14,998][INFO] writes 25000 landmark faces
[2016-11-30 22:51:15,207][INFO] writes 26000 landmark faces
[2016-11-30 22:51:15,409][INFO] writes 27000 landmark faces
[2016-11-30 22:51:15,628][INFO] writes 28000 landmark faces
[2016-11-30 22:51:15,845][INFO] writes 29000 landmark faces
[2016-11-30 22:51:16,082][INFO] writes 30000 landmark faces
[2016-11-30 22:51:16,338][INFO] writes 31000 landmark faces
[2016-11-30 22:51:16,570][INFO] writes 32000 landmark faces
[2016-11-30 22:51:16,806][INFO] writes 33000 landmark faces
[2016-11-30 22:51:17,043][INFO] writes 34000 landmark faces
[2016-11-30 22:51:17,253][INFO] writes 35000 landmark faces
[2016-11-30 22:51:17,467][INFO] writes 36000 landmark faces
[2016-11-30 22:51:17,702][INFO] writes 37000 landmark faces
[2016-11-30 22:51:17,922][INFO] writes 38000 landmark faces
[2016-11-30 22:51:18,192][INFO] writes 39000 landmark faces
[2016-11-30 22:51:18,426][INFO] writes 40000 landmark faces
[2016-11-30 22:51:18,632][INFO] writes 41000 landmark faces
[2016-11-30 22:51:18,856][INFO] writes 42000 landmark faces
[2016-11-30 22:51:19,115][INFO] writes 43000 landmark faces
[2016-11-30 22:51:19,355][INFO] writes 44000 landmark faces
[2016-11-30 22:51:19,581][INFO] writes 45000 landmark faces
[2016-11-30 22:51:19,849][INFO] writes 46000 landmark faces
[2016-11-30 22:51:20,089][INFO] writes 47000 landmark faces
[2016-11-30 22:51:20,322][INFO] writes 48000 landmark faces
[2016-11-30 22:51:20,558][INFO] writes 49000 landmark faces
[2016-11-30 22:51:20,794][INFO] writes 50000 landmark faces
[2016-11-30 22:51:21,099][INFO] writes 51000 landmark faces
[2016-11-30 22:51:21,341][INFO] writes 52000 landmark faces
[2016-11-30 22:51:21,608][INFO] writes 53000 landmark faces
[2016-11-30 22:51:21,809][INFO] writes 54000 landmark faces
[2016-11-30 22:51:22,054][INFO] writes 55000 landmark faces
[2016-11-30 22:51:22,284][INFO] writes 56000 landmark faces
[2016-11-30 22:51:22,511][INFO] writes 57000 landmark faces
[2016-11-30 22:51:22,751][INFO] writes 58000 landmark faces
[2016-11-30 22:51:23,014][INFO] writes 59000 landmark faces
[2016-11-30 22:51:23,248][INFO] writes 60000 landmark faces
[2016-11-30 22:51:23,464][INFO] writes 61000 landmark faces
[2016-11-30 22:51:23,694][INFO] writes 62000 landmark faces
[2016-11-30 22:51:23,896][INFO] writes 63000 landmark faces
[2016-11-30 22:51:24,169][INFO] writes 64000 landmark faces
[2016-11-30 22:51:24,390][INFO] writes 65000 landmark faces
[2016-11-30 22:51:24,648][INFO] writes 66000 landmark faces
[2016-11-30 22:51:24,946][INFO] writes 67000 landmark faces
[2016-11-30 22:51:25,230][INFO] writes 68000 landmark faces
[2016-11-30 22:51:25,437][INFO] writes 69000 landmark faces
[2016-11-30 22:51:25,673][INFO] writes 70000 landmark faces
[2016-11-30 22:51:25,935][INFO] writes 71000 landmark faces
[2016-11-30 22:51:26,185][INFO] writes 72000 landmark faces
[2016-11-30 22:51:26,408][INFO] writes 73000 landmark faces
[2016-11-30 22:51:26,633][INFO] writes 74000 landmark faces
[2016-11-30 22:51:26,886][INFO] writes 75000 landmark faces
[2016-11-30 22:51:27,115][INFO] writes 76000 landmark faces
[2016-11-30 22:51:27,243][INFO] Process-7 reads 1000
[2016-11-30 22:51:27,335][INFO] writes 77000 landmark faces
[2016-11-30 22:51:27,575][INFO] Process-1 reads 1000
[2016-11-30 22:51:27,607][INFO] writes 78000 landmark faces
[2016-11-30 22:51:27,893][INFO] writes 79000 landmark faces
[2016-11-30 22:51:27,893][INFO] Process-2 reads 1000
[2016-11-30 22:51:28,001][INFO] Process-5 reads 1000
[2016-11-30 22:51:28,043][INFO] Process-4 reads 1000
[2016-11-30 22:51:28,089][INFO] Process-8 reads 1000
[2016-11-30 22:51:28,115][INFO] writes 80000 landmark faces
[2016-11-30 22:51:28,343][INFO] writes 81000 landmark faces
[2016-11-30 22:51:28,561][INFO] writes 82000 landmark faces
[2016-11-30 22:51:28,692][INFO] Process-3 reads 1000
[2016-11-30 22:51:28,787][INFO] writes 83000 landmark faces
[2016-11-30 22:51:29,013][INFO] writes 84000 landmark faces
[2016-11-30 22:51:29,167][INFO] Process-6 reads 1000
[2016-11-30 22:51:29,242][INFO] writes 85000 landmark faces
[2016-11-30 22:51:29,446][INFO] writes 86000 landmark faces
[2016-11-30 22:51:29,670][INFO] writes 87000 landmark faces
[2016-11-30 22:51:29,922][INFO] writes 88000 landmark faces
[2016-11-30 22:51:30,183][INFO] writes 89000 landmark faces
[2016-11-30 22:51:30,394][INFO] writes 90000 landmark faces
[2016-11-30 22:51:30,630][INFO] writes 91000 landmark faces
[2016-11-30 22:51:30,874][INFO] writes 92000 landmark faces
[2016-11-30 22:51:31,122][INFO] writes 93000 landmark faces
[2016-11-30 22:51:31,351][INFO] writes 94000 landmark faces
[2016-11-30 22:51:31,598][INFO] writes 95000 landmark faces
[2016-11-30 22:51:31,817][INFO] writes 96000 landmark faces
[2016-11-30 22:51:32,041][INFO] writes 97000 landmark faces
[2016-11-30 22:51:32,271][INFO] writes 98000 landmark faces
[2016-11-30 22:51:32,498][INFO] writes 99000 landmark faces
[2016-11-30 22:51:32,720][INFO] writes 100000 landmark faces
[2016-11-30 22:51:32,938][INFO] writes 101000 landmark faces
[2016-11-30 22:51:33,166][INFO] writes 102000 landmark faces
[2016-11-30 22:51:33,387][INFO] writes 103000 landmark faces
[2016-11-30 22:51:33,605][INFO] writes 104000 landmark faces
[2016-11-30 22:51:33,822][INFO] writes 105000 landmark faces
[2016-11-30 22:51:34,036][INFO] writes 106000 landmark faces
[2016-11-30 22:51:34,282][INFO] writes 107000 landmark faces
[2016-11-30 22:51:34,509][INFO] writes 108000 landmark faces
[2016-11-30 22:51:34,741][INFO] writes 109000 landmark faces
[2016-11-30 22:51:34,959][INFO] writes 110000 landmark faces
[2016-11-30 22:51:35,166][INFO] writes 111000 landmark faces
[2016-11-30 22:51:35,384][INFO] writes 112000 landmark faces
[2016-11-30 22:51:35,635][INFO] writes 113000 landmark faces
[2016-11-30 22:51:35,872][INFO] writes 114000 landmark faces
[2016-11-30 22:51:36,086][INFO] writes 115000 landmark faces
[2016-11-30 22:51:36,354][INFO] writes 116000 landmark faces
[2016-11-30 22:51:36,571][INFO] writes 117000 landmark faces
[2016-11-30 22:51:36,805][INFO] writes 118000 landmark faces
[2016-11-30 22:51:37,043][INFO] writes 119000 landmark faces
[2016-11-30 22:51:37,261][INFO] writes 120000 landmark faces
[2016-11-30 22:51:37,521][INFO] writes 121000 landmark faces
[2016-11-30 22:51:37,756][INFO] writes 122000 landmark faces
[2016-11-30 22:51:37,987][INFO] writes 123000 landmark faces
[2016-11-30 22:51:38,198][INFO] writes 124000 landmark faces
[2016-11-30 22:51:38,416][INFO] writes 125000 landmark faces
[2016-11-30 22:51:38,661][INFO] writes 126000 landmark faces
[2016-11-30 22:51:38,880][INFO] writes 127000 landmark faces
[2016-11-30 22:51:39,173][INFO] writes 128000 landmark faces
[2016-11-30 22:51:39,307][INFO] writes 129000 landmark faces
[2016-11-30 22:51:39,555][INFO] writes 130000 landmark faces
[2016-11-30 22:51:39,833][INFO] writes 131000 landmark faces
[2016-11-30 22:51:40,051][INFO] writes 132000 landmark faces
[2016-11-30 22:51:40,294][INFO] writes 133000 landmark faces
[2016-11-30 22:51:40,529][INFO] writes 134000 landmark faces
[2016-11-30 22:51:40,746][INFO] writes 135000 landmark faces
[2016-11-30 22:51:40,948][INFO] writes 136000 landmark faces
[2016-11-30 22:51:41,184][INFO] writes 137000 landmark faces
[2016-11-30 22:51:41,416][INFO] writes 138000 landmark faces
[2016-11-30 22:51:41,624][INFO] writes 139000 landmark faces
[2016-11-30 22:51:41,871][INFO] writes 140000 landmark faces
[2016-11-30 22:51:42,193][INFO] writes 141000 landmark faces
[2016-11-30 22:51:42,499][INFO] writes 142000 landmark faces
[2016-11-30 22:51:42,774][INFO] writes 143000 landmark faces
[2016-11-30 22:51:43,064][INFO] writes 144000 landmark faces
[2016-11-30 22:51:43,237][INFO] writes 145000 landmark faces
[2016-11-30 22:51:43,491][INFO] writes 146000 landmark faces
[2016-11-30 22:51:43,765][INFO] writes 147000 landmark faces
[2016-11-30 22:51:44,052][INFO] writes 148000 landmark faces
[2016-11-30 22:51:44,301][INFO] writes 149000 landmark faces
[2016-11-30 22:51:44,545][INFO] writes 150000 landmark faces
[2016-11-30 22:51:44,765][INFO] writes 151000 landmark faces
[2016-11-30 22:51:44,998][INFO] writes 152000 landmark faces
[2016-11-30 22:51:45,232][INFO] writes 153000 landmark faces
[2016-11-30 22:51:45,457][INFO] writes 154000 landmark faces
[2016-11-30 22:51:45,682][INFO] writes 155000 landmark faces
[2016-11-30 22:51:45,914][INFO] writes 156000 landmark faces
[2016-11-30 22:51:46,137][INFO] writes 157000 landmark faces
[2016-11-30 22:51:46,194][INFO] Process-1 reads 2000
[2016-11-30 22:51:46,325][INFO] Process-5 reads 2000
[2016-11-30 22:51:46,346][INFO] writes 158000 landmark faces
[2016-11-30 22:51:46,408][INFO] Process-2 reads 2000
[2016-11-30 22:51:46,515][INFO] Process-7 reads 2000
[2016-11-30 22:51:46,568][INFO] writes 159000 landmark faces
[2016-11-30 22:51:46,632][INFO] Process-8 reads 2000
[2016-11-30 22:51:46,767][INFO] Process-4 reads 2000
[2016-11-30 22:51:46,859][INFO] writes 160000 landmark faces
[2016-11-30 22:51:47,008][INFO] writes 161000 landmark faces
[2016-11-30 22:51:47,206][INFO] writes 162000 landmark faces
[2016-11-30 22:51:47,438][INFO] writes 163000 landmark faces
[2016-11-30 22:51:47,576][INFO] Process-3 reads 2000
[2016-11-30 22:51:47,687][INFO] writes 164000 landmark faces
[2016-11-30 22:51:47,823][INFO] Process-6 reads 2000
[2016-11-30 22:51:47,896][INFO] writes 165000 landmark faces
[2016-11-30 22:51:48,119][INFO] writes 166000 landmark faces
[2016-11-30 22:51:48,400][INFO] writes 167000 landmark faces
[2016-11-30 22:51:48,620][INFO] writes 168000 landmark faces
[2016-11-30 22:51:48,923][INFO] writes 169000 landmark faces
[2016-11-30 22:51:49,202][INFO] writes 170000 landmark faces
[2016-11-30 22:51:49,447][INFO] writes 171000 landmark faces
[2016-11-30 22:51:49,656][INFO] writes 172000 landmark faces
[2016-11-30 22:51:49,885][INFO] writes 173000 landmark faces
[2016-11-30 22:51:50,128][INFO] writes 174000 landmark faces
[2016-11-30 22:51:50,343][INFO] writes 175000 landmark faces
[2016-11-30 22:51:50,628][INFO] writes 176000 landmark faces
[2016-11-30 22:51:50,793][INFO] writes 177000 landmark faces
[2016-11-30 22:51:50,988][INFO] writes 178000 landmark faces
[2016-11-30 22:51:51,243][INFO] writes 179000 landmark faces
[2016-11-30 22:51:51,481][INFO] writes 180000 landmark faces
[2016-11-30 22:51:51,695][INFO] writes 181000 landmark faces
[2016-11-30 22:51:51,925][INFO] writes 182000 landmark faces
[2016-11-30 22:51:52,180][INFO] writes 183000 landmark faces
[2016-11-30 22:51:52,429][INFO] writes 184000 landmark faces
[2016-11-30 22:51:52,660][INFO] writes 185000 landmark faces
[2016-11-30 22:51:52,936][INFO] writes 186000 landmark faces
[2016-11-30 22:51:53,178][INFO] writes 187000 landmark faces
[2016-11-30 22:51:53,408][INFO] writes 188000 landmark faces
[2016-11-30 22:51:53,602][INFO] writes 189000 landmark faces
[2016-11-30 22:51:53,815][INFO] writes 190000 landmark faces
[2016-11-30 22:51:54,045][INFO] writes 191000 landmark faces
[2016-11-30 22:51:54,325][INFO] writes 192000 landmark faces
[2016-11-30 22:51:54,506][INFO] writes 193000 landmark faces
[2016-11-30 22:51:54,747][INFO] writes 194000 landmark faces
[2016-11-30 22:51:54,980][INFO] writes 195000 landmark faces
[2016-11-30 22:51:55,211][INFO] writes 196000 landmark faces
[2016-11-30 22:51:55,485][INFO] writes 197000 landmark faces
[2016-11-30 22:51:55,754][INFO] writes 198000 landmark faces
[2016-11-30 22:51:55,997][INFO] writes 199000 landmark faces
[2016-11-30 22:51:56,246][INFO] writes 200000 landmark faces
[2016-11-30 22:51:56,462][INFO] writes 201000 landmark faces
[2016-11-30 22:51:56,669][INFO] writes 202000 landmark faces
[2016-11-30 22:51:56,954][INFO] writes 203000 landmark faces
[2016-11-30 22:51:57,182][INFO] writes 204000 landmark faces
[2016-11-30 22:51:57,434][INFO] writes 205000 landmark faces
[2016-11-30 22:51:57,700][INFO] writes 206000 landmark faces
[2016-11-30 22:51:57,969][INFO] writes 207000 landmark faces
[2016-11-30 22:51:58,249][INFO] writes 208000 landmark faces
[2016-11-30 22:51:58,416][INFO] writes 209000 landmark faces
[2016-11-30 22:51:58,667][INFO] writes 210000 landmark faces
[2016-11-30 22:51:58,921][INFO] writes 211000 landmark faces
[2016-11-30 22:51:59,166][INFO] writes 212000 landmark faces
[2016-11-30 22:51:59,402][INFO] writes 213000 landmark faces
[2016-11-30 22:51:59,652][INFO] writes 214000 landmark faces
[2016-11-30 22:51:59,894][INFO] writes 215000 landmark faces
[2016-11-30 22:52:00,158][INFO] writes 216000 landmark faces
[2016-11-30 22:52:00,426][INFO] writes 217000 landmark faces
[2016-11-30 22:52:00,669][INFO] writes 218000 landmark faces
[2016-11-30 22:52:00,918][INFO] writes 219000 landmark faces
[2016-11-30 22:52:01,162][INFO] writes 220000 landmark faces
[2016-11-30 22:52:01,372][INFO] writes 221000 landmark faces
[2016-11-30 22:52:01,593][INFO] writes 222000 landmark faces
[2016-11-30 22:52:01,881][INFO] writes 223000 landmark faces
[2016-11-30 22:52:02,185][INFO] writes 224000 landmark faces
[2016-11-30 22:52:02,366][INFO] writes 225000 landmark faces
[2016-11-30 22:52:02,653][INFO] writes 226000 landmark faces
[2016-11-30 22:52:02,904][INFO] writes 227000 landmark faces
[2016-11-30 22:52:03,123][INFO] writes 228000 landmark faces
[2016-11-30 22:52:03,367][INFO] writes 229000 landmark faces
[2016-11-30 22:52:03,600][INFO] writes 230000 landmark faces
[2016-11-30 22:52:03,861][INFO] writes 231000 landmark faces
[2016-11-30 22:52:04,116][INFO] writes 232000 landmark faces
[2016-11-30 22:52:04,325][INFO] writes 233000 landmark faces
[2016-11-30 22:52:04,527][INFO] writes 234000 landmark faces
[2016-11-30 22:52:04,759][INFO] writes 235000 landmark faces
[2016-11-30 22:52:04,822][INFO] Process-2 reads 3000
[2016-11-30 22:52:05,018][INFO] writes 236000 landmark faces
[2016-11-30 22:52:05,227][INFO] writes 237000 landmark faces
[2016-11-30 22:52:05,435][INFO] Process-1 reads 3000
[2016-11-30 22:52:05,472][INFO] writes 238000 landmark faces
[2016-11-30 22:52:05,500][INFO] Process-7 reads 3000
[2016-11-30 22:52:05,591][INFO] Process-8 reads 3000
[2016-11-30 22:52:05,676][INFO] Process-5 reads 3000
[2016-11-30 22:52:05,678][INFO] writes 239000 landmark faces
[2016-11-30 22:52:05,950][INFO] writes 240000 landmark faces
[2016-11-30 22:52:06,106][INFO] Process-3 reads 3000
[2016-11-30 22:52:06,121][INFO] writes 241000 landmark faces
[2016-11-30 22:52:06,369][INFO] writes 242000 landmark faces
[2016-11-30 22:52:06,590][INFO] writes 243000 landmark faces
[2016-11-30 22:52:06,832][INFO] writes 244000 landmark faces
[2016-11-30 22:52:06,994][INFO] Process-4 reads 3000
[2016-11-30 22:52:07,032][INFO] Process-6 reads 3000
[2016-11-30 22:52:07,049][INFO] writes 245000 landmark faces
[2016-11-30 22:52:07,300][INFO] writes 246000 landmark faces
[2016-11-30 22:52:07,540][INFO] writes 247000 landmark faces
[2016-11-30 22:52:07,782][INFO] writes 248000 landmark faces
[2016-11-30 22:52:08,080][INFO] writes 249000 landmark faces
[2016-11-30 22:52:08,319][INFO] writes 250000 landmark faces
[2016-11-30 22:52:08,546][INFO] writes 251000 landmark faces
[2016-11-30 22:52:08,762][INFO] writes 252000 landmark faces
[2016-11-30 22:52:08,985][INFO] writes 253000 landmark faces
[2016-11-30 22:52:09,201][INFO] writes 254000 landmark faces
[2016-11-30 22:52:09,438][INFO] writes 255000 landmark faces
[2016-11-30 22:52:09,732][INFO] writes 256000 landmark faces
[2016-11-30 22:52:09,912][INFO] writes 257000 landmark faces
[2016-11-30 22:52:10,150][INFO] writes 258000 landmark faces
[2016-11-30 22:52:10,361][INFO] writes 259000 landmark faces
[2016-11-30 22:52:10,585][INFO] writes 260000 landmark faces
[2016-11-30 22:52:10,821][INFO] writes 261000 landmark faces
[2016-11-30 22:52:11,040][INFO] writes 262000 landmark faces
[2016-11-30 22:52:11,268][INFO] writes 263000 landmark faces
[2016-11-30 22:52:11,593][INFO] writes 264000 landmark faces
[2016-11-30 22:52:11,801][INFO] writes 265000 landmark faces
[2016-11-30 22:52:12,014][INFO] writes 266000 landmark faces
[2016-11-30 22:52:12,229][INFO] writes 267000 landmark faces
[2016-11-30 22:52:12,440][INFO] writes 268000 landmark faces
[2016-11-30 22:52:12,698][INFO] writes 269000 landmark faces
[2016-11-30 22:52:12,927][INFO] writes 270000 landmark faces
[2016-11-30 22:52:13,130][INFO] writes 271000 landmark faces
[2016-11-30 22:52:13,371][INFO] writes 272000 landmark faces
[2016-11-30 22:52:13,523][INFO] writes 273000 landmark faces
[2016-11-30 22:52:13,771][INFO] writes 274000 landmark faces
[2016-11-30 22:52:13,998][INFO] writes 275000 landmark faces
[2016-11-30 22:52:14,239][INFO] writes 276000 landmark faces
[2016-11-30 22:52:14,478][INFO] writes 277000 landmark faces
[2016-11-30 22:52:14,683][INFO] writes 278000 landmark faces
[2016-11-30 22:52:14,907][INFO] writes 279000 landmark faces
[2016-11-30 22:52:15,123][INFO] writes 280000 landmark faces
[2016-11-30 22:52:15,388][INFO] writes 281000 landmark faces
[2016-11-30 22:52:15,623][INFO] writes 282000 landmark faces
[2016-11-30 22:52:15,884][INFO] writes 283000 landmark faces
[2016-11-30 22:52:16,112][INFO] writes 284000 landmark faces
[2016-11-30 22:52:16,326][INFO] writes 285000 landmark faces
[2016-11-30 22:52:16,578][INFO] writes 286000 landmark faces
[2016-11-30 22:52:16,807][INFO] writes 287000 landmark faces
[2016-11-30 22:52:17,072][INFO] writes 288000 landmark faces
[2016-11-30 22:52:17,258][INFO] writes 289000 landmark faces
[2016-11-30 22:52:17,463][INFO] writes 290000 landmark faces
[2016-11-30 22:52:17,685][INFO] writes 291000 landmark faces
[2016-11-30 22:52:18,011][INFO] writes 292000 landmark faces
[2016-11-30 22:52:18,254][INFO] writes 293000 landmark faces
[2016-11-30 22:52:18,538][INFO] writes 294000 landmark faces
[2016-11-30 22:52:18,762][INFO] writes 295000 landmark faces
[2016-11-30 22:52:18,963][INFO] writes 296000 landmark faces
[2016-11-30 22:52:19,188][INFO] writes 297000 landmark faces
[2016-11-30 22:52:19,438][INFO] writes 298000 landmark faces
[2016-11-30 22:52:19,667][INFO] writes 299000 landmark faces
[2016-11-30 22:52:19,893][INFO] writes 300000 landmark faces
[2016-11-30 22:52:20,119][INFO] writes 301000 landmark faces
[2016-11-30 22:52:20,362][INFO] writes 302000 landmark faces
[2016-11-30 22:52:20,568][INFO] writes 303000 landmark faces
[2016-11-30 22:52:20,864][INFO] writes 304000 landmark faces
[2016-11-30 22:52:21,075][INFO] writes 305000 landmark faces
[2016-11-30 22:52:21,290][INFO] writes 306000 landmark faces
[2016-11-30 22:52:21,539][INFO] writes 307000 landmark faces
[2016-11-30 22:52:21,762][INFO] writes 308000 landmark faces
[2016-11-30 22:52:21,986][INFO] writes 309000 landmark faces
[2016-11-30 22:52:22,248][INFO] writes 310000 landmark faces
[2016-11-30 22:52:22,488][INFO] writes 311000 landmark faces
[2016-11-30 22:52:22,745][INFO] writes 312000 landmark faces
[2016-11-30 22:52:22,985][INFO] writes 313000 landmark faces
[2016-11-30 22:52:23,236][INFO] writes 314000 landmark faces
[2016-11-30 22:52:23,463][INFO] writes 315000 landmark faces
[2016-11-30 22:52:23,609][INFO] Process-1 reads 4000
[2016-11-30 22:52:23,709][INFO] Process-8 reads 4000
[2016-11-30 22:52:23,756][INFO] writes 316000 landmark faces
[2016-11-30 22:52:23,993][INFO] writes 317000 landmark faces
[2016-11-30 22:52:24,145][INFO] Process-7 reads 4000
[2016-11-30 22:52:24,213][INFO] writes 318000 landmark faces
[2016-11-30 22:52:24,285][INFO] Process-2 reads 4000
[2016-11-30 22:52:24,445][INFO] writes 319000 landmark faces
[2016-11-30 22:52:24,523][INFO] Process-3 reads 4000
[2016-11-30 22:52:24,674][INFO] writes 320000 landmark faces
[2016-11-30 22:52:24,852][INFO] writes 321000 landmark faces
[2016-11-30 22:52:24,891][INFO] Process-5 reads 4000
[2016-11-30 22:52:25,131][INFO] writes 322000 landmark faces
[2016-11-30 22:52:25,332][INFO] writes 323000 landmark faces
[2016-11-30 22:52:25,531][INFO] Process-6 reads 4000
[2016-11-30 22:52:25,597][INFO] writes 324000 landmark faces
[2016-11-30 22:52:25,828][INFO] writes 325000 landmark faces
[2016-11-30 22:52:26,061][INFO] writes 326000 landmark faces
[2016-11-30 22:52:26,302][INFO] writes 327000 landmark faces
[2016-11-30 22:52:26,505][INFO] Process-4 reads 4000
[2016-11-30 22:52:26,519][INFO] writes 328000 landmark faces
[2016-11-30 22:52:26,749][INFO] writes 329000 landmark faces
[2016-11-30 22:52:27,020][INFO] writes 330000 landmark faces
[2016-11-30 22:52:27,242][INFO] writes 331000 landmark faces
[2016-11-30 22:52:27,495][INFO] writes 332000 landmark faces
[2016-11-30 22:52:27,750][INFO] writes 333000 landmark faces
[2016-11-30 22:52:28,001][INFO] writes 334000 landmark faces
[2016-11-30 22:52:28,235][INFO] writes 335000 landmark faces
[2016-11-30 22:52:28,463][INFO] writes 336000 landmark faces
[2016-11-30 22:52:28,675][INFO] writes 337000 landmark faces
[2016-11-30 22:52:28,889][INFO] writes 338000 landmark faces
[2016-11-30 22:52:29,137][INFO] writes 339000 landmark faces
[2016-11-30 22:52:29,405][INFO] writes 340000 landmark faces
[2016-11-30 22:52:29,643][INFO] writes 341000 landmark faces
[2016-11-30 22:52:29,855][INFO] writes 342000 landmark faces
[2016-11-30 22:52:30,126][INFO] writes 343000 landmark faces
[2016-11-30 22:52:30,351][INFO] writes 344000 landmark faces
[2016-11-30 22:52:30,566][INFO] writes 345000 landmark faces
[2016-11-30 22:52:30,799][INFO] writes 346000 landmark faces
[2016-11-30 22:52:31,037][INFO] writes 347000 landmark faces
[2016-11-30 22:52:31,311][INFO] writes 348000 landmark faces
[2016-11-30 22:52:31,527][INFO] writes 349000 landmark faces
[2016-11-30 22:52:31,756][INFO] writes 350000 landmark faces
[2016-11-30 22:52:31,986][INFO] writes 351000 landmark faces
[2016-11-30 22:52:32,256][INFO] writes 352000 landmark faces
[2016-11-30 22:52:32,449][INFO] writes 353000 landmark faces
[2016-11-30 22:52:32,680][INFO] writes 354000 landmark faces
[2016-11-30 22:52:32,902][INFO] writes 355000 landmark faces
[2016-11-30 22:52:33,129][INFO] writes 356000 landmark faces
[2016-11-30 22:52:33,347][INFO] writes 357000 landmark faces
[2016-11-30 22:52:33,554][INFO] writes 358000 landmark faces
[2016-11-30 22:52:33,775][INFO] writes 359000 landmark faces
[2016-11-30 22:52:34,006][INFO] writes 360000 landmark faces
[2016-11-30 22:52:34,226][INFO] writes 361000 landmark faces
[2016-11-30 22:52:34,459][INFO] writes 362000 landmark faces
[2016-11-30 22:52:34,663][INFO] writes 363000 landmark faces
[2016-11-30 22:52:34,884][INFO] writes 364000 landmark faces
[2016-11-30 22:52:35,102][INFO] writes 365000 landmark faces
[2016-11-30 22:52:35,326][INFO] writes 366000 landmark faces
[2016-11-30 22:52:35,550][INFO] writes 367000 landmark faces
[2016-11-30 22:52:35,788][INFO] writes 368000 landmark faces
[2016-11-30 22:52:35,993][INFO] writes 369000 landmark faces
[2016-11-30 22:52:36,295][INFO] writes 370000 landmark faces
[2016-11-30 22:52:36,506][INFO] writes 371000 landmark faces
[2016-11-30 22:52:36,768][INFO] writes 372000 landmark faces
[2016-11-30 22:52:36,985][INFO] writes 373000 landmark faces
[2016-11-30 22:52:37,214][INFO] writes 374000 landmark faces
[2016-11-30 22:52:37,461][INFO] writes 375000 landmark faces
[2016-11-30 22:52:37,691][INFO] writes 376000 landmark faces
[2016-11-30 22:52:37,913][INFO] writes 377000 landmark faces
[2016-11-30 22:52:38,127][INFO] writes 378000 landmark faces
[2016-11-30 22:52:38,362][INFO] writes 379000 landmark faces
[2016-11-30 22:52:38,603][INFO] writes 380000 landmark faces
[2016-11-30 22:52:38,803][INFO] writes 381000 landmark faces
[2016-11-30 22:52:39,062][INFO] writes 382000 landmark faces
[2016-11-30 22:52:39,271][INFO] writes 383000 landmark faces
[2016-11-30 22:52:39,552][INFO] writes 384000 landmark faces
[2016-11-30 22:52:39,773][INFO] writes 385000 landmark faces
[2016-11-30 22:52:40,041][INFO] writes 386000 landmark faces
[2016-11-30 22:52:40,284][INFO] writes 387000 landmark faces
[2016-11-30 22:52:40,533][INFO] writes 388000 landmark faces
[2016-11-30 22:52:40,792][INFO] writes 389000 landmark faces
[2016-11-30 22:52:41,076][INFO] writes 390000 landmark faces
[2016-11-30 22:52:41,371][INFO] writes 391000 landmark faces
[2016-11-30 22:52:41,639][INFO] writes 392000 landmark faces
[2016-11-30 22:52:41,726][INFO] Process-7 reads 5000
[2016-11-30 22:52:41,883][INFO] writes 393000 landmark faces
[2016-11-30 22:52:42,114][INFO] writes 394000 landmark faces
[2016-11-30 22:52:42,380][INFO] writes 395000 landmark faces
[2016-11-30 22:52:42,394][INFO] Process-8 reads 5000
[2016-11-30 22:52:42,633][INFO] Process-1 reads 5000
[2016-11-30 22:52:42,684][INFO] writes 396000 landmark faces
[2016-11-30 22:52:42,818][INFO] Process-3 reads 5000
[2016-11-30 22:52:42,888][INFO] writes 397000 landmark faces
[2016-11-30 22:52:43,102][INFO] writes 398000 landmark faces
[2016-11-30 22:52:43,294][INFO] Process-2 reads 5000
[2016-11-30 22:52:43,343][INFO] writes 399000 landmark faces
[2016-11-30 22:52:43,572][INFO] writes 400000 landmark faces
[2016-11-30 22:52:43,799][INFO] writes 401000 landmark faces
[2016-11-30 22:52:43,999][INFO] writes 402000 landmark faces
[2016-11-30 22:52:44,210][INFO] writes 403000 landmark faces
[2016-11-30 22:52:44,516][INFO] writes 404000 landmark faces
[2016-11-30 22:52:44,628][INFO] Process-6 reads 5000
[2016-11-30 22:52:44,675][INFO] Process-5 reads 5000
[2016-11-30 22:52:44,747][INFO] writes 405000 landmark faces
[2016-11-30 22:52:44,989][INFO] writes 406000 landmark faces
[2016-11-30 22:52:45,228][INFO] writes 407000 landmark faces
[2016-11-30 22:52:45,431][INFO] writes 408000 landmark faces
[2016-11-30 22:52:45,636][INFO] writes 409000 landmark faces
[2016-11-30 22:52:45,891][INFO] writes 410000 landmark faces
[2016-11-30 22:52:46,152][INFO] writes 411000 landmark faces
[2016-11-30 22:52:46,386][INFO] writes 412000 landmark faces
[2016-11-30 22:52:46,512][INFO] Process-4 reads 5000
[2016-11-30 22:52:46,593][INFO] writes 413000 landmark faces
[2016-11-30 22:52:46,855][INFO] writes 414000 landmark faces
[2016-11-30 22:52:47,137][INFO] writes 415000 landmark faces
[2016-11-30 22:52:47,392][INFO] writes 416000 landmark faces
[2016-11-30 22:52:47,599][INFO] writes 417000 landmark faces
[2016-11-30 22:52:47,838][INFO] writes 418000 landmark faces
[2016-11-30 22:52:48,107][INFO] writes 419000 landmark faces
[2016-11-30 22:52:48,324][INFO] writes 420000 landmark faces
[2016-11-30 22:52:48,543][INFO] writes 421000 landmark faces
[2016-11-30 22:52:48,772][INFO] writes 422000 landmark faces
[2016-11-30 22:52:49,001][INFO] writes 423000 landmark faces
[2016-11-30 22:52:49,228][INFO] writes 424000 landmark faces
[2016-11-30 22:52:49,440][INFO] writes 425000 landmark faces
[2016-11-30 22:52:49,672][INFO] writes 426000 landmark faces
[2016-11-30 22:52:49,887][INFO] writes 427000 landmark faces
[2016-11-30 22:52:50,140][INFO] writes 428000 landmark faces
[2016-11-30 22:52:50,373][INFO] writes 429000 landmark faces
[2016-11-30 22:52:50,596][INFO] writes 430000 landmark faces
[2016-11-30 22:52:50,805][INFO] writes 431000 landmark faces
[2016-11-30 22:52:51,012][INFO] writes 432000 landmark faces
[2016-11-30 22:52:51,278][INFO] writes 433000 landmark faces
[2016-11-30 22:52:51,494][INFO] writes 434000 landmark faces
[2016-11-30 22:52:51,722][INFO] writes 435000 landmark faces
[2016-11-30 22:52:52,019][INFO] writes 436000 landmark faces
[2016-11-30 22:52:52,287][INFO] writes 437000 landmark faces
[2016-11-30 22:52:52,517][INFO] writes 438000 landmark faces
[2016-11-30 22:52:52,768][INFO] writes 439000 landmark faces
[2016-11-30 22:52:52,988][INFO] writes 440000 landmark faces
[2016-11-30 22:52:53,249][INFO] writes 441000 landmark faces
[2016-11-30 22:52:53,503][INFO] writes 442000 landmark faces
[2016-11-30 22:52:53,756][INFO] writes 443000 landmark faces
[2016-11-30 22:52:54,007][INFO] writes 444000 landmark faces
[2016-11-30 22:52:54,257][INFO] writes 445000 landmark faces
[2016-11-30 22:52:54,484][INFO] writes 446000 landmark faces
[2016-11-30 22:52:54,729][INFO] writes 447000 landmark faces
[2016-11-30 22:52:54,968][INFO] writes 448000 landmark faces
[2016-11-30 22:52:55,188][INFO] writes 449000 landmark faces
[2016-11-30 22:52:55,476][INFO] writes 450000 landmark faces
[2016-11-30 22:52:55,720][INFO] writes 451000 landmark faces
[2016-11-30 22:52:55,976][INFO] writes 452000 landmark faces
[2016-11-30 22:52:56,192][INFO] writes 453000 landmark faces
[2016-11-30 22:52:56,408][INFO] writes 454000 landmark faces
[2016-11-30 22:52:56,623][INFO] writes 455000 landmark faces
[2016-11-30 22:52:56,844][INFO] writes 456000 landmark faces
[2016-11-30 22:52:57,115][INFO] writes 457000 landmark faces
[2016-11-30 22:52:57,320][INFO] writes 458000 landmark faces
[2016-11-30 22:52:57,560][INFO] writes 459000 landmark faces
[2016-11-30 22:52:57,777][INFO] writes 460000 landmark faces
[2016-11-30 22:52:58,000][INFO] writes 461000 landmark faces
[2016-11-30 22:52:58,273][INFO] writes 462000 landmark faces
[2016-11-30 22:52:58,536][INFO] writes 463000 landmark faces
[2016-11-30 22:52:58,779][INFO] writes 464000 landmark faces
[2016-11-30 22:52:59,012][INFO] writes 465000 landmark faces
[2016-11-30 22:52:59,226][INFO] writes 466000 landmark faces
[2016-11-30 22:52:59,441][INFO] writes 467000 landmark faces
[2016-11-30 22:52:59,682][INFO] Process-7 reads 6000
[2016-11-30 22:52:59,724][INFO] writes 468000 landmark faces
[2016-11-30 22:52:59,981][INFO] writes 469000 landmark faces
[2016-11-30 22:53:00,183][INFO] writes 470000 landmark faces
[2016-11-30 22:53:00,436][INFO] writes 471000 landmark faces
[2016-11-30 22:53:00,676][INFO] writes 472000 landmark faces
[2016-11-30 22:53:00,914][INFO] writes 473000 landmark faces
[2016-11-30 22:53:01,113][INFO] writes 474000 landmark faces
[2016-11-30 22:53:01,210][INFO] Process-8 reads 6000
[2016-11-30 22:53:01,323][INFO] writes 475000 landmark faces
[2016-11-30 22:53:01,547][INFO] Process-1 reads 6000
[2016-11-30 22:53:01,558][INFO] writes 476000 landmark faces
[2016-11-30 22:53:01,837][INFO] writes 477000 landmark faces
[2016-11-30 22:53:01,936][INFO] Process-2 reads 6000
[2016-11-30 22:53:02,073][INFO] writes 478000 landmark faces
[2016-11-30 22:53:02,328][INFO] writes 479000 landmark faces
[2016-11-30 22:53:02,514][INFO] Process-3 reads 6000
[2016-11-30 22:53:02,570][INFO] writes 480000 landmark faces
[2016-11-30 22:53:02,835][INFO] writes 481000 landmark faces
[2016-11-30 22:53:03,059][INFO] writes 482000 landmark faces
[2016-11-30 22:53:03,300][INFO] writes 483000 landmark faces
[2016-11-30 22:53:03,388][INFO] Process-6 reads 6000
[2016-11-30 22:53:03,524][INFO] writes 484000 landmark faces
[2016-11-30 22:53:03,647][INFO] Process-5 reads 6000
[2016-11-30 22:53:03,734][INFO] writes 485000 landmark faces
[2016-11-30 22:53:03,949][INFO] writes 486000 landmark faces
[2016-11-30 22:53:04,161][INFO] writes 487000 landmark faces
[2016-11-30 22:53:04,364][INFO] writes 488000 landmark faces
[2016-11-30 22:53:04,613][INFO] writes 489000 landmark faces
[2016-11-30 22:53:04,870][INFO] writes 490000 landmark faces
[2016-11-30 22:53:05,075][INFO] writes 491000 landmark faces
[2016-11-30 22:53:05,309][INFO] writes 492000 landmark faces
[2016-11-30 22:53:05,579][INFO] writes 493000 landmark faces
[2016-11-30 22:53:05,806][INFO] Process-4 reads 6000
[2016-11-30 22:53:05,810][INFO] writes 494000 landmark faces
[2016-11-30 22:53:06,056][INFO] writes 495000 landmark faces
[2016-11-30 22:53:06,293][INFO] writes 496000 landmark faces
[2016-11-30 22:53:06,510][INFO] writes 497000 landmark faces
[2016-11-30 22:53:06,748][INFO] writes 498000 landmark faces
[2016-11-30 22:53:06,954][INFO] writes 499000 landmark faces
[2016-11-30 22:53:07,206][INFO] writes 500000 landmark faces
[2016-11-30 22:53:07,419][INFO] writes 501000 landmark faces
[2016-11-30 22:53:07,632][INFO] writes 502000 landmark faces
[2016-11-30 22:53:07,871][INFO] writes 503000 landmark faces
[2016-11-30 22:53:08,074][INFO] writes 504000 landmark faces
[2016-11-30 22:53:08,312][INFO] writes 505000 landmark faces
[2016-11-30 22:53:08,560][INFO] writes 506000 landmark faces
[2016-11-30 22:53:08,790][INFO] writes 507000 landmark faces
[2016-11-30 22:53:09,058][INFO] writes 508000 landmark faces
[2016-11-30 22:53:09,279][INFO] writes 509000 landmark faces
[2016-11-30 22:53:09,507][INFO] writes 510000 landmark faces
[2016-11-30 22:53:09,758][INFO] writes 511000 landmark faces
[2016-11-30 22:53:09,984][INFO] writes 512000 landmark faces
[2016-11-30 22:53:10,230][INFO] writes 513000 landmark faces
[2016-11-30 22:53:10,448][INFO] writes 514000 landmark faces
[2016-11-30 22:53:10,756][INFO] writes 515000 landmark faces
[2016-11-30 22:53:10,987][INFO] writes 516000 landmark faces
[2016-11-30 22:53:11,193][INFO] writes 517000 landmark faces
[2016-11-30 22:53:11,470][INFO] writes 518000 landmark faces
[2016-11-30 22:53:11,716][INFO] writes 519000 landmark faces
[2016-11-30 22:53:11,957][INFO] writes 520000 landmark faces
[2016-11-30 22:53:12,237][INFO] writes 521000 landmark faces
[2016-11-30 22:53:12,449][INFO] writes 522000 landmark faces
[2016-11-30 22:53:12,688][INFO] writes 523000 landmark faces
[2016-11-30 22:53:12,946][INFO] writes 524000 landmark faces
[2016-11-30 22:53:13,206][INFO] writes 525000 landmark faces
[2016-11-30 22:53:13,446][INFO] writes 526000 landmark faces
[2016-11-30 22:53:13,659][INFO] writes 527000 landmark faces
[2016-11-30 22:53:13,868][INFO] writes 528000 landmark faces
[2016-11-30 22:53:14,071][INFO] writes 529000 landmark faces
[2016-11-30 22:53:14,301][INFO] writes 530000 landmark faces
[2016-11-30 22:53:14,536][INFO] writes 531000 landmark faces
[2016-11-30 22:53:14,762][INFO] writes 532000 landmark faces
[2016-11-30 22:53:14,977][INFO] writes 533000 landmark faces
[2016-11-30 22:53:15,182][INFO] writes 534000 landmark faces
[2016-11-30 22:53:15,393][INFO] writes 535000 landmark faces
[2016-11-30 22:53:15,628][INFO] writes 536000 landmark faces
[2016-11-30 22:53:15,837][INFO] writes 537000 landmark faces
[2016-11-30 22:53:16,070][INFO] writes 538000 landmark faces
[2016-11-30 22:53:16,285][INFO] writes 539000 landmark faces
[2016-11-30 22:53:16,509][INFO] writes 540000 landmark faces
[2016-11-30 22:53:16,723][INFO] writes 541000 landmark faces
[2016-11-30 22:53:16,932][INFO] writes 542000 landmark faces
[2016-11-30 22:53:17,168][INFO] writes 543000 landmark faces
[2016-11-30 22:53:17,420][INFO] writes 544000 landmark faces
[2016-11-30 22:53:17,687][INFO] writes 545000 landmark faces
[2016-11-30 22:53:17,791][INFO] Process-7 reads 7000
[2016-11-30 22:53:17,916][INFO] writes 546000 landmark faces
[2016-11-30 22:53:18,143][INFO] writes 547000 landmark faces
[2016-11-30 22:53:18,375][INFO] writes 548000 landmark faces
[2016-11-30 22:53:18,639][INFO] writes 549000 landmark faces
[2016-11-30 22:53:18,889][INFO] writes 550000 landmark faces
[2016-11-30 22:53:19,153][INFO] writes 551000 landmark faces
[2016-11-30 22:53:19,379][INFO] writes 552000 landmark faces
[2016-11-30 22:53:19,624][INFO] writes 553000 landmark faces
[2016-11-30 22:53:19,868][INFO] writes 554000 landmark faces
[2016-11-30 22:53:20,119][INFO] writes 555000 landmark faces
[2016-11-30 22:53:20,215][INFO] Process-2 reads 7000
[2016-11-30 22:53:20,340][INFO] writes 556000 landmark faces
[2016-11-30 22:53:20,475][INFO] Process-8 reads 7000
[2016-11-30 22:53:20,580][INFO] writes 557000 landmark faces
[2016-11-30 22:53:20,682][INFO] Process-1 reads 7000
[2016-11-30 22:53:20,837][INFO] writes 558000 landmark faces
[2016-11-30 22:53:21,074][INFO] writes 559000 landmark faces
[2016-11-30 22:53:21,338][INFO] writes 560000 landmark faces
[2016-11-30 22:53:21,582][INFO] writes 561000 landmark faces
[2016-11-30 22:53:21,744][INFO] Process-6 reads 7000
[2016-11-30 22:53:21,848][INFO] writes 562000 landmark faces
[2016-11-30 22:53:22,080][INFO] writes 563000 landmark faces
[2016-11-30 22:53:22,093][INFO] Process-3 reads 7000
[2016-11-30 22:53:22,334][INFO] writes 564000 landmark faces
[2016-11-30 22:53:22,570][INFO] writes 565000 landmark faces
[2016-11-30 22:53:22,704][INFO] Process-5 reads 7000
[2016-11-30 22:53:22,795][INFO] writes 566000 landmark faces
[2016-11-30 22:53:23,082][INFO] writes 567000 landmark faces
[2016-11-30 22:53:23,349][INFO] writes 568000 landmark faces
[2016-11-30 22:53:23,583][INFO] writes 569000 landmark faces
[2016-11-30 22:53:23,795][INFO] writes 570000 landmark faces
[2016-11-30 22:53:24,012][INFO] writes 571000 landmark faces
[2016-11-30 22:53:24,282][INFO] writes 572000 landmark faces
[2016-11-30 22:53:24,529][INFO] writes 573000 landmark faces
[2016-11-30 22:53:24,750][INFO] writes 574000 landmark faces
[2016-11-30 22:53:25,042][INFO] writes 575000 landmark faces
[2016-11-30 22:53:25,303][INFO] writes 576000 landmark faces
[2016-11-30 22:53:25,433][INFO] Process-4 reads 7000
[2016-11-30 22:53:25,533][INFO] writes 577000 landmark faces
[2016-11-30 22:53:25,742][INFO] writes 578000 landmark faces
[2016-11-30 22:53:25,970][INFO] writes 579000 landmark faces
[2016-11-30 22:53:26,167][INFO] writes 580000 landmark faces
[2016-11-30 22:53:26,409][INFO] writes 581000 landmark faces
[2016-11-30 22:53:26,652][INFO] writes 582000 landmark faces
[2016-11-30 22:53:26,893][INFO] writes 583000 landmark faces
[2016-11-30 22:53:27,109][INFO] writes 584000 landmark faces
[2016-11-30 22:53:27,359][INFO] writes 585000 landmark faces
[2016-11-30 22:53:27,588][INFO] writes 586000 landmark faces
[2016-11-30 22:53:27,800][INFO] writes 587000 landmark faces
[2016-11-30 22:53:28,049][INFO] writes 588000 landmark faces
[2016-11-30 22:53:28,329][INFO] writes 589000 landmark faces
[2016-11-30 22:53:28,636][INFO] writes 590000 landmark faces
[2016-11-30 22:53:28,951][INFO] writes 591000 landmark faces
[2016-11-30 22:53:29,288][INFO] writes 592000 landmark faces
[2016-11-30 22:53:29,491][INFO] writes 593000 landmark faces
[2016-11-30 22:53:29,722][INFO] writes 594000 landmark faces
[2016-11-30 22:53:29,956][INFO] writes 595000 landmark faces
[2016-11-30 22:53:30,191][INFO] writes 596000 landmark faces
[2016-11-30 22:53:30,438][INFO] writes 597000 landmark faces
[2016-11-30 22:53:30,706][INFO] writes 598000 landmark faces
[2016-11-30 22:53:30,970][INFO] writes 599000 landmark faces
[2016-11-30 22:53:31,229][INFO] writes 600000 landmark faces
[2016-11-30 22:53:31,478][INFO] writes 601000 landmark faces
[2016-11-30 22:53:31,730][INFO] writes 602000 landmark faces
[2016-11-30 22:53:31,948][INFO] writes 603000 landmark faces
[2016-11-30 22:53:32,167][INFO] writes 604000 landmark faces
[2016-11-30 22:53:32,379][INFO] writes 605000 landmark faces
[2016-11-30 22:53:32,607][INFO] writes 606000 landmark faces
[2016-11-30 22:53:32,860][INFO] writes 607000 landmark faces
[2016-11-30 22:53:33,094][INFO] writes 608000 landmark faces
[2016-11-30 22:53:33,306][INFO] writes 609000 landmark faces
[2016-11-30 22:53:33,550][INFO] writes 610000 landmark faces
[2016-11-30 22:53:33,786][INFO] writes 611000 landmark faces
[2016-11-30 22:53:33,989][INFO] writes 612000 landmark faces
[2016-11-30 22:53:34,212][INFO] writes 613000 landmark faces
[2016-11-30 22:53:34,426][INFO] writes 614000 landmark faces
[2016-11-30 22:53:34,646][INFO] writes 615000 landmark faces
[2016-11-30 22:53:34,894][INFO] writes 616000 landmark faces
[2016-11-30 22:53:35,099][INFO] writes 617000 landmark faces
[2016-11-30 22:53:35,352][INFO] writes 618000 landmark faces
[2016-11-30 22:53:35,660][INFO] writes 619000 landmark faces
[2016-11-30 22:53:35,942][INFO] writes 620000 landmark faces
[2016-11-30 22:53:36,159][INFO] writes 621000 landmark faces
[2016-11-30 22:53:36,400][INFO] writes 622000 landmark faces
[2016-11-30 22:53:36,610][INFO] writes 623000 landmark faces
[2016-11-30 22:53:36,834][INFO] writes 624000 landmark faces
[2016-11-30 22:53:37,088][INFO] writes 625000 landmark faces
[2016-11-30 22:53:37,340][INFO] writes 626000 landmark faces
[2016-11-30 22:53:37,622][INFO] writes 627000 landmark faces
[2016-11-30 22:53:37,918][INFO] writes 628000 landmark faces
[2016-11-30 22:53:38,133][INFO] writes 629000 landmark faces
[2016-11-30 22:53:38,192][INFO] Process-7 reads 8000
[2016-11-30 22:53:38,410][INFO] writes 630000 landmark faces
[2016-11-30 22:53:38,617][INFO] writes 631000 landmark faces
[2016-11-30 22:53:38,840][INFO] writes 632000 landmark faces
[2016-11-30 22:53:39,046][INFO] writes 633000 landmark faces
[2016-11-30 22:53:39,250][INFO] Process-2 reads 8000
[2016-11-30 22:53:39,276][INFO] writes 634000 landmark faces
[2016-11-30 22:53:39,362][INFO] Process-6 reads 8000
[2016-11-30 22:53:39,502][INFO] writes 635000 landmark faces
[2016-11-30 22:53:39,748][INFO] writes 636000 landmark faces
[2016-11-30 22:53:39,968][INFO] writes 637000 landmark faces
[2016-11-30 22:53:40,183][INFO] writes 638000 landmark faces
[2016-11-30 22:53:40,436][INFO] writes 639000 landmark faces
[2016-11-30 22:53:40,617][INFO] Process-8 reads 8000
[2016-11-30 22:53:40,674][INFO] writes 640000 landmark faces
[2016-11-30 22:53:40,817][INFO] Process-1 reads 8000
[2016-11-30 22:53:40,897][INFO] writes 641000 landmark faces
[2016-11-30 22:53:41,121][INFO] writes 642000 landmark faces
[2016-11-30 22:53:41,149][INFO] Process-3 reads 8000
[2016-11-30 22:53:41,343][INFO] writes 643000 landmark faces
[2016-11-30 22:53:41,361][INFO] Process-5 reads 8000
[2016-11-30 22:53:41,578][INFO] writes 644000 landmark faces
[2016-11-30 22:53:41,798][INFO] writes 645000 landmark faces
[2016-11-30 22:53:42,038][INFO] writes 646000 landmark faces
[2016-11-30 22:53:42,262][INFO] writes 647000 landmark faces
[2016-11-30 22:53:42,491][INFO] writes 648000 landmark faces
[2016-11-30 22:53:42,702][INFO] writes 649000 landmark faces
[2016-11-30 22:53:42,944][INFO] writes 650000 landmark faces
[2016-11-30 22:53:43,173][INFO] writes 651000 landmark faces
[2016-11-30 22:53:43,393][INFO] writes 652000 landmark faces
[2016-11-30 22:53:43,662][INFO] writes 653000 landmark faces
[2016-11-30 22:53:43,941][INFO] writes 654000 landmark faces
[2016-11-30 22:53:44,206][INFO] writes 655000 landmark faces
[2016-11-30 22:53:44,233][INFO] Process-4 reads 8000
[2016-11-30 22:53:44,448][INFO] writes 656000 landmark faces
[2016-11-30 22:53:44,744][INFO] writes 657000 landmark faces
[2016-11-30 22:53:44,957][INFO] writes 658000 landmark faces
[2016-11-30 22:53:45,201][INFO] writes 659000 landmark faces
[2016-11-30 22:53:45,483][INFO] writes 660000 landmark faces
[2016-11-30 22:53:45,714][INFO] writes 661000 landmark faces
[2016-11-30 22:53:45,961][INFO] writes 662000 landmark faces
[2016-11-30 22:53:46,184][INFO] writes 663000 landmark faces
[2016-11-30 22:53:46,423][INFO] writes 664000 landmark faces
[2016-11-30 22:53:46,658][INFO] writes 665000 landmark faces
[2016-11-30 22:53:46,866][INFO] writes 666000 landmark faces
[2016-11-30 22:53:47,075][INFO] writes 667000 landmark faces
[2016-11-30 22:53:47,271][INFO] writes 668000 landmark faces
[2016-11-30 22:53:47,526][INFO] writes 669000 landmark faces
[2016-11-30 22:53:47,801][INFO] writes 670000 landmark faces
[2016-11-30 22:53:48,062][INFO] writes 671000 landmark faces
[2016-11-30 22:53:48,281][INFO] writes 672000 landmark faces
[2016-11-30 22:53:48,493][INFO] writes 673000 landmark faces
[2016-11-30 22:53:48,697][INFO] writes 674000 landmark faces
[2016-11-30 22:53:48,919][INFO] writes 675000 landmark faces
[2016-11-30 22:53:49,167][INFO] writes 676000 landmark faces
[2016-11-30 22:53:49,413][INFO] writes 677000 landmark faces
[2016-11-30 22:53:49,711][INFO] writes 678000 landmark faces
[2016-11-30 22:53:49,931][INFO] writes 679000 landmark faces
[2016-11-30 22:53:50,127][INFO] writes 680000 landmark faces
[2016-11-30 22:53:50,341][INFO] writes 681000 landmark faces
[2016-11-30 22:53:50,565][INFO] writes 682000 landmark faces
[2016-11-30 22:53:50,777][INFO] writes 683000 landmark faces
[2016-11-30 22:53:51,009][INFO] writes 684000 landmark faces
[2016-11-30 22:53:51,250][INFO] writes 685000 landmark faces
[2016-11-30 22:53:51,495][INFO] writes 686000 landmark faces
[2016-11-30 22:53:51,757][INFO] writes 687000 landmark faces
[2016-11-30 22:53:51,948][INFO] writes 688000 landmark faces
[2016-11-30 22:53:52,147][INFO] writes 689000 landmark faces
[2016-11-30 22:53:52,369][INFO] writes 690000 landmark faces
[2016-11-30 22:53:52,598][INFO] writes 691000 landmark faces
[2016-11-30 22:53:52,820][INFO] writes 692000 landmark faces
[2016-11-30 22:53:53,064][INFO] writes 693000 landmark faces
[2016-11-30 22:53:53,276][INFO] writes 694000 landmark faces
[2016-11-30 22:53:53,515][INFO] writes 695000 landmark faces
[2016-11-30 22:53:53,742][INFO] writes 696000 landmark faces
[2016-11-30 22:53:53,961][INFO] writes 697000 landmark faces
[2016-11-30 22:53:54,195][INFO] writes 698000 landmark faces
[2016-11-30 22:53:54,438][INFO] writes 699000 landmark faces
[2016-11-30 22:53:54,705][INFO] writes 700000 landmark faces
[2016-11-30 22:53:55,003][INFO] writes 701000 landmark faces
[2016-11-30 22:53:55,255][INFO] writes 702000 landmark faces
[2016-11-30 22:53:55,475][INFO] writes 703000 landmark faces
[2016-11-30 22:53:55,699][INFO] writes 704000 landmark faces
[2016-11-30 22:53:55,905][INFO] writes 705000 landmark faces
[2016-11-30 22:53:56,129][INFO] writes 706000 landmark faces
[2016-11-30 22:53:56,351][INFO] writes 707000 landmark faces
[2016-11-30 22:53:56,585][INFO] writes 708000 landmark faces
[2016-11-30 22:53:56,750][INFO] Process-7 reads 9000
[2016-11-30 22:53:56,805][INFO] writes 709000 landmark faces
[2016-11-30 22:53:57,042][INFO] writes 710000 landmark faces
[2016-11-30 22:53:57,234][INFO] Process-6 reads 9000
[2016-11-30 22:53:57,272][INFO] writes 711000 landmark faces
[2016-11-30 22:53:57,519][INFO] writes 712000 landmark faces
[2016-11-30 22:53:57,718][INFO] writes 713000 landmark faces
[2016-11-30 22:53:57,924][INFO] writes 714000 landmark faces
[2016-11-30 22:53:58,146][INFO] writes 715000 landmark faces
[2016-11-30 22:53:58,390][INFO] writes 716000 landmark faces
[2016-11-30 22:53:58,636][INFO] writes 717000 landmark faces
[2016-11-30 22:53:58,714][INFO] Process-8 reads 9000
[2016-11-30 22:53:58,843][INFO] writes 718000 landmark faces
[2016-11-30 22:53:59,067][INFO] writes 719000 landmark faces
[2016-11-30 22:53:59,292][INFO] writes 720000 landmark faces
[2016-11-30 22:53:59,324][INFO] Process-2 reads 9000
[2016-11-30 22:53:59,422][INFO] Process-1 reads 9000
[2016-11-30 22:53:59,498][INFO] writes 721000 landmark faces
[2016-11-30 22:53:59,729][INFO] writes 722000 landmark faces
[2016-11-30 22:53:59,927][INFO] Process-5 reads 9000
[2016-11-30 22:53:59,964][INFO] writes 723000 landmark faces
[2016-11-30 22:54:00,146][INFO] writes 724000 landmark faces
[2016-11-30 22:54:00,357][INFO] writes 725000 landmark faces
[2016-11-30 22:54:00,551][INFO] Process-3 reads 9000
[2016-11-30 22:54:00,561][INFO] writes 726000 landmark faces
[2016-11-30 22:54:00,837][INFO] writes 727000 landmark faces
[2016-11-30 22:54:01,087][INFO] writes 728000 landmark faces
[2016-11-30 22:54:01,305][INFO] writes 729000 landmark faces
[2016-11-30 22:54:01,625][INFO] writes 730000 landmark faces
[2016-11-30 22:54:01,860][INFO] writes 731000 landmark faces
[2016-11-30 22:54:02,086][INFO] writes 732000 landmark faces
[2016-11-30 22:54:02,313][INFO] writes 733000 landmark faces
[2016-11-30 22:54:02,589][INFO] writes 734000 landmark faces
[2016-11-30 22:54:02,662][INFO] Process-4 reads 9000
[2016-11-30 22:54:02,858][INFO] writes 735000 landmark faces
[2016-11-30 22:54:03,115][INFO] writes 736000 landmark faces
[2016-11-30 22:54:03,378][INFO] writes 737000 landmark faces
[2016-11-30 22:54:03,614][INFO] writes 738000 landmark faces
[2016-11-30 22:54:03,828][INFO] writes 739000 landmark faces
[2016-11-30 22:54:04,050][INFO] writes 740000 landmark faces
[2016-11-30 22:54:04,306][INFO] writes 741000 landmark faces
[2016-11-30 22:54:04,518][INFO] writes 742000 landmark faces
[2016-11-30 22:54:04,778][INFO] writes 743000 landmark faces
[2016-11-30 22:54:05,062][INFO] writes 744000 landmark faces
[2016-11-30 22:54:05,289][INFO] writes 745000 landmark faces
[2016-11-30 22:54:05,524][INFO] writes 746000 landmark faces
[2016-11-30 22:54:05,788][INFO] writes 747000 landmark faces
[2016-11-30 22:54:05,993][INFO] writes 748000 landmark faces
[2016-11-30 22:54:06,253][INFO] writes 749000 landmark faces
[2016-11-30 22:54:06,518][INFO] writes 750000 landmark faces
[2016-11-30 22:54:06,782][INFO] writes 751000 landmark faces
[2016-11-30 22:54:06,990][INFO] writes 752000 landmark faces
[2016-11-30 22:54:07,243][INFO] writes 753000 landmark faces
[2016-11-30 22:54:07,511][INFO] writes 754000 landmark faces
[2016-11-30 22:54:07,707][INFO] writes 755000 landmark faces
[2016-11-30 22:54:07,974][INFO] writes 756000 landmark faces
[2016-11-30 22:54:08,207][INFO] writes 757000 landmark faces
[2016-11-30 22:54:08,433][INFO] writes 758000 landmark faces
[2016-11-30 22:54:08,684][INFO] writes 759000 landmark faces
[2016-11-30 22:54:08,936][INFO] writes 760000 landmark faces
[2016-11-30 22:54:09,237][INFO] writes 761000 landmark faces
[2016-11-30 22:54:09,512][INFO] writes 762000 landmark faces
[2016-11-30 22:54:09,742][INFO] writes 763000 landmark faces
[2016-11-30 22:54:09,997][INFO] writes 764000 landmark faces
[2016-11-30 22:54:10,252][INFO] writes 765000 landmark faces
[2016-11-30 22:54:10,512][INFO] writes 766000 landmark faces
[2016-11-30 22:54:10,741][INFO] writes 767000 landmark faces
[2016-11-30 22:54:10,985][INFO] writes 768000 landmark faces
[2016-11-30 22:54:11,215][INFO] writes 769000 landmark faces
[2016-11-30 22:54:11,442][INFO] writes 770000 landmark faces
[2016-11-30 22:54:11,658][INFO] writes 771000 landmark faces
[2016-11-30 22:54:11,906][INFO] writes 772000 landmark faces
[2016-11-30 22:54:12,127][INFO] writes 773000 landmark faces
[2016-11-30 22:54:12,328][INFO] writes 774000 landmark faces
[2016-11-30 22:54:12,530][INFO] writes 775000 landmark faces
[2016-11-30 22:54:12,767][INFO] writes 776000 landmark faces
[2016-11-30 22:54:12,992][INFO] writes 777000 landmark faces
[2016-11-30 22:54:13,219][INFO] writes 778000 landmark faces
[2016-11-30 22:54:13,442][INFO] writes 779000 landmark faces
[2016-11-30 22:54:13,676][INFO] writes 780000 landmark faces
[2016-11-30 22:54:13,916][INFO] writes 781000 landmark faces
[2016-11-30 22:54:14,133][INFO] writes 782000 landmark faces
[2016-11-30 22:54:14,338][INFO] writes 783000 landmark faces
[2016-11-30 22:54:14,540][INFO] Process-7 reads 10000
[2016-11-30 22:54:14,572][INFO] writes 784000 landmark faces
[2016-11-30 22:54:14,800][INFO] writes 785000 landmark faces
[2016-11-30 22:54:15,015][INFO] writes 786000 landmark faces
[2016-11-30 22:54:15,239][INFO] writes 787000 landmark faces
[2016-11-30 22:54:15,452][INFO] writes 788000 landmark faces
[2016-11-30 22:54:15,662][INFO] writes 789000 landmark faces
[2016-11-30 22:54:15,905][INFO] Process-6 reads 10000
[2016-11-30 22:54:15,905][INFO] writes 790000 landmark faces
[2016-11-30 22:54:16,146][INFO] writes 791000 landmark faces
[2016-11-30 22:54:16,389][INFO] writes 792000 landmark faces
[2016-11-30 22:54:16,594][INFO] writes 793000 landmark faces
[2016-11-30 22:54:16,831][INFO] writes 794000 landmark faces
[2016-11-30 22:54:17,079][INFO] writes 795000 landmark faces
[2016-11-30 22:54:17,298][INFO] writes 796000 landmark faces
[2016-11-30 22:54:17,421][INFO] Process-8 reads 10000
[2016-11-30 22:54:17,514][INFO] writes 797000 landmark faces
[2016-11-30 22:54:17,745][INFO] writes 798000 landmark faces
[2016-11-30 22:54:17,989][INFO] writes 799000 landmark faces
[2016-11-30 22:54:18,198][INFO] writes 800000 landmark faces
[2016-11-30 22:54:18,352][INFO] Process-5 reads 10000
[2016-11-30 22:54:18,437][INFO] writes 801000 landmark faces
[2016-11-30 22:54:18,675][INFO] writes 802000 landmark faces
[2016-11-30 22:54:18,909][INFO] writes 803000 landmark faces
[2016-11-30 22:54:19,034][INFO] Process-1 reads 10000
[2016-11-30 22:54:19,142][INFO] writes 804000 landmark faces
[2016-11-30 22:54:19,221][INFO] Process-2 reads 10000
[2016-11-30 22:54:19,357][INFO] writes 805000 landmark faces
[2016-11-30 22:54:19,575][INFO] writes 806000 landmark faces
[2016-11-30 22:54:19,785][INFO] writes 807000 landmark faces
[2016-11-30 22:54:19,990][INFO] writes 808000 landmark faces
[2016-11-30 22:54:20,211][INFO] writes 809000 landmark faces
[2016-11-30 22:54:20,442][INFO] writes 810000 landmark faces
[2016-11-30 22:54:20,465][INFO] Process-3 reads 10000
[2016-11-30 22:54:20,646][INFO] writes 811000 landmark faces
[2016-11-30 22:54:20,855][INFO] writes 812000 landmark faces
[2016-11-30 22:54:20,862][INFO] Process-4 reads 10000
[2016-11-30 22:54:21,074][INFO] writes 813000 landmark faces
[2016-11-30 22:54:21,344][INFO] writes 814000 landmark faces
[2016-11-30 22:54:21,586][INFO] writes 815000 landmark faces
[2016-11-30 22:54:21,798][INFO] writes 816000 landmark faces
[2016-11-30 22:54:22,019][INFO] writes 817000 landmark faces
[2016-11-30 22:54:22,322][INFO] writes 818000 landmark faces
[2016-11-30 22:54:22,589][INFO] writes 819000 landmark faces
[2016-11-30 22:54:22,848][INFO] writes 820000 landmark faces
[2016-11-30 22:54:23,096][INFO] writes 821000 landmark faces
[2016-11-30 22:54:23,334][INFO] writes 822000 landmark faces
[2016-11-30 22:54:23,574][INFO] writes 823000 landmark faces
[2016-11-30 22:54:23,782][INFO] writes 824000 landmark faces
[2016-11-30 22:54:24,028][INFO] writes 825000 landmark faces
[2016-11-30 22:54:24,253][INFO] writes 826000 landmark faces
[2016-11-30 22:54:24,485][INFO] writes 827000 landmark faces
[2016-11-30 22:54:24,729][INFO] writes 828000 landmark faces
[2016-11-30 22:54:24,958][INFO] writes 829000 landmark faces
[2016-11-30 22:54:25,178][INFO] writes 830000 landmark faces
[2016-11-30 22:54:25,405][INFO] writes 831000 landmark faces
[2016-11-30 22:54:25,703][INFO] writes 832000 landmark faces
[2016-11-30 22:54:26,030][INFO] writes 833000 landmark faces
[2016-11-30 22:54:26,266][INFO] writes 834000 landmark faces
[2016-11-30 22:54:26,475][INFO] writes 835000 landmark faces
[2016-11-30 22:54:26,711][INFO] writes 836000 landmark faces
[2016-11-30 22:54:26,945][INFO] writes 837000 landmark faces
[2016-11-30 22:54:27,168][INFO] writes 838000 landmark faces
[2016-11-30 22:54:27,380][INFO] writes 839000 landmark faces
[2016-11-30 22:54:27,612][INFO] writes 840000 landmark faces
[2016-11-30 22:54:27,832][INFO] writes 841000 landmark faces
[2016-11-30 22:54:28,067][INFO] writes 842000 landmark faces
[2016-11-30 22:54:28,314][INFO] writes 843000 landmark faces
[2016-11-30 22:54:28,570][INFO] writes 844000 landmark faces
[2016-11-30 22:54:28,830][INFO] writes 845000 landmark faces
[2016-11-30 22:54:29,079][INFO] writes 846000 landmark faces
[2016-11-30 22:54:29,435][INFO] writes 847000 landmark faces
[2016-11-30 22:54:29,528][INFO] writes 848000 landmark faces
[2016-11-30 22:54:29,743][INFO] writes 849000 landmark faces
[2016-11-30 22:54:29,960][INFO] writes 850000 landmark faces
[2016-11-30 22:54:30,208][INFO] writes 851000 landmark faces
[2016-11-30 22:54:30,436][INFO] writes 852000 landmark faces
[2016-11-30 22:54:30,664][INFO] writes 853000 landmark faces
[2016-11-30 22:54:30,903][INFO] writes 854000 landmark faces
[2016-11-30 22:54:31,157][INFO] writes 855000 landmark faces
[2016-11-30 22:54:31,392][INFO] writes 856000 landmark faces
[2016-11-30 22:54:31,668][INFO] writes 857000 landmark faces
[2016-11-30 22:54:31,903][INFO] writes 858000 landmark faces
[2016-11-30 22:54:32,154][INFO] writes 859000 landmark faces
[2016-11-30 22:54:32,402][INFO] writes 860000 landmark faces
[2016-11-30 22:54:32,660][INFO] writes 861000 landmark faces
[2016-11-30 22:54:32,895][INFO] writes 862000 landmark faces
[2016-11-30 22:54:33,241][INFO] writes 863000 landmark faces
[2016-11-30 22:54:33,354][INFO] writes 864000 landmark faces
[2016-11-30 22:54:33,598][INFO] writes 865000 landmark faces
[2016-11-30 22:54:33,821][INFO] writes 866000 landmark faces
[2016-11-30 22:54:34,069][INFO] writes 867000 landmark faces
[2016-11-30 22:54:34,342][INFO] writes 868000 landmark faces
[2016-11-30 22:54:34,406][INFO] Process-6 reads 11000
[2016-11-30 22:54:34,574][INFO] writes 869000 landmark faces
[2016-11-30 22:54:34,850][INFO] writes 870000 landmark faces
[2016-11-30 22:54:35,092][INFO] writes 871000 landmark faces
[2016-11-30 22:54:35,301][INFO] writes 872000 landmark faces
[2016-11-30 22:54:35,466][INFO] Process-7 reads 11000
[2016-11-30 22:54:35,539][INFO] writes 873000 landmark faces
[2016-11-30 22:54:35,808][INFO] writes 874000 landmark faces
[2016-11-30 22:54:35,837][INFO] Process-8 reads 11000
[2016-11-30 22:54:36,052][INFO] writes 875000 landmark faces
[2016-11-30 22:54:36,289][INFO] writes 876000 landmark faces
[2016-11-30 22:54:36,521][INFO] writes 877000 landmark faces
[2016-11-30 22:54:36,743][INFO] writes 878000 landmark faces
[2016-11-30 22:54:37,062][INFO] writes 879000 landmark faces
[2016-11-30 22:54:37,163][INFO] Process-5 reads 11000
[2016-11-30 22:54:37,211][INFO] writes 880000 landmark faces
[2016-11-30 22:54:37,438][INFO] writes 881000 landmark faces
[2016-11-30 22:54:37,665][INFO] writes 882000 landmark faces
[2016-11-30 22:54:37,790][INFO] Process-2 reads 11000
[2016-11-30 22:54:37,890][INFO] writes 883000 landmark faces
[2016-11-30 22:54:37,980][INFO] Process-1 reads 11000
[2016-11-30 22:54:38,123][INFO] writes 884000 landmark faces
[2016-11-30 22:54:38,370][INFO] writes 885000 landmark faces
[2016-11-30 22:54:38,663][INFO] writes 886000 landmark faces
[2016-11-30 22:54:38,887][INFO] writes 887000 landmark faces
[2016-11-30 22:54:39,108][INFO] writes 888000 landmark faces
[2016-11-30 22:54:39,231][INFO] Process-3 reads 11000
[2016-11-30 22:54:39,341][INFO] writes 889000 landmark faces
[2016-11-30 22:54:39,582][INFO] writes 890000 landmark faces
[2016-11-30 22:54:39,834][INFO] writes 891000 landmark faces
[2016-11-30 22:54:40,093][INFO] writes 892000 landmark faces
[2016-11-30 22:54:40,293][INFO] Process-4 reads 11000
[2016-11-30 22:54:40,339][INFO] writes 893000 landmark faces
[2016-11-30 22:54:40,582][INFO] writes 894000 landmark faces
[2016-11-30 22:54:40,911][INFO] writes 895000 landmark faces
[2016-11-30 22:54:41,086][INFO] writes 896000 landmark faces
[2016-11-30 22:54:41,353][INFO] writes 897000 landmark faces
[2016-11-30 22:54:41,569][INFO] writes 898000 landmark faces
[2016-11-30 22:54:41,853][INFO] writes 899000 landmark faces
[2016-11-30 22:54:42,108][INFO] writes 900000 landmark faces
[2016-11-30 22:54:42,353][INFO] writes 901000 landmark faces
[2016-11-30 22:54:42,630][INFO] writes 902000 landmark faces
[2016-11-30 22:54:42,864][INFO] writes 903000 landmark faces
[2016-11-30 22:54:43,120][INFO] writes 904000 landmark faces
[2016-11-30 22:54:43,337][INFO] writes 905000 landmark faces
[2016-11-30 22:54:43,536][INFO] writes 906000 landmark faces
[2016-11-30 22:54:43,770][INFO] writes 907000 landmark faces
[2016-11-30 22:54:44,016][INFO] writes 908000 landmark faces
[2016-11-30 22:54:44,263][INFO] writes 909000 landmark faces
[2016-11-30 22:54:44,484][INFO] writes 910000 landmark faces
[2016-11-30 22:54:44,859][INFO] writes 911000 landmark faces
[2016-11-30 22:54:44,990][INFO] writes 912000 landmark faces
[2016-11-30 22:54:45,249][INFO] writes 913000 landmark faces
[2016-11-30 22:54:45,492][INFO] writes 914000 landmark faces
[2016-11-30 22:54:45,715][INFO] writes 915000 landmark faces
[2016-11-30 22:54:45,959][INFO] writes 916000 landmark faces
[2016-11-30 22:54:46,216][INFO] writes 917000 landmark faces
[2016-11-30 22:54:46,430][INFO] writes 918000 landmark faces
[2016-11-30 22:54:46,659][INFO] writes 919000 landmark faces
[2016-11-30 22:54:46,904][INFO] writes 920000 landmark faces
[2016-11-30 22:54:47,155][INFO] writes 921000 landmark faces
[2016-11-30 22:54:47,382][INFO] writes 922000 landmark faces
[2016-11-30 22:54:47,598][INFO] writes 923000 landmark faces
[2016-11-30 22:54:47,842][INFO] writes 924000 landmark faces
[2016-11-30 22:54:48,079][INFO] writes 925000 landmark faces
[2016-11-30 22:54:48,300][INFO] writes 926000 landmark faces
[2016-11-30 22:54:48,654][INFO] writes 927000 landmark faces
[2016-11-30 22:54:48,749][INFO] writes 928000 landmark faces
[2016-11-30 22:54:48,980][INFO] writes 929000 landmark faces
[2016-11-30 22:54:49,257][INFO] writes 930000 landmark faces
[2016-11-30 22:54:49,489][INFO] writes 931000 landmark faces
[2016-11-30 22:54:49,712][INFO] writes 932000 landmark faces
[2016-11-30 22:54:49,935][INFO] writes 933000 landmark faces
[2016-11-30 22:54:50,198][INFO] writes 934000 landmark faces
[2016-11-30 22:54:50,445][INFO] writes 935000 landmark faces
[2016-11-30 22:54:50,716][INFO] writes 936000 landmark faces
[2016-11-30 22:54:50,939][INFO] writes 937000 landmark faces
[2016-11-30 22:54:51,164][INFO] writes 938000 landmark faces
[2016-11-30 22:54:51,414][INFO] writes 939000 landmark faces
[2016-11-30 22:54:51,684][INFO] writes 940000 landmark faces
[2016-11-30 22:54:51,952][INFO] writes 941000 landmark faces
[2016-11-30 22:54:52,186][INFO] writes 942000 landmark faces
[2016-11-30 22:54:52,469][INFO] writes 943000 landmark faces
[2016-11-30 22:54:52,625][INFO] writes 944000 landmark faces
[2016-11-30 22:54:52,679][INFO] Process-6 reads 12000
[2016-11-30 22:54:52,867][INFO] writes 945000 landmark faces
[2016-11-30 22:54:53,087][INFO] writes 946000 landmark faces
[2016-11-30 22:54:53,315][INFO] writes 947000 landmark faces
[2016-11-30 22:54:53,528][INFO] writes 948000 landmark faces
[2016-11-30 22:54:53,783][INFO] writes 949000 landmark faces
[2016-11-30 22:54:54,022][INFO] writes 950000 landmark faces
[2016-11-30 22:54:54,267][INFO] writes 951000 landmark faces
[2016-11-30 22:54:54,490][INFO] writes 952000 landmark faces
[2016-11-30 22:54:54,544][INFO] Process-7 reads 12000
[2016-11-30 22:54:54,741][INFO] writes 953000 landmark faces
[2016-11-30 22:54:55,008][INFO] writes 954000 landmark faces
[2016-11-30 22:54:55,242][INFO] writes 955000 landmark faces
[2016-11-30 22:54:55,480][INFO] writes 956000 landmark faces
[2016-11-30 22:54:55,552][INFO] Process-8 reads 12000
[2016-11-30 22:54:55,699][INFO] writes 957000 landmark faces
[2016-11-30 22:54:55,971][INFO] writes 958000 landmark faces
[2016-11-30 22:54:56,291][INFO] writes 959000 landmark faces
[2016-11-30 22:54:56,420][INFO] writes 960000 landmark faces
[2016-11-30 22:54:56,423][INFO] Process-5 reads 12000
[2016-11-30 22:54:56,668][INFO] writes 961000 landmark faces
[2016-11-30 22:54:56,927][INFO] writes 962000 landmark faces
[2016-11-30 22:54:57,118][INFO] Process-1 reads 12000
[2016-11-30 22:54:57,155][INFO] writes 963000 landmark faces
[2016-11-30 22:54:57,435][INFO] writes 964000 landmark faces
[2016-11-30 22:54:57,494][INFO] Process-2 reads 12000
[2016-11-30 22:54:57,689][INFO] writes 965000 landmark faces
[2016-11-30 22:54:57,935][INFO] writes 966000 landmark faces
[2016-11-30 22:54:58,192][INFO] writes 967000 landmark faces
[2016-11-30 22:54:58,456][INFO] writes 968000 landmark faces
[2016-11-30 22:54:58,665][INFO] Process-3 reads 12000
[2016-11-30 22:54:58,667][INFO] writes 969000 landmark faces
[2016-11-30 22:54:58,905][INFO] writes 970000 landmark faces
[2016-11-30 22:54:59,158][INFO] writes 971000 landmark faces
[2016-11-30 22:54:59,336][INFO] Process-4 reads 12000
[2016-11-30 22:54:59,395][INFO] writes 972000 landmark faces
[2016-11-30 22:54:59,625][INFO] writes 973000 landmark faces
[2016-11-30 22:54:59,844][INFO] writes 974000 landmark faces
[2016-11-30 22:55:00,168][INFO] writes 975000 landmark faces
[2016-11-30 22:55:00,344][INFO] writes 976000 landmark faces
[2016-11-30 22:55:00,569][INFO] writes 977000 landmark faces
[2016-11-30 22:55:00,793][INFO] writes 978000 landmark faces
[2016-11-30 22:55:01,006][INFO] writes 979000 landmark faces
[2016-11-30 22:55:01,219][INFO] writes 980000 landmark faces
[2016-11-30 22:55:01,426][INFO] writes 981000 landmark faces
[2016-11-30 22:55:01,655][INFO] writes 982000 landmark faces
[2016-11-30 22:55:01,920][INFO] writes 983000 landmark faces
[2016-11-30 22:55:02,178][INFO] writes 984000 landmark faces
[2016-11-30 22:55:02,465][INFO] writes 985000 landmark faces
[2016-11-30 22:55:02,692][INFO] writes 986000 landmark faces
[2016-11-30 22:55:02,974][INFO] writes 987000 landmark faces
[2016-11-30 22:55:03,268][INFO] writes 988000 landmark faces
[2016-11-30 22:55:03,486][INFO] writes 989000 landmark faces
[2016-11-30 22:55:03,728][INFO] writes 990000 landmark faces
[2016-11-30 22:55:04,027][INFO] writes 991000 landmark faces
[2016-11-30 22:55:04,178][INFO] writes 992000 landmark faces
[2016-11-30 22:55:04,462][INFO] writes 993000 landmark faces
[2016-11-30 22:55:04,712][INFO] writes 994000 landmark faces
[2016-11-30 22:55:04,953][INFO] writes 995000 landmark faces
[2016-11-30 22:55:05,206][INFO] writes 996000 landmark faces
[2016-11-30 22:55:05,417][INFO] writes 997000 landmark faces
[2016-11-30 22:55:05,643][INFO] writes 998000 landmark faces
[2016-11-30 22:55:05,871][INFO] writes 999000 landmark faces
[2016-11-30 22:55:06,080][INFO] writes 1000000 landmark faces
[2016-11-30 22:55:06,309][INFO] writes 1001000 landmark faces
[2016-11-30 22:55:06,551][INFO] writes 1002000 landmark faces
[2016-11-30 22:55:06,769][INFO] writes 1003000 landmark faces
[2016-11-30 22:55:06,983][INFO] writes 1004000 landmark faces
[2016-11-30 22:55:07,208][INFO] writes 1005000 landmark faces
[2016-11-30 22:55:07,412][INFO] writes 1006000 landmark faces
[2016-11-30 22:55:07,718][INFO] writes 1007000 landmark faces
[2016-11-30 22:55:07,922][INFO] writes 1008000 landmark faces
[2016-11-30 22:55:08,157][INFO] writes 1009000 landmark faces
[2016-11-30 22:55:08,431][INFO] writes 1010000 landmark faces
[2016-11-30 22:55:08,659][INFO] writes 1011000 landmark faces
[2016-11-30 22:55:08,902][INFO] writes 1012000 landmark faces
[2016-11-30 22:55:09,144][INFO] writes 1013000 landmark faces
[2016-11-30 22:55:09,381][INFO] writes 1014000 landmark faces
[2016-11-30 22:55:09,642][INFO] writes 1015000 landmark faces
[2016-11-30 22:55:09,854][INFO] writes 1016000 landmark faces
[2016-11-30 22:55:10,126][INFO] writes 1017000 landmark faces
[2016-11-30 22:55:10,431][INFO] writes 1018000 landmark faces
[2016-11-30 22:55:10,674][INFO] writes 1019000 landmark faces
[2016-11-30 22:55:10,901][INFO] writes 1020000 landmark faces
[2016-11-30 22:55:11,130][INFO] writes 1021000 landmark faces
[2016-11-30 22:55:11,422][INFO] Process-6 reads 13000
[2016-11-30 22:55:11,445][INFO] writes 1022000 landmark faces
[2016-11-30 22:55:11,763][INFO] writes 1023000 landmark faces
[2016-11-30 22:55:11,943][INFO] writes 1024000 landmark faces
[2016-11-30 22:55:12,181][INFO] writes 1025000 landmark faces
[2016-11-30 22:55:12,419][INFO] writes 1026000 landmark faces
[2016-11-30 22:55:12,652][INFO] writes 1027000 landmark faces
[2016-11-30 22:55:12,906][INFO] writes 1028000 landmark faces
[2016-11-30 22:55:13,119][INFO] writes 1029000 landmark faces
[2016-11-30 22:55:13,370][INFO] writes 1030000 landmark faces
[2016-11-30 22:55:13,496][INFO] Process-7 reads 13000
[2016-11-30 22:55:13,580][INFO] Process-8 reads 13000
[2016-11-30 22:55:13,633][INFO] writes 1031000 landmark faces
[2016-11-30 22:55:13,865][INFO] writes 1032000 landmark faces
[2016-11-30 22:55:14,096][INFO] writes 1033000 landmark faces
[2016-11-30 22:55:14,308][INFO] writes 1034000 landmark faces
[2016-11-30 22:55:14,525][INFO] writes 1035000 landmark faces
[2016-11-30 22:55:14,739][INFO] writes 1036000 landmark faces
[2016-11-30 22:55:14,951][INFO] writes 1037000 landmark faces
[2016-11-30 22:55:15,179][INFO] writes 1038000 landmark faces
[2016-11-30 22:55:15,557][INFO] writes 1039000 landmark faces
[2016-11-30 22:55:15,615][INFO] writes 1040000 landmark faces
[2016-11-30 22:55:15,841][INFO] writes 1041000 landmark faces
[2016-11-30 22:55:15,967][INFO] Process-1 reads 13000
[2016-11-30 22:55:16,097][INFO] writes 1042000 landmark faces
[2016-11-30 22:55:16,352][INFO] writes 1043000 landmark faces
[2016-11-30 22:55:16,632][INFO] writes 1044000 landmark faces
[2016-11-30 22:55:16,689][INFO] Process-5 reads 13000
[2016-11-30 22:55:16,906][INFO] writes 1045000 landmark faces
[2016-11-30 22:55:16,912][INFO] Process-2 reads 13000
[2016-11-30 22:55:17,122][INFO] writes 1046000 landmark faces
[2016-11-30 22:55:17,381][INFO] writes 1047000 landmark faces
[2016-11-30 22:55:17,608][INFO] writes 1048000 landmark faces
[2016-11-30 22:55:17,815][INFO] writes 1049000 landmark faces
[2016-11-30 22:55:18,037][INFO] writes 1050000 landmark faces
[2016-11-30 22:55:18,281][INFO] writes 1051000 landmark faces
[2016-11-30 22:55:18,503][INFO] writes 1052000 landmark faces
[2016-11-30 22:55:18,627][INFO] Process-3 reads 13000
[2016-11-30 22:55:18,764][INFO] Process-4 reads 13000
[2016-11-30 22:55:18,778][INFO] writes 1053000 landmark faces
[2016-11-30 22:55:18,978][INFO] writes 1054000 landmark faces
[2016-11-30 22:55:19,309][INFO] writes 1055000 landmark faces
[2016-11-30 22:55:19,475][INFO] writes 1056000 landmark faces
[2016-11-30 22:55:19,665][INFO] writes 1057000 landmark faces
[2016-11-30 22:55:19,905][INFO] writes 1058000 landmark faces
[2016-11-30 22:55:20,121][INFO] writes 1059000 landmark faces
[2016-11-30 22:55:20,326][INFO] writes 1060000 landmark faces
[2016-11-30 22:55:20,565][INFO] writes 1061000 landmark faces
[2016-11-30 22:55:20,800][INFO] writes 1062000 landmark faces
[2016-11-30 22:55:21,089][INFO] writes 1063000 landmark faces
[2016-11-30 22:55:21,349][INFO] writes 1064000 landmark faces
[2016-11-30 22:55:21,580][INFO] writes 1065000 landmark faces
[2016-11-30 22:55:21,797][INFO] writes 1066000 landmark faces
[2016-11-30 22:55:22,021][INFO] writes 1067000 landmark faces
[2016-11-30 22:55:22,224][INFO] writes 1068000 landmark faces
[2016-11-30 22:55:22,432][INFO] writes 1069000 landmark faces
[2016-11-30 22:55:22,665][INFO] writes 1070000 landmark faces
[2016-11-30 22:55:22,984][INFO] writes 1071000 landmark faces
[2016-11-30 22:55:23,097][INFO] writes 1072000 landmark faces
[2016-11-30 22:55:23,340][INFO] writes 1073000 landmark faces
[2016-11-30 22:55:23,563][INFO] writes 1074000 landmark faces
[2016-11-30 22:55:23,803][INFO] writes 1075000 landmark faces
[2016-11-30 22:55:24,030][INFO] writes 1076000 landmark faces
[2016-11-30 22:55:24,273][INFO] writes 1077000 landmark faces
[2016-11-30 22:55:24,490][INFO] writes 1078000 landmark faces
[2016-11-30 22:55:24,730][INFO] writes 1079000 landmark faces
[2016-11-30 22:55:24,962][INFO] writes 1080000 landmark faces
[2016-11-30 22:55:25,171][INFO] writes 1081000 landmark faces
[2016-11-30 22:55:25,407][INFO] writes 1082000 landmark faces
[2016-11-30 22:55:25,648][INFO] writes 1083000 landmark faces
[2016-11-30 22:55:25,938][INFO] writes 1084000 landmark faces
[2016-11-30 22:55:26,174][INFO] writes 1085000 landmark faces
[2016-11-30 22:55:26,404][INFO] writes 1086000 landmark faces
[2016-11-30 22:55:26,731][INFO] writes 1087000 landmark faces
[2016-11-30 22:55:26,880][INFO] writes 1088000 landmark faces
[2016-11-30 22:55:27,108][INFO] writes 1089000 landmark faces
[2016-11-30 22:55:27,352][INFO] writes 1090000 landmark faces
[2016-11-30 22:55:27,578][INFO] writes 1091000 landmark faces
[2016-11-30 22:55:27,810][INFO] writes 1092000 landmark faces
[2016-11-30 22:55:28,061][INFO] writes 1093000 landmark faces
[2016-11-30 22:55:28,317][INFO] writes 1094000 landmark faces
[2016-11-30 22:55:28,564][INFO] writes 1095000 landmark faces
[2016-11-30 22:55:28,780][INFO] writes 1096000 landmark faces
[2016-11-30 22:55:29,003][INFO] writes 1097000 landmark faces
[2016-11-30 22:55:29,266][INFO] writes 1098000 landmark faces
[2016-11-30 22:55:29,507][INFO] writes 1099000 landmark faces
[2016-11-30 22:55:29,526][INFO] Process-6 reads 14000
[2016-11-30 22:55:29,722][INFO] writes 1100000 landmark faces
[2016-11-30 22:55:29,964][INFO] writes 1101000 landmark faces
[2016-11-30 22:55:30,203][INFO] writes 1102000 landmark faces
[2016-11-30 22:55:30,500][INFO] writes 1103000 landmark faces
[2016-11-30 22:55:30,686][INFO] writes 1104000 landmark faces
[2016-11-30 22:55:30,920][INFO] writes 1105000 landmark faces
[2016-11-30 22:55:31,136][INFO] writes 1106000 landmark faces
[2016-11-30 22:55:31,352][INFO] writes 1107000 landmark faces
[2016-11-30 22:55:31,562][INFO] writes 1108000 landmark faces
[2016-11-30 22:55:31,794][INFO] writes 1109000 landmark faces
[2016-11-30 22:55:32,027][INFO] writes 1110000 landmark faces
[2016-11-30 22:55:32,236][INFO] writes 1111000 landmark faces
[2016-11-30 22:55:32,483][INFO] writes 1112000 landmark faces
[2016-11-30 22:55:32,541][INFO] Process-7 reads 14000
[2016-11-30 22:55:32,711][INFO] writes 1113000 landmark faces
[2016-11-30 22:55:32,984][INFO] writes 1114000 landmark faces
[2016-11-30 22:55:33,086][INFO] Process-8 reads 14000
[2016-11-30 22:55:33,210][INFO] writes 1115000 landmark faces
[2016-11-30 22:55:33,428][INFO] writes 1116000 landmark faces
[2016-11-30 22:55:33,632][INFO] writes 1117000 landmark faces
[2016-11-30 22:55:33,827][INFO] writes 1118000 landmark faces
[2016-11-30 22:55:34,138][INFO] writes 1119000 landmark faces
[2016-11-30 22:55:34,291][INFO] writes 1120000 landmark faces
[2016-11-30 22:55:34,527][INFO] writes 1121000 landmark faces
[2016-11-30 22:55:34,737][INFO] writes 1122000 landmark faces
[2016-11-30 22:55:34,955][INFO] writes 1123000 landmark faces
[2016-11-30 22:55:35,192][INFO] writes 1124000 landmark faces
[2016-11-30 22:55:35,236][INFO] Process-1 reads 14000
[2016-11-30 22:55:35,238][INFO] Process-5 reads 14000
[2016-11-30 22:55:35,414][INFO] writes 1125000 landmark faces
[2016-11-30 22:55:35,627][INFO] writes 1126000 landmark faces
[2016-11-30 22:55:35,770][INFO] Process-2 reads 14000
[2016-11-30 22:55:35,853][INFO] writes 1127000 landmark faces
[2016-11-30 22:55:36,115][INFO] writes 1128000 landmark faces
[2016-11-30 22:55:36,328][INFO] writes 1129000 landmark faces
[2016-11-30 22:55:36,342][INFO] Process-4 reads 14000
[2016-11-30 22:55:36,547][INFO] writes 1130000 landmark faces
[2016-11-30 22:55:36,775][INFO] writes 1131000 landmark faces
[2016-11-30 22:55:36,782][INFO] Process-3 reads 14000
[2016-11-30 22:55:37,003][INFO] writes 1132000 landmark faces
[2016-11-30 22:55:37,213][INFO] writes 1133000 landmark faces
[2016-11-30 22:55:37,436][INFO] writes 1134000 landmark faces
[2016-11-30 22:55:37,766][INFO] writes 1135000 landmark faces
[2016-11-30 22:55:37,918][INFO] writes 1136000 landmark faces
[2016-11-30 22:55:38,200][INFO] writes 1137000 landmark faces
[2016-11-30 22:55:38,460][INFO] writes 1138000 landmark faces
[2016-11-30 22:55:38,659][INFO] writes 1139000 landmark faces
[2016-11-30 22:55:38,901][INFO] writes 1140000 landmark faces
[2016-11-30 22:55:39,128][INFO] writes 1141000 landmark faces
[2016-11-30 22:55:39,341][INFO] writes 1142000 landmark faces
[2016-11-30 22:55:39,616][INFO] writes 1143000 landmark faces
[2016-11-30 22:55:39,858][INFO] writes 1144000 landmark faces
[2016-11-30 22:55:40,098][INFO] writes 1145000 landmark faces
[2016-11-30 22:55:40,351][INFO] writes 1146000 landmark faces
[2016-11-30 22:55:40,586][INFO] writes 1147000 landmark faces
[2016-11-30 22:55:40,808][INFO] writes 1148000 landmark faces
[2016-11-30 22:55:41,024][INFO] writes 1149000 landmark faces
[2016-11-30 22:55:41,243][INFO] writes 1150000 landmark faces
[2016-11-30 22:55:41,555][INFO] writes 1151000 landmark faces
[2016-11-30 22:55:41,697][INFO] writes 1152000 landmark faces
[2016-11-30 22:55:41,957][INFO] writes 1153000 landmark faces
[2016-11-30 22:55:42,201][INFO] writes 1154000 landmark faces
[2016-11-30 22:55:42,431][INFO] writes 1155000 landmark faces
[2016-11-30 22:55:42,657][INFO] writes 1156000 landmark faces
[2016-11-30 22:55:42,890][INFO] writes 1157000 landmark faces
[2016-11-30 22:55:43,137][INFO] writes 1158000 landmark faces
[2016-11-30 22:55:43,452][INFO] writes 1159000 landmark faces
[2016-11-30 22:55:43,743][INFO] writes 1160000 landmark faces
[2016-11-30 22:55:43,968][INFO] writes 1161000 landmark faces
[2016-11-30 22:55:44,226][INFO] writes 1162000 landmark faces
[2016-11-30 22:55:44,466][INFO] writes 1163000 landmark faces
[2016-11-30 22:55:44,700][INFO] writes 1164000 landmark faces
[2016-11-30 22:55:44,919][INFO] writes 1165000 landmark faces
[2016-11-30 22:55:45,117][INFO] writes 1166000 landmark faces
[2016-11-30 22:55:45,424][INFO] writes 1167000 landmark faces
[2016-11-30 22:55:45,564][INFO] writes 1168000 landmark faces
[2016-11-30 22:55:45,777][INFO] writes 1169000 landmark faces
[2016-11-30 22:55:45,975][INFO] writes 1170000 landmark faces
[2016-11-30 22:55:46,211][INFO] writes 1171000 landmark faces
[2016-11-30 22:55:46,471][INFO] writes 1172000 landmark faces
[2016-11-30 22:55:46,698][INFO] writes 1173000 landmark faces
[2016-11-30 22:55:46,895][INFO] writes 1174000 landmark faces
[2016-11-30 22:55:47,150][INFO] writes 1175000 landmark faces
[2016-11-30 22:55:47,433][INFO] writes 1176000 landmark faces
[2016-11-30 22:55:47,641][INFO] Process-6 reads 15000
[2016-11-30 22:55:47,668][INFO] writes 1177000 landmark faces
[2016-11-30 22:55:47,890][INFO] writes 1178000 landmark faces
[2016-11-30 22:55:48,134][INFO] writes 1179000 landmark faces
[2016-11-30 22:55:48,363][INFO] writes 1180000 landmark faces
[2016-11-30 22:55:48,574][INFO] writes 1181000 landmark faces
[2016-11-30 22:55:48,805][INFO] writes 1182000 landmark faces
[2016-11-30 22:55:49,102][INFO] writes 1183000 landmark faces
[2016-11-30 22:55:49,245][INFO] writes 1184000 landmark faces
[2016-11-30 22:55:49,441][INFO] writes 1185000 landmark faces
[2016-11-30 22:55:49,674][INFO] writes 1186000 landmark faces
[2016-11-30 22:55:49,897][INFO] writes 1187000 landmark faces
[2016-11-30 22:55:50,146][INFO] writes 1188000 landmark faces
[2016-11-30 22:55:50,391][INFO] writes 1189000 landmark faces
[2016-11-30 22:55:50,625][INFO] writes 1190000 landmark faces
[2016-11-30 22:55:50,855][INFO] writes 1191000 landmark faces
[2016-11-30 22:55:51,097][INFO] writes 1192000 landmark faces
[2016-11-30 22:55:51,311][INFO] writes 1193000 landmark faces
[2016-11-30 22:55:51,569][INFO] writes 1194000 landmark faces
[2016-11-30 22:55:51,804][INFO] writes 1195000 landmark faces
[2016-11-30 22:55:51,851][INFO] Process-8 reads 15000
[2016-11-30 22:55:52,034][INFO] writes 1196000 landmark faces
[2016-11-30 22:55:52,130][INFO] Process-7 reads 15000
[2016-11-30 22:55:52,586][INFO] writes 1197000 landmark faces
[2016-11-30 22:55:52,841][INFO] writes 1198000 landmark faces
[2016-11-30 22:55:53,138][INFO] writes 1199000 landmark faces
[2016-11-30 22:55:53,346][INFO] writes 1200000 landmark faces
[2016-11-30 22:55:53,558][INFO] writes 1201000 landmark faces
[2016-11-30 22:55:53,714][INFO] Process-1 reads 15000
[2016-11-30 22:55:53,791][INFO] writes 1202000 landmark faces
[2016-11-30 22:55:54,030][INFO] writes 1203000 landmark faces
[2016-11-30 22:55:54,291][INFO] Process-5 reads 15000
[2016-11-30 22:55:54,308][INFO] writes 1204000 landmark faces
[2016-11-30 22:55:54,592][INFO] writes 1205000 landmark faces
[2016-11-30 22:55:54,835][INFO] writes 1206000 landmark faces
[2016-11-30 22:55:54,861][INFO] Process-4 reads 15000
[2016-11-30 22:55:55,106][INFO] writes 1207000 landmark faces
[2016-11-30 22:55:55,188][INFO] Process-2 reads 15000
[2016-11-30 22:55:55,314][INFO] Process-3 reads 15000
[2016-11-30 22:55:55,344][INFO] writes 1208000 landmark faces
[2016-11-30 22:55:55,684][INFO] writes 1209000 landmark faces
[2016-11-30 22:55:55,931][INFO] writes 1210000 landmark faces
[2016-11-30 22:55:56,193][INFO] writes 1211000 landmark faces
[2016-11-30 22:55:56,393][INFO] writes 1212000 landmark faces
[2016-11-30 22:55:56,800][INFO] writes 1213000 landmark faces
[2016-11-30 22:55:57,040][INFO] writes 1214000 landmark faces
[2016-11-30 22:55:57,345][INFO] writes 1215000 landmark faces
[2016-11-30 22:55:57,703][INFO] writes 1216000 landmark faces
[2016-11-30 22:55:57,915][INFO] writes 1217000 landmark faces
[2016-11-30 22:55:58,137][INFO] writes 1218000 landmark faces
[2016-11-30 22:55:58,357][INFO] writes 1219000 landmark faces
[2016-11-30 22:55:58,570][INFO] writes 1220000 landmark faces
[2016-11-30 22:55:58,805][INFO] writes 1221000 landmark faces
[2016-11-30 22:55:59,024][INFO] writes 1222000 landmark faces
[2016-11-30 22:55:59,268][INFO] writes 1223000 landmark faces
[2016-11-30 22:55:59,510][INFO] writes 1224000 landmark faces
[2016-11-30 22:55:59,765][INFO] writes 1225000 landmark faces
[2016-11-30 22:56:00,006][INFO] writes 1226000 landmark faces
[2016-11-30 22:56:00,229][INFO] writes 1227000 landmark faces
[2016-11-30 22:56:00,557][INFO] writes 1228000 landmark faces
[2016-11-30 22:56:00,783][INFO] writes 1229000 landmark faces
[2016-11-30 22:56:00,992][INFO] writes 1230000 landmark faces
[2016-11-30 22:56:01,301][INFO] writes 1231000 landmark faces
[2016-11-30 22:56:01,471][INFO] writes 1232000 landmark faces
[2016-11-30 22:56:01,716][INFO] writes 1233000 landmark faces
[2016-11-30 22:56:02,026][INFO] writes 1234000 landmark faces
[2016-11-30 22:56:02,226][INFO] writes 1235000 landmark faces
[2016-11-30 22:56:02,461][INFO] writes 1236000 landmark faces
[2016-11-30 22:56:02,708][INFO] writes 1237000 landmark faces
[2016-11-30 22:56:02,925][INFO] writes 1238000 landmark faces
[2016-11-30 22:56:03,189][INFO] writes 1239000 landmark faces
[2016-11-30 22:56:03,408][INFO] writes 1240000 landmark faces
[2016-11-30 22:56:03,667][INFO] writes 1241000 landmark faces
[2016-11-30 22:56:03,875][INFO] writes 1242000 landmark faces
[2016-11-30 22:56:04,084][INFO] writes 1243000 landmark faces
[2016-11-30 22:56:04,307][INFO] writes 1244000 landmark faces
[2016-11-30 22:56:04,523][INFO] writes 1245000 landmark faces
[2016-11-30 22:56:04,760][INFO] writes 1246000 landmark faces
[2016-11-30 22:56:05,053][INFO] writes 1247000 landmark faces
[2016-11-30 22:56:05,197][INFO] writes 1248000 landmark faces
[2016-11-30 22:56:05,403][INFO] writes 1249000 landmark faces
[2016-11-30 22:56:05,632][INFO] writes 1250000 landmark faces
[2016-11-30 22:56:05,833][INFO] Process-6 reads 16000
[2016-11-30 22:56:05,855][INFO] writes 1251000 landmark faces
[2016-11-30 22:56:06,087][INFO] writes 1252000 landmark faces
[2016-11-30 22:56:06,344][INFO] writes 1253000 landmark faces
[2016-11-30 22:56:06,571][INFO] writes 1254000 landmark faces
[2016-11-30 22:56:06,823][INFO] writes 1255000 landmark faces
[2016-11-30 22:56:07,075][INFO] writes 1256000 landmark faces
[2016-11-30 22:56:07,331][INFO] writes 1257000 landmark faces
[2016-11-30 22:56:07,592][INFO] writes 1258000 landmark faces
[2016-11-30 22:56:07,842][INFO] writes 1259000 landmark faces
[2016-11-30 22:56:08,078][INFO] writes 1260000 landmark faces
[2016-11-30 22:56:08,300][INFO] writes 1261000 landmark faces
[2016-11-30 22:56:08,521][INFO] writes 1262000 landmark faces
[2016-11-30 22:56:08,792][INFO] writes 1263000 landmark faces
[2016-11-30 22:56:09,023][INFO] writes 1264000 landmark faces
[2016-11-30 22:56:09,261][INFO] writes 1265000 landmark faces
[2016-11-30 22:56:09,492][INFO] writes 1266000 landmark faces
[2016-11-30 22:56:09,741][INFO] writes 1267000 landmark faces
[2016-11-30 22:56:09,974][INFO] writes 1268000 landmark faces
[2016-11-30 22:56:10,228][INFO] writes 1269000 landmark faces
[2016-11-30 22:56:10,452][INFO] writes 1270000 landmark faces
[2016-11-30 22:56:10,660][INFO] writes 1271000 landmark faces
[2016-11-30 22:56:10,881][INFO] writes 1272000 landmark faces
[2016-11-30 22:56:11,091][INFO] writes 1273000 landmark faces
[2016-11-30 22:56:11,319][INFO] writes 1274000 landmark faces
[2016-11-30 22:56:11,540][INFO] writes 1275000 landmark faces
[2016-11-30 22:56:11,781][INFO] writes 1276000 landmark faces
[2016-11-30 22:56:11,819][INFO] Process-7 reads 16000
[2016-11-30 22:56:12,005][INFO] writes 1277000 landmark faces
[2016-11-30 22:56:12,250][INFO] writes 1278000 landmark faces
[2016-11-30 22:56:12,533][INFO] writes 1279000 landmark faces
[2016-11-30 22:56:12,697][INFO] Process-8 reads 16000
[2016-11-30 22:56:12,711][INFO] writes 1280000 landmark faces
[2016-11-30 22:56:12,986][INFO] writes 1281000 landmark faces
[2016-11-30 22:56:13,222][INFO] writes 1282000 landmark faces
[2016-11-30 22:56:13,236][INFO] Process-4 reads 16000
[2016-11-30 22:56:13,505][INFO] writes 1283000 landmark faces
[2016-11-30 22:56:13,538][INFO] Process-1 reads 16000
[2016-11-30 22:56:13,772][INFO] writes 1284000 landmark faces
[2016-11-30 22:56:14,027][INFO] writes 1285000 landmark faces
[2016-11-30 22:56:14,041][INFO] Process-2 reads 16000
[2016-11-30 22:56:14,259][INFO] writes 1286000 landmark faces
[2016-11-30 22:56:14,495][INFO] writes 1287000 landmark faces
[2016-11-30 22:56:14,726][INFO] writes 1288000 landmark faces
[2016-11-30 22:56:14,950][INFO] writes 1289000 landmark faces
[2016-11-30 22:56:14,981][INFO] Process-3 reads 16000
[2016-11-30 22:56:15,192][INFO] writes 1290000 landmark faces
[2016-11-30 22:56:15,421][INFO] writes 1291000 landmark faces
[2016-11-30 22:56:15,558][INFO] Process-5 reads 16000
[2016-11-30 22:56:15,666][INFO] writes 1292000 landmark faces
[2016-11-30 22:56:15,913][INFO] writes 1293000 landmark faces
[2016-11-30 22:56:16,168][INFO] writes 1294000 landmark faces
[2016-11-30 22:56:16,450][INFO] writes 1295000 landmark faces
[2016-11-30 22:56:16,632][INFO] writes 1296000 landmark faces
[2016-11-30 22:56:16,854][INFO] writes 1297000 landmark faces
[2016-11-30 22:56:17,095][INFO] writes 1298000 landmark faces
[2016-11-30 22:56:17,302][INFO] writes 1299000 landmark faces
[2016-11-30 22:56:17,514][INFO] writes 1300000 landmark faces
[2016-11-30 22:56:17,713][INFO] writes 1301000 landmark faces
[2016-11-30 22:56:17,964][INFO] writes 1302000 landmark faces
[2016-11-30 22:56:18,237][INFO] writes 1303000 landmark faces
[2016-11-30 22:56:18,461][INFO] writes 1304000 landmark faces
[2016-11-30 22:56:18,681][INFO] writes 1305000 landmark faces
[2016-11-30 22:56:18,907][INFO] writes 1306000 landmark faces
[2016-11-30 22:56:19,145][INFO] writes 1307000 landmark faces
[2016-11-30 22:56:19,407][INFO] writes 1308000 landmark faces
[2016-11-30 22:56:19,664][INFO] writes 1309000 landmark faces
[2016-11-30 22:56:19,920][INFO] writes 1310000 landmark faces
[2016-11-30 22:56:20,198][INFO] writes 1311000 landmark faces
[2016-11-30 22:56:20,390][INFO] writes 1312000 landmark faces
[2016-11-30 22:56:20,650][INFO] writes 1313000 landmark faces
[2016-11-30 22:56:20,877][INFO] writes 1314000 landmark faces
[2016-11-30 22:56:21,156][INFO] writes 1315000 landmark faces
[2016-11-30 22:56:21,367][INFO] writes 1316000 landmark faces
[2016-11-30 22:56:21,611][INFO] writes 1317000 landmark faces
[2016-11-30 22:56:21,841][INFO] writes 1318000 landmark faces
[2016-11-30 22:56:22,072][INFO] writes 1319000 landmark faces
[2016-11-30 22:56:22,380][INFO] writes 1320000 landmark faces
[2016-11-30 22:56:22,596][INFO] writes 1321000 landmark faces
[2016-11-30 22:56:22,861][INFO] writes 1322000 landmark faces
[2016-11-30 22:56:23,086][INFO] writes 1323000 landmark faces
[2016-11-30 22:56:23,310][INFO] writes 1324000 landmark faces
[2016-11-30 22:56:23,542][INFO] writes 1325000 landmark faces
[2016-11-30 22:56:23,757][INFO] writes 1326000 landmark faces
[2016-11-30 22:56:24,002][INFO] writes 1327000 landmark faces
[2016-11-30 22:56:24,243][INFO] writes 1328000 landmark faces
[2016-11-30 22:56:24,501][INFO] writes 1329000 landmark faces
[2016-11-30 22:56:24,751][INFO] writes 1330000 landmark faces
[2016-11-30 22:56:24,972][INFO] writes 1331000 landmark faces
[2016-11-30 22:56:25,218][INFO] writes 1332000 landmark faces
[2016-11-30 22:56:25,448][INFO] writes 1333000 landmark faces
[2016-11-30 22:56:25,668][INFO] writes 1334000 landmark faces
[2016-11-30 22:56:25,885][INFO] writes 1335000 landmark faces
[2016-11-30 22:56:26,110][INFO] writes 1336000 landmark faces
[2016-11-30 22:56:26,346][INFO] writes 1337000 landmark faces
[2016-11-30 22:56:26,553][INFO] writes 1338000 landmark faces
[2016-11-30 22:56:26,592][INFO] Process-6 reads 17000
[2016-11-30 22:56:26,776][INFO] writes 1339000 landmark faces
[2016-11-30 22:56:27,009][INFO] writes 1340000 landmark faces
[2016-11-30 22:56:27,243][INFO] writes 1341000 landmark faces
[2016-11-30 22:56:27,513][INFO] writes 1342000 landmark faces
[2016-11-30 22:56:27,819][INFO] writes 1343000 landmark faces
[2016-11-30 22:56:28,087][INFO] writes 1344000 landmark faces
[2016-11-30 22:56:28,359][INFO] writes 1345000 landmark faces
[2016-11-30 22:56:28,612][INFO] writes 1346000 landmark faces
[2016-11-30 22:56:28,903][INFO] writes 1347000 landmark faces
[2016-11-30 22:56:29,162][INFO] writes 1348000 landmark faces
[2016-11-30 22:56:29,397][INFO] writes 1349000 landmark faces
[2016-11-30 22:56:29,642][INFO] writes 1350000 landmark faces
[2016-11-30 22:56:29,910][INFO] writes 1351000 landmark faces
[2016-11-30 22:56:30,143][INFO] writes 1352000 landmark faces
[2016-11-30 22:56:30,409][INFO] writes 1353000 landmark faces
[2016-11-30 22:56:30,658][INFO] writes 1354000 landmark faces
[2016-11-30 22:56:30,750][INFO] Process-7 reads 17000
[2016-11-30 22:56:30,944][INFO] writes 1355000 landmark faces
[2016-11-30 22:56:31,170][INFO] writes 1356000 landmark faces
[2016-11-30 22:56:31,427][INFO] writes 1357000 landmark faces
[2016-11-30 22:56:31,656][INFO] writes 1358000 landmark faces
[2016-11-30 22:56:31,882][INFO] writes 1359000 landmark faces
[2016-11-30 22:56:31,897][INFO] Process-4 reads 17000
[2016-11-30 22:56:31,972][INFO] Process-8 reads 17000
[2016-11-30 22:56:32,148][INFO] writes 1360000 landmark faces
[2016-11-30 22:56:32,417][INFO] writes 1361000 landmark faces
[2016-11-30 22:56:32,684][INFO] writes 1362000 landmark faces
[2016-11-30 22:56:32,944][INFO] writes 1363000 landmark faces
[2016-11-30 22:56:33,054][INFO] Process-2 reads 17000
[2016-11-30 22:56:33,175][INFO] writes 1364000 landmark faces
[2016-11-30 22:56:33,372][INFO] Process-1 reads 17000
[2016-11-30 22:56:33,462][INFO] writes 1365000 landmark faces
[2016-11-30 22:56:33,714][INFO] writes 1366000 landmark faces
[2016-11-30 22:56:34,108][INFO] writes 1367000 landmark faces
[2016-11-30 22:56:34,335][INFO] writes 1368000 landmark faces
[2016-11-30 22:56:34,392][INFO] Process-3 reads 17000
[2016-11-30 22:56:34,562][INFO] writes 1369000 landmark faces
[2016-11-30 22:56:34,799][INFO] writes 1370000 landmark faces
[2016-11-30 22:56:35,020][INFO] writes 1371000 landmark faces
[2016-11-30 22:56:35,158][INFO] Process-5 reads 17000
[2016-11-30 22:56:35,351][INFO] writes 1372000 landmark faces
[2016-11-30 22:56:35,586][INFO] writes 1373000 landmark faces
[2016-11-30 22:56:35,888][INFO] writes 1374000 landmark faces
[2016-11-30 22:56:36,133][INFO] writes 1375000 landmark faces
[2016-11-30 22:56:36,463][INFO] writes 1376000 landmark faces
[2016-11-30 22:56:36,746][INFO] writes 1377000 landmark faces
[2016-11-30 22:56:37,182][INFO] writes 1378000 landmark faces
[2016-11-30 22:56:37,417][INFO] writes 1379000 landmark faces
[2016-11-30 22:56:37,672][INFO] writes 1380000 landmark faces
[2016-11-30 22:56:38,167][INFO] writes 1381000 landmark faces
[2016-11-30 22:56:38,535][INFO] writes 1382000 landmark faces
[2016-11-30 22:56:38,820][INFO] writes 1383000 landmark faces
[2016-11-30 22:56:39,129][INFO] writes 1384000 landmark faces
[2016-11-30 22:56:39,463][INFO] writes 1385000 landmark faces
[2016-11-30 22:56:39,768][INFO] writes 1386000 landmark faces
[2016-11-30 22:56:40,129][INFO] writes 1387000 landmark faces
[2016-11-30 22:56:40,399][INFO] writes 1388000 landmark faces
[2016-11-30 22:56:40,681][INFO] writes 1389000 landmark faces
[2016-11-30 22:56:40,975][INFO] writes 1390000 landmark faces
[2016-11-30 22:56:41,329][INFO] writes 1391000 landmark faces
[2016-11-30 22:56:41,527][INFO] writes 1392000 landmark faces
[2016-11-30 22:56:41,758][INFO] writes 1393000 landmark faces
[2016-11-30 22:56:41,966][INFO] writes 1394000 landmark faces
[2016-11-30 22:56:42,235][INFO] writes 1395000 landmark faces
[2016-11-30 22:56:42,487][INFO] writes 1396000 landmark faces
[2016-11-30 22:56:42,752][INFO] writes 1397000 landmark faces
[2016-11-30 22:56:42,982][INFO] writes 1398000 landmark faces
[2016-11-30 22:56:43,229][INFO] writes 1399000 landmark faces
[2016-11-30 22:56:43,456][INFO] writes 1400000 landmark faces
[2016-11-30 22:56:43,707][INFO] writes 1401000 landmark faces
[2016-11-30 22:56:43,978][INFO] writes 1402000 landmark faces
[2016-11-30 22:56:44,218][INFO] writes 1403000 landmark faces
[2016-11-30 22:56:44,422][INFO] writes 1404000 landmark faces
[2016-11-30 22:56:44,652][INFO] writes 1405000 landmark faces
[2016-11-30 22:56:44,893][INFO] writes 1406000 landmark faces
[2016-11-30 22:56:45,152][INFO] writes 1407000 landmark faces
[2016-11-30 22:56:45,390][INFO] writes 1408000 landmark faces
[2016-11-30 22:56:45,597][INFO] writes 1409000 landmark faces
[2016-11-30 22:56:45,794][INFO] writes 1410000 landmark faces
[2016-11-30 22:56:46,040][INFO] writes 1411000 landmark faces
[2016-11-30 22:56:46,326][INFO] writes 1412000 landmark faces
[2016-11-30 22:56:46,574][INFO] writes 1413000 landmark faces
[2016-11-30 22:56:46,796][INFO] writes 1414000 landmark faces
[2016-11-30 22:56:47,010][INFO] writes 1415000 landmark faces
[2016-11-30 22:56:47,226][INFO] writes 1416000 landmark faces
[2016-11-30 22:56:47,462][INFO] writes 1417000 landmark faces
[2016-11-30 22:56:47,706][INFO] writes 1418000 landmark faces
[2016-11-30 22:56:47,953][INFO] writes 1419000 landmark faces
[2016-11-30 22:56:48,210][INFO] writes 1420000 landmark faces
[2016-11-30 22:56:48,429][INFO] writes 1421000 landmark faces
[2016-11-30 22:56:48,668][INFO] writes 1422000 landmark faces
[2016-11-30 22:56:48,966][INFO] writes 1423000 landmark faces
[2016-11-30 22:56:49,193][INFO] Process-6 reads 18000
[2016-11-30 22:56:49,197][INFO] writes 1424000 landmark faces
[2016-11-30 22:56:49,418][INFO] writes 1425000 landmark faces
[2016-11-30 22:56:49,664][INFO] writes 1426000 landmark faces
[2016-11-30 22:56:49,952][INFO] writes 1427000 landmark faces
[2016-11-30 22:56:50,221][INFO] writes 1428000 landmark faces
[2016-11-30 22:56:50,449][INFO] writes 1429000 landmark faces
[2016-11-30 22:56:50,676][INFO] writes 1430000 landmark faces
[2016-11-30 22:56:50,911][INFO] writes 1431000 landmark faces
[2016-11-30 22:56:51,163][INFO] writes 1432000 landmark faces
[2016-11-30 22:56:51,398][INFO] writes 1433000 landmark faces
[2016-11-30 22:56:51,693][INFO] writes 1434000 landmark faces
[2016-11-30 22:56:51,983][INFO] writes 1435000 landmark faces
[2016-11-30 22:56:52,052][INFO] Process-4 reads 18000
[2016-11-30 22:56:52,187][INFO] writes 1436000 landmark faces
[2016-11-30 22:56:52,426][INFO] writes 1437000 landmark faces
[2016-11-30 22:56:52,568][INFO] Process-7 reads 18000
[2016-11-30 22:56:52,693][INFO] writes 1438000 landmark faces
[2016-11-30 22:56:52,960][INFO] writes 1439000 landmark faces
[2016-11-30 22:56:53,164][INFO] writes 1440000 landmark faces
[2016-11-30 22:56:53,435][INFO] writes 1441000 landmark faces
[2016-11-30 22:56:53,452][INFO] Process-1 reads 18000
[2016-11-30 22:56:53,727][INFO] Process-8 reads 18000
[2016-11-30 22:56:53,729][INFO] writes 1442000 landmark faces
[2016-11-30 22:56:53,935][INFO] writes 1443000 landmark faces
[2016-11-30 22:56:54,004][INFO] Process-2 reads 18000
[2016-11-30 22:56:54,137][INFO] writes 1444000 landmark faces
[2016-11-30 22:56:54,373][INFO] writes 1445000 landmark faces
[2016-11-30 22:56:54,594][INFO] writes 1446000 landmark faces
[2016-11-30 22:56:54,839][INFO] writes 1447000 landmark faces
[2016-11-30 22:56:55,062][INFO] Process-3 reads 18000
[2016-11-30 22:56:55,076][INFO] writes 1448000 landmark faces
[2016-11-30 22:56:55,302][INFO] writes 1449000 landmark faces
[2016-11-30 22:56:55,350][INFO] Process-5 reads 18000
[2016-11-30 22:56:55,554][INFO] writes 1450000 landmark faces
[2016-11-30 22:56:55,807][INFO] writes 1451000 landmark faces
[2016-11-30 22:56:56,063][INFO] writes 1452000 landmark faces
[2016-11-30 22:56:56,293][INFO] writes 1453000 landmark faces
[2016-11-30 22:56:56,498][INFO] writes 1454000 landmark faces
[2016-11-30 22:56:56,761][INFO] writes 1455000 landmark faces
[2016-11-30 22:56:56,968][INFO] writes 1456000 landmark faces
[2016-11-30 22:56:57,218][INFO] writes 1457000 landmark faces
[2016-11-30 22:56:57,444][INFO] writes 1458000 landmark faces
[2016-11-30 22:56:57,691][INFO] writes 1459000 landmark faces
[2016-11-30 22:56:57,913][INFO] writes 1460000 landmark faces
[2016-11-30 22:56:58,136][INFO] writes 1461000 landmark faces
[2016-11-30 22:56:58,394][INFO] writes 1462000 landmark faces
[2016-11-30 22:56:58,628][INFO] writes 1463000 landmark faces
[2016-11-30 22:56:58,856][INFO] writes 1464000 landmark faces
[2016-11-30 22:56:59,085][INFO] writes 1465000 landmark faces
[2016-11-30 22:56:59,326][INFO] writes 1466000 landmark faces
[2016-11-30 22:56:59,556][INFO] writes 1467000 landmark faces
[2016-11-30 22:56:59,825][INFO] writes 1468000 landmark faces
[2016-11-30 22:57:00,040][INFO] writes 1469000 landmark faces
[2016-11-30 22:57:00,281][INFO] writes 1470000 landmark faces
[2016-11-30 22:57:00,569][INFO] writes 1471000 landmark faces
[2016-11-30 22:57:00,809][INFO] writes 1472000 landmark faces
[2016-11-30 22:57:01,060][INFO] writes 1473000 landmark faces
[2016-11-30 22:57:01,311][INFO] writes 1474000 landmark faces
[2016-11-30 22:57:01,551][INFO] writes 1475000 landmark faces
[2016-11-30 22:57:01,770][INFO] writes 1476000 landmark faces
[2016-11-30 22:57:01,984][INFO] writes 1477000 landmark faces
[2016-11-30 22:57:02,237][INFO] writes 1478000 landmark faces
[2016-11-30 22:57:02,471][INFO] writes 1479000 landmark faces
[2016-11-30 22:57:02,700][INFO] writes 1480000 landmark faces
[2016-11-30 22:57:02,932][INFO] writes 1481000 landmark faces
[2016-11-30 22:57:03,157][INFO] writes 1482000 landmark faces
[2016-11-30 22:57:03,402][INFO] writes 1483000 landmark faces
[2016-11-30 22:57:03,645][INFO] writes 1484000 landmark faces
[2016-11-30 22:57:03,866][INFO] writes 1485000 landmark faces
[2016-11-30 22:57:04,140][INFO] writes 1486000 landmark faces
[2016-11-30 22:57:04,384][INFO] writes 1487000 landmark faces
[2016-11-30 22:57:04,607][INFO] writes 1488000 landmark faces
[2016-11-30 22:57:04,811][INFO] writes 1489000 landmark faces
[2016-11-30 22:57:05,034][INFO] writes 1490000 landmark faces
[2016-11-30 22:57:05,254][INFO] writes 1491000 landmark faces
[2016-11-30 22:57:05,495][INFO] writes 1492000 landmark faces
[2016-11-30 22:57:05,747][INFO] writes 1493000 landmark faces
[2016-11-30 22:57:05,975][INFO] writes 1494000 landmark faces
[2016-11-30 22:57:06,223][INFO] writes 1495000 landmark faces
[2016-11-30 22:57:06,443][INFO] writes 1496000 landmark faces
[2016-11-30 22:57:06,706][INFO] writes 1497000 landmark faces
[2016-11-30 22:57:06,963][INFO] writes 1498000 landmark faces
[2016-11-30 22:57:07,199][INFO] writes 1499000 landmark faces
[2016-11-30 22:57:07,453][INFO] writes 1500000 landmark faces
[2016-11-30 22:57:07,736][INFO] writes 1501000 landmark faces
[2016-11-30 22:57:08,000][INFO] writes 1502000 landmark faces
[2016-11-30 22:57:08,236][INFO] writes 1503000 landmark faces
[2016-11-30 22:57:08,459][INFO] writes 1504000 landmark faces
[2016-11-30 22:57:08,701][INFO] writes 1505000 landmark faces
[2016-11-30 22:57:08,960][INFO] writes 1506000 landmark faces
[2016-11-30 22:57:09,180][INFO] writes 1507000 landmark faces
[2016-11-30 22:57:09,439][INFO] writes 1508000 landmark faces
[2016-11-30 22:57:09,698][INFO] writes 1509000 landmark faces
[2016-11-30 22:57:09,914][INFO] writes 1510000 landmark faces
[2016-11-30 22:57:10,102][INFO] Process-4 reads 19000
[2016-11-30 22:57:10,127][INFO] Process-6 reads 19000
[2016-11-30 22:57:10,209][INFO] writes 1511000 landmark faces
[2016-11-30 22:57:10,465][INFO] writes 1512000 landmark faces
[2016-11-30 22:57:10,701][INFO] writes 1513000 landmark faces
[2016-11-30 22:57:11,005][INFO] writes 1514000 landmark faces
[2016-11-30 22:57:11,281][INFO] writes 1515000 landmark faces
[2016-11-30 22:57:11,594][INFO] writes 1516000 landmark faces
[2016-11-30 22:57:11,822][INFO] writes 1517000 landmark faces
[2016-11-30 22:57:11,880][INFO] Process-7 reads 19000
[2016-11-30 22:57:12,073][INFO] writes 1518000 landmark faces
[2016-11-30 22:57:12,344][INFO] writes 1519000 landmark faces
[2016-11-30 22:57:12,453][INFO] Process-2 reads 19000
[2016-11-30 22:57:12,574][INFO] writes 1520000 landmark faces
[2016-11-30 22:57:12,708][INFO] Process-1 reads 19000
[2016-11-30 22:57:12,804][INFO] writes 1521000 landmark faces
[2016-11-30 22:57:13,016][INFO] writes 1522000 landmark faces
[2016-11-30 22:57:13,243][INFO] writes 1523000 landmark faces
[2016-11-30 22:57:13,453][INFO] writes 1524000 landmark faces
[2016-11-30 22:57:13,712][INFO] writes 1525000 landmark faces
[2016-11-30 22:57:13,799][INFO] Process-8 reads 19000
[2016-11-30 22:57:13,829][INFO] Process-3 reads 19000
[2016-11-30 22:57:13,960][INFO] writes 1526000 landmark faces
[2016-11-30 22:57:14,168][INFO] writes 1527000 landmark faces
[2016-11-30 22:57:14,380][INFO] writes 1528000 landmark faces
[2016-11-30 22:57:14,639][INFO] writes 1529000 landmark faces
[2016-11-30 22:57:14,875][INFO] writes 1530000 landmark faces
[2016-11-30 22:57:15,130][INFO] writes 1531000 landmark faces
[2016-11-30 22:57:15,301][INFO] Process-5 reads 19000
[2016-11-30 22:57:15,358][INFO] writes 1532000 landmark faces
[2016-11-30 22:57:15,589][INFO] writes 1533000 landmark faces
[2016-11-30 22:57:15,822][INFO] writes 1534000 landmark faces
[2016-11-30 22:57:16,070][INFO] writes 1535000 landmark faces
[2016-11-30 22:57:16,518][INFO] writes 1536000 landmark faces
[2016-11-30 22:57:16,752][INFO] writes 1537000 landmark faces
[2016-11-30 22:57:17,089][INFO] writes 1538000 landmark faces
[2016-11-30 22:57:17,595][INFO] writes 1539000 landmark faces
[2016-11-30 22:57:17,855][INFO] writes 1540000 landmark faces
[2016-11-30 22:57:18,150][INFO] writes 1541000 landmark faces
[2016-11-30 22:57:18,399][INFO] writes 1542000 landmark faces
[2016-11-30 22:57:18,777][INFO] writes 1543000 landmark faces
[2016-11-30 22:57:19,032][INFO] writes 1544000 landmark faces
[2016-11-30 22:57:19,340][INFO] writes 1545000 landmark faces
[2016-11-30 22:57:19,620][INFO] writes 1546000 landmark faces
[2016-11-30 22:57:20,015][INFO] writes 1547000 landmark faces
[2016-11-30 22:57:20,313][INFO] writes 1548000 landmark faces
[2016-11-30 22:57:20,590][INFO] writes 1549000 landmark faces
[2016-11-30 22:57:20,890][INFO] writes 1550000 landmark faces
[2016-11-30 22:57:21,268][INFO] writes 1551000 landmark faces
[2016-11-30 22:57:21,497][INFO] writes 1552000 landmark faces
[2016-11-30 22:57:21,833][INFO] writes 1553000 landmark faces
[2016-11-30 22:57:22,269][INFO] writes 1554000 landmark faces
[2016-11-30 22:57:22,515][INFO] writes 1555000 landmark faces
[2016-11-30 22:57:22,884][INFO] writes 1556000 landmark faces
[2016-11-30 22:57:23,119][INFO] writes 1557000 landmark faces
[2016-11-30 22:57:23,373][INFO] writes 1558000 landmark faces
[2016-11-30 22:57:23,734][INFO] writes 1559000 landmark faces
[2016-11-30 22:57:23,974][INFO] writes 1560000 landmark faces
[2016-11-30 22:57:24,204][INFO] writes 1561000 landmark faces
[2016-11-30 22:57:24,526][INFO] writes 1562000 landmark faces
[2016-11-30 22:57:24,742][INFO] writes 1563000 landmark faces
[2016-11-30 22:57:24,995][INFO] writes 1564000 landmark faces
[2016-11-30 22:57:25,221][INFO] writes 1565000 landmark faces
[2016-11-30 22:57:25,485][INFO] writes 1566000 landmark faces
[2016-11-30 22:57:25,735][INFO] writes 1567000 landmark faces
[2016-11-30 22:57:25,948][INFO] writes 1568000 landmark faces
[2016-11-30 22:57:26,191][INFO] writes 1569000 landmark faces
[2016-11-30 22:57:26,463][INFO] writes 1570000 landmark faces
[2016-11-30 22:57:26,707][INFO] writes 1571000 landmark faces
[2016-11-30 22:57:26,940][INFO] writes 1572000 landmark faces
[2016-11-30 22:57:27,152][INFO] writes 1573000 landmark faces
[2016-11-30 22:57:27,384][INFO] writes 1574000 landmark faces
[2016-11-30 22:57:27,631][INFO] writes 1575000 landmark faces
[2016-11-30 22:57:27,912][INFO] writes 1576000 landmark faces
[2016-11-30 22:57:28,173][INFO] writes 1577000 landmark faces
[2016-11-30 22:57:28,420][INFO] writes 1578000 landmark faces
[2016-11-30 22:57:28,677][INFO] writes 1579000 landmark faces
[2016-11-30 22:57:28,893][INFO] writes 1580000 landmark faces
[2016-11-30 22:57:29,148][INFO] writes 1581000 landmark faces
[2016-11-30 22:57:29,352][INFO] writes 1582000 landmark faces
[2016-11-30 22:57:29,586][INFO] writes 1583000 landmark faces
[2016-11-30 22:57:29,826][INFO] writes 1584000 landmark faces
[2016-11-30 22:57:30,058][INFO] writes 1585000 landmark faces
[2016-11-30 22:57:30,298][INFO] writes 1586000 landmark faces
[2016-11-30 22:57:30,522][INFO] writes 1587000 landmark faces
[2016-11-30 22:57:30,770][INFO] writes 1588000 landmark faces
[2016-11-30 22:57:30,984][INFO] writes 1589000 landmark faces
[2016-11-30 22:57:31,240][INFO] writes 1590000 landmark faces
[2016-11-30 22:57:31,512][INFO] writes 1591000 landmark faces
[2016-11-30 22:57:31,725][INFO] writes 1592000 landmark faces
[2016-11-30 22:57:31,738][INFO] Process-6 reads 20000
[2016-11-30 22:57:31,949][INFO] writes 1593000 landmark faces
[2016-11-30 22:57:31,987][INFO] Process-4 reads 20000
[2016-11-30 22:57:32,193][INFO] writes 1594000 landmark faces
[2016-11-30 22:57:32,312][INFO] Process-7 reads 20000
[2016-11-30 22:57:32,434][INFO] writes 1595000 landmark faces
[2016-11-30 22:57:32,734][INFO] writes 1596000 landmark faces
[2016-11-30 22:57:32,878][INFO] Process-1 reads 20000
[2016-11-30 22:57:32,975][INFO] writes 1597000 landmark faces
[2016-11-30 22:57:33,218][INFO] writes 1598000 landmark faces
[2016-11-30 22:57:33,468][INFO] writes 1599000 landmark faces
[2016-11-30 22:57:33,720][INFO] writes 1600000 landmark faces
[2016-11-30 22:57:33,882][INFO] Process-2 reads 20000
[2016-11-30 22:57:33,952][INFO] writes 1601000 landmark faces
[2016-11-30 22:57:34,220][INFO] writes 1602000 landmark faces
[2016-11-30 22:57:34,236][INFO] Process-8 reads 20000
[2016-11-30 22:57:34,477][INFO] writes 1603000 landmark faces
[2016-11-30 22:57:34,679][INFO] writes 1604000 landmark faces
[2016-11-30 22:57:34,921][INFO] writes 1605000 landmark faces
[2016-11-30 22:57:35,148][INFO] writes 1606000 landmark faces
[2016-11-30 22:57:35,382][INFO] writes 1607000 landmark faces
[2016-11-30 22:57:35,618][INFO] writes 1608000 landmark faces
[2016-11-30 22:57:35,812][INFO] Process-3 reads 20000
[2016-11-30 22:57:35,856][INFO] writes 1609000 landmark faces
[2016-11-30 22:57:36,083][INFO] writes 1610000 landmark faces
[2016-11-30 22:57:36,320][INFO] writes 1611000 landmark faces
[2016-11-30 22:57:36,551][INFO] writes 1612000 landmark faces
[2016-11-30 22:57:36,566][INFO] Process-5 reads 20000
[2016-11-30 22:57:36,778][INFO] writes 1613000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 22:57:37,057][INFO] writes 1614000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 22:57:37,328][INFO] writes 1615000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 22:57:37,721][INFO] writes 1616000 landmark faces
[2016-11-30 22:57:38,132][INFO] writes 1617000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 22:57:38,595][INFO] writes 1618000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 22:57:39,240][INFO] writes 1619000 landmark faces
[2016-11-30 22:57:40,016][INFO] writes 1620000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 22:57:51,267][INFO] Finish
[2016-11-30 22:57:51,367][INFO] writing val data, 40520 images
[2016-11-30 22:57:51,371][INFO] remove data/onet_landmark_val
[2016-11-30 22:57:51,388][INFO] fill queues
[2016-11-30 22:57:52,093][INFO] writes 1000 landmark faces
[2016-11-30 22:57:52,344][INFO] writes 2000 landmark faces
[2016-11-30 22:57:52,621][INFO] writes 3000 landmark faces
[2016-11-30 22:57:52,847][INFO] writes 4000 landmark faces
[2016-11-30 22:57:53,072][INFO] writes 5000 landmark faces
[2016-11-30 22:57:53,326][INFO] writes 6000 landmark faces
[2016-11-30 22:57:53,565][INFO] writes 7000 landmark faces
[2016-11-30 22:57:53,818][INFO] writes 8000 landmark faces
[2016-11-30 22:57:54,156][INFO] writes 9000 landmark faces
[2016-11-30 22:57:54,393][INFO] writes 10000 landmark faces
[2016-11-30 22:57:54,649][INFO] writes 11000 landmark faces
[2016-11-30 22:57:54,893][INFO] writes 12000 landmark faces
[2016-11-30 22:57:55,156][INFO] writes 13000 landmark faces
[2016-11-30 22:57:55,404][INFO] writes 14000 landmark faces
[2016-11-30 22:57:55,647][INFO] writes 15000 landmark faces
[2016-11-30 22:57:55,880][INFO] writes 16000 landmark faces
[2016-11-30 22:57:56,107][INFO] writes 17000 landmark faces
[2016-11-30 22:57:56,344][INFO] writes 18000 landmark faces
[2016-11-30 22:57:56,599][INFO] writes 19000 landmark faces
[2016-11-30 22:57:56,845][INFO] writes 20000 landmark faces
[2016-11-30 22:57:57,071][INFO] writes 21000 landmark faces
[2016-11-30 22:57:57,366][INFO] writes 22000 landmark faces
[2016-11-30 22:57:57,609][INFO] writes 23000 landmark faces
[2016-11-30 22:57:57,854][INFO] writes 24000 landmark faces
[2016-11-30 22:57:58,060][INFO] writes 25000 landmark faces
[2016-11-30 22:57:58,289][INFO] writes 26000 landmark faces
[2016-11-30 22:57:58,516][INFO] writes 27000 landmark faces
[2016-11-30 22:57:58,758][INFO] writes 28000 landmark faces
[2016-11-30 22:57:59,024][INFO] writes 29000 landmark faces
[2016-11-30 22:57:59,251][INFO] writes 30000 landmark faces
[2016-11-30 22:57:59,490][INFO] writes 31000 landmark faces
[2016-11-30 22:57:59,807][INFO] writes 32000 landmark faces
[2016-11-30 22:58:00,043][INFO] writes 33000 landmark faces
[2016-11-30 22:58:00,272][INFO] writes 34000 landmark faces
[2016-11-30 22:58:00,489][INFO] writes 35000 landmark faces
[2016-11-30 22:58:00,722][INFO] writes 36000 landmark faces
[2016-11-30 22:58:00,945][INFO] writes 37000 landmark faces
[2016-11-30 22:58:01,159][INFO] writes 38000 landmark faces
[2016-11-30 22:58:01,396][INFO] writes 39000 landmark faces
[2016-11-30 22:58:01,635][INFO] writes 40000 landmark faces
[2016-11-30 22:58:01,873][INFO] writes 41000 landmark faces
[2016-11-30 22:58:02,087][INFO] writes 42000 landmark faces
[2016-11-30 22:58:02,345][INFO] writes 43000 landmark faces
[2016-11-30 22:58:02,603][INFO] writes 44000 landmark faces
[2016-11-30 22:58:02,882][INFO] writes 45000 landmark faces
[2016-11-30 22:58:03,109][INFO] writes 46000 landmark faces
[2016-11-30 22:58:03,342][INFO] writes 47000 landmark faces
[2016-11-30 22:58:03,556][INFO] writes 48000 landmark faces
[2016-11-30 22:58:03,798][INFO] writes 49000 landmark faces
[2016-11-30 22:58:04,039][INFO] writes 50000 landmark faces
[2016-11-30 22:58:04,314][INFO] writes 51000 landmark faces
[2016-11-30 22:58:04,542][INFO] writes 52000 landmark faces
[2016-11-30 22:58:04,769][INFO] writes 53000 landmark faces
[2016-11-30 22:58:05,021][INFO] writes 54000 landmark faces
[2016-11-30 22:58:05,286][INFO] writes 55000 landmark faces
[2016-11-30 22:58:05,527][INFO] writes 56000 landmark faces
[2016-11-30 22:58:05,784][INFO] writes 57000 landmark faces
[2016-11-30 22:58:06,019][INFO] writes 58000 landmark faces
[2016-11-30 22:58:06,251][INFO] writes 59000 landmark faces
[2016-11-30 22:58:06,481][INFO] writes 60000 landmark faces
[2016-11-30 22:58:06,750][INFO] writes 61000 landmark faces
[2016-11-30 22:58:07,014][INFO] writes 62000 landmark faces
[2016-11-30 22:58:07,243][INFO] writes 63000 landmark faces
[2016-11-30 22:58:07,472][INFO] writes 64000 landmark faces
[2016-11-30 22:58:07,742][INFO] writes 65000 landmark faces
[2016-11-30 22:58:07,991][INFO] writes 66000 landmark faces
[2016-11-30 22:58:08,282][INFO] writes 67000 landmark faces
[2016-11-30 22:58:08,504][INFO] writes 68000 landmark faces
[2016-11-30 22:58:08,747][INFO] writes 69000 landmark faces
[2016-11-30 22:58:09,004][INFO] writes 70000 landmark faces
[2016-11-30 22:58:09,240][INFO] writes 71000 landmark faces
[2016-11-30 22:58:09,466][INFO] writes 72000 landmark faces
[2016-11-30 22:58:09,681][INFO] writes 73000 landmark faces
[2016-11-30 22:58:09,898][INFO] writes 74000 landmark faces
[2016-11-30 22:58:10,126][INFO] writes 75000 landmark faces
[2016-11-30 22:58:10,367][INFO] writes 76000 landmark faces
[2016-11-30 22:58:10,391][INFO] Process-15 reads 1000
[2016-11-30 22:58:10,580][INFO] writes 77000 landmark faces
[2016-11-30 22:58:10,689][INFO] Process-13 reads 1000
[2016-11-30 22:58:10,810][INFO] Process-10 reads 1000
[2016-11-30 22:58:10,825][INFO] writes 78000 landmark faces
[2016-11-30 22:58:11,045][INFO] Process-16 reads 1000
[2016-11-30 22:58:11,055][INFO] writes 79000 landmark faces
[2016-11-30 22:58:11,304][INFO] writes 80000 landmark faces
[2016-11-30 22:58:11,348][INFO] Process-12 reads 1000
[2016-11-30 22:58:11,375][INFO] Process-17 reads 1000
[2016-11-30 22:58:11,573][INFO] writes 81000 landmark faces
[2016-11-30 22:58:11,632][INFO] Process-11 reads 1000
[2016-11-30 22:58:11,801][INFO] writes 82000 landmark faces
[2016-11-30 22:58:12,032][INFO] writes 83000 landmark faces
[2016-11-30 22:58:12,259][INFO] writes 84000 landmark faces
[2016-11-30 22:58:12,544][INFO] writes 85000 landmark faces
[2016-11-30 22:58:12,810][INFO] writes 86000 landmark faces
[2016-11-30 22:58:13,009][INFO] writes 87000 landmark faces
[2016-11-30 22:58:13,243][INFO] writes 88000 landmark faces
[2016-11-30 22:58:13,490][INFO] writes 89000 landmark faces
[2016-11-30 22:58:13,504][INFO] Process-14 reads 1000
[2016-11-30 22:58:13,740][INFO] writes 90000 landmark faces
[2016-11-30 22:58:13,959][INFO] writes 91000 landmark faces
[2016-11-30 22:58:14,190][INFO] writes 92000 landmark faces
[2016-11-30 22:58:14,429][INFO] writes 93000 landmark faces
[2016-11-30 22:58:14,643][INFO] writes 94000 landmark faces
[2016-11-30 22:58:14,887][INFO] writes 95000 landmark faces
[2016-11-30 22:58:15,104][INFO] writes 96000 landmark faces
[2016-11-30 22:58:15,337][INFO] writes 97000 landmark faces
[2016-11-30 22:58:15,592][INFO] writes 98000 landmark faces
[2016-11-30 22:58:15,889][INFO] writes 99000 landmark faces
[2016-11-30 22:58:16,188][INFO] writes 100000 landmark faces
[2016-11-30 22:58:16,503][INFO] writes 101000 landmark faces
[2016-11-30 22:58:16,715][INFO] writes 102000 landmark faces
[2016-11-30 22:58:16,957][INFO] writes 103000 landmark faces
[2016-11-30 22:58:17,195][INFO] writes 104000 landmark faces
[2016-11-30 22:58:17,419][INFO] writes 105000 landmark faces
[2016-11-30 22:58:17,679][INFO] writes 106000 landmark faces
[2016-11-30 22:58:17,916][INFO] writes 107000 landmark faces
[2016-11-30 22:58:18,133][INFO] writes 108000 landmark faces
[2016-11-30 22:58:18,369][INFO] writes 109000 landmark faces
[2016-11-30 22:58:18,614][INFO] writes 110000 landmark faces
[2016-11-30 22:58:18,829][INFO] writes 111000 landmark faces
[2016-11-30 22:58:19,034][INFO] writes 112000 landmark faces
[2016-11-30 22:58:19,265][INFO] writes 113000 landmark faces
[2016-11-30 22:58:19,503][INFO] writes 114000 landmark faces
[2016-11-30 22:58:19,734][INFO] writes 115000 landmark faces
[2016-11-30 22:58:19,960][INFO] writes 116000 landmark faces
[2016-11-30 22:58:20,179][INFO] writes 117000 landmark faces
[2016-11-30 22:58:20,417][INFO] writes 118000 landmark faces
[2016-11-30 22:58:20,667][INFO] writes 119000 landmark faces
[2016-11-30 22:58:20,894][INFO] writes 120000 landmark faces
[2016-11-30 22:58:21,111][INFO] writes 121000 landmark faces
[2016-11-30 22:58:21,367][INFO] writes 122000 landmark faces
[2016-11-30 22:58:21,610][INFO] writes 123000 landmark faces
[2016-11-30 22:58:21,874][INFO] writes 124000 landmark faces
[2016-11-30 22:58:22,112][INFO] writes 125000 landmark faces
[2016-11-30 22:58:22,376][INFO] writes 126000 landmark faces
[2016-11-30 22:58:22,599][INFO] writes 127000 landmark faces
[2016-11-30 22:58:22,950][INFO] writes 128000 landmark faces
[2016-11-30 22:58:23,023][INFO] writes 129000 landmark faces
[2016-11-30 22:58:23,251][INFO] writes 130000 landmark faces
[2016-11-30 22:58:23,468][INFO] writes 131000 landmark faces
[2016-11-30 22:58:23,708][INFO] writes 132000 landmark faces
[2016-11-30 22:58:23,939][INFO] writes 133000 landmark faces
[2016-11-30 22:58:24,185][INFO] writes 134000 landmark faces
[2016-11-30 22:58:24,580][INFO] writes 135000 landmark faces
[2016-11-30 22:58:24,892][INFO] writes 136000 landmark faces
[2016-11-30 22:58:25,254][INFO] writes 137000 landmark faces
[2016-11-30 22:58:25,520][INFO] writes 138000 landmark faces
[2016-11-30 22:58:25,819][INFO] writes 139000 landmark faces
[2016-11-30 22:58:26,058][INFO] writes 140000 landmark faces
[2016-11-30 22:58:26,388][INFO] writes 141000 landmark faces
[2016-11-30 22:58:26,644][INFO] writes 142000 landmark faces
[2016-11-30 22:58:26,858][INFO] writes 143000 landmark faces
[2016-11-30 22:58:27,225][INFO] writes 144000 landmark faces
[2016-11-30 22:58:27,379][INFO] writes 145000 landmark faces
[2016-11-30 22:58:27,633][INFO] writes 146000 landmark faces
[2016-11-30 22:58:27,908][INFO] writes 147000 landmark faces
[2016-11-30 22:58:28,137][INFO] writes 148000 landmark faces
[2016-11-30 22:58:28,411][INFO] writes 149000 landmark faces
[2016-11-30 22:58:28,677][INFO] writes 150000 landmark faces
[2016-11-30 22:58:28,870][INFO] Process-15 reads 2000
[2016-11-30 22:58:28,905][INFO] writes 151000 landmark faces
[2016-11-30 22:58:29,178][INFO] writes 152000 landmark faces
[2016-11-30 22:58:29,411][INFO] writes 153000 landmark faces
[2016-11-30 22:58:29,657][INFO] writes 154000 landmark faces
[2016-11-30 22:58:29,887][INFO] Process-13 reads 2000
[2016-11-30 22:58:29,904][INFO] writes 155000 landmark faces
[2016-11-30 22:58:30,116][INFO] writes 156000 landmark faces
[2016-11-30 22:58:30,276][INFO] Process-11 reads 2000
[2016-11-30 22:58:30,377][INFO] writes 157000 landmark faces
[2016-11-30 22:58:30,466][INFO] Process-17 reads 2000
[2016-11-30 22:58:30,537][INFO] Process-10 reads 2000
[2016-11-30 22:58:30,576][INFO] writes 158000 landmark faces
[2016-11-30 22:58:30,818][INFO] writes 159000 landmark faces
[2016-11-30 22:58:31,157][INFO] writes 160000 landmark faces
[2016-11-30 22:58:31,351][INFO] writes 161000 landmark faces
[2016-11-30 22:58:31,611][INFO] writes 162000 landmark faces
[2016-11-30 22:58:31,835][INFO] writes 163000 landmark faces
[2016-11-30 22:58:32,082][INFO] writes 164000 landmark faces
[2016-11-30 22:58:32,343][INFO] writes 165000 landmark faces
[2016-11-30 22:58:32,439][INFO] Process-12 reads 2000
[2016-11-30 22:58:32,541][INFO] Process-16 reads 2000
[2016-11-30 22:58:32,614][INFO] writes 166000 landmark faces
[2016-11-30 22:58:32,857][INFO] writes 167000 landmark faces
[2016-11-30 22:58:33,115][INFO] writes 168000 landmark faces
[2016-11-30 22:58:33,341][INFO] writes 169000 landmark faces
[2016-11-30 22:58:33,540][INFO] Process-14 reads 2000
[2016-11-30 22:58:33,560][INFO] writes 170000 landmark faces
[2016-11-30 22:58:33,767][INFO] writes 171000 landmark faces
[2016-11-30 22:58:34,005][INFO] writes 172000 landmark faces
[2016-11-30 22:58:34,263][INFO] writes 173000 landmark faces
[2016-11-30 22:58:34,492][INFO] writes 174000 landmark faces
[2016-11-30 22:58:34,729][INFO] writes 175000 landmark faces
[2016-11-30 22:58:35,028][INFO] writes 176000 landmark faces
[2016-11-30 22:58:35,171][INFO] writes 177000 landmark faces
[2016-11-30 22:58:35,424][INFO] writes 178000 landmark faces
[2016-11-30 22:58:35,628][INFO] writes 179000 landmark faces
[2016-11-30 22:58:35,847][INFO] writes 180000 landmark faces
[2016-11-30 22:58:36,087][INFO] writes 181000 landmark faces
[2016-11-30 22:58:36,321][INFO] writes 182000 landmark faces
[2016-11-30 22:58:36,574][INFO] writes 183000 landmark faces
[2016-11-30 22:58:36,807][INFO] writes 184000 landmark faces
[2016-11-30 22:58:37,044][INFO] writes 185000 landmark faces
[2016-11-30 22:58:37,260][INFO] writes 186000 landmark faces
[2016-11-30 22:58:37,465][INFO] writes 187000 landmark faces
[2016-11-30 22:58:37,692][INFO] writes 188000 landmark faces
[2016-11-30 22:58:37,959][INFO] writes 189000 landmark faces
[2016-11-30 22:58:38,195][INFO] writes 190000 landmark faces
[2016-11-30 22:58:38,445][INFO] writes 191000 landmark faces
[2016-11-30 22:58:38,739][INFO] writes 192000 landmark faces
[2016-11-30 22:58:38,926][INFO] writes 193000 landmark faces
[2016-11-30 22:58:39,148][INFO] writes 194000 landmark faces
[2016-11-30 22:58:39,361][INFO] writes 195000 landmark faces
[2016-11-30 22:58:39,618][INFO] writes 196000 landmark faces
[2016-11-30 22:58:39,871][INFO] writes 197000 landmark faces
[2016-11-30 22:58:40,125][INFO] writes 198000 landmark faces
[2016-11-30 22:58:40,366][INFO] writes 199000 landmark faces
[2016-11-30 22:58:40,607][INFO] writes 200000 landmark faces
[2016-11-30 22:58:40,829][INFO] writes 201000 landmark faces
[2016-11-30 22:58:41,045][INFO] writes 202000 landmark faces
[2016-11-30 22:58:41,299][INFO] writes 203000 landmark faces
[2016-11-30 22:58:41,525][INFO] writes 204000 landmark faces
[2016-11-30 22:58:41,718][INFO] writes 205000 landmark faces
[2016-11-30 22:58:41,918][INFO] writes 206000 landmark faces
[2016-11-30 22:58:42,162][INFO] writes 207000 landmark faces
[2016-11-30 22:58:42,456][INFO] writes 208000 landmark faces
[2016-11-30 22:58:42,674][INFO] writes 209000 landmark faces
[2016-11-30 22:58:42,908][INFO] writes 210000 landmark faces
[2016-11-30 22:58:43,131][INFO] writes 211000 landmark faces
[2016-11-30 22:58:43,379][INFO] writes 212000 landmark faces
[2016-11-30 22:58:43,593][INFO] writes 213000 landmark faces
[2016-11-30 22:58:43,851][INFO] writes 214000 landmark faces
[2016-11-30 22:58:44,103][INFO] writes 215000 landmark faces
[2016-11-30 22:58:44,357][INFO] writes 216000 landmark faces
[2016-11-30 22:58:44,581][INFO] writes 217000 landmark faces
[2016-11-30 22:58:44,800][INFO] writes 218000 landmark faces
[2016-11-30 22:58:45,025][INFO] writes 219000 landmark faces
[2016-11-30 22:58:45,262][INFO] writes 220000 landmark faces
[2016-11-30 22:58:45,479][INFO] writes 221000 landmark faces
[2016-11-30 22:58:45,679][INFO] writes 222000 landmark faces
[2016-11-30 22:58:45,907][INFO] writes 223000 landmark faces
[2016-11-30 22:58:46,211][INFO] writes 224000 landmark faces
[2016-11-30 22:58:46,371][INFO] writes 225000 landmark faces
[2016-11-30 22:58:46,587][INFO] writes 226000 landmark faces
[2016-11-30 22:58:46,830][INFO] writes 227000 landmark faces
[2016-11-30 22:58:47,054][INFO] writes 228000 landmark faces
[2016-11-30 22:58:47,299][INFO] Process-15 reads 3000
[2016-11-30 22:58:47,304][INFO] writes 229000 landmark faces
[2016-11-30 22:58:47,515][INFO] writes 230000 landmark faces
[2016-11-30 22:58:47,747][INFO] writes 231000 landmark faces
[2016-11-30 22:58:47,974][INFO] writes 232000 landmark faces
[2016-11-30 22:58:48,213][INFO] writes 233000 landmark faces
[2016-11-30 22:58:48,366][INFO] Process-11 reads 3000
[2016-11-30 22:58:48,459][INFO] writes 234000 landmark faces
[2016-11-30 22:58:48,674][INFO] Process-13 reads 3000
[2016-11-30 22:58:48,725][INFO] writes 235000 landmark faces
[2016-11-30 22:58:48,960][INFO] writes 236000 landmark faces
[2016-11-30 22:58:49,172][INFO] writes 237000 landmark faces
[2016-11-30 22:58:49,236][INFO] Process-17 reads 3000
[2016-11-30 22:58:49,393][INFO] writes 238000 landmark faces
[2016-11-30 22:58:49,620][INFO] writes 239000 landmark faces
[2016-11-30 22:58:49,887][INFO] writes 240000 landmark faces
[2016-11-30 22:58:50,039][INFO] writes 241000 landmark faces
[2016-11-30 22:58:50,117][INFO] Process-10 reads 3000
[2016-11-30 22:58:50,244][INFO] writes 242000 landmark faces
[2016-11-30 22:58:50,461][INFO] writes 243000 landmark faces
[2016-11-30 22:58:50,719][INFO] writes 244000 landmark faces
[2016-11-30 22:58:51,006][INFO] writes 245000 landmark faces
[2016-11-30 22:58:51,214][INFO] writes 246000 landmark faces
[2016-11-30 22:58:51,312][INFO] Process-16 reads 3000
[2016-11-30 22:58:51,321][INFO] Process-12 reads 3000
[2016-11-30 22:58:51,425][INFO] writes 247000 landmark faces
[2016-11-30 22:58:51,636][INFO] writes 248000 landmark faces
[2016-11-30 22:58:51,867][INFO] writes 249000 landmark faces
[2016-11-30 22:58:51,940][INFO] Process-14 reads 3000
[2016-11-30 22:58:52,097][INFO] writes 250000 landmark faces
[2016-11-30 22:58:52,337][INFO] writes 251000 landmark faces
[2016-11-30 22:58:52,560][INFO] writes 252000 landmark faces
[2016-11-30 22:58:52,765][INFO] writes 253000 landmark faces
[2016-11-30 22:58:52,988][INFO] writes 254000 landmark faces
[2016-11-30 22:58:53,210][INFO] writes 255000 landmark faces
[2016-11-30 22:58:53,515][INFO] writes 256000 landmark faces
[2016-11-30 22:58:53,689][INFO] writes 257000 landmark faces
[2016-11-30 22:58:53,943][INFO] writes 258000 landmark faces
[2016-11-30 22:58:54,217][INFO] writes 259000 landmark faces
[2016-11-30 22:58:54,415][INFO] writes 260000 landmark faces
[2016-11-30 22:58:54,627][INFO] writes 261000 landmark faces
[2016-11-30 22:58:54,863][INFO] writes 262000 landmark faces
[2016-11-30 22:58:55,116][INFO] writes 263000 landmark faces
[2016-11-30 22:58:55,337][INFO] writes 264000 landmark faces
[2016-11-30 22:58:55,564][INFO] writes 265000 landmark faces
[2016-11-30 22:58:55,801][INFO] writes 266000 landmark faces
[2016-11-30 22:58:56,018][INFO] writes 267000 landmark faces
[2016-11-30 22:58:56,255][INFO] writes 268000 landmark faces
[2016-11-30 22:58:56,479][INFO] writes 269000 landmark faces
[2016-11-30 22:58:56,723][INFO] writes 270000 landmark faces
[2016-11-30 22:58:56,942][INFO] writes 271000 landmark faces
[2016-11-30 22:58:57,184][INFO] writes 272000 landmark faces
[2016-11-30 22:58:57,368][INFO] writes 273000 landmark faces
[2016-11-30 22:58:57,593][INFO] writes 274000 landmark faces
[2016-11-30 22:58:57,803][INFO] writes 275000 landmark faces
[2016-11-30 22:58:58,055][INFO] writes 276000 landmark faces
[2016-11-30 22:58:58,274][INFO] writes 277000 landmark faces
[2016-11-30 22:58:58,509][INFO] writes 278000 landmark faces
[2016-11-30 22:58:58,724][INFO] writes 279000 landmark faces
[2016-11-30 22:58:58,978][INFO] writes 280000 landmark faces
[2016-11-30 22:58:59,198][INFO] writes 281000 landmark faces
[2016-11-30 22:58:59,444][INFO] writes 282000 landmark faces
[2016-11-30 22:58:59,680][INFO] writes 283000 landmark faces
[2016-11-30 22:59:00,161][INFO] writes 284000 landmark faces
[2016-11-30 22:59:00,558][INFO] writes 285000 landmark faces
[2016-11-30 22:59:00,830][INFO] writes 286000 landmark faces
[2016-11-30 22:59:01,230][INFO] writes 287000 landmark faces
[2016-11-30 22:59:01,692][INFO] writes 288000 landmark faces
[2016-11-30 22:59:01,968][INFO] writes 289000 landmark faces
[2016-11-30 22:59:02,170][INFO] writes 290000 landmark faces
[2016-11-30 22:59:02,518][INFO] writes 291000 landmark faces
[2016-11-30 22:59:02,812][INFO] writes 292000 landmark faces
[2016-11-30 22:59:03,108][INFO] writes 293000 landmark faces
[2016-11-30 22:59:03,322][INFO] writes 294000 landmark faces
[2016-11-30 22:59:03,628][INFO] writes 295000 landmark faces
[2016-11-30 22:59:03,847][INFO] writes 296000 landmark faces
[2016-11-30 22:59:04,265][INFO] writes 297000 landmark faces
[2016-11-30 22:59:04,520][INFO] writes 298000 landmark faces
[2016-11-30 22:59:04,745][INFO] writes 299000 landmark faces
[2016-11-30 22:59:04,979][INFO] writes 300000 landmark faces
[2016-11-30 22:59:05,207][INFO] writes 301000 landmark faces
[2016-11-30 22:59:05,495][INFO] writes 302000 landmark faces
[2016-11-30 22:59:05,882][INFO] writes 303000 landmark faces
[2016-11-30 22:59:06,179][INFO] writes 304000 landmark faces
[2016-11-30 22:59:06,468][INFO] writes 305000 landmark faces
[2016-11-30 22:59:06,729][INFO] writes 306000 landmark faces
[2016-11-30 22:59:06,948][INFO] writes 307000 landmark faces
[2016-11-30 22:59:07,219][INFO] Process-15 reads 4000
[2016-11-30 22:59:07,223][INFO] writes 308000 landmark faces
[2016-11-30 22:59:07,611][INFO] writes 309000 landmark faces
[2016-11-30 22:59:07,875][INFO] writes 310000 landmark faces
[2016-11-30 22:59:08,113][INFO] writes 311000 landmark faces
[2016-11-30 22:59:08,484][INFO] Process-11 reads 4000
[2016-11-30 22:59:08,515][INFO] writes 312000 landmark faces
[2016-11-30 22:59:08,837][INFO] writes 313000 landmark faces
[2016-11-30 22:59:08,929][INFO] Process-13 reads 4000
[2016-11-30 22:59:09,078][INFO] writes 314000 landmark faces
[2016-11-30 22:59:09,467][INFO] writes 315000 landmark faces
[2016-11-30 22:59:09,712][INFO] writes 316000 landmark faces
[2016-11-30 22:59:09,835][INFO] Process-17 reads 4000
[2016-11-30 22:59:10,012][INFO] writes 317000 landmark faces
[2016-11-30 22:59:10,242][INFO] writes 318000 landmark faces
[2016-11-30 22:59:10,442][INFO] writes 319000 landmark faces
[2016-11-30 22:59:10,659][INFO] writes 320000 landmark faces
[2016-11-30 22:59:10,865][INFO] writes 321000 landmark faces
[2016-11-30 22:59:11,099][INFO] writes 322000 landmark faces
[2016-11-30 22:59:11,329][INFO] writes 323000 landmark faces
[2016-11-30 22:59:11,541][INFO] writes 324000 landmark faces
[2016-11-30 22:59:11,705][INFO] Process-10 reads 4000
[2016-11-30 22:59:11,760][INFO] writes 325000 landmark faces
[2016-11-30 22:59:11,983][INFO] writes 326000 landmark faces
[2016-11-30 22:59:12,189][INFO] writes 327000 landmark faces
[2016-11-30 22:59:12,374][INFO] Process-12 reads 4000
[2016-11-30 22:59:12,389][INFO] writes 328000 landmark faces
[2016-11-30 22:59:12,620][INFO] writes 329000 landmark faces
[2016-11-30 22:59:12,663][INFO] Process-16 reads 4000
[2016-11-30 22:59:12,831][INFO] writes 330000 landmark faces
[2016-11-30 22:59:12,885][INFO] Process-14 reads 4000
[2016-11-30 22:59:13,066][INFO] writes 331000 landmark faces
[2016-11-30 22:59:13,269][INFO] writes 332000 landmark faces
[2016-11-30 22:59:13,481][INFO] writes 333000 landmark faces
[2016-11-30 22:59:13,759][INFO] writes 334000 landmark faces
[2016-11-30 22:59:13,980][INFO] writes 335000 landmark faces
[2016-11-30 22:59:14,210][INFO] writes 336000 landmark faces
[2016-11-30 22:59:14,443][INFO] writes 337000 landmark faces
[2016-11-30 22:59:14,648][INFO] writes 338000 landmark faces
[2016-11-30 22:59:14,875][INFO] writes 339000 landmark faces
[2016-11-30 22:59:15,082][INFO] writes 340000 landmark faces
[2016-11-30 22:59:15,320][INFO] writes 341000 landmark faces
[2016-11-30 22:59:15,515][INFO] writes 342000 landmark faces
[2016-11-30 22:59:15,729][INFO] writes 343000 landmark faces
[2016-11-30 22:59:15,978][INFO] writes 344000 landmark faces
[2016-11-30 22:59:16,237][INFO] writes 345000 landmark faces
[2016-11-30 22:59:16,460][INFO] writes 346000 landmark faces
[2016-11-30 22:59:16,738][INFO] writes 347000 landmark faces
[2016-11-30 22:59:16,948][INFO] writes 348000 landmark faces
[2016-11-30 22:59:17,158][INFO] writes 349000 landmark faces
[2016-11-30 22:59:17,377][INFO] writes 350000 landmark faces
[2016-11-30 22:59:17,610][INFO] writes 351000 landmark faces
[2016-11-30 22:59:17,889][INFO] writes 352000 landmark faces
[2016-11-30 22:59:18,117][INFO] writes 353000 landmark faces
[2016-11-30 22:59:18,348][INFO] writes 354000 landmark faces
[2016-11-30 22:59:18,569][INFO] writes 355000 landmark faces
[2016-11-30 22:59:18,795][INFO] writes 356000 landmark faces
[2016-11-30 22:59:19,026][INFO] writes 357000 landmark faces
[2016-11-30 22:59:19,247][INFO] writes 358000 landmark faces
[2016-11-30 22:59:19,459][INFO] writes 359000 landmark faces
[2016-11-30 22:59:19,680][INFO] writes 360000 landmark faces
[2016-11-30 22:59:19,931][INFO] writes 361000 landmark faces
[2016-11-30 22:59:20,182][INFO] writes 362000 landmark faces
[2016-11-30 22:59:20,408][INFO] writes 363000 landmark faces
[2016-11-30 22:59:20,613][INFO] writes 364000 landmark faces
[2016-11-30 22:59:20,840][INFO] writes 365000 landmark faces
[2016-11-30 22:59:21,050][INFO] writes 366000 landmark faces
[2016-11-30 22:59:21,306][INFO] writes 367000 landmark faces
[2016-11-30 22:59:21,562][INFO] writes 368000 landmark faces
[2016-11-30 22:59:21,789][INFO] writes 369000 landmark faces
[2016-11-30 22:59:22,022][INFO] writes 370000 landmark faces
[2016-11-30 22:59:22,256][INFO] writes 371000 landmark faces
[2016-11-30 22:59:22,491][INFO] writes 372000 landmark faces
[2016-11-30 22:59:22,710][INFO] writes 373000 landmark faces
[2016-11-30 22:59:22,953][INFO] writes 374000 landmark faces
[2016-11-30 22:59:23,165][INFO] writes 375000 landmark faces
[2016-11-30 22:59:23,410][INFO] writes 376000 landmark faces
[2016-11-30 22:59:23,710][INFO] writes 377000 landmark faces
[2016-11-30 22:59:23,945][INFO] writes 378000 landmark faces
[2016-11-30 22:59:24,211][INFO] writes 379000 landmark faces
[2016-11-30 22:59:24,417][INFO] writes 380000 landmark faces
[2016-11-30 22:59:24,655][INFO] writes 381000 landmark faces
[2016-11-30 22:59:24,894][INFO] writes 382000 landmark faces
[2016-11-30 22:59:25,099][INFO] writes 383000 landmark faces
[2016-11-30 22:59:25,361][INFO] writes 384000 landmark faces
[2016-11-30 22:59:25,548][INFO] writes 385000 landmark faces
[2016-11-30 22:59:25,788][INFO] writes 386000 landmark faces
[2016-11-30 22:59:26,050][INFO] writes 387000 landmark faces
[2016-11-30 22:59:26,251][INFO] writes 388000 landmark faces
[2016-11-30 22:59:26,309][INFO] Process-13 reads 5000
[2016-11-30 22:59:26,485][INFO] writes 389000 landmark faces
[2016-11-30 22:59:26,706][INFO] writes 390000 landmark faces
[2016-11-30 22:59:26,827][INFO] Process-15 reads 5000
[2016-11-30 22:59:26,928][INFO] Process-11 reads 5000
[2016-11-30 22:59:26,951][INFO] writes 391000 landmark faces
[2016-11-30 22:59:27,166][INFO] writes 392000 landmark faces
[2016-11-30 22:59:27,395][INFO] writes 393000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 22:59:27,635][INFO] writes 394000 landmark faces
[2016-11-30 22:59:27,681][INFO] Process-17 reads 5000
[2016-11-30 22:59:27,900][INFO] writes 395000 landmark faces
[2016-11-30 22:59:28,165][INFO] writes 396000 landmark faces
[2016-11-30 22:59:28,525][INFO] writes 397000 landmark faces
[2016-11-30 22:59:28,900][INFO] writes 398000 landmark faces
[2016-11-30 22:59:29,380][INFO] writes 399000 landmark faces
[2016-11-30 22:59:29,762][INFO] writes 400000 landmark faces
[2016-11-30 22:59:30,165][INFO] writes 401000 landmark faces
[2016-11-30 22:59:30,257][INFO] Process-14 reads 5000
[2016-11-30 22:59:30,485][INFO] Process-10 reads 5000
[2016-11-30 22:59:30,569][INFO] writes 402000 landmark faces
[2016-11-30 22:59:30,644][INFO] Process-12 reads 5000
[2016-11-30 22:59:30,966][INFO] writes 403000 landmark faces
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[WARN] ridiculous x1, y1, x2, y2
[2016-11-30 22:59:31,387][INFO] writes 404000 landmark faces
[2016-11-30 22:59:32,076][INFO] Process-16 reads 5000
[2016-11-30 22:59:32,867][INFO] writes 405000 landmark faces
[2016-11-30 22:59:45,692][INFO] Finish
[2016-11-30 22:59:48,381][INFO] loading WIDER
[2016-11-30 22:59:49,128][INFO] total images, train: 12797, val: 3196
[2016-11-30 22:59:49,131][INFO] total faces, train: 97311, val: 24101
[2016-11-30 22:59:49,131][INFO] writing train data, 12797 images
[2016-11-30 22:59:49,131][INFO] remove data/onet_positive_train
[2016-11-30 22:59:49,131][INFO] remove data/onet_negative_train
[2016-11-30 22:59:49,131][INFO] remove data/onet_part_train
[2016-11-30 22:59:49,132][INFO] fill queues
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 22:59:51.360960 12480 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
  }
}
I1130 22:59:51.361117 12480 layer_factory.hpp:77] Creating layer data
I1130 22:59:51.361140 12480 net.cpp:100] Creating Layer data
I1130 22:59:51.361147 12480 net.cpp:408] data -> data
I1130 22:59:51.380074 12480 net.cpp:150] Setting up data
I1130 22:59:51.380120 12480 net.cpp:157] Top shape: 1 3 12 12 (432)
I1130 22:59:51.380125 12480 net.cpp:165] Memory required for data: 1728
I1130 22:59:51.380132 12480 layer_factory.hpp:77] Creating layer conv1
I1130 22:59:51.380151 12480 net.cpp:100] Creating Layer conv1
I1130 22:59:51.380156 12480 net.cpp:434] conv1 <- data
I1130 22:59:51.380162 12480 net.cpp:408] conv1 -> conv1
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 22:59:51.401788 12481 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
  }
}
I1130 22:59:51.401952 12481 layer_factory.hpp:77] Creating layer data
I1130 22:59:51.401981 12481 net.cpp:100] Creating Layer data
I1130 22:59:51.401990 12481 net.cpp:408] data -> data
I1130 22:59:51.420774 12481 net.cpp:150] Setting up data
I1130 22:59:51.420832 12481 net.cpp:157] Top shape: 1 3 12 12 (432)
I1130 22:59:51.420837 12481 net.cpp:165] Memory required for data: 1728
I1130 22:59:51.420847 12481 layer_factory.hpp:77] Creating layer conv1
I1130 22:59:51.420868 12481 net.cpp:100] Creating Layer conv1
I1130 22:59:51.420874 12481 net.cpp:434] conv1 <- data
I1130 22:59:51.420882 12481 net.cpp:408] conv1 -> conv1
I1130 22:59:51.663473 12480 net.cpp:150] Setting up conv1
I1130 22:59:51.663532 12480 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:59:51.663538 12480 net.cpp:165] Memory required for data: 5728
I1130 22:59:51.663570 12480 layer_factory.hpp:77] Creating layer prelu1
I1130 22:59:51.663595 12480 net.cpp:100] Creating Layer prelu1
I1130 22:59:51.663601 12480 net.cpp:434] prelu1 <- conv1
I1130 22:59:51.663607 12480 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:59:51.663722 12480 net.cpp:150] Setting up prelu1
I1130 22:59:51.663733 12480 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:59:51.663738 12480 net.cpp:165] Memory required for data: 9728
I1130 22:59:51.663746 12480 layer_factory.hpp:77] Creating layer pool1
I1130 22:59:51.663758 12480 net.cpp:100] Creating Layer pool1
I1130 22:59:51.663763 12480 net.cpp:434] pool1 <- conv1
I1130 22:59:51.663769 12480 net.cpp:408] pool1 -> pool1
I1130 22:59:51.663810 12480 net.cpp:150] Setting up pool1
I1130 22:59:51.663817 12480 net.cpp:157] Top shape: 1 10 5 5 (250)
I1130 22:59:51.663821 12480 net.cpp:165] Memory required for data: 10728
I1130 22:59:51.663825 12480 layer_factory.hpp:77] Creating layer conv2
I1130 22:59:51.663837 12480 net.cpp:100] Creating Layer conv2
I1130 22:59:51.663841 12480 net.cpp:434] conv2 <- pool1
I1130 22:59:51.663846 12480 net.cpp:408] conv2 -> conv2
I1130 22:59:51.666460 12480 net.cpp:150] Setting up conv2
I1130 22:59:51.666482 12480 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:59:51.666487 12480 net.cpp:165] Memory required for data: 11304
I1130 22:59:51.666499 12480 layer_factory.hpp:77] Creating layer prelu2
I1130 22:59:51.666509 12480 net.cpp:100] Creating Layer prelu2
I1130 22:59:51.666513 12480 net.cpp:434] prelu2 <- conv2
I1130 22:59:51.666520 12480 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:59:51.666616 12480 net.cpp:150] Setting up prelu2
I1130 22:59:51.666625 12480 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:59:51.666628 12480 net.cpp:165] Memory required for data: 11880
I1130 22:59:51.666635 12480 layer_factory.hpp:77] Creating layer conv3
I1130 22:59:51.666645 12480 net.cpp:100] Creating Layer conv3
I1130 22:59:51.666649 12480 net.cpp:434] conv3 <- conv2
I1130 22:59:51.666656 12480 net.cpp:408] conv3 -> conv3
I1130 22:59:51.669235 12480 net.cpp:150] Setting up conv3
I1130 22:59:51.669256 12480 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:59:51.669261 12480 net.cpp:165] Memory required for data: 12008
I1130 22:59:51.669270 12480 layer_factory.hpp:77] Creating layer prelu3
I1130 22:59:51.669281 12480 net.cpp:100] Creating Layer prelu3
I1130 22:59:51.669296 12480 net.cpp:434] prelu3 <- conv3
I1130 22:59:51.669302 12480 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:59:51.669400 12480 net.cpp:150] Setting up prelu3
I1130 22:59:51.669409 12480 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:59:51.669411 12480 net.cpp:165] Memory required for data: 12136
I1130 22:59:51.669420 12480 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 22:59:51.669435 12480 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 22:59:51.669440 12480 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 22:59:51.669445 12480 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 22:59:51.669451 12480 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 22:59:51.669457 12480 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 22:59:51.669509 12480 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 22:59:51.669517 12480 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:59:51.669522 12480 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:59:51.669525 12480 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:59:51.669528 12480 net.cpp:165] Memory required for data: 12520
I1130 22:59:51.669533 12480 layer_factory.hpp:77] Creating layer score
I1130 22:59:51.669541 12480 net.cpp:100] Creating Layer score
I1130 22:59:51.669545 12480 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 22:59:51.669551 12480 net.cpp:408] score -> score
I1130 22:59:51.670626 12480 net.cpp:150] Setting up score
I1130 22:59:51.670645 12480 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:59:51.670650 12480 net.cpp:165] Memory required for data: 12528
I1130 22:59:51.670657 12480 layer_factory.hpp:77] Creating layer prob
I1130 22:59:51.670670 12480 net.cpp:100] Creating Layer prob
I1130 22:59:51.670675 12480 net.cpp:434] prob <- score
I1130 22:59:51.670680 12480 net.cpp:408] prob -> prob
I1130 22:59:51.670939 12480 net.cpp:150] Setting up prob
I1130 22:59:51.670950 12480 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:59:51.670954 12480 net.cpp:165] Memory required for data: 12536
I1130 22:59:51.670958 12480 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:59:51.670969 12480 net.cpp:100] Creating Layer bbox_pred
I1130 22:59:51.670974 12480 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 22:59:51.670979 12480 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:59:51.672080 12480 net.cpp:150] Setting up bbox_pred
I1130 22:59:51.672099 12480 net.cpp:157] Top shape: 1 4 1 1 (4)
I1130 22:59:51.672106 12480 net.cpp:165] Memory required for data: 12552
I1130 22:59:51.672116 12480 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:59:51.672124 12480 net.cpp:100] Creating Layer landmark_pred
I1130 22:59:51.672128 12480 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 22:59:51.672137 12480 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:59:51.673241 12480 net.cpp:150] Setting up landmark_pred
I1130 22:59:51.673260 12480 net.cpp:157] Top shape: 1 10 1 1 (10)
I1130 22:59:51.673264 12480 net.cpp:165] Memory required for data: 12592
I1130 22:59:51.673272 12480 net.cpp:228] landmark_pred does not need backward computation.
I1130 22:59:51.673277 12480 net.cpp:228] bbox_pred does not need backward computation.
I1130 22:59:51.673281 12480 net.cpp:228] prob does not need backward computation.
I1130 22:59:51.673285 12480 net.cpp:228] score does not need backward computation.
I1130 22:59:51.673288 12480 net.cpp:228] conv3_prelu3_0_split does not need backward computation.
I1130 22:59:51.673292 12480 net.cpp:228] prelu3 does not need backward computation.
I1130 22:59:51.673295 12480 net.cpp:228] conv3 does not need backward computation.
I1130 22:59:51.673300 12480 net.cpp:228] prelu2 does not need backward computation.
I1130 22:59:51.673302 12480 net.cpp:228] conv2 does not need backward computation.
I1130 22:59:51.673306 12480 net.cpp:228] pool1 does not need backward computation.
I1130 22:59:51.673310 12480 net.cpp:228] prelu1 does not need backward computation.
I1130 22:59:51.673313 12480 net.cpp:228] conv1 does not need backward computation.
I1130 22:59:51.673326 12480 net.cpp:228] data does not need backward computation.
I1130 22:59:51.673329 12480 net.cpp:270] This network produces output bbox_pred
I1130 22:59:51.673334 12480 net.cpp:270] This network produces output landmark_pred
I1130 22:59:51.673338 12480 net.cpp:270] This network produces output prob
I1130 22:59:51.673354 12480 net.cpp:283] Network initialization done.
I1130 22:59:51.673642 12480 net.cpp:761] Ignoring source layer loss
I1130 22:59:51.692687 12480 net.cpp:58] Initializing net from parameters: 
name: "rNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 24
      dim: 24
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "conv3"
  top: "fc"
  inner_product_param {
    num_output: 128
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "fc"
  top: "fc"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "fc"
  top: "score"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "bbox_pred"
  inner_product_param {
    num_output: 4
  }
}
layer {
  name: "landmark_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "landmark_pred"
  inner_product_param {
    num_output: 10
  }
}
I1130 22:59:51.692777 12480 layer_factory.hpp:77] Creating layer data
I1130 22:59:51.692790 12480 net.cpp:100] Creating Layer data
I1130 22:59:51.692796 12480 net.cpp:408] data -> data
I1130 22:59:51.692867 12480 net.cpp:150] Setting up data
I1130 22:59:51.692876 12480 net.cpp:157] Top shape: 1 3 24 24 (1728)
I1130 22:59:51.692879 12480 net.cpp:165] Memory required for data: 6912
I1130 22:59:51.692884 12480 layer_factory.hpp:77] Creating layer conv1
I1130 22:59:51.692893 12480 net.cpp:100] Creating Layer conv1
I1130 22:59:51.692898 12480 net.cpp:434] conv1 <- data
I1130 22:59:51.692903 12480 net.cpp:408] conv1 -> conv1
I1130 22:59:51.694147 12480 net.cpp:150] Setting up conv1
I1130 22:59:51.694169 12480 net.cpp:157] Top shape: 1 28 22 22 (13552)
I1130 22:59:51.694174 12480 net.cpp:165] Memory required for data: 61120
I1130 22:59:51.694185 12480 layer_factory.hpp:77] Creating layer prelu1
I1130 22:59:51.694197 12480 net.cpp:100] Creating Layer prelu1
I1130 22:59:51.694202 12480 net.cpp:434] prelu1 <- conv1
I1130 22:59:51.694207 12480 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:59:51.694344 12480 net.cpp:150] Setting up prelu1
I1130 22:59:51.694352 12480 net.cpp:157] Top shape: 1 28 22 22 (13552)
I1130 22:59:51.694356 12480 net.cpp:165] Memory required for data: 115328
I1130 22:59:51.694365 12480 layer_factory.hpp:77] Creating layer pool1
I1130 22:59:51.694373 12480 net.cpp:100] Creating Layer pool1
I1130 22:59:51.694376 12480 net.cpp:434] pool1 <- conv1
I1130 22:59:51.694385 12480 net.cpp:408] pool1 -> pool1
I1130 22:59:51.694425 12480 net.cpp:150] Setting up pool1
I1130 22:59:51.694434 12480 net.cpp:157] Top shape: 1 28 11 11 (3388)
I1130 22:59:51.694438 12480 net.cpp:165] Memory required for data: 128880
I1130 22:59:51.694449 12480 layer_factory.hpp:77] Creating layer conv2
I1130 22:59:51.694458 12480 net.cpp:100] Creating Layer conv2
I1130 22:59:51.694461 12480 net.cpp:434] conv2 <- pool1
I1130 22:59:51.694469 12480 net.cpp:408] conv2 -> conv2
I1130 22:59:51.695600 12480 net.cpp:150] Setting up conv2
I1130 22:59:51.695618 12480 net.cpp:157] Top shape: 1 48 9 9 (3888)
I1130 22:59:51.695623 12480 net.cpp:165] Memory required for data: 144432
I1130 22:59:51.695633 12480 layer_factory.hpp:77] Creating layer prelu2
I1130 22:59:51.695643 12480 net.cpp:100] Creating Layer prelu2
I1130 22:59:51.695648 12480 net.cpp:434] prelu2 <- conv2
I1130 22:59:51.695653 12480 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:59:51.695775 12480 net.cpp:150] Setting up prelu2
I1130 22:59:51.695783 12480 net.cpp:157] Top shape: 1 48 9 9 (3888)
I1130 22:59:51.695786 12480 net.cpp:165] Memory required for data: 159984
I1130 22:59:51.695791 12480 layer_factory.hpp:77] Creating layer pool2
I1130 22:59:51.695801 12480 net.cpp:100] Creating Layer pool2
I1130 22:59:51.695806 12480 net.cpp:434] pool2 <- conv2
I1130 22:59:51.695811 12480 net.cpp:408] pool2 -> pool2
I1130 22:59:51.695852 12480 net.cpp:150] Setting up pool2
I1130 22:59:51.695859 12480 net.cpp:157] Top shape: 1 48 4 4 (768)
I1130 22:59:51.695863 12480 net.cpp:165] Memory required for data: 163056
I1130 22:59:51.695866 12480 layer_factory.hpp:77] Creating layer conv3
I1130 22:59:51.695875 12480 net.cpp:100] Creating Layer conv3
I1130 22:59:51.695878 12480 net.cpp:434] conv3 <- pool2
I1130 22:59:51.695883 12480 net.cpp:408] conv3 -> conv3
I1130 22:59:51.696735 12480 net.cpp:150] Setting up conv3
I1130 22:59:51.696753 12480 net.cpp:157] Top shape: 1 64 3 3 (576)
I1130 22:59:51.696756 12480 net.cpp:165] Memory required for data: 165360
I1130 22:59:51.696764 12480 layer_factory.hpp:77] Creating layer prelu3
I1130 22:59:51.696774 12480 net.cpp:100] Creating Layer prelu3
I1130 22:59:51.696779 12480 net.cpp:434] prelu3 <- conv3
I1130 22:59:51.696784 12480 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:59:51.696892 12480 net.cpp:150] Setting up prelu3
I1130 22:59:51.696899 12480 net.cpp:157] Top shape: 1 64 3 3 (576)
I1130 22:59:51.696902 12480 net.cpp:165] Memory required for data: 167664
I1130 22:59:51.696910 12480 layer_factory.hpp:77] Creating layer fc
I1130 22:59:51.696919 12480 net.cpp:100] Creating Layer fc
I1130 22:59:51.696923 12480 net.cpp:434] fc <- conv3
I1130 22:59:51.696938 12480 net.cpp:408] fc -> fc
I1130 22:59:51.698719 12480 net.cpp:150] Setting up fc
I1130 22:59:51.698737 12480 net.cpp:157] Top shape: 1 128 (128)
I1130 22:59:51.698741 12480 net.cpp:165] Memory required for data: 168176
I1130 22:59:51.698750 12480 layer_factory.hpp:77] Creating layer prelu4
I1130 22:59:51.698760 12480 net.cpp:100] Creating Layer prelu4
I1130 22:59:51.698763 12480 net.cpp:434] prelu4 <- fc
I1130 22:59:51.698768 12480 net.cpp:395] prelu4 -> fc (in-place)
I1130 22:59:51.698848 12480 net.cpp:150] Setting up prelu4
I1130 22:59:51.698854 12480 net.cpp:157] Top shape: 1 128 (128)
I1130 22:59:51.698858 12480 net.cpp:165] Memory required for data: 168688
I1130 22:59:51.698863 12480 layer_factory.hpp:77] Creating layer fc_prelu4_0_split
I1130 22:59:51.698868 12480 net.cpp:100] Creating Layer fc_prelu4_0_split
I1130 22:59:51.698873 12480 net.cpp:434] fc_prelu4_0_split <- fc
I1130 22:59:51.698878 12480 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_0
I1130 22:59:51.698889 12480 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_1
I1130 22:59:51.698895 12480 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_2
I1130 22:59:51.698941 12480 net.cpp:150] Setting up fc_prelu4_0_split
I1130 22:59:51.698947 12480 net.cpp:157] Top shape: 1 128 (128)
I1130 22:59:51.698956 12480 net.cpp:157] Top shape: 1 128 (128)
I1130 22:59:51.698959 12480 net.cpp:157] Top shape: 1 128 (128)
I1130 22:59:51.698963 12480 net.cpp:165] Memory required for data: 170224
I1130 22:59:51.698966 12480 layer_factory.hpp:77] Creating layer score
I1130 22:59:51.698972 12480 net.cpp:100] Creating Layer score
I1130 22:59:51.698993 12480 net.cpp:434] score <- fc_prelu4_0_split_0
I1130 22:59:51.699000 12480 net.cpp:408] score -> score
I1130 22:59:51.699100 12480 net.cpp:150] Setting up score
I1130 22:59:51.699110 12480 net.cpp:157] Top shape: 1 2 (2)
I1130 22:59:51.699113 12480 net.cpp:165] Memory required for data: 170232
I1130 22:59:51.699120 12480 layer_factory.hpp:77] Creating layer prob
I1130 22:59:51.699127 12480 net.cpp:100] Creating Layer prob
I1130 22:59:51.699131 12480 net.cpp:434] prob <- score
I1130 22:59:51.699138 12480 net.cpp:408] prob -> prob
I1130 22:59:51.699646 12480 net.cpp:150] Setting up prob
I1130 22:59:51.699661 12480 net.cpp:157] Top shape: 1 2 (2)
I1130 22:59:51.699666 12480 net.cpp:165] Memory required for data: 170240
I1130 22:59:51.699669 12480 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:59:51.699676 12480 net.cpp:100] Creating Layer bbox_pred
I1130 22:59:51.699681 12480 net.cpp:434] bbox_pred <- fc_prelu4_0_split_1
I1130 22:59:51.699689 12480 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:59:51.699803 12480 net.cpp:150] Setting up bbox_pred
I1130 22:59:51.699811 12480 net.cpp:157] Top shape: 1 4 (4)
I1130 22:59:51.699815 12480 net.cpp:165] Memory required for data: 170256
I1130 22:59:51.699821 12480 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:59:51.699827 12480 net.cpp:100] Creating Layer landmark_pred
I1130 22:59:51.699831 12480 net.cpp:434] landmark_pred <- fc_prelu4_0_split_2
I1130 22:59:51.699836 12480 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:59:51.699944 12480 net.cpp:150] Setting up landmark_pred
I1130 22:59:51.699951 12480 net.cpp:157] Top shape: 1 10 (10)
I1130 22:59:51.699955 12480 net.cpp:165] Memory required for data: 170296
I1130 22:59:51.699967 12480 net.cpp:228] landmark_pred does not need backward computation.
I1130 22:59:51.699972 12480 net.cpp:228] bbox_pred does not need backward computation.
I1130 22:59:51.699975 12480 net.cpp:228] prob does not need backward computation.
I1130 22:59:51.699980 12480 net.cpp:228] score does not need backward computation.
I1130 22:59:51.699983 12480 net.cpp:228] fc_prelu4_0_split does not need backward computation.
I1130 22:59:51.699986 12480 net.cpp:228] prelu4 does not need backward computation.
I1130 22:59:51.699990 12480 net.cpp:228] fc does not need backward computation.
I1130 22:59:51.699993 12480 net.cpp:228] prelu3 does not need backward computation.
I1130 22:59:51.699996 12480 net.cpp:228] conv3 does not need backward computation.
I1130 22:59:51.700001 12480 net.cpp:228] pool2 does not need backward computation.
I1130 22:59:51.700003 12480 net.cpp:228] prelu2 does not need backward computation.
I1130 22:59:51.700007 12480 net.cpp:228] conv2 does not need backward computation.
I1130 22:59:51.700011 12480 net.cpp:228] pool1 does not need backward computation.
I1130 22:59:51.700014 12480 net.cpp:228] prelu1 does not need backward computation.
I1130 22:59:51.700017 12480 net.cpp:228] conv1 does not need backward computation.
I1130 22:59:51.700021 12480 net.cpp:228] data does not need backward computation.
I1130 22:59:51.700024 12480 net.cpp:270] This network produces output bbox_pred
I1130 22:59:51.700028 12480 net.cpp:270] This network produces output landmark_pred
I1130 22:59:51.700031 12480 net.cpp:270] This network produces output prob
I1130 22:59:51.700043 12480 net.cpp:283] Network initialization done.
I1130 22:59:51.700489 12481 net.cpp:150] Setting up conv1
I1130 22:59:51.700515 12481 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:59:51.700520 12481 net.cpp:165] Memory required for data: 5728
I1130 22:59:51.700542 12481 layer_factory.hpp:77] Creating layer prelu1
I1130 22:59:51.700561 12481 net.cpp:100] Creating Layer prelu1
I1130 22:59:51.700565 12481 net.cpp:434] prelu1 <- conv1
I1130 22:59:51.700572 12481 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:59:51.700676 12481 net.cpp:150] Setting up prelu1
I1130 22:59:51.700688 12481 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 22:59:51.700692 12481 net.cpp:165] Memory required for data: 9728
I1130 22:59:51.700700 12481 layer_factory.hpp:77] Creating layer pool1
I1130 22:59:51.700717 12481 net.cpp:100] Creating Layer pool1
I1130 22:59:51.700722 12481 net.cpp:434] pool1 <- conv1
I1130 22:59:51.700728 12481 net.cpp:408] pool1 -> pool1
I1130 22:59:51.700768 12481 net.cpp:150] Setting up pool1
I1130 22:59:51.700776 12481 net.cpp:157] Top shape: 1 10 5 5 (250)
I1130 22:59:51.700779 12481 net.cpp:165] Memory required for data: 10728
I1130 22:59:51.700783 12481 layer_factory.hpp:77] Creating layer conv2
I1130 22:59:51.700793 12481 net.cpp:100] Creating Layer conv2
I1130 22:59:51.700796 12481 net.cpp:434] conv2 <- pool1
I1130 22:59:51.700801 12481 net.cpp:408] conv2 -> conv2
I1130 22:59:51.701513 12480 net.cpp:761] Ignoring source layer loss
I1130 22:59:51.703444 12481 net.cpp:150] Setting up conv2
I1130 22:59:51.703462 12481 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:59:51.703467 12481 net.cpp:165] Memory required for data: 11304
I1130 22:59:51.703479 12481 layer_factory.hpp:77] Creating layer prelu2
I1130 22:59:51.703488 12481 net.cpp:100] Creating Layer prelu2
I1130 22:59:51.703493 12481 net.cpp:434] prelu2 <- conv2
I1130 22:59:51.703498 12481 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:59:51.703595 12481 net.cpp:150] Setting up prelu2
I1130 22:59:51.703603 12481 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 22:59:51.703606 12481 net.cpp:165] Memory required for data: 11880
I1130 22:59:51.703613 12481 layer_factory.hpp:77] Creating layer conv3
I1130 22:59:51.703622 12481 net.cpp:100] Creating Layer conv3
I1130 22:59:51.703627 12481 net.cpp:434] conv3 <- conv2
I1130 22:59:51.703634 12481 net.cpp:408] conv3 -> conv3
I1130 22:59:51.706156 12481 net.cpp:150] Setting up conv3
I1130 22:59:51.706176 12481 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:59:51.706181 12481 net.cpp:165] Memory required for data: 12008
I1130 22:59:51.706189 12481 layer_factory.hpp:77] Creating layer prelu3
I1130 22:59:51.706200 12481 net.cpp:100] Creating Layer prelu3
I1130 22:59:51.706204 12481 net.cpp:434] prelu3 <- conv3
I1130 22:59:51.706210 12481 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:59:51.706308 12481 net.cpp:150] Setting up prelu3
I1130 22:59:51.706316 12481 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:59:51.706320 12481 net.cpp:165] Memory required for data: 12136
I1130 22:59:51.706327 12481 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 22:59:51.706341 12481 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 22:59:51.706344 12481 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 22:59:51.706351 12481 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 22:59:51.706357 12481 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 22:59:51.706363 12481 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 22:59:51.706415 12481 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 22:59:51.706423 12481 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:59:51.706426 12481 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:59:51.706430 12481 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 22:59:51.706434 12481 net.cpp:165] Memory required for data: 12520
I1130 22:59:51.706437 12481 layer_factory.hpp:77] Creating layer score
I1130 22:59:51.706447 12481 net.cpp:100] Creating Layer score
I1130 22:59:51.706451 12481 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 22:59:51.706457 12481 net.cpp:408] score -> score
I1130 22:59:51.707542 12481 net.cpp:150] Setting up score
I1130 22:59:51.707561 12481 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:59:51.707566 12481 net.cpp:165] Memory required for data: 12528
I1130 22:59:51.707574 12481 layer_factory.hpp:77] Creating layer prob
I1130 22:59:51.707586 12481 net.cpp:100] Creating Layer prob
I1130 22:59:51.707590 12481 net.cpp:434] prob <- score
I1130 22:59:51.707597 12481 net.cpp:408] prob -> prob
I1130 22:59:51.707851 12481 net.cpp:150] Setting up prob
I1130 22:59:51.707862 12481 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 22:59:51.707866 12481 net.cpp:165] Memory required for data: 12536
I1130 22:59:51.707870 12481 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:59:51.707886 12481 net.cpp:100] Creating Layer bbox_pred
I1130 22:59:51.707892 12481 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 22:59:51.707898 12481 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:59:51.708997 12481 net.cpp:150] Setting up bbox_pred
I1130 22:59:51.709017 12481 net.cpp:157] Top shape: 1 4 1 1 (4)
I1130 22:59:51.709023 12481 net.cpp:165] Memory required for data: 12552
I1130 22:59:51.709033 12481 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:59:51.709040 12481 net.cpp:100] Creating Layer landmark_pred
I1130 22:59:51.709045 12481 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 22:59:51.709054 12481 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:59:51.710167 12481 net.cpp:150] Setting up landmark_pred
I1130 22:59:51.710186 12481 net.cpp:157] Top shape: 1 10 1 1 (10)
I1130 22:59:51.710191 12481 net.cpp:165] Memory required for data: 12592
I1130 22:59:51.710198 12481 net.cpp:228] landmark_pred does not need backward computation.
I1130 22:59:51.710202 12481 net.cpp:228] bbox_pred does not need backward computation.
I1130 22:59:51.710206 12481 net.cpp:228] prob does not need backward computation.
I1130 22:59:51.710211 12481 net.cpp:228] score does not need backward computation.
I1130 22:59:51.710214 12481 net.cpp:228] conv3_prelu3_0_split does not need backward computation.
I1130 22:59:51.710217 12481 net.cpp:228] prelu3 does not need backward computation.
I1130 22:59:51.710222 12481 net.cpp:228] conv3 does not need backward computation.
I1130 22:59:51.710224 12481 net.cpp:228] prelu2 does not need backward computation.
I1130 22:59:51.710228 12481 net.cpp:228] conv2 does not need backward computation.
I1130 22:59:51.710232 12481 net.cpp:228] pool1 does not need backward computation.
I1130 22:59:51.710235 12481 net.cpp:228] prelu1 does not need backward computation.
I1130 22:59:51.710238 12481 net.cpp:228] conv1 does not need backward computation.
I1130 22:59:51.710242 12481 net.cpp:228] data does not need backward computation.
I1130 22:59:51.710245 12481 net.cpp:270] This network produces output bbox_pred
I1130 22:59:51.710249 12481 net.cpp:270] This network produces output landmark_pred
I1130 22:59:51.710253 12481 net.cpp:270] This network produces output prob
I1130 22:59:51.710270 12481 net.cpp:283] Network initialization done.
I1130 22:59:51.710496 12481 net.cpp:761] Ignoring source layer loss
I1130 22:59:51.710881 12481 net.cpp:58] Initializing net from parameters: 
name: "rNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 24
      dim: 24
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "conv3"
  top: "fc"
  inner_product_param {
    num_output: 128
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "fc"
  top: "fc"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "fc"
  top: "score"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "bbox_pred"
  inner_product_param {
    num_output: 4
  }
}
layer {
  name: "landmark_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "landmark_pred"
  inner_product_param {
    num_output: 10
  }
}
I1130 22:59:51.710957 12481 layer_factory.hpp:77] Creating layer data
I1130 22:59:51.710968 12481 net.cpp:100] Creating Layer data
I1130 22:59:51.710973 12481 net.cpp:408] data -> data
I1130 22:59:51.711009 12481 net.cpp:150] Setting up data
I1130 22:59:51.711016 12481 net.cpp:157] Top shape: 1 3 24 24 (1728)
I1130 22:59:51.711019 12481 net.cpp:165] Memory required for data: 6912
I1130 22:59:51.711024 12481 layer_factory.hpp:77] Creating layer conv1
I1130 22:59:51.711031 12481 net.cpp:100] Creating Layer conv1
I1130 22:59:51.711035 12481 net.cpp:434] conv1 <- data
I1130 22:59:51.711040 12481 net.cpp:408] conv1 -> conv1
I1130 22:59:51.712151 12481 net.cpp:150] Setting up conv1
I1130 22:59:51.712169 12481 net.cpp:157] Top shape: 1 28 22 22 (13552)
I1130 22:59:51.712174 12481 net.cpp:165] Memory required for data: 61120
I1130 22:59:51.712187 12481 layer_factory.hpp:77] Creating layer prelu1
I1130 22:59:51.712196 12481 net.cpp:100] Creating Layer prelu1
I1130 22:59:51.712201 12481 net.cpp:434] prelu1 <- conv1
I1130 22:59:51.712206 12481 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 22:59:51.712316 12481 net.cpp:150] Setting up prelu1
I1130 22:59:51.712324 12481 net.cpp:157] Top shape: 1 28 22 22 (13552)
I1130 22:59:51.712328 12481 net.cpp:165] Memory required for data: 115328
I1130 22:59:51.712337 12481 layer_factory.hpp:77] Creating layer pool1
I1130 22:59:51.712344 12481 net.cpp:100] Creating Layer pool1
I1130 22:59:51.712348 12481 net.cpp:434] pool1 <- conv1
I1130 22:59:51.712363 12481 net.cpp:408] pool1 -> pool1
I1130 22:59:51.712404 12481 net.cpp:150] Setting up pool1
I1130 22:59:51.712414 12481 net.cpp:157] Top shape: 1 28 11 11 (3388)
I1130 22:59:51.712416 12481 net.cpp:165] Memory required for data: 128880
I1130 22:59:51.712420 12481 layer_factory.hpp:77] Creating layer conv2
I1130 22:59:51.712427 12481 net.cpp:100] Creating Layer conv2
I1130 22:59:51.712431 12481 net.cpp:434] conv2 <- pool1
I1130 22:59:51.712438 12481 net.cpp:408] conv2 -> conv2
I1130 22:59:51.713559 12481 net.cpp:150] Setting up conv2
I1130 22:59:51.713578 12481 net.cpp:157] Top shape: 1 48 9 9 (3888)
I1130 22:59:51.713583 12481 net.cpp:165] Memory required for data: 144432
I1130 22:59:51.713593 12481 layer_factory.hpp:77] Creating layer prelu2
I1130 22:59:51.713603 12481 net.cpp:100] Creating Layer prelu2
I1130 22:59:51.713608 12481 net.cpp:434] prelu2 <- conv2
I1130 22:59:51.713613 12481 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 22:59:51.713726 12481 net.cpp:150] Setting up prelu2
I1130 22:59:51.713735 12481 net.cpp:157] Top shape: 1 48 9 9 (3888)
I1130 22:59:51.713738 12481 net.cpp:165] Memory required for data: 159984
I1130 22:59:51.713744 12481 layer_factory.hpp:77] Creating layer pool2
I1130 22:59:51.713754 12481 net.cpp:100] Creating Layer pool2
I1130 22:59:51.713758 12481 net.cpp:434] pool2 <- conv2
I1130 22:59:51.713763 12481 net.cpp:408] pool2 -> pool2
I1130 22:59:51.713805 12481 net.cpp:150] Setting up pool2
I1130 22:59:51.713814 12481 net.cpp:157] Top shape: 1 48 4 4 (768)
I1130 22:59:51.713816 12481 net.cpp:165] Memory required for data: 163056
I1130 22:59:51.713820 12481 layer_factory.hpp:77] Creating layer conv3
I1130 22:59:51.713829 12481 net.cpp:100] Creating Layer conv3
I1130 22:59:51.713834 12481 net.cpp:434] conv3 <- pool2
I1130 22:59:51.713837 12481 net.cpp:408] conv3 -> conv3
I1130 22:59:51.714666 12481 net.cpp:150] Setting up conv3
I1130 22:59:51.714682 12481 net.cpp:157] Top shape: 1 64 3 3 (576)
I1130 22:59:51.714687 12481 net.cpp:165] Memory required for data: 165360
I1130 22:59:51.714694 12481 layer_factory.hpp:77] Creating layer prelu3
I1130 22:59:51.714705 12481 net.cpp:100] Creating Layer prelu3
I1130 22:59:51.714709 12481 net.cpp:434] prelu3 <- conv3
I1130 22:59:51.714715 12481 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 22:59:51.714819 12481 net.cpp:150] Setting up prelu3
I1130 22:59:51.714833 12481 net.cpp:157] Top shape: 1 64 3 3 (576)
I1130 22:59:51.714836 12481 net.cpp:165] Memory required for data: 167664
I1130 22:59:51.714844 12481 layer_factory.hpp:77] Creating layer fc
I1130 22:59:51.714854 12481 net.cpp:100] Creating Layer fc
I1130 22:59:51.714859 12481 net.cpp:434] fc <- conv3
I1130 22:59:51.714866 12481 net.cpp:408] fc -> fc
I1130 22:59:51.716497 12481 net.cpp:150] Setting up fc
I1130 22:59:51.716516 12481 net.cpp:157] Top shape: 1 128 (128)
I1130 22:59:51.716519 12481 net.cpp:165] Memory required for data: 168176
I1130 22:59:51.716527 12481 layer_factory.hpp:77] Creating layer prelu4
I1130 22:59:51.716536 12481 net.cpp:100] Creating Layer prelu4
I1130 22:59:51.716541 12481 net.cpp:434] prelu4 <- fc
I1130 22:59:51.716545 12481 net.cpp:395] prelu4 -> fc (in-place)
I1130 22:59:51.716624 12481 net.cpp:150] Setting up prelu4
I1130 22:59:51.716632 12481 net.cpp:157] Top shape: 1 128 (128)
I1130 22:59:51.716635 12481 net.cpp:165] Memory required for data: 168688
I1130 22:59:51.716640 12481 layer_factory.hpp:77] Creating layer fc_prelu4_0_split
I1130 22:59:51.716645 12481 net.cpp:100] Creating Layer fc_prelu4_0_split
I1130 22:59:51.716650 12481 net.cpp:434] fc_prelu4_0_split <- fc
I1130 22:59:51.716655 12481 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_0
I1130 22:59:51.716665 12481 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_1
I1130 22:59:51.716672 12481 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_2
I1130 22:59:51.716718 12481 net.cpp:150] Setting up fc_prelu4_0_split
I1130 22:59:51.716724 12481 net.cpp:157] Top shape: 1 128 (128)
I1130 22:59:51.716732 12481 net.cpp:157] Top shape: 1 128 (128)
I1130 22:59:51.716737 12481 net.cpp:157] Top shape: 1 128 (128)
I1130 22:59:51.716739 12481 net.cpp:165] Memory required for data: 170224
I1130 22:59:51.716742 12481 layer_factory.hpp:77] Creating layer score
I1130 22:59:51.716748 12481 net.cpp:100] Creating Layer score
I1130 22:59:51.716753 12481 net.cpp:434] score <- fc_prelu4_0_split_0
I1130 22:59:51.716758 12481 net.cpp:408] score -> score
I1130 22:59:51.716847 12481 net.cpp:150] Setting up score
I1130 22:59:51.716855 12481 net.cpp:157] Top shape: 1 2 (2)
I1130 22:59:51.716857 12481 net.cpp:165] Memory required for data: 170232
I1130 22:59:51.716864 12481 layer_factory.hpp:77] Creating layer prob
I1130 22:59:51.716869 12481 net.cpp:100] Creating Layer prob
I1130 22:59:51.716873 12481 net.cpp:434] prob <- score
I1130 22:59:51.716881 12481 net.cpp:408] prob -> prob
I1130 22:59:51.717389 12481 net.cpp:150] Setting up prob
I1130 22:59:51.717406 12481 net.cpp:157] Top shape: 1 2 (2)
I1130 22:59:51.717411 12481 net.cpp:165] Memory required for data: 170240
I1130 22:59:51.717417 12481 layer_factory.hpp:77] Creating layer bbox_pred
I1130 22:59:51.717423 12481 net.cpp:100] Creating Layer bbox_pred
I1130 22:59:51.717427 12481 net.cpp:434] bbox_pred <- fc_prelu4_0_split_1
I1130 22:59:51.717442 12481 net.cpp:408] bbox_pred -> bbox_pred
I1130 22:59:51.717556 12481 net.cpp:150] Setting up bbox_pred
I1130 22:59:51.717564 12481 net.cpp:157] Top shape: 1 4 (4)
I1130 22:59:51.717567 12481 net.cpp:165] Memory required for data: 170256
I1130 22:59:51.717574 12481 layer_factory.hpp:77] Creating layer landmark_pred
I1130 22:59:51.717581 12481 net.cpp:100] Creating Layer landmark_pred
I1130 22:59:51.717584 12481 net.cpp:434] landmark_pred <- fc_prelu4_0_split_2
I1130 22:59:51.717589 12481 net.cpp:408] landmark_pred -> landmark_pred
I1130 22:59:51.717694 12481 net.cpp:150] Setting up landmark_pred
I1130 22:59:51.717700 12481 net.cpp:157] Top shape: 1 10 (10)
I1130 22:59:51.717705 12481 net.cpp:165] Memory required for data: 170296
I1130 22:59:51.717716 12481 net.cpp:228] landmark_pred does not need backward computation.
I1130 22:59:51.717720 12481 net.cpp:228] bbox_pred does not need backward computation.
I1130 22:59:51.717725 12481 net.cpp:228] prob does not need backward computation.
I1130 22:59:51.717727 12481 net.cpp:228] score does not need backward computation.
I1130 22:59:51.717731 12481 net.cpp:228] fc_prelu4_0_split does not need backward computation.
I1130 22:59:51.717741 12481 net.cpp:228] prelu4 does not need backward computation.
I1130 22:59:51.717744 12481 net.cpp:228] fc does not need backward computation.
I1130 22:59:51.717748 12481 net.cpp:228] prelu3 does not need backward computation.
I1130 22:59:51.717751 12481 net.cpp:228] conv3 does not need backward computation.
I1130 22:59:51.717756 12481 net.cpp:228] pool2 does not need backward computation.
I1130 22:59:51.717758 12481 net.cpp:228] prelu2 does not need backward computation.
I1130 22:59:51.717762 12481 net.cpp:228] conv2 does not need backward computation.
I1130 22:59:51.717766 12481 net.cpp:228] pool1 does not need backward computation.
I1130 22:59:51.717768 12481 net.cpp:228] prelu1 does not need backward computation.
I1130 22:59:51.717772 12481 net.cpp:228] conv1 does not need backward computation.
I1130 22:59:51.717775 12481 net.cpp:228] data does not need backward computation.
I1130 22:59:51.717778 12481 net.cpp:270] This network produces output bbox_pred
I1130 22:59:51.717782 12481 net.cpp:270] This network produces output landmark_pred
I1130 22:59:51.717787 12481 net.cpp:270] This network produces output prob
I1130 22:59:51.717797 12481 net.cpp:283] Network initialization done.
I1130 22:59:51.719121 12481 net.cpp:761] Ignoring source layer loss
[2016-11-30 23:00:10,190][INFO] writes 4631 positives, 1436 negatives, 3932 part
[2016-11-30 23:00:26,823][INFO] writes 9347 positives, 2691 negatives, 7961 part
[2016-11-30 23:00:46,864][INFO] writes 13983 positives, 4122 negatives, 11894 part
[2016-11-30 23:01:02,253][INFO] writes 19704 positives, 4888 negatives, 15407 part
[2016-11-30 23:01:14,602][INFO] writes 26059 positives, 5532 negatives, 18408 part
[2016-11-30 23:01:25,756][INFO] writes 32470 positives, 6222 negatives, 21307 part
[2016-11-30 23:02:00,728][INFO] writes 37965 positives, 7437 negatives, 24597 part
[2016-11-30 23:02:06,639][INFO] Process-2 reads 1000
[2016-11-30 23:02:09,941][INFO] Process-1 reads 1000
[2016-11-30 23:02:41,447][INFO] writes 43110 positives, 9122 negatives, 27767 part
[2016-11-30 23:03:12,563][INFO] writes 48013 positives, 10719 negatives, 31267 part
[2016-11-30 23:03:32,964][INFO] writes 52332 positives, 12156 negatives, 35511 part
[2016-11-30 23:03:46,901][INFO] writes 56703 positives, 13559 negatives, 39737 part
[2016-11-30 23:04:03,840][INFO] writes 60876 positives, 14921 negatives, 44202 part
[2016-11-30 23:04:20,080][INFO] writes 65023 positives, 16419 negatives, 48557 part
[2016-11-30 23:04:35,031][INFO] writes 69515 positives, 17631 negatives, 52853 part
[2016-11-30 23:04:36,466][INFO] Process-2 reads 2000
[2016-11-30 23:04:44,360][INFO] Process-1 reads 2000
[2016-11-30 23:04:50,733][INFO] writes 75236 positives, 18410 negatives, 56353 part
[2016-11-30 23:05:25,807][INFO] writes 79485 positives, 20445 negatives, 60069 part
[2016-11-30 23:06:15,259][INFO] writes 83887 positives, 22693 negatives, 63419 part
[2016-11-30 23:06:43,932][INFO] writes 88524 positives, 24245 negatives, 67230 part
[2016-11-30 23:06:52,062][INFO] Process-1 reads 3000
[2016-11-30 23:07:12,564][INFO] Process-2 reads 3000
[2016-11-30 23:07:20,096][INFO] writes 93683 positives, 25766 negatives, 70550 part
[2016-11-30 23:07:49,171][INFO] writes 98408 positives, 27247 negatives, 74344 part
[2016-11-30 23:08:14,284][INFO] writes 103390 positives, 28728 negatives, 77881 part
[2016-11-30 23:08:41,347][INFO] writes 108908 positives, 30107 negatives, 80984 part
[2016-11-30 23:08:51,673][INFO] Process-1 reads 4000
[2016-11-30 23:09:13,842][INFO] Process-2 reads 4000
[2016-11-30 23:09:14,892][INFO] writes 114063 positives, 31442 negatives, 84494 part
[2016-11-30 23:09:49,277][INFO] writes 119282 positives, 32635 negatives, 88082 part
[2016-11-30 23:10:30,550][INFO] writes 123968 positives, 34415 negatives, 91616 part
[2016-11-30 23:10:45,405][INFO] Process-1 reads 5000
[2016-11-30 23:11:10,000][INFO] Process-2 reads 5000
[2016-11-30 23:11:12,108][INFO] writes 128321 positives, 36531 negatives, 95147 part
[2016-11-30 23:12:00,507][INFO] writes 133093 positives, 38536 negatives, 98370 part
[2016-11-30 23:12:27,878][INFO] writes 138007 positives, 40026 negatives, 101966 part
[2016-11-30 23:13:00,168][INFO] writes 142966 positives, 41372 negatives, 105661 part
[2016-11-30 23:13:05,166][INFO] Process-1 reads 6000
[2016-11-30 23:13:19,063][INFO] Process-2 reads 6000
[2016-11-30 23:13:23,443][INFO] writes 147499 positives, 42766 negatives, 109734 part
[2016-11-30 23:13:43,470][INFO] writes 152823 positives, 43887 negatives, 113289 part
[2016-11-30 23:14:38,185][INFO] Finish
[2016-11-30 23:14:38,443][INFO] writing val data, 3196 images
[2016-11-30 23:14:38,455][INFO] remove data/onet_positive_val
[2016-11-30 23:14:38,459][INFO] remove data/onet_negative_val
[2016-11-30 23:14:38,475][INFO] remove data/onet_part_val
[2016-11-30 23:14:38,482][INFO] fill queues
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 23:14:40.718045 12653 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
  }
}
I1130 23:14:40.718192 12653 layer_factory.hpp:77] Creating layer data
I1130 23:14:40.718211 12653 net.cpp:100] Creating Layer data
I1130 23:14:40.718220 12653 net.cpp:408] data -> data
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 23:14:40.724521 12652 net.cpp:58] Initializing net from parameters: 
name: "pNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "score"
  type: "Convolution"
  bottom: "conv3"
  top: "score"
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "bbox_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "bbox_pred"
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "landmark_pred"
  type: "Convolution"
  bottom: "conv3"
  top: "landmark_pred"
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
  }
}
I1130 23:14:40.724671 12652 layer_factory.hpp:77] Creating layer data
I1130 23:14:40.724690 12652 net.cpp:100] Creating Layer data
I1130 23:14:40.724699 12652 net.cpp:408] data -> data
I1130 23:14:40.746606 12653 net.cpp:150] Setting up data
I1130 23:14:40.746635 12653 net.cpp:157] Top shape: 1 3 12 12 (432)
I1130 23:14:40.746640 12653 net.cpp:165] Memory required for data: 1728
I1130 23:14:40.746646 12653 layer_factory.hpp:77] Creating layer conv1
I1130 23:14:40.746659 12653 net.cpp:100] Creating Layer conv1
I1130 23:14:40.746665 12653 net.cpp:434] conv1 <- data
I1130 23:14:40.746670 12653 net.cpp:408] conv1 -> conv1
I1130 23:14:40.752709 12652 net.cpp:150] Setting up data
I1130 23:14:40.752745 12652 net.cpp:157] Top shape: 1 3 12 12 (432)
I1130 23:14:40.752750 12652 net.cpp:165] Memory required for data: 1728
I1130 23:14:40.752758 12652 layer_factory.hpp:77] Creating layer conv1
I1130 23:14:40.752773 12652 net.cpp:100] Creating Layer conv1
I1130 23:14:40.752777 12652 net.cpp:434] conv1 <- data
I1130 23:14:40.752784 12652 net.cpp:408] conv1 -> conv1
I1130 23:14:41.021055 12653 net.cpp:150] Setting up conv1
I1130 23:14:41.021114 12653 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 23:14:41.021121 12653 net.cpp:165] Memory required for data: 5728
I1130 23:14:41.021152 12653 layer_factory.hpp:77] Creating layer prelu1
I1130 23:14:41.021173 12653 net.cpp:100] Creating Layer prelu1
I1130 23:14:41.021178 12653 net.cpp:434] prelu1 <- conv1
I1130 23:14:41.021186 12653 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 23:14:41.021298 12653 net.cpp:150] Setting up prelu1
I1130 23:14:41.021309 12653 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 23:14:41.021314 12653 net.cpp:165] Memory required for data: 9728
I1130 23:14:41.021322 12653 layer_factory.hpp:77] Creating layer pool1
I1130 23:14:41.021333 12653 net.cpp:100] Creating Layer pool1
I1130 23:14:41.021338 12653 net.cpp:434] pool1 <- conv1
I1130 23:14:41.021343 12653 net.cpp:408] pool1 -> pool1
I1130 23:14:41.021384 12653 net.cpp:150] Setting up pool1
I1130 23:14:41.021391 12653 net.cpp:157] Top shape: 1 10 5 5 (250)
I1130 23:14:41.021395 12653 net.cpp:165] Memory required for data: 10728
I1130 23:14:41.021399 12653 layer_factory.hpp:77] Creating layer conv2
I1130 23:14:41.021410 12653 net.cpp:100] Creating Layer conv2
I1130 23:14:41.021414 12653 net.cpp:434] conv2 <- pool1
I1130 23:14:41.021420 12653 net.cpp:408] conv2 -> conv2
I1130 23:14:41.023762 12653 net.cpp:150] Setting up conv2
I1130 23:14:41.023782 12653 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 23:14:41.023787 12653 net.cpp:165] Memory required for data: 11304
I1130 23:14:41.023798 12653 layer_factory.hpp:77] Creating layer prelu2
I1130 23:14:41.023808 12653 net.cpp:100] Creating Layer prelu2
I1130 23:14:41.023813 12653 net.cpp:434] prelu2 <- conv2
I1130 23:14:41.023819 12653 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 23:14:41.023913 12653 net.cpp:150] Setting up prelu2
I1130 23:14:41.023921 12653 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 23:14:41.023926 12653 net.cpp:165] Memory required for data: 11880
I1130 23:14:41.023931 12653 layer_factory.hpp:77] Creating layer conv3
I1130 23:14:41.023941 12653 net.cpp:100] Creating Layer conv3
I1130 23:14:41.023944 12653 net.cpp:434] conv3 <- conv2
I1130 23:14:41.023952 12653 net.cpp:408] conv3 -> conv3
I1130 23:14:41.025413 12652 net.cpp:150] Setting up conv1
I1130 23:14:41.025457 12652 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 23:14:41.025463 12652 net.cpp:165] Memory required for data: 5728
I1130 23:14:41.025490 12652 layer_factory.hpp:77] Creating layer prelu1
I1130 23:14:41.025508 12652 net.cpp:100] Creating Layer prelu1
I1130 23:14:41.025524 12652 net.cpp:434] prelu1 <- conv1
I1130 23:14:41.025532 12652 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 23:14:41.025640 12652 net.cpp:150] Setting up prelu1
I1130 23:14:41.025652 12652 net.cpp:157] Top shape: 1 10 10 10 (1000)
I1130 23:14:41.025656 12652 net.cpp:165] Memory required for data: 9728
I1130 23:14:41.025665 12652 layer_factory.hpp:77] Creating layer pool1
I1130 23:14:41.025676 12652 net.cpp:100] Creating Layer pool1
I1130 23:14:41.025679 12652 net.cpp:434] pool1 <- conv1
I1130 23:14:41.025684 12652 net.cpp:408] pool1 -> pool1
I1130 23:14:41.025725 12652 net.cpp:150] Setting up pool1
I1130 23:14:41.025732 12652 net.cpp:157] Top shape: 1 10 5 5 (250)
I1130 23:14:41.025735 12652 net.cpp:165] Memory required for data: 10728
I1130 23:14:41.025739 12652 layer_factory.hpp:77] Creating layer conv2
I1130 23:14:41.025750 12652 net.cpp:100] Creating Layer conv2
I1130 23:14:41.025753 12652 net.cpp:434] conv2 <- pool1
I1130 23:14:41.025758 12652 net.cpp:408] conv2 -> conv2
I1130 23:14:41.026268 12653 net.cpp:150] Setting up conv3
I1130 23:14:41.026288 12653 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 23:14:41.026293 12653 net.cpp:165] Memory required for data: 12008
I1130 23:14:41.026302 12653 layer_factory.hpp:77] Creating layer prelu3
I1130 23:14:41.026309 12653 net.cpp:100] Creating Layer prelu3
I1130 23:14:41.026314 12653 net.cpp:434] prelu3 <- conv3
I1130 23:14:41.026322 12653 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 23:14:41.026420 12653 net.cpp:150] Setting up prelu3
I1130 23:14:41.026428 12653 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 23:14:41.026432 12653 net.cpp:165] Memory required for data: 12136
I1130 23:14:41.026440 12653 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 23:14:41.026454 12653 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 23:14:41.026458 12653 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 23:14:41.026464 12653 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 23:14:41.026471 12653 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 23:14:41.026478 12653 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 23:14:41.026530 12653 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 23:14:41.026538 12653 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 23:14:41.026542 12653 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 23:14:41.026546 12653 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 23:14:41.026551 12653 net.cpp:165] Memory required for data: 12520
I1130 23:14:41.026554 12653 layer_factory.hpp:77] Creating layer score
I1130 23:14:41.026563 12653 net.cpp:100] Creating Layer score
I1130 23:14:41.026567 12653 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 23:14:41.026573 12653 net.cpp:408] score -> score
I1130 23:14:41.027637 12653 net.cpp:150] Setting up score
I1130 23:14:41.027657 12653 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 23:14:41.027660 12653 net.cpp:165] Memory required for data: 12528
I1130 23:14:41.027668 12653 layer_factory.hpp:77] Creating layer prob
I1130 23:14:41.027680 12653 net.cpp:100] Creating Layer prob
I1130 23:14:41.027685 12653 net.cpp:434] prob <- score
I1130 23:14:41.027691 12653 net.cpp:408] prob -> prob
I1130 23:14:41.027940 12653 net.cpp:150] Setting up prob
I1130 23:14:41.027951 12653 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 23:14:41.027956 12653 net.cpp:165] Memory required for data: 12536
I1130 23:14:41.027959 12653 layer_factory.hpp:77] Creating layer bbox_pred
I1130 23:14:41.027969 12653 net.cpp:100] Creating Layer bbox_pred
I1130 23:14:41.027974 12653 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 23:14:41.027981 12653 net.cpp:408] bbox_pred -> bbox_pred
I1130 23:14:41.028060 12652 net.cpp:150] Setting up conv2
I1130 23:14:41.028087 12652 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 23:14:41.028093 12652 net.cpp:165] Memory required for data: 11304
I1130 23:14:41.028105 12652 layer_factory.hpp:77] Creating layer prelu2
I1130 23:14:41.028113 12652 net.cpp:100] Creating Layer prelu2
I1130 23:14:41.028118 12652 net.cpp:434] prelu2 <- conv2
I1130 23:14:41.028125 12652 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 23:14:41.028228 12652 net.cpp:150] Setting up prelu2
I1130 23:14:41.028237 12652 net.cpp:157] Top shape: 1 16 3 3 (144)
I1130 23:14:41.028240 12652 net.cpp:165] Memory required for data: 11880
I1130 23:14:41.028246 12652 layer_factory.hpp:77] Creating layer conv3
I1130 23:14:41.028256 12652 net.cpp:100] Creating Layer conv3
I1130 23:14:41.028260 12652 net.cpp:434] conv3 <- conv2
I1130 23:14:41.028267 12652 net.cpp:408] conv3 -> conv3
I1130 23:14:41.029062 12653 net.cpp:150] Setting up bbox_pred
I1130 23:14:41.029088 12653 net.cpp:157] Top shape: 1 4 1 1 (4)
I1130 23:14:41.029093 12653 net.cpp:165] Memory required for data: 12552
I1130 23:14:41.029103 12653 layer_factory.hpp:77] Creating layer landmark_pred
I1130 23:14:41.029114 12653 net.cpp:100] Creating Layer landmark_pred
I1130 23:14:41.029119 12653 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 23:14:41.029126 12653 net.cpp:408] landmark_pred -> landmark_pred
I1130 23:14:41.030218 12653 net.cpp:150] Setting up landmark_pred
I1130 23:14:41.030237 12653 net.cpp:157] Top shape: 1 10 1 1 (10)
I1130 23:14:41.030242 12653 net.cpp:165] Memory required for data: 12592
I1130 23:14:41.030251 12653 net.cpp:228] landmark_pred does not need backward computation.
I1130 23:14:41.030256 12653 net.cpp:228] bbox_pred does not need backward computation.
I1130 23:14:41.030259 12653 net.cpp:228] prob does not need backward computation.
I1130 23:14:41.030263 12653 net.cpp:228] score does not need backward computation.
I1130 23:14:41.030267 12653 net.cpp:228] conv3_prelu3_0_split does not need backward computation.
I1130 23:14:41.030272 12653 net.cpp:228] prelu3 does not need backward computation.
I1130 23:14:41.030274 12653 net.cpp:228] conv3 does not need backward computation.
I1130 23:14:41.030278 12653 net.cpp:228] prelu2 does not need backward computation.
I1130 23:14:41.030282 12653 net.cpp:228] conv2 does not need backward computation.
I1130 23:14:41.030285 12653 net.cpp:228] pool1 does not need backward computation.
I1130 23:14:41.030289 12653 net.cpp:228] prelu1 does not need backward computation.
I1130 23:14:41.030292 12653 net.cpp:228] conv1 does not need backward computation.
I1130 23:14:41.030297 12653 net.cpp:228] data does not need backward computation.
I1130 23:14:41.030299 12653 net.cpp:270] This network produces output bbox_pred
I1130 23:14:41.030304 12653 net.cpp:270] This network produces output landmark_pred
I1130 23:14:41.030308 12653 net.cpp:270] This network produces output prob
I1130 23:14:41.030325 12653 net.cpp:283] Network initialization done.
I1130 23:14:41.030495 12652 net.cpp:150] Setting up conv3
I1130 23:14:41.030513 12652 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 23:14:41.030516 12652 net.cpp:165] Memory required for data: 12008
I1130 23:14:41.030525 12652 layer_factory.hpp:77] Creating layer prelu3
I1130 23:14:41.030532 12652 net.cpp:100] Creating Layer prelu3
I1130 23:14:41.030536 12652 net.cpp:434] prelu3 <- conv3
I1130 23:14:41.030544 12652 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 23:14:41.030583 12653 net.cpp:761] Ignoring source layer loss
I1130 23:14:41.030640 12652 net.cpp:150] Setting up prelu3
I1130 23:14:41.030649 12652 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 23:14:41.030652 12652 net.cpp:165] Memory required for data: 12136
I1130 23:14:41.030661 12652 layer_factory.hpp:77] Creating layer conv3_prelu3_0_split
I1130 23:14:41.030673 12652 net.cpp:100] Creating Layer conv3_prelu3_0_split
I1130 23:14:41.030678 12652 net.cpp:434] conv3_prelu3_0_split <- conv3
I1130 23:14:41.030683 12652 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_0
I1130 23:14:41.030690 12652 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_1
I1130 23:14:41.030696 12652 net.cpp:408] conv3_prelu3_0_split -> conv3_prelu3_0_split_2
I1130 23:14:41.030752 12652 net.cpp:150] Setting up conv3_prelu3_0_split
I1130 23:14:41.030760 12652 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 23:14:41.030764 12652 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 23:14:41.030768 12652 net.cpp:157] Top shape: 1 32 1 1 (32)
I1130 23:14:41.030776 12652 net.cpp:165] Memory required for data: 12520
I1130 23:14:41.030781 12652 layer_factory.hpp:77] Creating layer score
I1130 23:14:41.030791 12652 net.cpp:100] Creating Layer score
I1130 23:14:41.030796 12652 net.cpp:434] score <- conv3_prelu3_0_split_0
I1130 23:14:41.030802 12652 net.cpp:408] score -> score
I1130 23:14:41.030992 12653 net.cpp:58] Initializing net from parameters: 
name: "rNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 24
      dim: 24
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "conv3"
  top: "fc"
  inner_product_param {
    num_output: 128
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "fc"
  top: "fc"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "fc"
  top: "score"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "bbox_pred"
  inner_product_param {
    num_output: 4
  }
}
layer {
  name: "landmark_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "landmark_pred"
  inner_product_param {
    num_output: 10
  }
}
I1130 23:14:41.031060 12653 layer_factory.hpp:77] Creating layer data
I1130 23:14:41.031078 12653 net.cpp:100] Creating Layer data
I1130 23:14:41.031087 12653 net.cpp:408] data -> data
I1130 23:14:41.031126 12653 net.cpp:150] Setting up data
I1130 23:14:41.031133 12653 net.cpp:157] Top shape: 1 3 24 24 (1728)
I1130 23:14:41.031137 12653 net.cpp:165] Memory required for data: 6912
I1130 23:14:41.031141 12653 layer_factory.hpp:77] Creating layer conv1
I1130 23:14:41.031149 12653 net.cpp:100] Creating Layer conv1
I1130 23:14:41.031153 12653 net.cpp:434] conv1 <- data
I1130 23:14:41.031159 12653 net.cpp:408] conv1 -> conv1
I1130 23:14:41.031848 12652 net.cpp:150] Setting up score
I1130 23:14:41.031863 12652 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 23:14:41.031867 12652 net.cpp:165] Memory required for data: 12528
I1130 23:14:41.031877 12652 layer_factory.hpp:77] Creating layer prob
I1130 23:14:41.031888 12652 net.cpp:100] Creating Layer prob
I1130 23:14:41.031893 12652 net.cpp:434] prob <- score
I1130 23:14:41.031898 12652 net.cpp:408] prob -> prob
I1130 23:14:41.032155 12652 net.cpp:150] Setting up prob
I1130 23:14:41.032171 12652 net.cpp:157] Top shape: 1 2 1 1 (2)
I1130 23:14:41.032174 12652 net.cpp:165] Memory required for data: 12536
I1130 23:14:41.032178 12652 layer_factory.hpp:77] Creating layer bbox_pred
I1130 23:14:41.032189 12652 net.cpp:100] Creating Layer bbox_pred
I1130 23:14:41.032193 12652 net.cpp:434] bbox_pred <- conv3_prelu3_0_split_1
I1130 23:14:41.032199 12652 net.cpp:408] bbox_pred -> bbox_pred
I1130 23:14:41.032243 12653 net.cpp:150] Setting up conv1
I1130 23:14:41.032259 12653 net.cpp:157] Top shape: 1 28 22 22 (13552)
I1130 23:14:41.032264 12653 net.cpp:165] Memory required for data: 61120
I1130 23:14:41.032279 12653 layer_factory.hpp:77] Creating layer prelu1
I1130 23:14:41.032294 12653 net.cpp:100] Creating Layer prelu1
I1130 23:14:41.032299 12653 net.cpp:434] prelu1 <- conv1
I1130 23:14:41.032308 12653 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 23:14:41.032413 12653 net.cpp:150] Setting up prelu1
I1130 23:14:41.032423 12653 net.cpp:157] Top shape: 1 28 22 22 (13552)
I1130 23:14:41.032426 12653 net.cpp:165] Memory required for data: 115328
I1130 23:14:41.032435 12653 layer_factory.hpp:77] Creating layer pool1
I1130 23:14:41.032443 12653 net.cpp:100] Creating Layer pool1
I1130 23:14:41.032446 12653 net.cpp:434] pool1 <- conv1
I1130 23:14:41.032454 12653 net.cpp:408] pool1 -> pool1
I1130 23:14:41.032492 12653 net.cpp:150] Setting up pool1
I1130 23:14:41.032500 12653 net.cpp:157] Top shape: 1 28 11 11 (3388)
I1130 23:14:41.032503 12653 net.cpp:165] Memory required for data: 128880
I1130 23:14:41.032506 12653 layer_factory.hpp:77] Creating layer conv2
I1130 23:14:41.032521 12653 net.cpp:100] Creating Layer conv2
I1130 23:14:41.032524 12653 net.cpp:434] conv2 <- pool1
I1130 23:14:41.032531 12653 net.cpp:408] conv2 -> conv2
I1130 23:14:41.033259 12652 net.cpp:150] Setting up bbox_pred
I1130 23:14:41.033278 12652 net.cpp:157] Top shape: 1 4 1 1 (4)
I1130 23:14:41.033283 12652 net.cpp:165] Memory required for data: 12552
I1130 23:14:41.033291 12652 layer_factory.hpp:77] Creating layer landmark_pred
I1130 23:14:41.033303 12652 net.cpp:100] Creating Layer landmark_pred
I1130 23:14:41.033308 12652 net.cpp:434] landmark_pred <- conv3_prelu3_0_split_2
I1130 23:14:41.033316 12652 net.cpp:408] landmark_pred -> landmark_pred
I1130 23:14:41.033628 12653 net.cpp:150] Setting up conv2
I1130 23:14:41.033644 12653 net.cpp:157] Top shape: 1 48 9 9 (3888)
I1130 23:14:41.033648 12653 net.cpp:165] Memory required for data: 144432
I1130 23:14:41.033659 12653 layer_factory.hpp:77] Creating layer prelu2
I1130 23:14:41.033670 12653 net.cpp:100] Creating Layer prelu2
I1130 23:14:41.033675 12653 net.cpp:434] prelu2 <- conv2
I1130 23:14:41.033680 12653 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 23:14:41.033787 12653 net.cpp:150] Setting up prelu2
I1130 23:14:41.033794 12653 net.cpp:157] Top shape: 1 48 9 9 (3888)
I1130 23:14:41.033798 12653 net.cpp:165] Memory required for data: 159984
I1130 23:14:41.033803 12653 layer_factory.hpp:77] Creating layer pool2
I1130 23:14:41.033813 12653 net.cpp:100] Creating Layer pool2
I1130 23:14:41.033818 12653 net.cpp:434] pool2 <- conv2
I1130 23:14:41.033823 12653 net.cpp:408] pool2 -> pool2
I1130 23:14:41.033862 12653 net.cpp:150] Setting up pool2
I1130 23:14:41.033870 12653 net.cpp:157] Top shape: 1 48 4 4 (768)
I1130 23:14:41.033874 12653 net.cpp:165] Memory required for data: 163056
I1130 23:14:41.033877 12653 layer_factory.hpp:77] Creating layer conv3
I1130 23:14:41.033886 12653 net.cpp:100] Creating Layer conv3
I1130 23:14:41.033890 12653 net.cpp:434] conv3 <- pool2
I1130 23:14:41.033895 12653 net.cpp:408] conv3 -> conv3
I1130 23:14:41.034387 12652 net.cpp:150] Setting up landmark_pred
I1130 23:14:41.034406 12652 net.cpp:157] Top shape: 1 10 1 1 (10)
I1130 23:14:41.034410 12652 net.cpp:165] Memory required for data: 12592
I1130 23:14:41.034418 12652 net.cpp:228] landmark_pred does not need backward computation.
I1130 23:14:41.034423 12652 net.cpp:228] bbox_pred does not need backward computation.
I1130 23:14:41.034427 12652 net.cpp:228] prob does not need backward computation.
I1130 23:14:41.034431 12652 net.cpp:228] score does not need backward computation.
I1130 23:14:41.034435 12652 net.cpp:228] conv3_prelu3_0_split does not need backward computation.
I1130 23:14:41.034440 12652 net.cpp:228] prelu3 does not need backward computation.
I1130 23:14:41.034442 12652 net.cpp:228] conv3 does not need backward computation.
I1130 23:14:41.034446 12652 net.cpp:228] prelu2 does not need backward computation.
I1130 23:14:41.034449 12652 net.cpp:228] conv2 does not need backward computation.
I1130 23:14:41.034453 12652 net.cpp:228] pool1 does not need backward computation.
I1130 23:14:41.034457 12652 net.cpp:228] prelu1 does not need backward computation.
I1130 23:14:41.034461 12652 net.cpp:228] conv1 does not need backward computation.
I1130 23:14:41.034471 12652 net.cpp:228] data does not need backward computation.
I1130 23:14:41.034476 12652 net.cpp:270] This network produces output bbox_pred
I1130 23:14:41.034479 12652 net.cpp:270] This network produces output landmark_pred
I1130 23:14:41.034483 12652 net.cpp:270] This network produces output prob
I1130 23:14:41.034498 12652 net.cpp:283] Network initialization done.
I1130 23:14:41.034698 12653 net.cpp:150] Setting up conv3
I1130 23:14:41.034713 12653 net.cpp:157] Top shape: 1 64 3 3 (576)
I1130 23:14:41.034716 12653 net.cpp:165] Memory required for data: 165360
I1130 23:14:41.034724 12653 layer_factory.hpp:77] Creating layer prelu3
I1130 23:14:41.034734 12653 net.cpp:100] Creating Layer prelu3
I1130 23:14:41.034739 12653 net.cpp:434] prelu3 <- conv3
I1130 23:14:41.034735 12652 net.cpp:761] Ignoring source layer loss
I1130 23:14:41.034745 12653 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 23:14:41.034847 12653 net.cpp:150] Setting up prelu3
I1130 23:14:41.034855 12653 net.cpp:157] Top shape: 1 64 3 3 (576)
I1130 23:14:41.034859 12653 net.cpp:165] Memory required for data: 167664
I1130 23:14:41.034868 12653 layer_factory.hpp:77] Creating layer fc
I1130 23:14:41.034875 12653 net.cpp:100] Creating Layer fc
I1130 23:14:41.034879 12653 net.cpp:434] fc <- conv3
I1130 23:14:41.034884 12653 net.cpp:408] fc -> fc
I1130 23:14:41.035131 12652 net.cpp:58] Initializing net from parameters: 
name: "rNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 24
      dim: 24
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "conv3"
  top: "fc"
  inner_product_param {
    num_output: 128
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "fc"
  top: "fc"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "fc"
  top: "score"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "bbox_pred"
  inner_product_param {
    num_output: 4
  }
}
layer {
  name: "landmark_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "landmark_pred"
  inner_product_param {
    num_output: 10
  }
}
I1130 23:14:41.035202 12652 layer_factory.hpp:77] Creating layer data
I1130 23:14:41.035213 12652 net.cpp:100] Creating Layer data
I1130 23:14:41.035218 12652 net.cpp:408] data -> data
I1130 23:14:41.035254 12652 net.cpp:150] Setting up data
I1130 23:14:41.035262 12652 net.cpp:157] Top shape: 1 3 24 24 (1728)
I1130 23:14:41.035266 12652 net.cpp:165] Memory required for data: 6912
I1130 23:14:41.035270 12652 layer_factory.hpp:77] Creating layer conv1
I1130 23:14:41.035279 12652 net.cpp:100] Creating Layer conv1
I1130 23:14:41.035281 12652 net.cpp:434] conv1 <- data
I1130 23:14:41.035287 12652 net.cpp:408] conv1 -> conv1
I1130 23:14:41.036386 12653 net.cpp:150] Setting up fc
I1130 23:14:41.036406 12653 net.cpp:157] Top shape: 1 128 (128)
I1130 23:14:41.036414 12653 net.cpp:165] Memory required for data: 168176
I1130 23:14:41.036423 12653 layer_factory.hpp:77] Creating layer prelu4
I1130 23:14:41.036429 12653 net.cpp:100] Creating Layer prelu4
I1130 23:14:41.036434 12653 net.cpp:434] prelu4 <- fc
I1130 23:14:41.036442 12653 net.cpp:395] prelu4 -> fc (in-place)
I1130 23:14:41.036468 12652 net.cpp:150] Setting up conv1
I1130 23:14:41.036485 12652 net.cpp:157] Top shape: 1 28 22 22 (13552)
I1130 23:14:41.036489 12652 net.cpp:165] Memory required for data: 61120
I1130 23:14:41.036504 12652 layer_factory.hpp:77] Creating layer prelu1
I1130 23:14:41.036511 12652 net.cpp:100] Creating Layer prelu1
I1130 23:14:41.036515 12652 net.cpp:434] prelu1 <- conv1
I1130 23:14:41.036523 12652 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 23:14:41.036522 12653 net.cpp:150] Setting up prelu4
I1130 23:14:41.036531 12653 net.cpp:157] Top shape: 1 128 (128)
I1130 23:14:41.036535 12653 net.cpp:165] Memory required for data: 168688
I1130 23:14:41.036540 12653 layer_factory.hpp:77] Creating layer fc_prelu4_0_split
I1130 23:14:41.036545 12653 net.cpp:100] Creating Layer fc_prelu4_0_split
I1130 23:14:41.036548 12653 net.cpp:434] fc_prelu4_0_split <- fc
I1130 23:14:41.036555 12653 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_0
I1130 23:14:41.036561 12653 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_1
I1130 23:14:41.036571 12653 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_2
I1130 23:14:41.036615 12653 net.cpp:150] Setting up fc_prelu4_0_split
I1130 23:14:41.036622 12653 net.cpp:157] Top shape: 1 128 (128)
I1130 23:14:41.036628 12653 net.cpp:157] Top shape: 1 128 (128)
I1130 23:14:41.036630 12652 net.cpp:150] Setting up prelu1
I1130 23:14:41.036633 12653 net.cpp:157] Top shape: 1 128 (128)
I1130 23:14:41.036639 12653 net.cpp:165] Memory required for data: 170224
I1130 23:14:41.036640 12652 net.cpp:157] Top shape: 1 28 22 22 (13552)
I1130 23:14:41.036643 12653 layer_factory.hpp:77] Creating layer score
I1130 23:14:41.036644 12652 net.cpp:165] Memory required for data: 115328
I1130 23:14:41.036650 12653 net.cpp:100] Creating Layer score
I1130 23:14:41.036655 12653 net.cpp:434] score <- fc_prelu4_0_split_0
I1130 23:14:41.036655 12652 layer_factory.hpp:77] Creating layer pool1
I1130 23:14:41.036660 12653 net.cpp:408] score -> score
I1130 23:14:41.036664 12652 net.cpp:100] Creating Layer pool1
I1130 23:14:41.036669 12652 net.cpp:434] pool1 <- conv1
I1130 23:14:41.036675 12652 net.cpp:408] pool1 -> pool1
I1130 23:14:41.036713 12652 net.cpp:150] Setting up pool1
I1130 23:14:41.036721 12652 net.cpp:157] Top shape: 1 28 11 11 (3388)
I1130 23:14:41.036725 12652 net.cpp:165] Memory required for data: 128880
I1130 23:14:41.036728 12652 layer_factory.hpp:77] Creating layer conv2
I1130 23:14:41.036737 12652 net.cpp:100] Creating Layer conv2
I1130 23:14:41.036741 12652 net.cpp:434] conv2 <- pool1
I1130 23:14:41.036748 12652 net.cpp:408] conv2 -> conv2
I1130 23:14:41.036751 12653 net.cpp:150] Setting up score
I1130 23:14:41.036757 12653 net.cpp:157] Top shape: 1 2 (2)
I1130 23:14:41.036761 12653 net.cpp:165] Memory required for data: 170232
I1130 23:14:41.036767 12653 layer_factory.hpp:77] Creating layer prob
I1130 23:14:41.036773 12653 net.cpp:100] Creating Layer prob
I1130 23:14:41.036777 12653 net.cpp:434] prob <- score
I1130 23:14:41.036783 12653 net.cpp:408] prob -> prob
I1130 23:14:41.037294 12653 net.cpp:150] Setting up prob
I1130 23:14:41.037313 12653 net.cpp:157] Top shape: 1 2 (2)
I1130 23:14:41.037317 12653 net.cpp:165] Memory required for data: 170240
I1130 23:14:41.037322 12653 layer_factory.hpp:77] Creating layer bbox_pred
I1130 23:14:41.037330 12653 net.cpp:100] Creating Layer bbox_pred
I1130 23:14:41.037335 12653 net.cpp:434] bbox_pred <- fc_prelu4_0_split_1
I1130 23:14:41.037343 12653 net.cpp:408] bbox_pred -> bbox_pred
I1130 23:14:41.037459 12653 net.cpp:150] Setting up bbox_pred
I1130 23:14:41.037467 12653 net.cpp:157] Top shape: 1 4 (4)
I1130 23:14:41.037472 12653 net.cpp:165] Memory required for data: 170256
I1130 23:14:41.037478 12653 layer_factory.hpp:77] Creating layer landmark_pred
I1130 23:14:41.037489 12653 net.cpp:100] Creating Layer landmark_pred
I1130 23:14:41.037493 12653 net.cpp:434] landmark_pred <- fc_prelu4_0_split_2
I1130 23:14:41.037499 12653 net.cpp:408] landmark_pred -> landmark_pred
I1130 23:14:41.037605 12653 net.cpp:150] Setting up landmark_pred
I1130 23:14:41.037611 12653 net.cpp:157] Top shape: 1 10 (10)
I1130 23:14:41.037614 12653 net.cpp:165] Memory required for data: 170296
I1130 23:14:41.037626 12653 net.cpp:228] landmark_pred does not need backward computation.
I1130 23:14:41.037631 12653 net.cpp:228] bbox_pred does not need backward computation.
I1130 23:14:41.037634 12653 net.cpp:228] prob does not need backward computation.
I1130 23:14:41.037637 12653 net.cpp:228] score does not need backward computation.
I1130 23:14:41.037642 12653 net.cpp:228] fc_prelu4_0_split does not need backward computation.
I1130 23:14:41.037645 12653 net.cpp:228] prelu4 does not need backward computation.
I1130 23:14:41.037648 12653 net.cpp:228] fc does not need backward computation.
I1130 23:14:41.037652 12653 net.cpp:228] prelu3 does not need backward computation.
I1130 23:14:41.037655 12653 net.cpp:228] conv3 does not need backward computation.
I1130 23:14:41.037659 12653 net.cpp:228] pool2 does not need backward computation.
I1130 23:14:41.037662 12653 net.cpp:228] prelu2 does not need backward computation.
I1130 23:14:41.037667 12653 net.cpp:228] conv2 does not need backward computation.
I1130 23:14:41.037669 12653 net.cpp:228] pool1 does not need backward computation.
I1130 23:14:41.037673 12653 net.cpp:228] prelu1 does not need backward computation.
I1130 23:14:41.037677 12653 net.cpp:228] conv1 does not need backward computation.
I1130 23:14:41.037680 12653 net.cpp:228] data does not need backward computation.
I1130 23:14:41.037683 12653 net.cpp:270] This network produces output bbox_pred
I1130 23:14:41.037688 12653 net.cpp:270] This network produces output landmark_pred
I1130 23:14:41.037691 12653 net.cpp:270] This network produces output prob
I1130 23:14:41.037703 12653 net.cpp:283] Network initialization done.
I1130 23:14:41.037822 12652 net.cpp:150] Setting up conv2
I1130 23:14:41.037837 12652 net.cpp:157] Top shape: 1 48 9 9 (3888)
I1130 23:14:41.037842 12652 net.cpp:165] Memory required for data: 144432
I1130 23:14:41.037853 12652 layer_factory.hpp:77] Creating layer prelu2
I1130 23:14:41.037864 12652 net.cpp:100] Creating Layer prelu2
I1130 23:14:41.037869 12652 net.cpp:434] prelu2 <- conv2
I1130 23:14:41.037875 12652 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 23:14:41.037982 12652 net.cpp:150] Setting up prelu2
I1130 23:14:41.037991 12652 net.cpp:157] Top shape: 1 48 9 9 (3888)
I1130 23:14:41.037994 12652 net.cpp:165] Memory required for data: 159984
I1130 23:14:41.037999 12652 layer_factory.hpp:77] Creating layer pool2
I1130 23:14:41.038008 12652 net.cpp:100] Creating Layer pool2
I1130 23:14:41.038012 12652 net.cpp:434] pool2 <- conv2
I1130 23:14:41.038018 12652 net.cpp:408] pool2 -> pool2
I1130 23:14:41.038058 12652 net.cpp:150] Setting up pool2
I1130 23:14:41.038065 12652 net.cpp:157] Top shape: 1 48 4 4 (768)
I1130 23:14:41.038079 12652 net.cpp:165] Memory required for data: 163056
I1130 23:14:41.038084 12652 layer_factory.hpp:77] Creating layer conv3
I1130 23:14:41.038092 12652 net.cpp:100] Creating Layer conv3
I1130 23:14:41.038096 12652 net.cpp:434] conv3 <- pool2
I1130 23:14:41.038102 12652 net.cpp:408] conv3 -> conv3
I1130 23:14:41.038805 12653 net.cpp:761] Ignoring source layer loss
I1130 23:14:41.038904 12652 net.cpp:150] Setting up conv3
I1130 23:14:41.038918 12652 net.cpp:157] Top shape: 1 64 3 3 (576)
I1130 23:14:41.038923 12652 net.cpp:165] Memory required for data: 165360
I1130 23:14:41.038929 12652 layer_factory.hpp:77] Creating layer prelu3
I1130 23:14:41.038939 12652 net.cpp:100] Creating Layer prelu3
I1130 23:14:41.038944 12652 net.cpp:434] prelu3 <- conv3
I1130 23:14:41.038949 12652 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 23:14:41.039049 12652 net.cpp:150] Setting up prelu3
I1130 23:14:41.039057 12652 net.cpp:157] Top shape: 1 64 3 3 (576)
I1130 23:14:41.039073 12652 net.cpp:165] Memory required for data: 167664
I1130 23:14:41.039086 12652 layer_factory.hpp:77] Creating layer fc
I1130 23:14:41.039096 12652 net.cpp:100] Creating Layer fc
I1130 23:14:41.039100 12652 net.cpp:434] fc <- conv3
I1130 23:14:41.039106 12652 net.cpp:408] fc -> fc
I1130 23:14:41.040417 12652 net.cpp:150] Setting up fc
I1130 23:14:41.040436 12652 net.cpp:157] Top shape: 1 128 (128)
I1130 23:14:41.040439 12652 net.cpp:165] Memory required for data: 168176
I1130 23:14:41.040447 12652 layer_factory.hpp:77] Creating layer prelu4
I1130 23:14:41.040454 12652 net.cpp:100] Creating Layer prelu4
I1130 23:14:41.040458 12652 net.cpp:434] prelu4 <- fc
I1130 23:14:41.040469 12652 net.cpp:395] prelu4 -> fc (in-place)
I1130 23:14:41.040547 12652 net.cpp:150] Setting up prelu4
I1130 23:14:41.040555 12652 net.cpp:157] Top shape: 1 128 (128)
I1130 23:14:41.040557 12652 net.cpp:165] Memory required for data: 168688
I1130 23:14:41.040562 12652 layer_factory.hpp:77] Creating layer fc_prelu4_0_split
I1130 23:14:41.040568 12652 net.cpp:100] Creating Layer fc_prelu4_0_split
I1130 23:14:41.040572 12652 net.cpp:434] fc_prelu4_0_split <- fc
I1130 23:14:41.040577 12652 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_0
I1130 23:14:41.040583 12652 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_1
I1130 23:14:41.040594 12652 net.cpp:408] fc_prelu4_0_split -> fc_prelu4_0_split_2
I1130 23:14:41.040640 12652 net.cpp:150] Setting up fc_prelu4_0_split
I1130 23:14:41.040647 12652 net.cpp:157] Top shape: 1 128 (128)
I1130 23:14:41.040653 12652 net.cpp:157] Top shape: 1 128 (128)
I1130 23:14:41.040657 12652 net.cpp:157] Top shape: 1 128 (128)
I1130 23:14:41.040660 12652 net.cpp:165] Memory required for data: 170224
I1130 23:14:41.040664 12652 layer_factory.hpp:77] Creating layer score
I1130 23:14:41.040669 12652 net.cpp:100] Creating Layer score
I1130 23:14:41.040673 12652 net.cpp:434] score <- fc_prelu4_0_split_0
I1130 23:14:41.040678 12652 net.cpp:408] score -> score
I1130 23:14:41.040767 12652 net.cpp:150] Setting up score
I1130 23:14:41.040773 12652 net.cpp:157] Top shape: 1 2 (2)
I1130 23:14:41.040777 12652 net.cpp:165] Memory required for data: 170232
I1130 23:14:41.040783 12652 layer_factory.hpp:77] Creating layer prob
I1130 23:14:41.040789 12652 net.cpp:100] Creating Layer prob
I1130 23:14:41.040793 12652 net.cpp:434] prob <- score
I1130 23:14:41.040801 12652 net.cpp:408] prob -> prob
I1130 23:14:41.041301 12652 net.cpp:150] Setting up prob
I1130 23:14:41.041319 12652 net.cpp:157] Top shape: 1 2 (2)
I1130 23:14:41.041323 12652 net.cpp:165] Memory required for data: 170240
I1130 23:14:41.041328 12652 layer_factory.hpp:77] Creating layer bbox_pred
I1130 23:14:41.041337 12652 net.cpp:100] Creating Layer bbox_pred
I1130 23:14:41.041342 12652 net.cpp:434] bbox_pred <- fc_prelu4_0_split_1
I1130 23:14:41.041349 12652 net.cpp:408] bbox_pred -> bbox_pred
I1130 23:14:41.041461 12652 net.cpp:150] Setting up bbox_pred
I1130 23:14:41.041468 12652 net.cpp:157] Top shape: 1 4 (4)
I1130 23:14:41.041471 12652 net.cpp:165] Memory required for data: 170256
I1130 23:14:41.041479 12652 layer_factory.hpp:77] Creating layer landmark_pred
I1130 23:14:41.041484 12652 net.cpp:100] Creating Layer landmark_pred
I1130 23:14:41.041488 12652 net.cpp:434] landmark_pred <- fc_prelu4_0_split_2
I1130 23:14:41.041493 12652 net.cpp:408] landmark_pred -> landmark_pred
I1130 23:14:41.041594 12652 net.cpp:150] Setting up landmark_pred
I1130 23:14:41.041601 12652 net.cpp:157] Top shape: 1 10 (10)
I1130 23:14:41.041604 12652 net.cpp:165] Memory required for data: 170296
I1130 23:14:41.041616 12652 net.cpp:228] landmark_pred does not need backward computation.
I1130 23:14:41.041620 12652 net.cpp:228] bbox_pred does not need backward computation.
I1130 23:14:41.041625 12652 net.cpp:228] prob does not need backward computation.
I1130 23:14:41.041627 12652 net.cpp:228] score does not need backward computation.
I1130 23:14:41.041631 12652 net.cpp:228] fc_prelu4_0_split does not need backward computation.
I1130 23:14:41.041635 12652 net.cpp:228] prelu4 does not need backward computation.
I1130 23:14:41.041643 12652 net.cpp:228] fc does not need backward computation.
I1130 23:14:41.041647 12652 net.cpp:228] prelu3 does not need backward computation.
I1130 23:14:41.041651 12652 net.cpp:228] conv3 does not need backward computation.
I1130 23:14:41.041654 12652 net.cpp:228] pool2 does not need backward computation.
I1130 23:14:41.041657 12652 net.cpp:228] prelu2 does not need backward computation.
I1130 23:14:41.041661 12652 net.cpp:228] conv2 does not need backward computation.
I1130 23:14:41.041664 12652 net.cpp:228] pool1 does not need backward computation.
I1130 23:14:41.041667 12652 net.cpp:228] prelu1 does not need backward computation.
I1130 23:14:41.041671 12652 net.cpp:228] conv1 does not need backward computation.
I1130 23:14:41.041674 12652 net.cpp:228] data does not need backward computation.
I1130 23:14:41.041677 12652 net.cpp:270] This network produces output bbox_pred
I1130 23:14:41.041682 12652 net.cpp:270] This network produces output landmark_pred
I1130 23:14:41.041685 12652 net.cpp:270] This network produces output prob
I1130 23:14:41.041697 12652 net.cpp:283] Network initialization done.
I1130 23:14:41.042778 12652 net.cpp:761] Ignoring source layer loss
[2016-11-30 23:14:57,074][INFO] writes 4782 positives, 1277 negatives, 3940 part
[2016-11-30 23:15:15,894][INFO] writes 10601 positives, 2170 negatives, 7228 part
[2016-11-30 23:15:38,650][INFO] writes 15102 positives, 3688 negatives, 11209 part
[2016-11-30 23:15:56,055][INFO] writes 19869 positives, 4828 negatives, 15302 part
[2016-11-30 23:16:32,360][INFO] writes 24588 positives, 6500 negatives, 18911 part
[2016-11-30 23:16:43,350][INFO] Process-4 reads 1000
[2016-11-30 23:16:59,353][INFO] Process-5 reads 1000
[2016-11-30 23:17:00,459][INFO] writes 29915 positives, 7736 negatives, 22348 part
[2016-11-30 23:17:40,530][INFO] writes 34721 positives, 9401 negatives, 25877 part
[2016-11-30 23:18:18,565][INFO] Finish
Train oNet
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 23:18:21.494196 12698 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1042
test_interval: 4299
base_lr: 0.01
display: 500
max_iter: 171960
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 42990
snapshot: 4299
snapshot_prefix: "tmp/onet"
solver_mode: GPU
net: "proto/o_train_val.prototxt"
test_initialization: false
average_loss: 500
I1130 23:18:21.494446 12698 solver.cpp:91] Creating training net from net file: proto/o_train_val.prototxt
I1130 23:18:21.495712 12698 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1130 23:18:21.496003 12698 net.cpp:58] Initializing net from parameters: 
name: "oNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "bbox_target"
  top: "landmark_target"
  top: "label"
  include {
    phase: TRAIN
  }
  python_param {
    module: "layers.data_layer"
    layer: "FaceDataLayer"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "conv4"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu5"
  type: "PReLU"
  bottom: "fc"
  top: "fc"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "fc"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "bbox_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "landmark_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "landmark_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "JfdaLoss"
  bottom: "score"
  bottom: "bbox_pred"
  bottom: "landmark_pred"
  bottom: "bbox_target"
  bottom: "landmark_target"
  bottom: "label"
  top: "face_cls_loss"
  top: "bbox_reg_loss"
  top: "landmark_reg_loss"
  top: "face_cls_neg_acc"
  top: "face_cls_pos_acc"
  loss_weight: 1
  loss_weight: 0.5
  loss_weight: 1
  loss_weight: 0
  loss_weight: 0
  jfda_loss_param {
    drop_loss_rate: 0.3
  }
}
I1130 23:18:21.496211 12698 layer_factory.hpp:77] Creating layer data
I1130 23:18:21.496870 12698 net.cpp:100] Creating Layer data
I1130 23:18:21.496897 12698 net.cpp:408] data -> data
I1130 23:18:21.496927 12698 net.cpp:408] data -> bbox_target
I1130 23:18:21.496942 12698 net.cpp:408] data -> landmark_target
I1130 23:18:21.496956 12698 net.cpp:408] data -> label
I1130 23:18:21.527624 12698 net.cpp:150] Setting up data
I1130 23:18:21.527662 12698 net.cpp:157] Top shape: 4 3 48 48 (27648)
I1130 23:18:21.527673 12698 net.cpp:157] Top shape: 4 4 (16)
I1130 23:18:21.527683 12698 net.cpp:157] Top shape: 4 10 (40)
I1130 23:18:21.527689 12698 net.cpp:157] Top shape: 4 (4)
I1130 23:18:21.527696 12698 net.cpp:165] Memory required for data: 110832
I1130 23:18:21.527704 12698 layer_factory.hpp:77] Creating layer conv1
I1130 23:18:21.527729 12698 net.cpp:100] Creating Layer conv1
I1130 23:18:21.527737 12698 net.cpp:434] conv1 <- data
I1130 23:18:21.527750 12698 net.cpp:408] conv1 -> conv1
I1130 23:18:21.783843 12698 net.cpp:150] Setting up conv1
I1130 23:18:21.783886 12698 net.cpp:157] Top shape: 4 32 46 46 (270848)
I1130 23:18:21.783891 12698 net.cpp:165] Memory required for data: 1194224
I1130 23:18:21.783911 12698 layer_factory.hpp:77] Creating layer prelu1
I1130 23:18:21.783932 12698 net.cpp:100] Creating Layer prelu1
I1130 23:18:21.783936 12698 net.cpp:434] prelu1 <- conv1
I1130 23:18:21.783942 12698 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 23:18:21.785009 12698 net.cpp:150] Setting up prelu1
I1130 23:18:21.785024 12698 net.cpp:157] Top shape: 4 32 46 46 (270848)
I1130 23:18:21.785028 12698 net.cpp:165] Memory required for data: 2277616
I1130 23:18:21.785035 12698 layer_factory.hpp:77] Creating layer pool1
I1130 23:18:21.785045 12698 net.cpp:100] Creating Layer pool1
I1130 23:18:21.785049 12698 net.cpp:434] pool1 <- conv1
I1130 23:18:21.785053 12698 net.cpp:408] pool1 -> pool1
I1130 23:18:21.785092 12698 net.cpp:150] Setting up pool1
I1130 23:18:21.785100 12698 net.cpp:157] Top shape: 4 32 23 23 (67712)
I1130 23:18:21.785104 12698 net.cpp:165] Memory required for data: 2548464
I1130 23:18:21.785106 12698 layer_factory.hpp:77] Creating layer conv2
I1130 23:18:21.785118 12698 net.cpp:100] Creating Layer conv2
I1130 23:18:21.785122 12698 net.cpp:434] conv2 <- pool1
I1130 23:18:21.785126 12698 net.cpp:408] conv2 -> conv2
I1130 23:18:21.787212 12698 net.cpp:150] Setting up conv2
I1130 23:18:21.787227 12698 net.cpp:157] Top shape: 4 64 21 21 (112896)
I1130 23:18:21.787231 12698 net.cpp:165] Memory required for data: 3000048
I1130 23:18:21.787240 12698 layer_factory.hpp:77] Creating layer prelu2
I1130 23:18:21.787245 12698 net.cpp:100] Creating Layer prelu2
I1130 23:18:21.787250 12698 net.cpp:434] prelu2 <- conv2
I1130 23:18:21.787256 12698 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 23:18:21.787345 12698 net.cpp:150] Setting up prelu2
I1130 23:18:21.787351 12698 net.cpp:157] Top shape: 4 64 21 21 (112896)
I1130 23:18:21.787354 12698 net.cpp:165] Memory required for data: 3451632
I1130 23:18:21.787359 12698 layer_factory.hpp:77] Creating layer pool2
I1130 23:18:21.787364 12698 net.cpp:100] Creating Layer pool2
I1130 23:18:21.787369 12698 net.cpp:434] pool2 <- conv2
I1130 23:18:21.787374 12698 net.cpp:408] pool2 -> pool2
I1130 23:18:21.787402 12698 net.cpp:150] Setting up pool2
I1130 23:18:21.787407 12698 net.cpp:157] Top shape: 4 64 10 10 (25600)
I1130 23:18:21.787410 12698 net.cpp:165] Memory required for data: 3554032
I1130 23:18:21.787413 12698 layer_factory.hpp:77] Creating layer conv3
I1130 23:18:21.787423 12698 net.cpp:100] Creating Layer conv3
I1130 23:18:21.787427 12698 net.cpp:434] conv3 <- pool2
I1130 23:18:21.787431 12698 net.cpp:408] conv3 -> conv3
I1130 23:18:21.789316 12698 net.cpp:150] Setting up conv3
I1130 23:18:21.789332 12698 net.cpp:157] Top shape: 4 64 9 9 (20736)
I1130 23:18:21.789336 12698 net.cpp:165] Memory required for data: 3636976
I1130 23:18:21.789342 12698 layer_factory.hpp:77] Creating layer prelu3
I1130 23:18:21.789351 12698 net.cpp:100] Creating Layer prelu3
I1130 23:18:21.789355 12698 net.cpp:434] prelu3 <- conv3
I1130 23:18:21.789360 12698 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 23:18:21.789434 12698 net.cpp:150] Setting up prelu3
I1130 23:18:21.789441 12698 net.cpp:157] Top shape: 4 64 9 9 (20736)
I1130 23:18:21.789444 12698 net.cpp:165] Memory required for data: 3719920
I1130 23:18:21.789450 12698 layer_factory.hpp:77] Creating layer pool3
I1130 23:18:21.789458 12698 net.cpp:100] Creating Layer pool3
I1130 23:18:21.789461 12698 net.cpp:434] pool3 <- conv3
I1130 23:18:21.789465 12698 net.cpp:408] pool3 -> pool3
I1130 23:18:21.789495 12698 net.cpp:150] Setting up pool3
I1130 23:18:21.789500 12698 net.cpp:157] Top shape: 4 64 5 5 (6400)
I1130 23:18:21.789504 12698 net.cpp:165] Memory required for data: 3745520
I1130 23:18:21.789506 12698 layer_factory.hpp:77] Creating layer conv4
I1130 23:18:21.789515 12698 net.cpp:100] Creating Layer conv4
I1130 23:18:21.789520 12698 net.cpp:434] conv4 <- pool3
I1130 23:18:21.789525 12698 net.cpp:408] conv4 -> conv4
I1130 23:18:21.805454 12698 net.cpp:150] Setting up conv4
I1130 23:18:21.805491 12698 net.cpp:157] Top shape: 4 128 4 4 (8192)
I1130 23:18:21.805531 12698 net.cpp:165] Memory required for data: 3778288
I1130 23:18:21.805548 12698 layer_factory.hpp:77] Creating layer prelu4
I1130 23:18:21.805572 12698 net.cpp:100] Creating Layer prelu4
I1130 23:18:21.805583 12698 net.cpp:434] prelu4 <- conv4
I1130 23:18:21.805598 12698 net.cpp:395] prelu4 -> conv4 (in-place)
I1130 23:18:21.805716 12698 net.cpp:150] Setting up prelu4
I1130 23:18:21.805721 12698 net.cpp:157] Top shape: 4 128 4 4 (8192)
I1130 23:18:21.805724 12698 net.cpp:165] Memory required for data: 3811056
I1130 23:18:21.805728 12698 layer_factory.hpp:77] Creating layer fc
I1130 23:18:21.805738 12698 net.cpp:100] Creating Layer fc
I1130 23:18:21.805742 12698 net.cpp:434] fc <- conv4
I1130 23:18:21.805748 12698 net.cpp:408] fc -> fc
I1130 23:18:21.809881 12698 net.cpp:150] Setting up fc
I1130 23:18:21.809896 12698 net.cpp:157] Top shape: 4 256 (1024)
I1130 23:18:21.809900 12698 net.cpp:165] Memory required for data: 3815152
I1130 23:18:21.809906 12698 layer_factory.hpp:77] Creating layer prelu5
I1130 23:18:21.809911 12698 net.cpp:100] Creating Layer prelu5
I1130 23:18:21.809914 12698 net.cpp:434] prelu5 <- fc
I1130 23:18:21.809918 12698 net.cpp:395] prelu5 -> fc (in-place)
I1130 23:18:21.809983 12698 net.cpp:150] Setting up prelu5
I1130 23:18:21.809988 12698 net.cpp:157] Top shape: 4 256 (1024)
I1130 23:18:21.809991 12698 net.cpp:165] Memory required for data: 3819248
I1130 23:18:21.809995 12698 layer_factory.hpp:77] Creating layer fc_prelu5_0_split
I1130 23:18:21.810003 12698 net.cpp:100] Creating Layer fc_prelu5_0_split
I1130 23:18:21.810006 12698 net.cpp:434] fc_prelu5_0_split <- fc
I1130 23:18:21.810010 12698 net.cpp:408] fc_prelu5_0_split -> fc_prelu5_0_split_0
I1130 23:18:21.810016 12698 net.cpp:408] fc_prelu5_0_split -> fc_prelu5_0_split_1
I1130 23:18:21.810020 12698 net.cpp:408] fc_prelu5_0_split -> fc_prelu5_0_split_2
I1130 23:18:21.810060 12698 net.cpp:150] Setting up fc_prelu5_0_split
I1130 23:18:21.810065 12698 net.cpp:157] Top shape: 4 256 (1024)
I1130 23:18:21.810071 12698 net.cpp:157] Top shape: 4 256 (1024)
I1130 23:18:21.810077 12698 net.cpp:157] Top shape: 4 256 (1024)
I1130 23:18:21.810081 12698 net.cpp:165] Memory required for data: 3831536
I1130 23:18:21.810083 12698 layer_factory.hpp:77] Creating layer score
I1130 23:18:21.810091 12698 net.cpp:100] Creating Layer score
I1130 23:18:21.810094 12698 net.cpp:434] score <- fc_prelu5_0_split_0
I1130 23:18:21.810101 12698 net.cpp:408] score -> score
I1130 23:18:21.810184 12698 net.cpp:150] Setting up score
I1130 23:18:21.810190 12698 net.cpp:157] Top shape: 4 2 (8)
I1130 23:18:21.810194 12698 net.cpp:165] Memory required for data: 3831568
I1130 23:18:21.810200 12698 layer_factory.hpp:77] Creating layer bbox_pred
I1130 23:18:21.810209 12698 net.cpp:100] Creating Layer bbox_pred
I1130 23:18:21.810212 12698 net.cpp:434] bbox_pred <- fc_prelu5_0_split_1
I1130 23:18:21.810217 12698 net.cpp:408] bbox_pred -> bbox_pred
I1130 23:18:21.810295 12698 net.cpp:150] Setting up bbox_pred
I1130 23:18:21.810302 12698 net.cpp:157] Top shape: 4 4 (16)
I1130 23:18:21.810304 12698 net.cpp:165] Memory required for data: 3831632
I1130 23:18:21.810309 12698 layer_factory.hpp:77] Creating layer landmark_pred
I1130 23:18:21.810315 12698 net.cpp:100] Creating Layer landmark_pred
I1130 23:18:21.810318 12698 net.cpp:434] landmark_pred <- fc_prelu5_0_split_2
I1130 23:18:21.810322 12698 net.cpp:408] landmark_pred -> landmark_pred
I1130 23:18:21.810413 12698 net.cpp:150] Setting up landmark_pred
I1130 23:18:21.810420 12698 net.cpp:157] Top shape: 4 10 (40)
I1130 23:18:21.810422 12698 net.cpp:165] Memory required for data: 3831792
I1130 23:18:21.810426 12698 layer_factory.hpp:77] Creating layer loss
I1130 23:18:21.810438 12698 net.cpp:100] Creating Layer loss
I1130 23:18:21.810442 12698 net.cpp:434] loss <- score
I1130 23:18:21.810446 12698 net.cpp:434] loss <- bbox_pred
I1130 23:18:21.810449 12698 net.cpp:434] loss <- landmark_pred
I1130 23:18:21.810452 12698 net.cpp:434] loss <- bbox_target
I1130 23:18:21.810456 12698 net.cpp:434] loss <- landmark_target
I1130 23:18:21.810458 12698 net.cpp:434] loss <- label
I1130 23:18:21.810462 12698 net.cpp:408] loss -> face_cls_loss
I1130 23:18:21.810469 12698 net.cpp:408] loss -> bbox_reg_loss
I1130 23:18:21.810478 12698 net.cpp:408] loss -> landmark_reg_loss
I1130 23:18:21.810483 12698 net.cpp:408] loss -> face_cls_neg_acc
I1130 23:18:21.810488 12698 net.cpp:408] loss -> face_cls_pos_acc
I1130 23:18:21.810565 12698 net.cpp:150] Setting up loss
I1130 23:18:21.810570 12698 net.cpp:157] Top shape: (1)
I1130 23:18:21.810573 12698 net.cpp:160]     with loss weight 1
I1130 23:18:21.810588 12698 net.cpp:157] Top shape: (1)
I1130 23:18:21.810590 12698 net.cpp:160]     with loss weight 0.5
I1130 23:18:21.810595 12698 net.cpp:157] Top shape: (1)
I1130 23:18:21.810597 12698 net.cpp:160]     with loss weight 1
I1130 23:18:21.810600 12698 net.cpp:157] Top shape: (1)
I1130 23:18:21.810605 12698 net.cpp:157] Top shape: (1)
I1130 23:18:21.810606 12698 net.cpp:165] Memory required for data: 3831812
I1130 23:18:21.810609 12698 net.cpp:226] loss needs backward computation.
I1130 23:18:21.810614 12698 net.cpp:226] landmark_pred needs backward computation.
I1130 23:18:21.810617 12698 net.cpp:226] bbox_pred needs backward computation.
I1130 23:18:21.810621 12698 net.cpp:226] score needs backward computation.
I1130 23:18:21.810623 12698 net.cpp:226] fc_prelu5_0_split needs backward computation.
I1130 23:18:21.810626 12698 net.cpp:226] prelu5 needs backward computation.
I1130 23:18:21.810629 12698 net.cpp:226] fc needs backward computation.
I1130 23:18:21.810632 12698 net.cpp:226] prelu4 needs backward computation.
I1130 23:18:21.810634 12698 net.cpp:226] conv4 needs backward computation.
I1130 23:18:21.810637 12698 net.cpp:226] pool3 needs backward computation.
I1130 23:18:21.810641 12698 net.cpp:226] prelu3 needs backward computation.
I1130 23:18:21.810643 12698 net.cpp:226] conv3 needs backward computation.
I1130 23:18:21.810647 12698 net.cpp:226] pool2 needs backward computation.
I1130 23:18:21.810648 12698 net.cpp:226] prelu2 needs backward computation.
I1130 23:18:21.810652 12698 net.cpp:226] conv2 needs backward computation.
I1130 23:18:21.810654 12698 net.cpp:226] pool1 needs backward computation.
I1130 23:18:21.810657 12698 net.cpp:226] prelu1 needs backward computation.
I1130 23:18:21.810660 12698 net.cpp:226] conv1 needs backward computation.
I1130 23:18:21.810663 12698 net.cpp:228] data does not need backward computation.
I1130 23:18:21.810667 12698 net.cpp:270] This network produces output bbox_reg_loss
I1130 23:18:21.810670 12698 net.cpp:270] This network produces output face_cls_loss
I1130 23:18:21.810673 12698 net.cpp:270] This network produces output face_cls_neg_acc
I1130 23:18:21.810677 12698 net.cpp:270] This network produces output face_cls_pos_acc
I1130 23:18:21.810678 12698 net.cpp:270] This network produces output landmark_reg_loss
I1130 23:18:21.810693 12698 net.cpp:283] Network initialization done.
I1130 23:18:21.811120 12698 solver.cpp:181] Creating test net (#0) specified by net file: proto/o_train_val.prototxt
I1130 23:18:21.811154 12698 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1130 23:18:21.811280 12698 net.cpp:58] Initializing net from parameters: 
name: "oNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "bbox_target"
  top: "landmark_target"
  top: "label"
  include {
    phase: TEST
  }
  python_param {
    module: "layers.data_layer"
    layer: "FaceDataLayer"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "fc"
  type: "InnerProduct"
  bottom: "conv4"
  top: "fc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu5"
  type: "PReLU"
  bottom: "fc"
  top: "fc"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "fc"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "bbox_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "landmark_pred"
  type: "InnerProduct"
  bottom: "fc"
  top: "landmark_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "JfdaLoss"
  bottom: "score"
  bottom: "bbox_pred"
  bottom: "landmark_pred"
  bottom: "bbox_target"
  bottom: "landmark_target"
  bottom: "label"
  top: "face_cls_loss"
  top: "bbox_reg_loss"
  top: "landmark_reg_loss"
  top: "face_cls_neg_acc"
  top: "face_cls_pos_acc"
  loss_weight: 1
  loss_weight: 0.5
  loss_weight: 1
  loss_weight: 0
  loss_weight: 0
  jfda_loss_param {
    drop_loss_rate: 0.3
  }
}
I1130 23:18:21.811363 12698 layer_factory.hpp:77] Creating layer data
I1130 23:18:21.811420 12698 net.cpp:100] Creating Layer data
I1130 23:18:21.811427 12698 net.cpp:408] data -> data
I1130 23:18:21.811434 12698 net.cpp:408] data -> bbox_target
I1130 23:18:21.811439 12698 net.cpp:408] data -> landmark_target
I1130 23:18:21.811444 12698 net.cpp:408] data -> label
I1130 23:18:21.811743 12698 net.cpp:150] Setting up data
I1130 23:18:21.811751 12698 net.cpp:157] Top shape: 4 3 48 48 (27648)
I1130 23:18:21.811755 12698 net.cpp:157] Top shape: 4 4 (16)
I1130 23:18:21.811758 12698 net.cpp:157] Top shape: 4 10 (40)
I1130 23:18:21.811763 12698 net.cpp:157] Top shape: 4 (4)
I1130 23:18:21.811764 12698 net.cpp:165] Memory required for data: 110832
I1130 23:18:21.811769 12698 layer_factory.hpp:77] Creating layer conv1
I1130 23:18:21.811779 12698 net.cpp:100] Creating Layer conv1
I1130 23:18:21.811781 12698 net.cpp:434] conv1 <- data
I1130 23:18:21.811792 12698 net.cpp:408] conv1 -> conv1
I1130 23:18:21.812667 12698 net.cpp:150] Setting up conv1
I1130 23:18:21.812683 12698 net.cpp:157] Top shape: 4 32 46 46 (270848)
I1130 23:18:21.812687 12698 net.cpp:165] Memory required for data: 1194224
I1130 23:18:21.812695 12698 layer_factory.hpp:77] Creating layer prelu1
I1130 23:18:21.812703 12698 net.cpp:100] Creating Layer prelu1
I1130 23:18:21.812707 12698 net.cpp:434] prelu1 <- conv1
I1130 23:18:21.812711 12698 net.cpp:395] prelu1 -> conv1 (in-place)
I1130 23:18:21.812824 12698 net.cpp:150] Setting up prelu1
I1130 23:18:21.812831 12698 net.cpp:157] Top shape: 4 32 46 46 (270848)
I1130 23:18:21.812834 12698 net.cpp:165] Memory required for data: 2277616
I1130 23:18:21.812840 12698 layer_factory.hpp:77] Creating layer pool1
I1130 23:18:21.812845 12698 net.cpp:100] Creating Layer pool1
I1130 23:18:21.812849 12698 net.cpp:434] pool1 <- conv1
I1130 23:18:21.812855 12698 net.cpp:408] pool1 -> pool1
I1130 23:18:21.812885 12698 net.cpp:150] Setting up pool1
I1130 23:18:21.812891 12698 net.cpp:157] Top shape: 4 32 23 23 (67712)
I1130 23:18:21.812893 12698 net.cpp:165] Memory required for data: 2548464
I1130 23:18:21.812896 12698 layer_factory.hpp:77] Creating layer conv2
I1130 23:18:21.812906 12698 net.cpp:100] Creating Layer conv2
I1130 23:18:21.812908 12698 net.cpp:434] conv2 <- pool1
I1130 23:18:21.812913 12698 net.cpp:408] conv2 -> conv2
I1130 23:18:21.813877 12698 net.cpp:150] Setting up conv2
I1130 23:18:21.813892 12698 net.cpp:157] Top shape: 4 64 21 21 (112896)
I1130 23:18:21.813896 12698 net.cpp:165] Memory required for data: 3000048
I1130 23:18:21.813905 12698 layer_factory.hpp:77] Creating layer prelu2
I1130 23:18:21.813911 12698 net.cpp:100] Creating Layer prelu2
I1130 23:18:21.813915 12698 net.cpp:434] prelu2 <- conv2
I1130 23:18:21.813920 12698 net.cpp:395] prelu2 -> conv2 (in-place)
I1130 23:18:21.814009 12698 net.cpp:150] Setting up prelu2
I1130 23:18:21.814018 12698 net.cpp:157] Top shape: 4 64 21 21 (112896)
I1130 23:18:21.814020 12698 net.cpp:165] Memory required for data: 3451632
I1130 23:18:21.814024 12698 layer_factory.hpp:77] Creating layer pool2
I1130 23:18:21.814029 12698 net.cpp:100] Creating Layer pool2
I1130 23:18:21.814033 12698 net.cpp:434] pool2 <- conv2
I1130 23:18:21.814038 12698 net.cpp:408] pool2 -> pool2
I1130 23:18:21.814072 12698 net.cpp:150] Setting up pool2
I1130 23:18:21.814081 12698 net.cpp:157] Top shape: 4 64 10 10 (25600)
I1130 23:18:21.814085 12698 net.cpp:165] Memory required for data: 3554032
I1130 23:18:21.814087 12698 layer_factory.hpp:77] Creating layer conv3
I1130 23:18:21.814097 12698 net.cpp:100] Creating Layer conv3
I1130 23:18:21.814101 12698 net.cpp:434] conv3 <- pool2
I1130 23:18:21.814106 12698 net.cpp:408] conv3 -> conv3
I1130 23:18:21.814811 12698 net.cpp:150] Setting up conv3
I1130 23:18:21.814822 12698 net.cpp:157] Top shape: 4 64 9 9 (20736)
I1130 23:18:21.814826 12698 net.cpp:165] Memory required for data: 3636976
I1130 23:18:21.814831 12698 layer_factory.hpp:77] Creating layer prelu3
I1130 23:18:21.814839 12698 net.cpp:100] Creating Layer prelu3
I1130 23:18:21.814843 12698 net.cpp:434] prelu3 <- conv3
I1130 23:18:21.814847 12698 net.cpp:395] prelu3 -> conv3 (in-place)
I1130 23:18:21.814924 12698 net.cpp:150] Setting up prelu3
I1130 23:18:21.814930 12698 net.cpp:157] Top shape: 4 64 9 9 (20736)
I1130 23:18:21.814932 12698 net.cpp:165] Memory required for data: 3719920
I1130 23:18:21.814939 12698 layer_factory.hpp:77] Creating layer pool3
I1130 23:18:21.814946 12698 net.cpp:100] Creating Layer pool3
I1130 23:18:21.814949 12698 net.cpp:434] pool3 <- conv3
I1130 23:18:21.814954 12698 net.cpp:408] pool3 -> pool3
I1130 23:18:21.814985 12698 net.cpp:150] Setting up pool3
I1130 23:18:21.814990 12698 net.cpp:157] Top shape: 4 64 5 5 (6400)
I1130 23:18:21.814992 12698 net.cpp:165] Memory required for data: 3745520
I1130 23:18:21.814996 12698 layer_factory.hpp:77] Creating layer conv4
I1130 23:18:21.815003 12698 net.cpp:100] Creating Layer conv4
I1130 23:18:21.815007 12698 net.cpp:434] conv4 <- pool3
I1130 23:18:21.815017 12698 net.cpp:408] conv4 -> conv4
I1130 23:18:21.816040 12698 net.cpp:150] Setting up conv4
I1130 23:18:21.816056 12698 net.cpp:157] Top shape: 4 128 4 4 (8192)
I1130 23:18:21.816059 12698 net.cpp:165] Memory required for data: 3778288
I1130 23:18:21.816066 12698 layer_factory.hpp:77] Creating layer prelu4
I1130 23:18:21.816082 12698 net.cpp:100] Creating Layer prelu4
I1130 23:18:21.816085 12698 net.cpp:434] prelu4 <- conv4
I1130 23:18:21.816090 12698 net.cpp:395] prelu4 -> conv4 (in-place)
I1130 23:18:21.816166 12698 net.cpp:150] Setting up prelu4
I1130 23:18:21.816174 12698 net.cpp:157] Top shape: 4 128 4 4 (8192)
I1130 23:18:21.816176 12698 net.cpp:165] Memory required for data: 3811056
I1130 23:18:21.816180 12698 layer_factory.hpp:77] Creating layer fc
I1130 23:18:21.816187 12698 net.cpp:100] Creating Layer fc
I1130 23:18:21.816190 12698 net.cpp:434] fc <- conv4
I1130 23:18:21.816195 12698 net.cpp:408] fc -> fc
I1130 23:18:21.820358 12698 net.cpp:150] Setting up fc
I1130 23:18:21.820372 12698 net.cpp:157] Top shape: 4 256 (1024)
I1130 23:18:21.820376 12698 net.cpp:165] Memory required for data: 3815152
I1130 23:18:21.820382 12698 layer_factory.hpp:77] Creating layer prelu5
I1130 23:18:21.820387 12698 net.cpp:100] Creating Layer prelu5
I1130 23:18:21.820391 12698 net.cpp:434] prelu5 <- fc
I1130 23:18:21.820395 12698 net.cpp:395] prelu5 -> fc (in-place)
I1130 23:18:21.820459 12698 net.cpp:150] Setting up prelu5
I1130 23:18:21.820466 12698 net.cpp:157] Top shape: 4 256 (1024)
I1130 23:18:21.820468 12698 net.cpp:165] Memory required for data: 3819248
I1130 23:18:21.820472 12698 layer_factory.hpp:77] Creating layer fc_prelu5_0_split
I1130 23:18:21.820477 12698 net.cpp:100] Creating Layer fc_prelu5_0_split
I1130 23:18:21.820479 12698 net.cpp:434] fc_prelu5_0_split <- fc
I1130 23:18:21.820485 12698 net.cpp:408] fc_prelu5_0_split -> fc_prelu5_0_split_0
I1130 23:18:21.820490 12698 net.cpp:408] fc_prelu5_0_split -> fc_prelu5_0_split_1
I1130 23:18:21.820495 12698 net.cpp:408] fc_prelu5_0_split -> fc_prelu5_0_split_2
I1130 23:18:21.820530 12698 net.cpp:150] Setting up fc_prelu5_0_split
I1130 23:18:21.820536 12698 net.cpp:157] Top shape: 4 256 (1024)
I1130 23:18:21.820539 12698 net.cpp:157] Top shape: 4 256 (1024)
I1130 23:18:21.820543 12698 net.cpp:157] Top shape: 4 256 (1024)
I1130 23:18:21.820545 12698 net.cpp:165] Memory required for data: 3831536
I1130 23:18:21.820549 12698 layer_factory.hpp:77] Creating layer score
I1130 23:18:21.820554 12698 net.cpp:100] Creating Layer score
I1130 23:18:21.820556 12698 net.cpp:434] score <- fc_prelu5_0_split_0
I1130 23:18:21.820562 12698 net.cpp:408] score -> score
I1130 23:18:21.820641 12698 net.cpp:150] Setting up score
I1130 23:18:21.820647 12698 net.cpp:157] Top shape: 4 2 (8)
I1130 23:18:21.820648 12698 net.cpp:165] Memory required for data: 3831568
I1130 23:18:21.820657 12698 layer_factory.hpp:77] Creating layer bbox_pred
I1130 23:18:21.820663 12698 net.cpp:100] Creating Layer bbox_pred
I1130 23:18:21.820667 12698 net.cpp:434] bbox_pred <- fc_prelu5_0_split_1
I1130 23:18:21.820673 12698 net.cpp:408] bbox_pred -> bbox_pred
I1130 23:18:21.820750 12698 net.cpp:150] Setting up bbox_pred
I1130 23:18:21.820756 12698 net.cpp:157] Top shape: 4 4 (16)
I1130 23:18:21.820760 12698 net.cpp:165] Memory required for data: 3831632
I1130 23:18:21.820763 12698 layer_factory.hpp:77] Creating layer landmark_pred
I1130 23:18:21.820770 12698 net.cpp:100] Creating Layer landmark_pred
I1130 23:18:21.820773 12698 net.cpp:434] landmark_pred <- fc_prelu5_0_split_2
I1130 23:18:21.820778 12698 net.cpp:408] landmark_pred -> landmark_pred
I1130 23:18:21.820868 12698 net.cpp:150] Setting up landmark_pred
I1130 23:18:21.820874 12698 net.cpp:157] Top shape: 4 10 (40)
I1130 23:18:21.820878 12698 net.cpp:165] Memory required for data: 3831792
I1130 23:18:21.820881 12698 layer_factory.hpp:77] Creating layer loss
I1130 23:18:21.820888 12698 net.cpp:100] Creating Layer loss
I1130 23:18:21.820890 12698 net.cpp:434] loss <- score
I1130 23:18:21.820894 12698 net.cpp:434] loss <- bbox_pred
I1130 23:18:21.820904 12698 net.cpp:434] loss <- landmark_pred
I1130 23:18:21.820906 12698 net.cpp:434] loss <- bbox_target
I1130 23:18:21.820910 12698 net.cpp:434] loss <- landmark_target
I1130 23:18:21.820914 12698 net.cpp:434] loss <- label
I1130 23:18:21.820919 12698 net.cpp:408] loss -> face_cls_loss
I1130 23:18:21.820925 12698 net.cpp:408] loss -> bbox_reg_loss
I1130 23:18:21.820930 12698 net.cpp:408] loss -> landmark_reg_loss
I1130 23:18:21.820935 12698 net.cpp:408] loss -> face_cls_neg_acc
I1130 23:18:21.820940 12698 net.cpp:408] loss -> face_cls_pos_acc
I1130 23:18:21.821014 12698 net.cpp:150] Setting up loss
I1130 23:18:21.821020 12698 net.cpp:157] Top shape: (1)
I1130 23:18:21.821022 12698 net.cpp:160]     with loss weight 1
I1130 23:18:21.821028 12698 net.cpp:157] Top shape: (1)
I1130 23:18:21.821032 12698 net.cpp:160]     with loss weight 0.5
I1130 23:18:21.821034 12698 net.cpp:157] Top shape: (1)
I1130 23:18:21.821038 12698 net.cpp:160]     with loss weight 1
I1130 23:18:21.821040 12698 net.cpp:157] Top shape: (1)
I1130 23:18:21.821044 12698 net.cpp:157] Top shape: (1)
I1130 23:18:21.821046 12698 net.cpp:165] Memory required for data: 3831812
I1130 23:18:21.821049 12698 net.cpp:226] loss needs backward computation.
I1130 23:18:21.821054 12698 net.cpp:226] landmark_pred needs backward computation.
I1130 23:18:21.821058 12698 net.cpp:226] bbox_pred needs backward computation.
I1130 23:18:21.821060 12698 net.cpp:226] score needs backward computation.
I1130 23:18:21.821063 12698 net.cpp:226] fc_prelu5_0_split needs backward computation.
I1130 23:18:21.821071 12698 net.cpp:226] prelu5 needs backward computation.
I1130 23:18:21.821076 12698 net.cpp:226] fc needs backward computation.
I1130 23:18:21.821080 12698 net.cpp:226] prelu4 needs backward computation.
I1130 23:18:21.821082 12698 net.cpp:226] conv4 needs backward computation.
I1130 23:18:21.821085 12698 net.cpp:226] pool3 needs backward computation.
I1130 23:18:21.821089 12698 net.cpp:226] prelu3 needs backward computation.
I1130 23:18:21.821091 12698 net.cpp:226] conv3 needs backward computation.
I1130 23:18:21.821094 12698 net.cpp:226] pool2 needs backward computation.
I1130 23:18:21.821097 12698 net.cpp:226] prelu2 needs backward computation.
I1130 23:18:21.821099 12698 net.cpp:226] conv2 needs backward computation.
I1130 23:18:21.821102 12698 net.cpp:226] pool1 needs backward computation.
I1130 23:18:21.821105 12698 net.cpp:226] prelu1 needs backward computation.
I1130 23:18:21.821107 12698 net.cpp:226] conv1 needs backward computation.
I1130 23:18:21.821111 12698 net.cpp:228] data does not need backward computation.
I1130 23:18:21.821115 12698 net.cpp:270] This network produces output bbox_reg_loss
I1130 23:18:21.821117 12698 net.cpp:270] This network produces output face_cls_loss
I1130 23:18:21.821120 12698 net.cpp:270] This network produces output face_cls_neg_acc
I1130 23:18:21.821123 12698 net.cpp:270] This network produces output face_cls_pos_acc
I1130 23:18:21.821126 12698 net.cpp:270] This network produces output landmark_reg_loss
I1130 23:18:21.821140 12698 net.cpp:283] Network initialization done.
I1130 23:18:21.821182 12698 solver.cpp:60] Solver scaffolding done.
Namespace(epoch=40, gpu=0, lr=0.01, lrp=10, lrw=0.1, net='o', size=64, snapshot=None)
I1130 23:18:21.838547 12698 solver.cpp:279] Solving oNet
I1130 23:18:21.838599 12698 solver.cpp:280] Learning Rate Policy: step
I1130 23:18:21.946321 12698 solver.cpp:228] Iteration 0, loss = 0.818923
I1130 23:18:21.946379 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0412246 (* 0.5 = 0.0206123 loss)
I1130 23:18:21.946389 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.342851 (* 1 = 0.342851 loss)
I1130 23:18:21.946395 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.664062
I1130 23:18:21.946401 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.421875
I1130 23:18:21.946408 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.45546 (* 1 = 0.45546 loss)
I1130 23:18:21.946418 12698 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I1130 23:18:36.331619 12698 solver.cpp:228] Iteration 500, loss = 0.250634
I1130 23:18:36.331691 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00968415 (* 0.5 = 0.00484208 loss)
I1130 23:18:36.331699 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.132141 (* 1 = 0.132141 loss)
I1130 23:18:36.331703 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.953125
I1130 23:18:36.331707 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.78125
I1130 23:18:36.331713 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00660889 (* 1 = 0.00660889 loss)
I1130 23:18:36.331719 12698 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I1130 23:18:50.724737 12698 solver.cpp:228] Iteration 1000, loss = 0.16595
I1130 23:18:50.724827 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0102917 (* 0.5 = 0.00514583 loss)
I1130 23:18:50.724835 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.128545 (* 1 = 0.128545 loss)
I1130 23:18:50.724840 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:18:50.724844 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 23:18:50.724850 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0047428 (* 1 = 0.0047428 loss)
I1130 23:18:50.724856 12698 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I1130 23:19:05.107332 12698 solver.cpp:228] Iteration 1500, loss = 0.137845
I1130 23:19:05.107405 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0103169 (* 0.5 = 0.00515847 loss)
I1130 23:19:05.107414 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0887535 (* 1 = 0.0887535 loss)
I1130 23:19:05.107419 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.953125
I1130 23:19:05.107424 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:19:05.107429 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00386367 (* 1 = 0.00386367 loss)
I1130 23:19:05.107436 12698 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I1130 23:19:19.519363 12698 solver.cpp:228] Iteration 2000, loss = 0.11421
I1130 23:19:19.519433 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00763192 (* 0.5 = 0.00381596 loss)
I1130 23:19:19.519443 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.10268 (* 1 = 0.10268 loss)
I1130 23:19:19.519446 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:19:19.519451 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.796875
I1130 23:19:19.519457 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00432949 (* 1 = 0.00432949 loss)
I1130 23:19:19.519464 12698 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I1130 23:19:33.899236 12698 solver.cpp:228] Iteration 2500, loss = 0.124673
I1130 23:19:33.899309 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00807041 (* 0.5 = 0.00403521 loss)
I1130 23:19:33.899318 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.154776 (* 1 = 0.154776 loss)
I1130 23:19:33.899322 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.953125
I1130 23:19:33.899327 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.75
I1130 23:19:33.899333 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00388746 (* 1 = 0.00388746 loss)
I1130 23:19:33.899339 12698 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I1130 23:19:48.262645 12698 solver.cpp:228] Iteration 3000, loss = 0.0969479
I1130 23:19:48.262719 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00783507 (* 0.5 = 0.00391754 loss)
I1130 23:19:48.262727 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0503408 (* 1 = 0.0503408 loss)
I1130 23:19:48.262732 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:19:48.262737 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:19:48.262742 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00349656 (* 1 = 0.00349656 loss)
I1130 23:19:48.262758 12698 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I1130 23:20:02.617861 12698 solver.cpp:228] Iteration 3500, loss = 0.110902
I1130 23:20:02.617935 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0069166 (* 0.5 = 0.0034583 loss)
I1130 23:20:02.617944 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.137818 (* 1 = 0.137818 loss)
I1130 23:20:02.617949 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.9375
I1130 23:20:02.617952 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 23:20:02.617959 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00331471 (* 1 = 0.00331471 loss)
I1130 23:20:02.617964 12698 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I1130 23:20:16.990568 12698 solver.cpp:228] Iteration 4000, loss = 0.0958518
I1130 23:20:16.990634 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0084077 (* 0.5 = 0.00420385 loss)
I1130 23:20:16.990643 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0728733 (* 1 = 0.0728733 loss)
I1130 23:20:16.990648 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:20:16.990653 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 23:20:16.990658 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00280928 (* 1 = 0.00280928 loss)
I1130 23:20:16.990664 12698 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I1130 23:20:25.562311 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_4299.caffemodel
I1130 23:20:25.586678 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_4299.solverstate
I1130 23:20:25.589439 12698 solver.cpp:337] Iteration 4299, Testing net (#0)
I1130 23:20:50.594357 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00785503 (* 0.5 = 0.00392751 loss)
I1130 23:20:50.594419 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.110202 (* 1 = 0.110202 loss)
I1130 23:20:50.594425 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.987157
I1130 23:20:50.594429 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.785524
I1130 23:20:50.594434 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00320348 (* 1 = 0.00320348 loss)
I1130 23:20:56.409380 12698 solver.cpp:228] Iteration 4500, loss = 0.0871493
I1130 23:20:56.409446 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00712044 (* 0.5 = 0.00356022 loss)
I1130 23:20:56.409453 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.1019 (* 1 = 0.1019 loss)
I1130 23:20:56.409458 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 23:20:56.409463 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:20:56.409468 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00222662 (* 1 = 0.00222662 loss)
I1130 23:20:56.409476 12698 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I1130 23:21:10.828398 12698 solver.cpp:228] Iteration 5000, loss = 0.0984292
I1130 23:21:10.828465 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0107748 (* 0.5 = 0.0053874 loss)
I1130 23:21:10.828474 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.125414 (* 1 = 0.125414 loss)
I1130 23:21:10.828480 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 23:21:10.828485 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.734375
I1130 23:21:10.828490 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00481541 (* 1 = 0.00481541 loss)
I1130 23:21:10.828496 12698 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I1130 23:21:25.213479 12698 solver.cpp:228] Iteration 5500, loss = 0.0752207
I1130 23:21:25.213551 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00577003 (* 0.5 = 0.00288502 loss)
I1130 23:21:25.213559 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0469867 (* 1 = 0.0469867 loss)
I1130 23:21:25.213572 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 23:21:25.213577 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:21:25.213583 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00263645 (* 1 = 0.00263645 loss)
I1130 23:21:25.213589 12698 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I1130 23:21:39.586833 12698 solver.cpp:228] Iteration 6000, loss = 0.0957355
I1130 23:21:39.586901 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00645177 (* 0.5 = 0.00322589 loss)
I1130 23:21:39.586910 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0916465 (* 1 = 0.0916465 loss)
I1130 23:21:39.586915 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:21:39.586920 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.8125
I1130 23:21:39.586925 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0031564 (* 1 = 0.0031564 loss)
I1130 23:21:39.586932 12698 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I1130 23:21:53.978899 12698 solver.cpp:228] Iteration 6500, loss = 0.0806694
I1130 23:21:53.978966 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00592686 (* 0.5 = 0.00296343 loss)
I1130 23:21:53.978974 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0673757 (* 1 = 0.0673757 loss)
I1130 23:21:53.978979 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:21:53.978983 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:21:53.978989 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00162024 (* 1 = 0.00162024 loss)
I1130 23:21:53.978996 12698 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I1130 23:22:08.379876 12698 solver.cpp:228] Iteration 7000, loss = 0.075038
I1130 23:22:08.379952 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00725521 (* 0.5 = 0.0036276 loss)
I1130 23:22:08.379961 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0960106 (* 1 = 0.0960106 loss)
I1130 23:22:08.379966 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 23:22:08.379971 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:22:08.379976 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00148664 (* 1 = 0.00148664 loss)
I1130 23:22:08.379983 12698 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I1130 23:22:22.762217 12698 solver.cpp:228] Iteration 7500, loss = 0.086444
I1130 23:22:22.762289 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0067518 (* 0.5 = 0.0033759 loss)
I1130 23:22:22.762296 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.101311 (* 1 = 0.101311 loss)
I1130 23:22:22.762301 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:22:22.762305 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.828125
I1130 23:22:22.762311 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00153362 (* 1 = 0.00153362 loss)
I1130 23:22:22.762318 12698 sgd_solver.cpp:106] Iteration 7500, lr = 0.01
I1130 23:22:37.149618 12698 solver.cpp:228] Iteration 8000, loss = 0.0635739
I1130 23:22:37.149683 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00667803 (* 0.5 = 0.00333902 loss)
I1130 23:22:37.149693 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0463211 (* 1 = 0.0463211 loss)
I1130 23:22:37.149696 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:22:37.149701 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:22:37.149708 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00189511 (* 1 = 0.00189511 loss)
I1130 23:22:37.149713 12698 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I1130 23:22:51.535017 12698 solver.cpp:228] Iteration 8500, loss = 0.0888373
I1130 23:22:51.535096 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00609463 (* 0.5 = 0.00304732 loss)
I1130 23:22:51.535115 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0901375 (* 1 = 0.0901375 loss)
I1130 23:22:51.535121 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 23:22:51.535125 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:22:51.535130 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00335092 (* 1 = 0.00335092 loss)
I1130 23:22:51.535137 12698 sgd_solver.cpp:106] Iteration 8500, lr = 0.01
I1130 23:22:54.329171 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_8598.caffemodel
I1130 23:22:54.351802 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_8598.solverstate
I1130 23:22:54.354609 12698 solver.cpp:337] Iteration 8598, Testing net (#0)
I1130 23:23:19.164780 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00713559 (* 0.5 = 0.00356779 loss)
I1130 23:23:19.164840 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0823303 (* 1 = 0.0823303 loss)
I1130 23:23:19.164847 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.974193
I1130 23:23:19.164854 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.878944
I1130 23:23:19.164858 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00238827 (* 1 = 0.00238827 loss)
I1130 23:23:30.763869 12698 solver.cpp:228] Iteration 9000, loss = 0.0714594
I1130 23:23:30.763932 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00508964 (* 0.5 = 0.00254482 loss)
I1130 23:23:30.763942 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0893453 (* 1 = 0.0893453 loss)
I1130 23:23:30.763947 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 23:23:30.763952 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 23:23:30.763957 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00322255 (* 1 = 0.00322255 loss)
I1130 23:23:30.763963 12698 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I1130 23:23:45.145087 12698 solver.cpp:228] Iteration 9500, loss = 0.0694616
I1130 23:23:45.145164 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00680282 (* 0.5 = 0.00340141 loss)
I1130 23:23:45.145174 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0669135 (* 1 = 0.0669135 loss)
I1130 23:23:45.145179 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:23:45.145184 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 23:23:45.145190 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0019679 (* 1 = 0.0019679 loss)
I1130 23:23:45.145196 12698 sgd_solver.cpp:106] Iteration 9500, lr = 0.01
I1130 23:23:59.530921 12698 solver.cpp:228] Iteration 10000, loss = 0.0797649
I1130 23:23:59.530994 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00889211 (* 0.5 = 0.00444606 loss)
I1130 23:23:59.531003 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0522417 (* 1 = 0.0522417 loss)
I1130 23:23:59.531008 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:23:59.531013 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:23:59.531019 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00449027 (* 1 = 0.00449027 loss)
I1130 23:23:59.531026 12698 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I1130 23:24:13.935834 12698 solver.cpp:228] Iteration 10500, loss = 0.0575856
I1130 23:24:13.935900 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00589674 (* 0.5 = 0.00294837 loss)
I1130 23:24:13.935909 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0523042 (* 1 = 0.0523042 loss)
I1130 23:24:13.935914 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 23:24:13.935919 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:24:13.935923 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00244539 (* 1 = 0.00244539 loss)
I1130 23:24:13.935940 12698 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I1130 23:24:28.330796 12698 solver.cpp:228] Iteration 11000, loss = 0.0831368
I1130 23:24:28.330867 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00691939 (* 0.5 = 0.00345969 loss)
I1130 23:24:28.330875 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0553372 (* 1 = 0.0553372 loss)
I1130 23:24:28.330880 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:24:28.330885 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:24:28.330890 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00237119 (* 1 = 0.00237119 loss)
I1130 23:24:28.330898 12698 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I1130 23:24:42.725636 12698 solver.cpp:228] Iteration 11500, loss = 0.0658367
I1130 23:24:42.725709 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00774595 (* 0.5 = 0.00387298 loss)
I1130 23:24:42.725718 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0589159 (* 1 = 0.0589159 loss)
I1130 23:24:42.725723 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:24:42.725728 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 23:24:42.725733 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0015059 (* 1 = 0.0015059 loss)
I1130 23:24:42.725740 12698 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I1130 23:24:57.135334 12698 solver.cpp:228] Iteration 12000, loss = 0.0656046
I1130 23:24:57.135408 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00626252 (* 0.5 = 0.00313126 loss)
I1130 23:24:57.135419 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0438507 (* 1 = 0.0438507 loss)
I1130 23:24:57.135426 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 23:24:57.135431 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:24:57.135437 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00240726 (* 1 = 0.00240726 loss)
I1130 23:24:57.135445 12698 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I1130 23:25:11.533802 12698 solver.cpp:228] Iteration 12500, loss = 0.0745574
I1130 23:25:11.533882 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00695411 (* 0.5 = 0.00347706 loss)
I1130 23:25:11.533891 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0600877 (* 1 = 0.0600877 loss)
I1130 23:25:11.533896 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:25:11.533901 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:25:11.533907 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00281095 (* 1 = 0.00281095 loss)
I1130 23:25:11.533915 12698 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I1130 23:25:22.944612 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_12897.caffemodel
I1130 23:25:22.968153 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_12897.solverstate
I1130 23:25:22.970969 12698 solver.cpp:337] Iteration 12897, Testing net (#0)
I1130 23:25:48.385166 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00676101 (* 0.5 = 0.00338051 loss)
I1130 23:25:48.385226 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0732696 (* 1 = 0.0732696 loss)
I1130 23:25:48.385233 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.980484
I1130 23:25:48.385239 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.888451
I1130 23:25:48.385246 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00200809 (* 1 = 0.00200809 loss)
I1130 23:25:51.364889 12698 solver.cpp:228] Iteration 13000, loss = 0.0543435
I1130 23:25:51.364953 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00673058 (* 0.5 = 0.00336529 loss)
I1130 23:25:51.364961 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.056175 (* 1 = 0.056175 loss)
I1130 23:25:51.364976 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:25:51.364981 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1130 23:25:51.364986 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00263925 (* 1 = 0.00263925 loss)
I1130 23:25:51.364994 12698 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I1130 23:26:05.727715 12698 solver.cpp:228] Iteration 13500, loss = 0.0766806
I1130 23:26:05.727790 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00565375 (* 0.5 = 0.00282687 loss)
I1130 23:26:05.727798 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0639451 (* 1 = 0.0639451 loss)
I1130 23:26:05.727803 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:26:05.727808 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 23:26:05.727813 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00174425 (* 1 = 0.00174425 loss)
I1130 23:26:05.727820 12698 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I1130 23:26:20.101766 12698 solver.cpp:228] Iteration 14000, loss = 0.0621859
I1130 23:26:20.101840 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00620524 (* 0.5 = 0.00310262 loss)
I1130 23:26:20.101850 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0838106 (* 1 = 0.0838106 loss)
I1130 23:26:20.101853 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 23:26:20.101858 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:26:20.101863 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00158694 (* 1 = 0.00158694 loss)
I1130 23:26:20.101871 12698 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I1130 23:26:34.476984 12698 solver.cpp:228] Iteration 14500, loss = 0.0621528
I1130 23:26:34.477051 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0061024 (* 0.5 = 0.0030512 loss)
I1130 23:26:34.477058 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0354868 (* 1 = 0.0354868 loss)
I1130 23:26:34.477063 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:26:34.477074 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:26:34.477082 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00141176 (* 1 = 0.00141176 loss)
I1130 23:26:34.477088 12698 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I1130 23:26:48.862671 12698 solver.cpp:228] Iteration 15000, loss = 0.0698836
I1130 23:26:48.862747 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00605932 (* 0.5 = 0.00302966 loss)
I1130 23:26:48.862756 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0647174 (* 1 = 0.0647174 loss)
I1130 23:26:48.862761 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:26:48.862764 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 23:26:48.862769 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00235471 (* 1 = 0.00235471 loss)
I1130 23:26:48.862776 12698 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I1130 23:27:03.237229 12698 solver.cpp:228] Iteration 15500, loss = 0.0524846
I1130 23:27:03.237311 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00871752 (* 0.5 = 0.00435876 loss)
I1130 23:27:03.237321 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0681402 (* 1 = 0.0681402 loss)
I1130 23:27:03.237327 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:27:03.237332 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:27:03.237339 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00227096 (* 1 = 0.00227096 loss)
I1130 23:27:03.237346 12698 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I1130 23:27:17.625329 12698 solver.cpp:228] Iteration 16000, loss = 0.0718378
I1130 23:27:17.625406 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00457162 (* 0.5 = 0.00228581 loss)
I1130 23:27:17.625416 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.038047 (* 1 = 0.038047 loss)
I1130 23:27:17.625421 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:27:17.625424 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:27:17.625429 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00147184 (* 1 = 0.00147184 loss)
I1130 23:27:17.625437 12698 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I1130 23:27:31.979702 12698 solver.cpp:228] Iteration 16500, loss = 0.0601535
I1130 23:27:31.979775 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00622044 (* 0.5 = 0.00311022 loss)
I1130 23:27:31.979784 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0543296 (* 1 = 0.0543296 loss)
I1130 23:27:31.979789 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:27:31.979794 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 23:27:31.979799 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00143625 (* 1 = 0.00143625 loss)
I1130 23:27:31.979806 12698 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I1130 23:27:46.344135 12698 solver.cpp:228] Iteration 17000, loss = 0.0605334
I1130 23:27:46.344207 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00607072 (* 0.5 = 0.00303536 loss)
I1130 23:27:46.344214 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0478391 (* 1 = 0.0478391 loss)
I1130 23:27:46.344219 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:27:46.344223 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:27:46.344229 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00113832 (* 1 = 0.00113832 loss)
I1130 23:27:46.344236 12698 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I1130 23:27:51.958334 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_17196.caffemodel
I1130 23:27:51.981256 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_17196.solverstate
I1130 23:27:51.984036 12698 solver.cpp:337] Iteration 17196, Testing net (#0)
I1130 23:28:16.818923 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00655716 (* 0.5 = 0.00327858 loss)
I1130 23:28:16.818991 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0698786 (* 1 = 0.0698786 loss)
I1130 23:28:16.818999 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.976945
I1130 23:28:16.819002 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.904286
I1130 23:28:16.819008 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00184385 (* 1 = 0.00184385 loss)
I1130 23:28:25.515945 12698 solver.cpp:228] Iteration 17500, loss = 0.0672777
I1130 23:28:25.516013 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00433074 (* 0.5 = 0.00216537 loss)
I1130 23:28:25.516022 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0578374 (* 1 = 0.0578374 loss)
I1130 23:28:25.516026 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 23:28:25.516031 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:28:25.516036 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00132527 (* 1 = 0.00132527 loss)
I1130 23:28:25.516044 12698 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I1130 23:28:39.784720 12698 solver.cpp:228] Iteration 18000, loss = 0.049676
I1130 23:28:39.784795 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00616467 (* 0.5 = 0.00308233 loss)
I1130 23:28:39.784803 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0508727 (* 1 = 0.0508727 loss)
I1130 23:28:39.784807 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:28:39.784812 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:28:39.784827 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00271304 (* 1 = 0.00271304 loss)
I1130 23:28:39.784834 12698 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I1130 23:28:54.042177 12698 solver.cpp:228] Iteration 18500, loss = 0.0684518
I1130 23:28:54.042249 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00426644 (* 0.5 = 0.00213322 loss)
I1130 23:28:54.042258 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0534142 (* 1 = 0.0534142 loss)
I1130 23:28:54.042263 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:28:54.042268 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:28:54.042273 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00127894 (* 1 = 0.00127894 loss)
I1130 23:28:54.042279 12698 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I1130 23:29:08.316941 12698 solver.cpp:228] Iteration 19000, loss = 0.0578775
I1130 23:29:08.317016 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00554187 (* 0.5 = 0.00277093 loss)
I1130 23:29:08.317026 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0395834 (* 1 = 0.0395834 loss)
I1130 23:29:08.317030 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:29:08.317035 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:29:08.317041 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00160691 (* 1 = 0.00160691 loss)
I1130 23:29:08.317049 12698 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I1130 23:29:22.587719 12698 solver.cpp:228] Iteration 19500, loss = 0.0588004
I1130 23:29:22.587795 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00692126 (* 0.5 = 0.00346063 loss)
I1130 23:29:22.587805 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0604048 (* 1 = 0.0604048 loss)
I1130 23:29:22.587810 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:29:22.587813 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:29:22.587819 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0013495 (* 1 = 0.0013495 loss)
I1130 23:29:22.587826 12698 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I1130 23:29:36.847265 12698 solver.cpp:228] Iteration 20000, loss = 0.0655042
I1130 23:29:36.847335 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00512446 (* 0.5 = 0.00256223 loss)
I1130 23:29:36.847343 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0755265 (* 1 = 0.0755265 loss)
I1130 23:29:36.847348 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:29:36.847353 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:29:36.847358 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00153715 (* 1 = 0.00153715 loss)
I1130 23:29:36.847365 12698 sgd_solver.cpp:106] Iteration 20000, lr = 0.01
I1130 23:29:51.111824 12698 solver.cpp:228] Iteration 20500, loss = 0.0467116
I1130 23:29:51.111896 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00699295 (* 0.5 = 0.00349648 loss)
I1130 23:29:51.111904 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.074207 (* 1 = 0.074207 loss)
I1130 23:29:51.111909 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:29:51.111913 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 23:29:51.111919 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00141378 (* 1 = 0.00141378 loss)
I1130 23:29:51.111927 12698 sgd_solver.cpp:106] Iteration 20500, lr = 0.01
I1130 23:30:05.386962 12698 solver.cpp:228] Iteration 21000, loss = 0.0662235
I1130 23:30:05.387037 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00487242 (* 0.5 = 0.00243621 loss)
I1130 23:30:05.387045 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0495397 (* 1 = 0.0495397 loss)
I1130 23:30:05.387060 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:30:05.387065 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 23:30:05.387078 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0011952 (* 1 = 0.0011952 loss)
I1130 23:30:05.387085 12698 sgd_solver.cpp:106] Iteration 21000, lr = 0.01
I1130 23:30:19.489190 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_21495.caffemodel
I1130 23:30:19.513197 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_21495.solverstate
I1130 23:30:19.516722 12698 solver.cpp:337] Iteration 21495, Testing net (#0)
I1130 23:30:46.634163 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00638239 (* 0.5 = 0.0031912 loss)
I1130 23:30:46.634220 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0684124 (* 1 = 0.0684124 loss)
I1130 23:30:46.634227 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.976038
I1130 23:30:46.634232 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.908334
I1130 23:30:46.634238 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00180869 (* 1 = 0.00180869 loss)
I1130 23:30:46.806887 12698 solver.cpp:228] Iteration 21500, loss = 0.0550912
I1130 23:30:46.806960 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00403464 (* 0.5 = 0.00201732 loss)
I1130 23:30:46.806970 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0544024 (* 1 = 0.0544024 loss)
I1130 23:30:46.806975 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:30:46.806980 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:30:46.806985 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00244742 (* 1 = 0.00244742 loss)
I1130 23:30:46.806993 12698 sgd_solver.cpp:106] Iteration 21500, lr = 0.01
I1130 23:31:01.195271 12698 solver.cpp:228] Iteration 22000, loss = 0.0580664
I1130 23:31:01.195345 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00723692 (* 0.5 = 0.00361846 loss)
I1130 23:31:01.195354 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0315019 (* 1 = 0.0315019 loss)
I1130 23:31:01.195358 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:31:01.195363 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 23:31:01.195369 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00255389 (* 1 = 0.00255389 loss)
I1130 23:31:01.195375 12698 sgd_solver.cpp:106] Iteration 22000, lr = 0.01
I1130 23:31:15.581493 12698 solver.cpp:228] Iteration 22500, loss = 0.0624012
I1130 23:31:15.581568 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0058341 (* 0.5 = 0.00291705 loss)
I1130 23:31:15.581578 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0420928 (* 1 = 0.0420928 loss)
I1130 23:31:15.581584 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:31:15.581589 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:31:15.581596 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000919882 (* 1 = 0.000919882 loss)
I1130 23:31:15.581604 12698 sgd_solver.cpp:106] Iteration 22500, lr = 0.01
I1130 23:31:29.966758 12698 solver.cpp:228] Iteration 23000, loss = 0.0468234
I1130 23:31:29.966833 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0070419 (* 0.5 = 0.00352095 loss)
I1130 23:31:29.966842 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0952737 (* 1 = 0.0952737 loss)
I1130 23:31:29.966847 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 23:31:29.966851 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 23:31:29.966856 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00181135 (* 1 = 0.00181135 loss)
I1130 23:31:29.966863 12698 sgd_solver.cpp:106] Iteration 23000, lr = 0.01
I1130 23:31:44.347996 12698 solver.cpp:228] Iteration 23500, loss = 0.0637446
I1130 23:31:44.348079 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00475353 (* 0.5 = 0.00237677 loss)
I1130 23:31:44.348090 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0459109 (* 1 = 0.0459109 loss)
I1130 23:31:44.348096 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 23:31:44.348100 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 23:31:44.348106 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000995354 (* 1 = 0.000995354 loss)
I1130 23:31:44.348114 12698 sgd_solver.cpp:106] Iteration 23500, lr = 0.01
I1130 23:31:58.718760 12698 solver.cpp:228] Iteration 24000, loss = 0.0511048
I1130 23:31:58.718835 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00494058 (* 0.5 = 0.00247029 loss)
I1130 23:31:58.718844 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0432286 (* 1 = 0.0432286 loss)
I1130 23:31:58.718849 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:31:58.718854 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:31:58.718859 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00096499 (* 1 = 0.00096499 loss)
I1130 23:31:58.718868 12698 sgd_solver.cpp:106] Iteration 24000, lr = 0.01
I1130 23:32:13.082764 12698 solver.cpp:228] Iteration 24500, loss = 0.0572269
I1130 23:32:13.082834 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00495142 (* 0.5 = 0.00247571 loss)
I1130 23:32:13.082844 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0345128 (* 1 = 0.0345128 loss)
I1130 23:32:13.082849 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:32:13.082852 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:32:13.082859 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00210834 (* 1 = 0.00210834 loss)
I1130 23:32:13.082864 12698 sgd_solver.cpp:106] Iteration 24500, lr = 0.01
I1130 23:32:27.464107 12698 solver.cpp:228] Iteration 25000, loss = 0.0578837
I1130 23:32:27.464186 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00689865 (* 0.5 = 0.00344933 loss)
I1130 23:32:27.464196 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.052418 (* 1 = 0.052418 loss)
I1130 23:32:27.464202 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:32:27.464208 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:32:27.464215 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00111967 (* 1 = 0.00111967 loss)
I1130 23:32:27.464222 12698 sgd_solver.cpp:106] Iteration 25000, lr = 0.01
I1130 23:32:41.861836 12698 solver.cpp:228] Iteration 25500, loss = 0.0483806
I1130 23:32:41.861910 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00788709 (* 0.5 = 0.00394355 loss)
I1130 23:32:41.861920 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.093604 (* 1 = 0.093604 loss)
I1130 23:32:41.861924 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 23:32:41.861929 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.84375
I1130 23:32:41.861934 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0020835 (* 1 = 0.0020835 loss)
I1130 23:32:41.861941 12698 sgd_solver.cpp:106] Iteration 25500, lr = 0.01
I1130 23:32:50.288702 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_25794.caffemodel
I1130 23:32:50.312531 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_25794.solverstate
I1130 23:32:50.315507 12698 solver.cpp:337] Iteration 25794, Testing net (#0)
I1130 23:33:17.544344 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0062945 (* 0.5 = 0.00314725 loss)
I1130 23:33:17.544402 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0644608 (* 1 = 0.0644608 loss)
I1130 23:33:17.544409 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.982711
I1130 23:33:17.544421 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.905335
I1130 23:33:17.544427 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00168667 (* 1 = 0.00168667 loss)
I1130 23:33:23.518774 12698 solver.cpp:228] Iteration 26000, loss = 0.0608629
I1130 23:33:23.518859 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00666881 (* 0.5 = 0.00333441 loss)
I1130 23:33:23.518869 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0597685 (* 1 = 0.0597685 loss)
I1130 23:33:23.518874 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:33:23.518879 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:33:23.518884 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00090656 (* 1 = 0.00090656 loss)
I1130 23:33:23.518893 12698 sgd_solver.cpp:106] Iteration 26000, lr = 0.01
I1130 23:33:37.941673 12698 solver.cpp:228] Iteration 26500, loss = 0.0486127
I1130 23:33:37.941740 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00541639 (* 0.5 = 0.0027082 loss)
I1130 23:33:37.941748 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.024659 (* 1 = 0.024659 loss)
I1130 23:33:37.941753 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:33:37.941758 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:33:37.941763 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00272792 (* 1 = 0.00272792 loss)
I1130 23:33:37.941771 12698 sgd_solver.cpp:106] Iteration 26500, lr = 0.01
I1130 23:33:52.328060 12698 solver.cpp:228] Iteration 27000, loss = 0.0574558
I1130 23:33:52.328140 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00630164 (* 0.5 = 0.00315082 loss)
I1130 23:33:52.328150 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0534677 (* 1 = 0.0534677 loss)
I1130 23:33:52.328153 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:33:52.328158 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:33:52.328163 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0010064 (* 1 = 0.0010064 loss)
I1130 23:33:52.328171 12698 sgd_solver.cpp:106] Iteration 27000, lr = 0.01
I1130 23:34:06.736727 12698 solver.cpp:228] Iteration 27500, loss = 0.05473
I1130 23:34:06.736804 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00719515 (* 0.5 = 0.00359757 loss)
I1130 23:34:06.736812 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.05692 (* 1 = 0.05692 loss)
I1130 23:34:06.736817 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:34:06.736821 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:34:06.736827 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00164106 (* 1 = 0.00164106 loss)
I1130 23:34:06.736835 12698 sgd_solver.cpp:106] Iteration 27500, lr = 0.01
I1130 23:34:21.140601 12698 solver.cpp:228] Iteration 28000, loss = 0.0505541
I1130 23:34:21.140677 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00655167 (* 0.5 = 0.00327583 loss)
I1130 23:34:21.140686 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0639944 (* 1 = 0.0639944 loss)
I1130 23:34:21.140691 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:34:21.140696 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 23:34:21.140700 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00176825 (* 1 = 0.00176825 loss)
I1130 23:34:21.140708 12698 sgd_solver.cpp:106] Iteration 28000, lr = 0.01
I1130 23:34:35.552059 12698 solver.cpp:228] Iteration 28500, loss = 0.0579257
I1130 23:34:35.552134 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00559217 (* 0.5 = 0.00279608 loss)
I1130 23:34:35.552142 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0416069 (* 1 = 0.0416069 loss)
I1130 23:34:35.552156 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:34:35.552161 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:34:35.552167 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00303402 (* 1 = 0.00303402 loss)
I1130 23:34:35.552173 12698 sgd_solver.cpp:106] Iteration 28500, lr = 0.01
I1130 23:34:49.959538 12698 solver.cpp:228] Iteration 29000, loss = 0.046424
I1130 23:34:49.959612 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00608383 (* 0.5 = 0.00304191 loss)
I1130 23:34:49.959621 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0460091 (* 1 = 0.0460091 loss)
I1130 23:34:49.959626 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:34:49.959630 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:34:49.959636 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00113167 (* 1 = 0.00113167 loss)
I1130 23:34:49.959643 12698 sgd_solver.cpp:106] Iteration 29000, lr = 0.01
I1130 23:35:04.369819 12698 solver.cpp:228] Iteration 29500, loss = 0.0569439
I1130 23:35:04.369895 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00423429 (* 0.5 = 0.00211715 loss)
I1130 23:35:04.369904 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0444745 (* 1 = 0.0444745 loss)
I1130 23:35:04.369910 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:35:04.369913 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:35:04.369920 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00128006 (* 1 = 0.00128006 loss)
I1130 23:35:04.369925 12698 sgd_solver.cpp:106] Iteration 29500, lr = 0.01
I1130 23:35:18.776626 12698 solver.cpp:228] Iteration 30000, loss = 0.0505071
I1130 23:35:18.776700 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00521654 (* 0.5 = 0.00260827 loss)
I1130 23:35:18.776708 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0207696 (* 1 = 0.0207696 loss)
I1130 23:35:18.776712 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:35:18.776717 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:35:18.776722 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00177703 (* 1 = 0.00177703 loss)
I1130 23:35:18.776731 12698 sgd_solver.cpp:106] Iteration 30000, lr = 0.01
I1130 23:35:21.435698 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_30093.caffemodel
I1130 23:35:21.458497 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_30093.solverstate
I1130 23:35:21.461416 12698 solver.cpp:337] Iteration 30093, Testing net (#0)
I1130 23:35:46.281896 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00614036 (* 0.5 = 0.00307018 loss)
I1130 23:35:46.281960 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.069466 (* 1 = 0.069466 loss)
I1130 23:35:46.281967 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.983078
I1130 23:35:46.281971 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.888691
I1130 23:35:46.281977 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00161853 (* 1 = 0.00161853 loss)
I1130 23:35:58.036993 12698 solver.cpp:228] Iteration 30500, loss = 0.0525269
I1130 23:35:58.037084 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00573733 (* 0.5 = 0.00286866 loss)
I1130 23:35:58.037096 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0693448 (* 1 = 0.0693448 loss)
I1130 23:35:58.037101 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.953125
I1130 23:35:58.037104 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:35:58.037111 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000987508 (* 1 = 0.000987508 loss)
I1130 23:35:58.037118 12698 sgd_solver.cpp:106] Iteration 30500, lr = 0.01
I1130 23:36:12.447408 12698 solver.cpp:228] Iteration 31000, loss = 0.0555138
I1130 23:36:12.447482 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0072247 (* 0.5 = 0.00361235 loss)
I1130 23:36:12.447491 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0433147 (* 1 = 0.0433147 loss)
I1130 23:36:12.447496 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:36:12.447500 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 23:36:12.447506 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00230386 (* 1 = 0.00230386 loss)
I1130 23:36:12.447513 12698 sgd_solver.cpp:106] Iteration 31000, lr = 0.01
I1130 23:36:26.853401 12698 solver.cpp:228] Iteration 31500, loss = 0.0453525
I1130 23:36:26.853482 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00679804 (* 0.5 = 0.00339902 loss)
I1130 23:36:26.853490 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0505554 (* 1 = 0.0505554 loss)
I1130 23:36:26.853495 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:36:26.853500 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:36:26.853505 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00135443 (* 1 = 0.00135443 loss)
I1130 23:36:26.853513 12698 sgd_solver.cpp:106] Iteration 31500, lr = 0.01
I1130 23:36:41.258379 12698 solver.cpp:228] Iteration 32000, loss = 0.0554677
I1130 23:36:41.258451 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00585728 (* 0.5 = 0.00292864 loss)
I1130 23:36:41.258460 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0507431 (* 1 = 0.0507431 loss)
I1130 23:36:41.258465 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:36:41.258469 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:36:41.258474 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00120688 (* 1 = 0.00120688 loss)
I1130 23:36:41.258482 12698 sgd_solver.cpp:106] Iteration 32000, lr = 0.01
I1130 23:36:55.666054 12698 solver.cpp:228] Iteration 32500, loss = 0.0471158
I1130 23:36:55.666123 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00670386 (* 0.5 = 0.00335193 loss)
I1130 23:36:55.666131 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0325041 (* 1 = 0.0325041 loss)
I1130 23:36:55.666136 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:36:55.666141 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:36:55.666146 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00133909 (* 1 = 0.00133909 loss)
I1130 23:36:55.666153 12698 sgd_solver.cpp:106] Iteration 32500, lr = 0.01
I1130 23:37:10.079424 12698 solver.cpp:228] Iteration 33000, loss = 0.054088
I1130 23:37:10.079500 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0055226 (* 0.5 = 0.0027613 loss)
I1130 23:37:10.079509 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0612376 (* 1 = 0.0612376 loss)
I1130 23:37:10.079514 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:37:10.079519 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:37:10.079524 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000995574 (* 1 = 0.000995574 loss)
I1130 23:37:10.079531 12698 sgd_solver.cpp:106] Iteration 33000, lr = 0.01
I1130 23:37:24.476951 12698 solver.cpp:228] Iteration 33500, loss = 0.0521767
I1130 23:37:24.477021 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00515128 (* 0.5 = 0.00257564 loss)
I1130 23:37:24.477030 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0396143 (* 1 = 0.0396143 loss)
I1130 23:37:24.477035 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:37:24.477039 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 23:37:24.477044 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00235379 (* 1 = 0.00235379 loss)
I1130 23:37:24.477061 12698 sgd_solver.cpp:106] Iteration 33500, lr = 0.01
I1130 23:37:38.892658 12698 solver.cpp:228] Iteration 34000, loss = 0.0457384
I1130 23:37:38.892730 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0057049 (* 0.5 = 0.00285245 loss)
I1130 23:37:38.892740 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0665283 (* 1 = 0.0665283 loss)
I1130 23:37:38.892745 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:37:38.892750 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:37:38.892755 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00131973 (* 1 = 0.00131973 loss)
I1130 23:37:38.892762 12698 sgd_solver.cpp:106] Iteration 34000, lr = 0.01
I1130 23:37:50.148705 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_34392.caffemodel
I1130 23:37:50.172353 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_34392.solverstate
I1130 23:37:50.175259 12698 solver.cpp:337] Iteration 34392, Testing net (#0)
I1130 23:38:15.145500 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00609372 (* 0.5 = 0.00304686 loss)
I1130 23:38:15.145556 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0667225 (* 1 = 0.0667225 loss)
I1130 23:38:15.145562 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.967708
I1130 23:38:15.145567 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.931667
I1130 23:38:15.145572 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00156244 (* 1 = 0.00156244 loss)
I1130 23:38:18.274122 12698 solver.cpp:228] Iteration 34500, loss = 0.0535152
I1130 23:38:18.274188 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00666283 (* 0.5 = 0.00333141 loss)
I1130 23:38:18.274196 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0297306 (* 1 = 0.0297306 loss)
I1130 23:38:18.274201 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:38:18.274205 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 23:38:18.274211 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00101833 (* 1 = 0.00101833 loss)
I1130 23:38:18.274219 12698 sgd_solver.cpp:106] Iteration 34500, lr = 0.01
I1130 23:38:32.632372 12698 solver.cpp:228] Iteration 35000, loss = 0.045413
I1130 23:38:32.632447 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00631077 (* 0.5 = 0.00315538 loss)
I1130 23:38:32.632455 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0221753 (* 1 = 0.0221753 loss)
I1130 23:38:32.632462 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:38:32.632465 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:38:32.632470 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00148034 (* 1 = 0.00148034 loss)
I1130 23:38:32.632477 12698 sgd_solver.cpp:106] Iteration 35000, lr = 0.01
I1130 23:38:47.175487 12698 solver.cpp:228] Iteration 35500, loss = 0.0545333
I1130 23:38:47.175564 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00500563 (* 0.5 = 0.00250281 loss)
I1130 23:38:47.175572 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.044837 (* 1 = 0.044837 loss)
I1130 23:38:47.175577 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:38:47.175581 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:38:47.175587 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00107647 (* 1 = 0.00107647 loss)
I1130 23:38:47.175595 12698 sgd_solver.cpp:106] Iteration 35500, lr = 0.01
I1130 23:39:01.570688 12698 solver.cpp:228] Iteration 36000, loss = 0.0499571
I1130 23:39:01.570761 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00507039 (* 0.5 = 0.00253519 loss)
I1130 23:39:01.570770 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0555705 (* 1 = 0.0555705 loss)
I1130 23:39:01.570785 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:39:01.570789 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:39:01.570796 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00130982 (* 1 = 0.00130982 loss)
I1130 23:39:01.570802 12698 sgd_solver.cpp:106] Iteration 36000, lr = 0.01
I1130 23:39:15.948329 12698 solver.cpp:228] Iteration 36500, loss = 0.0449795
I1130 23:39:15.948395 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00411161 (* 0.5 = 0.0020558 loss)
I1130 23:39:15.948405 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0265585 (* 1 = 0.0265585 loss)
I1130 23:39:15.948408 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:39:15.948412 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 23:39:15.948418 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0033957 (* 1 = 0.0033957 loss)
I1130 23:39:15.948424 12698 sgd_solver.cpp:106] Iteration 36500, lr = 0.01
I1130 23:39:30.331303 12698 solver.cpp:228] Iteration 37000, loss = 0.0530372
I1130 23:39:30.331380 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0044929 (* 0.5 = 0.00224645 loss)
I1130 23:39:30.331389 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0556779 (* 1 = 0.0556779 loss)
I1130 23:39:30.331394 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:39:30.331399 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:39:30.331404 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00142562 (* 1 = 0.00142562 loss)
I1130 23:39:30.331411 12698 sgd_solver.cpp:106] Iteration 37000, lr = 0.01
I1130 23:39:44.714792 12698 solver.cpp:228] Iteration 37500, loss = 0.0434979
I1130 23:39:44.714867 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00451929 (* 0.5 = 0.00225964 loss)
I1130 23:39:44.714876 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0335255 (* 1 = 0.0335255 loss)
I1130 23:39:44.714880 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:39:44.714885 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:39:44.714890 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00151396 (* 1 = 0.00151396 loss)
I1130 23:39:44.714897 12698 sgd_solver.cpp:106] Iteration 37500, lr = 0.01
I1130 23:39:59.090000 12698 solver.cpp:228] Iteration 38000, loss = 0.0547213
I1130 23:39:59.090071 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00525545 (* 0.5 = 0.00262772 loss)
I1130 23:39:59.090082 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0665571 (* 1 = 0.0665571 loss)
I1130 23:39:59.090087 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:39:59.090092 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 23:39:59.090097 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00216628 (* 1 = 0.00216628 loss)
I1130 23:39:59.090106 12698 sgd_solver.cpp:106] Iteration 38000, lr = 0.01
I1130 23:40:13.475462 12698 solver.cpp:228] Iteration 38500, loss = 0.0480416
I1130 23:40:13.475538 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00659792 (* 0.5 = 0.00329896 loss)
I1130 23:40:13.475546 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0783904 (* 1 = 0.0783904 loss)
I1130 23:40:13.475551 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:40:13.475555 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:40:13.475561 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00082438 (* 1 = 0.00082438 loss)
I1130 23:40:13.475569 12698 sgd_solver.cpp:106] Iteration 38500, lr = 0.01
I1130 23:40:18.933676 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_38691.caffemodel
I1130 23:40:18.956616 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_38691.solverstate
I1130 23:40:18.959532 12698 solver.cpp:337] Iteration 38691, Testing net (#0)
I1130 23:40:43.865219 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00596443 (* 0.5 = 0.00298221 loss)
I1130 23:40:43.865277 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0646932 (* 1 = 0.0646932 loss)
I1130 23:40:43.865283 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.983708
I1130 23:40:43.865288 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.902636
I1130 23:40:43.865294 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00150933 (* 1 = 0.00150933 loss)
I1130 23:40:52.699039 12698 solver.cpp:228] Iteration 39000, loss = 0.0450073
I1130 23:40:52.699111 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00626534 (* 0.5 = 0.00313267 loss)
I1130 23:40:52.699120 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0474482 (* 1 = 0.0474482 loss)
I1130 23:40:52.699126 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:40:52.699129 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 23:40:52.699136 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00125932 (* 1 = 0.00125932 loss)
I1130 23:40:52.699142 12698 sgd_solver.cpp:106] Iteration 39000, lr = 0.01
I1130 23:41:06.972959 12698 solver.cpp:228] Iteration 39500, loss = 0.0517069
I1130 23:41:06.973031 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0061098 (* 0.5 = 0.0030549 loss)
I1130 23:41:06.973039 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0486402 (* 1 = 0.0486402 loss)
I1130 23:41:06.973044 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:41:06.973048 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:41:06.973054 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00101245 (* 1 = 0.00101245 loss)
I1130 23:41:06.973062 12698 sgd_solver.cpp:106] Iteration 39500, lr = 0.01
I1130 23:41:21.229490 12698 solver.cpp:228] Iteration 40000, loss = 0.0413898
I1130 23:41:21.229563 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00555144 (* 0.5 = 0.00277572 loss)
I1130 23:41:21.229573 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0347362 (* 1 = 0.0347362 loss)
I1130 23:41:21.229576 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:41:21.229581 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:41:21.229586 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000784834 (* 1 = 0.000784834 loss)
I1130 23:41:21.229593 12698 sgd_solver.cpp:106] Iteration 40000, lr = 0.01
I1130 23:41:35.499331 12698 solver.cpp:228] Iteration 40500, loss = 0.0545794
I1130 23:41:35.499397 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0052086 (* 0.5 = 0.0026043 loss)
I1130 23:41:35.499405 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0541533 (* 1 = 0.0541533 loss)
I1130 23:41:35.499410 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:41:35.499414 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 23:41:35.499420 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00145007 (* 1 = 0.00145007 loss)
I1130 23:41:35.499426 12698 sgd_solver.cpp:106] Iteration 40500, lr = 0.01
I1130 23:41:49.774693 12698 solver.cpp:228] Iteration 41000, loss = 0.0471058
I1130 23:41:49.774770 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0063908 (* 0.5 = 0.0031954 loss)
I1130 23:41:49.774778 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0250582 (* 1 = 0.0250582 loss)
I1130 23:41:49.774783 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:41:49.774788 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 23:41:49.774803 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00188544 (* 1 = 0.00188544 loss)
I1130 23:41:49.774811 12698 sgd_solver.cpp:106] Iteration 41000, lr = 0.01
I1130 23:42:04.063426 12698 solver.cpp:228] Iteration 41500, loss = 0.0444215
I1130 23:42:04.063500 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00550227 (* 0.5 = 0.00275113 loss)
I1130 23:42:04.063510 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.025974 (* 1 = 0.025974 loss)
I1130 23:42:04.063514 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:42:04.063519 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:42:04.063524 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00148375 (* 1 = 0.00148375 loss)
I1130 23:42:04.063531 12698 sgd_solver.cpp:106] Iteration 41500, lr = 0.01
I1130 23:42:18.344808 12698 solver.cpp:228] Iteration 42000, loss = 0.0525125
I1130 23:42:18.344877 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00569353 (* 0.5 = 0.00284677 loss)
I1130 23:42:18.344887 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0555214 (* 1 = 0.0555214 loss)
I1130 23:42:18.344892 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:42:18.344895 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:42:18.344902 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00292152 (* 1 = 0.00292152 loss)
I1130 23:42:18.344907 12698 sgd_solver.cpp:106] Iteration 42000, lr = 0.01
I1130 23:42:32.644758 12698 solver.cpp:228] Iteration 42500, loss = 0.0390207
I1130 23:42:32.644834 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00468926 (* 0.5 = 0.00234463 loss)
I1130 23:42:32.644843 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0484314 (* 1 = 0.0484314 loss)
I1130 23:42:32.644847 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:42:32.644852 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:42:32.644858 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000969019 (* 1 = 0.000969019 loss)
I1130 23:42:32.644865 12698 sgd_solver.cpp:106] Iteration 42500, lr = 0.01
I1130 23:42:46.610148 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_42990.caffemodel
I1130 23:42:46.632822 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_42990.solverstate
I1130 23:42:46.635684 12698 solver.cpp:337] Iteration 42990, Testing net (#0)
I1130 23:43:11.079376 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00594081 (* 0.5 = 0.0029704 loss)
I1130 23:43:11.079438 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.062998 (* 1 = 0.062998 loss)
I1130 23:43:11.079445 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.974531
I1130 23:43:11.079450 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.925414
I1130 23:43:11.079455 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00150788 (* 1 = 0.00150788 loss)
I1130 23:43:11.395403 12698 solver.cpp:228] Iteration 43000, loss = 0.0547504
I1130 23:43:11.395473 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00540375 (* 0.5 = 0.00270188 loss)
I1130 23:43:11.395483 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0456464 (* 1 = 0.0456464 loss)
I1130 23:43:11.395488 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:43:11.395493 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:43:11.395498 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00114307 (* 1 = 0.00114307 loss)
I1130 23:43:11.395504 12698 sgd_solver.cpp:106] Iteration 43000, lr = 0.001
I1130 23:43:25.784139 12698 solver.cpp:228] Iteration 43500, loss = 0.0464471
I1130 23:43:25.784210 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00586957 (* 0.5 = 0.00293478 loss)
I1130 23:43:25.784229 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0269985 (* 1 = 0.0269985 loss)
I1130 23:43:25.784234 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:43:25.784238 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:43:25.784243 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00169866 (* 1 = 0.00169866 loss)
I1130 23:43:25.784250 12698 sgd_solver.cpp:106] Iteration 43500, lr = 0.001
I1130 23:43:40.157435 12698 solver.cpp:228] Iteration 44000, loss = 0.041253
I1130 23:43:40.157511 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00577509 (* 0.5 = 0.00288755 loss)
I1130 23:43:40.157521 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0643609 (* 1 = 0.0643609 loss)
I1130 23:43:40.157527 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:43:40.157532 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 23:43:40.157539 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00119762 (* 1 = 0.00119762 loss)
I1130 23:43:40.157546 12698 sgd_solver.cpp:106] Iteration 44000, lr = 0.001
I1130 23:43:54.540365 12698 solver.cpp:228] Iteration 44500, loss = 0.0483309
I1130 23:43:54.540434 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00708963 (* 0.5 = 0.00354481 loss)
I1130 23:43:54.540442 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0467653 (* 1 = 0.0467653 loss)
I1130 23:43:54.540447 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:43:54.540452 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:43:54.540457 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0010179 (* 1 = 0.0010179 loss)
I1130 23:43:54.540463 12698 sgd_solver.cpp:106] Iteration 44500, lr = 0.001
I1130 23:44:08.904834 12698 solver.cpp:228] Iteration 45000, loss = 0.0328891
I1130 23:44:08.904906 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00490636 (* 0.5 = 0.00245318 loss)
I1130 23:44:08.904914 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0331683 (* 1 = 0.0331683 loss)
I1130 23:44:08.904919 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:44:08.904923 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:44:08.904929 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0011236 (* 1 = 0.0011236 loss)
I1130 23:44:08.904935 12698 sgd_solver.cpp:106] Iteration 45000, lr = 0.001
I1130 23:44:23.281596 12698 solver.cpp:228] Iteration 45500, loss = 0.0502523
I1130 23:44:23.281667 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00492889 (* 0.5 = 0.00246445 loss)
I1130 23:44:23.281677 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0356684 (* 1 = 0.0356684 loss)
I1130 23:44:23.281680 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:44:23.281685 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:44:23.281690 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00124374 (* 1 = 0.00124374 loss)
I1130 23:44:23.281697 12698 sgd_solver.cpp:106] Iteration 45500, lr = 0.001
I1130 23:44:37.671602 12698 solver.cpp:228] Iteration 46000, loss = 0.0409766
I1130 23:44:37.671669 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00504494 (* 0.5 = 0.00252247 loss)
I1130 23:44:37.671679 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0476267 (* 1 = 0.0476267 loss)
I1130 23:44:37.671684 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:44:37.671689 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:44:37.671694 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00117348 (* 1 = 0.00117348 loss)
I1130 23:44:37.671700 12698 sgd_solver.cpp:106] Iteration 46000, lr = 0.001
I1130 23:44:52.053104 12698 solver.cpp:228] Iteration 46500, loss = 0.0397045
I1130 23:44:52.053181 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00526837 (* 0.5 = 0.00263419 loss)
I1130 23:44:52.053190 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0363709 (* 1 = 0.0363709 loss)
I1130 23:44:52.053194 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.960938
I1130 23:44:52.053200 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 23:44:52.053205 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00212357 (* 1 = 0.00212357 loss)
I1130 23:44:52.053210 12698 sgd_solver.cpp:106] Iteration 46500, lr = 0.001
I1130 23:45:06.436221 12698 solver.cpp:228] Iteration 47000, loss = 0.0471837
I1130 23:45:06.436297 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00542092 (* 0.5 = 0.00271046 loss)
I1130 23:45:06.436305 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0245557 (* 1 = 0.0245557 loss)
I1130 23:45:06.436311 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:45:06.436316 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:45:06.436321 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00101218 (* 1 = 0.00101218 loss)
I1130 23:45:06.436326 12698 sgd_solver.cpp:106] Iteration 47000, lr = 0.001
I1130 23:45:14.716334 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_47289.caffemodel
I1130 23:45:14.739838 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_47289.solverstate
I1130 23:45:14.742694 12698 solver.cpp:337] Iteration 47289, Testing net (#0)
I1130 23:45:38.975740 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00584608 (* 0.5 = 0.00292304 loss)
I1130 23:45:38.975796 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0591028 (* 1 = 0.0591028 loss)
I1130 23:45:38.975803 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.982343
I1130 23:45:38.975808 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.917092
I1130 23:45:38.975813 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00136925 (* 1 = 0.00136925 loss)
I1130 23:45:45.074941 12698 solver.cpp:228] Iteration 47500, loss = 0.0323521
I1130 23:45:45.075014 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00567023 (* 0.5 = 0.00283511 loss)
I1130 23:45:45.075023 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0394438 (* 1 = 0.0394438 loss)
I1130 23:45:45.075028 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:45:45.075033 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:45:45.075039 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000842198 (* 1 = 0.000842198 loss)
I1130 23:45:45.075047 12698 sgd_solver.cpp:106] Iteration 47500, lr = 0.001
I1130 23:45:59.502221 12698 solver.cpp:228] Iteration 48000, loss = 0.0496359
I1130 23:45:59.502292 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00547938 (* 0.5 = 0.00273969 loss)
I1130 23:45:59.502300 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0389162 (* 1 = 0.0389162 loss)
I1130 23:45:59.502305 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:45:59.502310 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:45:59.502315 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000792122 (* 1 = 0.000792122 loss)
I1130 23:45:59.502323 12698 sgd_solver.cpp:106] Iteration 48000, lr = 0.001
I1130 23:46:13.916055 12698 solver.cpp:228] Iteration 48500, loss = 0.0401202
I1130 23:46:13.916131 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00428188 (* 0.5 = 0.00214094 loss)
I1130 23:46:13.916138 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0297018 (* 1 = 0.0297018 loss)
I1130 23:46:13.916143 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:46:13.916157 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:46:13.916162 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00242687 (* 1 = 0.00242687 loss)
I1130 23:46:13.916169 12698 sgd_solver.cpp:106] Iteration 48500, lr = 0.001
I1130 23:46:28.331580 12698 solver.cpp:228] Iteration 49000, loss = 0.03976
I1130 23:46:28.331653 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00498396 (* 0.5 = 0.00249198 loss)
I1130 23:46:28.331661 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0243331 (* 1 = 0.0243331 loss)
I1130 23:46:28.331666 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:46:28.331670 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:46:28.331676 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00124327 (* 1 = 0.00124327 loss)
I1130 23:46:28.331682 12698 sgd_solver.cpp:106] Iteration 49000, lr = 0.001
I1130 23:46:42.768944 12698 solver.cpp:228] Iteration 49500, loss = 0.046142
I1130 23:46:42.769016 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00443337 (* 0.5 = 0.00221669 loss)
I1130 23:46:42.769026 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0213835 (* 1 = 0.0213835 loss)
I1130 23:46:42.769031 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:46:42.769034 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:46:42.769040 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00102431 (* 1 = 0.00102431 loss)
I1130 23:46:42.769047 12698 sgd_solver.cpp:106] Iteration 49500, lr = 0.001
I1130 23:46:57.165714 12698 solver.cpp:228] Iteration 50000, loss = 0.0323682
I1130 23:46:57.165786 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00497772 (* 0.5 = 0.00248886 loss)
I1130 23:46:57.165794 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0498098 (* 1 = 0.0498098 loss)
I1130 23:46:57.165799 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:46:57.165804 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:46:57.165809 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0011273 (* 1 = 0.0011273 loss)
I1130 23:46:57.165817 12698 sgd_solver.cpp:106] Iteration 50000, lr = 0.001
I1130 23:47:11.580473 12698 solver.cpp:228] Iteration 50500, loss = 0.0491749
I1130 23:47:11.580548 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00529132 (* 0.5 = 0.00264566 loss)
I1130 23:47:11.580556 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0271402 (* 1 = 0.0271402 loss)
I1130 23:47:11.580561 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:47:11.580566 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:47:11.580571 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00101156 (* 1 = 0.00101156 loss)
I1130 23:47:11.580579 12698 sgd_solver.cpp:106] Iteration 50500, lr = 0.001
I1130 23:47:26.006136 12698 solver.cpp:228] Iteration 51000, loss = 0.0397087
I1130 23:47:26.006209 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0040097 (* 0.5 = 0.00200485 loss)
I1130 23:47:26.006218 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0251364 (* 1 = 0.0251364 loss)
I1130 23:47:26.006223 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:47:26.006227 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 23:47:26.006232 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00171112 (* 1 = 0.00171112 loss)
I1130 23:47:26.006239 12698 sgd_solver.cpp:106] Iteration 51000, lr = 0.001
I1130 23:47:40.408493 12698 solver.cpp:228] Iteration 51500, loss = 0.040247
I1130 23:47:40.408568 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.004442 (* 0.5 = 0.002221 loss)
I1130 23:47:40.408576 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0574885 (* 1 = 0.0574885 loss)
I1130 23:47:40.408591 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:47:40.408596 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:47:40.408601 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000875015 (* 1 = 0.000875015 loss)
I1130 23:47:40.408608 12698 sgd_solver.cpp:106] Iteration 51500, lr = 0.001
I1130 23:47:42.920707 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_51588.caffemodel
I1130 23:47:42.943418 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_51588.solverstate
I1130 23:47:42.946279 12698 solver.cpp:337] Iteration 51588, Testing net (#0)
I1130 23:48:07.404520 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00574359 (* 0.5 = 0.00287179 loss)
I1130 23:48:07.404578 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0585358 (* 1 = 0.0585358 loss)
I1130 23:48:07.404585 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.973878
I1130 23:48:07.404590 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.939075
I1130 23:48:07.404595 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00144556 (* 1 = 0.00144556 loss)
I1130 23:48:19.302685 12698 solver.cpp:228] Iteration 52000, loss = 0.0447604
I1130 23:48:19.302752 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00385017 (* 0.5 = 0.00192508 loss)
I1130 23:48:19.302760 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0187095 (* 1 = 0.0187095 loss)
I1130 23:48:19.302765 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:48:19.302770 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 23:48:19.302775 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00168672 (* 1 = 0.00168672 loss)
I1130 23:48:19.302783 12698 sgd_solver.cpp:106] Iteration 52000, lr = 0.001
I1130 23:48:33.701056 12698 solver.cpp:228] Iteration 52500, loss = 0.0323814
I1130 23:48:33.701135 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0060867 (* 0.5 = 0.00304335 loss)
I1130 23:48:33.701144 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0253164 (* 1 = 0.0253164 loss)
I1130 23:48:33.701149 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:48:33.701154 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:48:33.701159 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000758382 (* 1 = 0.000758382 loss)
I1130 23:48:33.701166 12698 sgd_solver.cpp:106] Iteration 52500, lr = 0.001
I1130 23:48:48.117328 12698 solver.cpp:228] Iteration 53000, loss = 0.0475768
I1130 23:48:48.117403 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00409596 (* 0.5 = 0.00204798 loss)
I1130 23:48:48.117413 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0266725 (* 1 = 0.0266725 loss)
I1130 23:48:48.117416 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:48:48.117421 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 23:48:48.117427 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000820481 (* 1 = 0.000820481 loss)
I1130 23:48:48.117434 12698 sgd_solver.cpp:106] Iteration 53000, lr = 0.001
I1130 23:49:02.508127 12698 solver.cpp:228] Iteration 53500, loss = 0.0397747
I1130 23:49:02.508204 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00581115 (* 0.5 = 0.00290558 loss)
I1130 23:49:02.508213 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0371846 (* 1 = 0.0371846 loss)
I1130 23:49:02.508219 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:49:02.508222 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:49:02.508229 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00126253 (* 1 = 0.00126253 loss)
I1130 23:49:02.508255 12698 sgd_solver.cpp:106] Iteration 53500, lr = 0.001
I1130 23:49:16.905179 12698 solver.cpp:228] Iteration 54000, loss = 0.0405871
I1130 23:49:16.905249 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00467899 (* 0.5 = 0.0023395 loss)
I1130 23:49:16.905258 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0443762 (* 1 = 0.0443762 loss)
I1130 23:49:16.905262 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:49:16.905267 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:49:16.905272 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00150377 (* 1 = 0.00150377 loss)
I1130 23:49:16.905279 12698 sgd_solver.cpp:106] Iteration 54000, lr = 0.001
I1130 23:49:31.309218 12698 solver.cpp:228] Iteration 54500, loss = 0.0439234
I1130 23:49:31.309293 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00469056 (* 0.5 = 0.00234528 loss)
I1130 23:49:31.309303 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0539109 (* 1 = 0.0539109 loss)
I1130 23:49:31.309308 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:49:31.309311 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:49:31.309317 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00109782 (* 1 = 0.00109782 loss)
I1130 23:49:31.309324 12698 sgd_solver.cpp:106] Iteration 54500, lr = 0.001
I1130 23:49:45.707291 12698 solver.cpp:228] Iteration 55000, loss = 0.0325155
I1130 23:49:45.707367 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00594645 (* 0.5 = 0.00297323 loss)
I1130 23:49:45.707376 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.031232 (* 1 = 0.031232 loss)
I1130 23:49:45.707381 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:49:45.707386 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:49:45.707391 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00100318 (* 1 = 0.00100318 loss)
I1130 23:49:45.707398 12698 sgd_solver.cpp:106] Iteration 55000, lr = 0.001
I1130 23:50:00.102821 12698 solver.cpp:228] Iteration 55500, loss = 0.0470555
I1130 23:50:00.102897 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00552817 (* 0.5 = 0.00276409 loss)
I1130 23:50:00.102906 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0382682 (* 1 = 0.0382682 loss)
I1130 23:50:00.102911 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:50:00.102916 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:50:00.102921 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00142659 (* 1 = 0.00142659 loss)
I1130 23:50:00.102927 12698 sgd_solver.cpp:106] Iteration 55500, lr = 0.001
I1130 23:50:11.219056 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_55887.caffemodel
I1130 23:50:11.241971 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_55887.solverstate
I1130 23:50:11.244812 12698 solver.cpp:337] Iteration 55887, Testing net (#0)
I1130 23:50:35.700410 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00567632 (* 0.5 = 0.00283816 loss)
I1130 23:50:35.700474 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0581884 (* 1 = 0.0581884 loss)
I1130 23:50:35.700482 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.979329
I1130 23:50:35.700489 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.928878
I1130 23:50:35.700495 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00136609 (* 1 = 0.00136609 loss)
I1130 23:50:38.977013 12698 solver.cpp:228] Iteration 56000, loss = 0.0390702
I1130 23:50:38.977087 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00599787 (* 0.5 = 0.00299893 loss)
I1130 23:50:38.977097 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0407815 (* 1 = 0.0407815 loss)
I1130 23:50:38.977113 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:50:38.977118 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:50:38.977123 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00192626 (* 1 = 0.00192626 loss)
I1130 23:50:38.977129 12698 sgd_solver.cpp:106] Iteration 56000, lr = 0.001
I1130 23:50:53.330116 12698 solver.cpp:228] Iteration 56500, loss = 0.0407593
I1130 23:50:53.330184 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00568633 (* 0.5 = 0.00284317 loss)
I1130 23:50:53.330193 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0830008 (* 1 = 0.0830008 loss)
I1130 23:50:53.330199 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:50:53.330202 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 23:50:53.330207 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00266856 (* 1 = 0.00266856 loss)
I1130 23:50:53.330214 12698 sgd_solver.cpp:106] Iteration 56500, lr = 0.001
I1130 23:51:07.709316 12698 solver.cpp:228] Iteration 57000, loss = 0.0437742
I1130 23:51:07.709395 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00404583 (* 0.5 = 0.00202292 loss)
I1130 23:51:07.709404 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0346103 (* 1 = 0.0346103 loss)
I1130 23:51:07.709409 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:51:07.709414 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:51:07.709419 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00102847 (* 1 = 0.00102847 loss)
I1130 23:51:07.709426 12698 sgd_solver.cpp:106] Iteration 57000, lr = 0.001
I1130 23:51:22.103242 12698 solver.cpp:228] Iteration 57500, loss = 0.0330597
I1130 23:51:22.103318 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00382682 (* 0.5 = 0.00191341 loss)
I1130 23:51:22.103327 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0597569 (* 1 = 0.0597569 loss)
I1130 23:51:22.103332 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:51:22.103338 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1130 23:51:22.103343 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000804656 (* 1 = 0.000804656 loss)
I1130 23:51:22.103349 12698 sgd_solver.cpp:106] Iteration 57500, lr = 0.001
I1130 23:51:36.475776 12698 solver.cpp:228] Iteration 58000, loss = 0.0463262
I1130 23:51:36.475846 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00491565 (* 0.5 = 0.00245783 loss)
I1130 23:51:36.475853 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0526133 (* 1 = 0.0526133 loss)
I1130 23:51:36.475858 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:51:36.475862 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:51:36.475868 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000996452 (* 1 = 0.000996452 loss)
I1130 23:51:36.475874 12698 sgd_solver.cpp:106] Iteration 58000, lr = 0.001
I1130 23:51:50.837328 12698 solver.cpp:228] Iteration 58500, loss = 0.0378095
I1130 23:51:50.837404 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00460614 (* 0.5 = 0.00230307 loss)
I1130 23:51:50.837412 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.00664325 (* 1 = 0.00664325 loss)
I1130 23:51:50.837417 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:51:50.837421 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 23:51:50.837427 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00107662 (* 1 = 0.00107662 loss)
I1130 23:51:50.837433 12698 sgd_solver.cpp:106] Iteration 58500, lr = 0.001
I1130 23:52:05.208796 12698 solver.cpp:228] Iteration 59000, loss = 0.041159
I1130 23:52:05.208869 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00674598 (* 0.5 = 0.00337299 loss)
I1130 23:52:05.208887 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0165289 (* 1 = 0.0165289 loss)
I1130 23:52:05.208892 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:52:05.208897 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 23:52:05.208904 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00112437 (* 1 = 0.00112437 loss)
I1130 23:52:05.208909 12698 sgd_solver.cpp:106] Iteration 59000, lr = 0.001
I1130 23:52:19.579851 12698 solver.cpp:228] Iteration 59500, loss = 0.0430048
I1130 23:52:19.579933 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00552425 (* 0.5 = 0.00276213 loss)
I1130 23:52:19.579942 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0355559 (* 1 = 0.0355559 loss)
I1130 23:52:19.579947 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:52:19.579952 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:52:19.579957 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00136296 (* 1 = 0.00136296 loss)
I1130 23:52:19.579964 12698 sgd_solver.cpp:106] Iteration 59500, lr = 0.001
I1130 23:52:33.941938 12698 solver.cpp:228] Iteration 60000, loss = 0.0345313
I1130 23:52:33.942006 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00582381 (* 0.5 = 0.0029119 loss)
I1130 23:52:33.942015 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0722622 (* 1 = 0.0722622 loss)
I1130 23:52:33.942020 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:52:33.942025 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1130 23:52:33.942030 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00107769 (* 1 = 0.00107769 loss)
I1130 23:52:33.942037 12698 sgd_solver.cpp:106] Iteration 60000, lr = 0.001
I1130 23:52:39.270390 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_60186.caffemodel
I1130 23:52:39.294283 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_60186.solverstate
I1130 23:52:39.297811 12698 solver.cpp:337] Iteration 60186, Testing net (#0)
I1130 23:53:03.673800 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00576396 (* 0.5 = 0.00288198 loss)
I1130 23:53:03.673858 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0605363 (* 1 = 0.0605363 loss)
I1130 23:53:03.673866 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.969612
I1130 23:53:03.673871 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.943453
I1130 23:53:03.673877 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00135634 (* 1 = 0.00135634 loss)
I1130 23:53:12.643160 12698 solver.cpp:228] Iteration 60500, loss = 0.0450197
I1130 23:53:12.643226 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00436426 (* 0.5 = 0.00218213 loss)
I1130 23:53:12.643234 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0171245 (* 1 = 0.0171245 loss)
I1130 23:53:12.643239 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:53:12.643244 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 23:53:12.643249 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000676413 (* 1 = 0.000676413 loss)
I1130 23:53:12.643255 12698 sgd_solver.cpp:106] Iteration 60500, lr = 0.001
I1130 23:53:26.898965 12698 solver.cpp:228] Iteration 61000, loss = 0.0370226
I1130 23:53:26.899040 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00521324 (* 0.5 = 0.00260662 loss)
I1130 23:53:26.899049 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0327981 (* 1 = 0.0327981 loss)
I1130 23:53:26.899054 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:53:26.899058 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:53:26.899063 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00110981 (* 1 = 0.00110981 loss)
I1130 23:53:26.899085 12698 sgd_solver.cpp:106] Iteration 61000, lr = 0.001
I1130 23:53:41.173684 12698 solver.cpp:228] Iteration 61500, loss = 0.0419303
I1130 23:53:41.173763 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00553763 (* 0.5 = 0.00276882 loss)
I1130 23:53:41.173771 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.032665 (* 1 = 0.032665 loss)
I1130 23:53:41.173777 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:53:41.173781 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:53:41.173787 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.001005 (* 1 = 0.001005 loss)
I1130 23:53:41.173794 12698 sgd_solver.cpp:106] Iteration 61500, lr = 0.001
I1130 23:53:55.426903 12698 solver.cpp:228] Iteration 62000, loss = 0.0415278
I1130 23:53:55.426971 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0047813 (* 0.5 = 0.00239065 loss)
I1130 23:53:55.426980 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0162155 (* 1 = 0.0162155 loss)
I1130 23:53:55.426985 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:53:55.426990 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:53:55.426995 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000996524 (* 1 = 0.000996524 loss)
I1130 23:53:55.427001 12698 sgd_solver.cpp:106] Iteration 62000, lr = 0.001
I1130 23:54:09.675424 12698 solver.cpp:228] Iteration 62500, loss = 0.0360646
I1130 23:54:09.675498 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00670219 (* 0.5 = 0.0033511 loss)
I1130 23:54:09.675508 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0526387 (* 1 = 0.0526387 loss)
I1130 23:54:09.675511 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1130 23:54:09.675516 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1130 23:54:09.675523 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000919576 (* 1 = 0.000919576 loss)
I1130 23:54:09.675529 12698 sgd_solver.cpp:106] Iteration 62500, lr = 0.001
I1130 23:54:23.929867 12698 solver.cpp:228] Iteration 63000, loss = 0.0442901
I1130 23:54:23.929942 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00454433 (* 0.5 = 0.00227216 loss)
I1130 23:54:23.929951 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.044687 (* 1 = 0.044687 loss)
I1130 23:54:23.929956 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:54:23.929961 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:54:23.929967 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00141293 (* 1 = 0.00141293 loss)
I1130 23:54:23.929975 12698 sgd_solver.cpp:106] Iteration 63000, lr = 0.001
I1130 23:54:38.198226 12698 solver.cpp:228] Iteration 63500, loss = 0.0352539
I1130 23:54:38.198302 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00551825 (* 0.5 = 0.00275912 loss)
I1130 23:54:38.198312 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0202859 (* 1 = 0.0202859 loss)
I1130 23:54:38.198315 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:54:38.198320 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:54:38.198326 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00103977 (* 1 = 0.00103977 loss)
I1130 23:54:38.198333 12698 sgd_solver.cpp:106] Iteration 63500, lr = 0.001
I1130 23:54:52.458092 12698 solver.cpp:228] Iteration 64000, loss = 0.0426586
I1130 23:54:52.458166 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00572056 (* 0.5 = 0.00286028 loss)
I1130 23:54:52.458175 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0335729 (* 1 = 0.0335729 loss)
I1130 23:54:52.458179 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:54:52.458192 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:54:52.458199 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000888383 (* 1 = 0.000888383 loss)
I1130 23:54:52.458205 12698 sgd_solver.cpp:106] Iteration 64000, lr = 0.001
I1130 23:55:06.298394 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_64485.caffemodel
I1130 23:55:06.321188 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_64485.solverstate
I1130 23:55:06.324012 12698 solver.cpp:337] Iteration 64485, Testing net (#0)
I1130 23:55:30.799119 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00576141 (* 0.5 = 0.0028807 loss)
I1130 23:55:30.799180 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0599803 (* 1 = 0.0599803 loss)
I1130 23:55:30.799186 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.977215
I1130 23:55:30.799191 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.928713
I1130 23:55:30.799197 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00142232 (* 1 = 0.00142232 loss)
I1130 23:55:31.257772 12698 solver.cpp:228] Iteration 64500, loss = 0.039537
I1130 23:55:31.257851 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00458974 (* 0.5 = 0.00229487 loss)
I1130 23:55:31.257859 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0181471 (* 1 = 0.0181471 loss)
I1130 23:55:31.257864 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:55:31.257869 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:55:31.257874 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00114143 (* 1 = 0.00114143 loss)
I1130 23:55:31.257882 12698 sgd_solver.cpp:106] Iteration 64500, lr = 0.001
I1130 23:55:45.664772 12698 solver.cpp:228] Iteration 65000, loss = 0.0379478
I1130 23:55:45.664880 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00526866 (* 0.5 = 0.00263433 loss)
I1130 23:55:45.664891 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0612915 (* 1 = 0.0612915 loss)
I1130 23:55:45.664896 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:55:45.664901 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:55:45.664909 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000924589 (* 1 = 0.000924589 loss)
I1130 23:55:45.664917 12698 sgd_solver.cpp:106] Iteration 65000, lr = 0.001
I1130 23:56:00.054437 12698 solver.cpp:228] Iteration 65500, loss = 0.0437658
I1130 23:56:00.054530 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00485062 (* 0.5 = 0.00242531 loss)
I1130 23:56:00.054540 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0427741 (* 1 = 0.0427741 loss)
I1130 23:56:00.054544 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:56:00.054549 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:56:00.054554 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00092856 (* 1 = 0.00092856 loss)
I1130 23:56:00.054563 12698 sgd_solver.cpp:106] Iteration 65500, lr = 0.001
I1130 23:56:14.488018 12698 solver.cpp:228] Iteration 66000, loss = 0.0346166
I1130 23:56:14.488114 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.006423 (* 0.5 = 0.0032115 loss)
I1130 23:56:14.488126 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0330028 (* 1 = 0.0330028 loss)
I1130 23:56:14.488131 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:56:14.488135 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:56:14.488142 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00197134 (* 1 = 0.00197134 loss)
I1130 23:56:14.488149 12698 sgd_solver.cpp:106] Iteration 66000, lr = 0.001
I1130 23:56:28.884522 12698 solver.cpp:228] Iteration 66500, loss = 0.0431056
I1130 23:56:28.884615 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00453915 (* 0.5 = 0.00226958 loss)
I1130 23:56:28.884625 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0387279 (* 1 = 0.0387279 loss)
I1130 23:56:28.884630 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:56:28.884635 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:56:28.884640 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000744872 (* 1 = 0.000744872 loss)
I1130 23:56:28.884647 12698 sgd_solver.cpp:106] Iteration 66500, lr = 0.001
I1130 23:56:43.282075 12698 solver.cpp:228] Iteration 67000, loss = 0.0374255
I1130 23:56:43.282166 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00605617 (* 0.5 = 0.00302808 loss)
I1130 23:56:43.282176 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.018875 (* 1 = 0.018875 loss)
I1130 23:56:43.282181 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:56:43.282184 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:56:43.282191 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00400227 (* 1 = 0.00400227 loss)
I1130 23:56:43.282198 12698 sgd_solver.cpp:106] Iteration 67000, lr = 0.001
I1130 23:56:57.659657 12698 solver.cpp:228] Iteration 67500, loss = 0.0402855
I1130 23:56:57.659731 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00661978 (* 0.5 = 0.00330989 loss)
I1130 23:56:57.659739 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0592368 (* 1 = 0.0592368 loss)
I1130 23:56:57.659744 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:56:57.659749 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:56:57.659754 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00160554 (* 1 = 0.00160554 loss)
I1130 23:56:57.659761 12698 sgd_solver.cpp:106] Iteration 67500, lr = 0.001
I1130 23:57:12.047657 12698 solver.cpp:228] Iteration 68000, loss = 0.0421762
I1130 23:57:12.047736 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00678248 (* 0.5 = 0.00339124 loss)
I1130 23:57:12.047745 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0573297 (* 1 = 0.0573297 loss)
I1130 23:57:12.047750 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1130 23:57:12.047755 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1130 23:57:12.047760 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000914693 (* 1 = 0.000914693 loss)
I1130 23:57:12.047767 12698 sgd_solver.cpp:106] Iteration 68000, lr = 0.001
I1130 23:57:26.419603 12698 solver.cpp:228] Iteration 68500, loss = 0.0350744
I1130 23:57:26.419682 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0060289 (* 0.5 = 0.00301445 loss)
I1130 23:57:26.419689 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.061997 (* 1 = 0.061997 loss)
I1130 23:57:26.419694 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:57:26.419699 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:57:26.419704 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000838963 (* 1 = 0.000838963 loss)
I1130 23:57:26.419711 12698 sgd_solver.cpp:106] Iteration 68500, lr = 0.001
I1130 23:57:34.555594 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_68784.caffemodel
I1130 23:57:34.579349 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_68784.solverstate
I1130 23:57:34.582160 12698 solver.cpp:337] Iteration 68784, Testing net (#0)
I1130 23:57:59.251783 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00565785 (* 0.5 = 0.00282893 loss)
I1130 23:57:59.251849 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0587205 (* 1 = 0.0587205 loss)
I1130 23:57:59.251857 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.972289
I1130 23:57:59.251869 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.942853
I1130 23:57:59.251875 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.0013697 (* 1 = 0.0013697 loss)
I1130 23:58:05.493695 12698 solver.cpp:228] Iteration 69000, loss = 0.0427433
I1130 23:58:05.493785 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00431602 (* 0.5 = 0.00215801 loss)
I1130 23:58:05.493794 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.037548 (* 1 = 0.037548 loss)
I1130 23:58:05.493799 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:58:05.493803 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:58:05.493809 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000805264 (* 1 = 0.000805264 loss)
I1130 23:58:05.493816 12698 sgd_solver.cpp:106] Iteration 69000, lr = 0.001
I1130 23:58:19.906435 12698 solver.cpp:228] Iteration 69500, loss = 0.0361298
I1130 23:58:19.906507 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00527431 (* 0.5 = 0.00263715 loss)
I1130 23:58:19.906517 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0202432 (* 1 = 0.0202432 loss)
I1130 23:58:19.906522 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:58:19.906525 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1130 23:58:19.906532 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00119852 (* 1 = 0.00119852 loss)
I1130 23:58:19.906538 12698 sgd_solver.cpp:106] Iteration 69500, lr = 0.001
I1130 23:58:34.319614 12698 solver.cpp:228] Iteration 70000, loss = 0.0422905
I1130 23:58:34.319684 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00499595 (* 0.5 = 0.00249797 loss)
I1130 23:58:34.319692 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.069365 (* 1 = 0.069365 loss)
I1130 23:58:34.319697 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:58:34.319702 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1130 23:58:34.319707 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00110913 (* 1 = 0.00110913 loss)
I1130 23:58:34.319715 12698 sgd_solver.cpp:106] Iteration 70000, lr = 0.001
I1130 23:58:48.735424 12698 solver.cpp:228] Iteration 70500, loss = 0.0407974
I1130 23:58:48.735497 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00524387 (* 0.5 = 0.00262194 loss)
I1130 23:58:48.735507 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0138112 (* 1 = 0.0138112 loss)
I1130 23:58:48.735512 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:58:48.735515 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1130 23:58:48.735520 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00137792 (* 1 = 0.00137792 loss)
I1130 23:58:48.735527 12698 sgd_solver.cpp:106] Iteration 70500, lr = 0.001
I1130 23:59:03.142701 12698 solver.cpp:228] Iteration 71000, loss = 0.0351368
I1130 23:59:03.142777 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00610758 (* 0.5 = 0.00305379 loss)
I1130 23:59:03.142786 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0339057 (* 1 = 0.0339057 loss)
I1130 23:59:03.142791 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:59:03.142796 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:59:03.142802 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000926513 (* 1 = 0.000926513 loss)
I1130 23:59:03.142808 12698 sgd_solver.cpp:106] Iteration 71000, lr = 0.001
I1130 23:59:17.548990 12698 solver.cpp:228] Iteration 71500, loss = 0.042353
I1130 23:59:17.549062 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00526536 (* 0.5 = 0.00263268 loss)
I1130 23:59:17.549079 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0304553 (* 1 = 0.0304553 loss)
I1130 23:59:17.549104 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1130 23:59:17.549110 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:59:17.549116 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000829039 (* 1 = 0.000829039 loss)
I1130 23:59:17.549124 12698 sgd_solver.cpp:106] Iteration 71500, lr = 0.001
I1130 23:59:31.957926 12698 solver.cpp:228] Iteration 72000, loss = 0.0342575
I1130 23:59:31.957999 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00410095 (* 0.5 = 0.00205047 loss)
I1130 23:59:31.958009 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0176757 (* 1 = 0.0176757 loss)
I1130 23:59:31.958014 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1130 23:59:31.958017 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1130 23:59:31.958024 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00148035 (* 1 = 0.00148035 loss)
I1130 23:59:31.958030 12698 sgd_solver.cpp:106] Iteration 72000, lr = 0.001
I1130 23:59:46.394259 12698 solver.cpp:228] Iteration 72500, loss = 0.0436312
I1130 23:59:46.394332 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00439512 (* 0.5 = 0.00219756 loss)
I1130 23:59:46.394341 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0415037 (* 1 = 0.0415037 loss)
I1130 23:59:46.394345 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1130 23:59:46.394351 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1130 23:59:46.394356 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00119254 (* 1 = 0.00119254 loss)
I1130 23:59:46.394362 12698 sgd_solver.cpp:106] Iteration 72500, lr = 0.001
I1201 00:00:00.807505 12698 solver.cpp:228] Iteration 73000, loss = 0.039699
I1201 00:00:00.807579 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00484793 (* 0.5 = 0.00242397 loss)
I1201 00:00:00.807587 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.012104 (* 1 = 0.012104 loss)
I1201 00:00:00.807591 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:00:00.807596 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:00:00.807602 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00103454 (* 1 = 0.00103454 loss)
I1201 00:00:00.807610 12698 sgd_solver.cpp:106] Iteration 73000, lr = 0.001
I1201 00:00:03.164860 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_73083.caffemodel
I1201 00:00:03.188406 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_73083.solverstate
I1201 00:00:03.191305 12698 solver.cpp:337] Iteration 73083, Testing net (#0)
I1201 00:00:27.625705 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0057463 (* 0.5 = 0.00287315 loss)
I1201 00:00:27.625767 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0587499 (* 1 = 0.0587499 loss)
I1201 00:00:27.625775 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.979779
I1201 00:00:27.625779 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.926688
I1201 00:00:27.625784 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00135069 (* 1 = 0.00135069 loss)
I1201 00:00:39.646991 12698 solver.cpp:228] Iteration 73500, loss = 0.0361653
I1201 00:00:39.647064 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00542369 (* 0.5 = 0.00271185 loss)
I1201 00:00:39.647081 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0549023 (* 1 = 0.0549023 loss)
I1201 00:00:39.647086 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:00:39.647091 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1201 00:00:39.647096 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00252382 (* 1 = 0.00252382 loss)
I1201 00:00:39.647104 12698 sgd_solver.cpp:106] Iteration 73500, lr = 0.001
I1201 00:00:54.046607 12698 solver.cpp:228] Iteration 74000, loss = 0.042414
I1201 00:00:54.046669 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00601219 (* 0.5 = 0.0030061 loss)
I1201 00:00:54.046679 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0515314 (* 1 = 0.0515314 loss)
I1201 00:00:54.046684 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:00:54.046689 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:00:54.046695 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000868835 (* 1 = 0.000868835 loss)
I1201 00:00:54.046702 12698 sgd_solver.cpp:106] Iteration 74000, lr = 0.001
I1201 00:01:08.438628 12698 solver.cpp:228] Iteration 74500, loss = 0.0329343
I1201 00:01:08.438706 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00517061 (* 0.5 = 0.0025853 loss)
I1201 00:01:08.438715 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0112061 (* 1 = 0.0112061 loss)
I1201 00:01:08.438720 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:01:08.438724 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:01:08.438730 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000804151 (* 1 = 0.000804151 loss)
I1201 00:01:08.438736 12698 sgd_solver.cpp:106] Iteration 74500, lr = 0.001
I1201 00:01:22.841115 12698 solver.cpp:228] Iteration 75000, loss = 0.0447639
I1201 00:01:22.841181 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00815372 (* 0.5 = 0.00407686 loss)
I1201 00:01:22.841190 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0200326 (* 1 = 0.0200326 loss)
I1201 00:01:22.841194 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:01:22.841199 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:01:22.841205 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00179685 (* 1 = 0.00179685 loss)
I1201 00:01:22.841212 12698 sgd_solver.cpp:106] Iteration 75000, lr = 0.001
I1201 00:01:37.234230 12698 solver.cpp:228] Iteration 75500, loss = 0.038059
I1201 00:01:37.234300 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00599297 (* 0.5 = 0.00299649 loss)
I1201 00:01:37.234309 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0208097 (* 1 = 0.0208097 loss)
I1201 00:01:37.234313 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:01:37.234318 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:01:37.234323 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000917357 (* 1 = 0.000917357 loss)
I1201 00:01:37.234330 12698 sgd_solver.cpp:106] Iteration 75500, lr = 0.001
I1201 00:01:51.635097 12698 solver.cpp:228] Iteration 76000, loss = 0.0363871
I1201 00:01:51.635171 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00418021 (* 0.5 = 0.0020901 loss)
I1201 00:01:51.635179 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0186439 (* 1 = 0.0186439 loss)
I1201 00:01:51.635185 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:01:51.635190 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:01:51.635195 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00117166 (* 1 = 0.00117166 loss)
I1201 00:01:51.635202 12698 sgd_solver.cpp:106] Iteration 76000, lr = 0.001
I1201 00:02:06.004695 12698 solver.cpp:228] Iteration 76500, loss = 0.042081
I1201 00:02:06.004770 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0045048 (* 0.5 = 0.0022524 loss)
I1201 00:02:06.004778 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.07294 (* 1 = 0.07294 loss)
I1201 00:02:06.004783 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:02:06.004788 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1201 00:02:06.004793 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00172271 (* 1 = 0.00172271 loss)
I1201 00:02:06.004808 12698 sgd_solver.cpp:106] Iteration 76500, lr = 0.001
I1201 00:02:20.399791 12698 solver.cpp:228] Iteration 77000, loss = 0.0321593
I1201 00:02:20.399862 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00540338 (* 0.5 = 0.00270169 loss)
I1201 00:02:20.399871 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.024611 (* 1 = 0.024611 loss)
I1201 00:02:20.399876 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1201 00:02:20.399881 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:02:20.399886 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00214511 (* 1 = 0.00214511 loss)
I1201 00:02:20.399893 12698 sgd_solver.cpp:106] Iteration 77000, lr = 0.001
I1201 00:02:31.375639 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_77382.caffemodel
I1201 00:02:31.400532 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_77382.solverstate
I1201 00:02:31.404089 12698 solver.cpp:337] Iteration 77382, Testing net (#0)
I1201 00:02:55.796288 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00569545 (* 0.5 = 0.00284773 loss)
I1201 00:02:55.796344 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0597056 (* 1 = 0.0597056 loss)
I1201 00:02:55.796350 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.970579
I1201 00:02:55.796356 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.944053
I1201 00:02:55.796361 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00141352 (* 1 = 0.00141352 loss)
I1201 00:02:59.209123 12698 solver.cpp:228] Iteration 77500, loss = 0.0454731
I1201 00:02:59.209202 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00484221 (* 0.5 = 0.00242111 loss)
I1201 00:02:59.209209 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0415559 (* 1 = 0.0415559 loss)
I1201 00:02:59.209214 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:02:59.209219 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:02:59.209224 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00104348 (* 1 = 0.00104348 loss)
I1201 00:02:59.209233 12698 sgd_solver.cpp:106] Iteration 77500, lr = 0.001
I1201 00:03:14.635591 12698 solver.cpp:228] Iteration 78000, loss = 0.0378246
I1201 00:03:14.635664 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00693166 (* 0.5 = 0.00346583 loss)
I1201 00:03:14.635673 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0760291 (* 1 = 0.0760291 loss)
I1201 00:03:14.635677 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:03:14.635682 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.859375
I1201 00:03:14.635687 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000963019 (* 1 = 0.000963019 loss)
I1201 00:03:14.635694 12698 sgd_solver.cpp:106] Iteration 78000, lr = 0.001
I1201 00:03:28.989768 12698 solver.cpp:228] Iteration 78500, loss = 0.0359922
I1201 00:03:28.989840 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00446319 (* 0.5 = 0.00223159 loss)
I1201 00:03:28.989850 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0163607 (* 1 = 0.0163607 loss)
I1201 00:03:28.989855 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:03:28.989858 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:03:28.989863 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00114661 (* 1 = 0.00114661 loss)
I1201 00:03:28.989871 12698 sgd_solver.cpp:106] Iteration 78500, lr = 0.001
I1201 00:03:43.383193 12698 solver.cpp:228] Iteration 79000, loss = 0.0419131
I1201 00:03:43.383267 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00610598 (* 0.5 = 0.00305299 loss)
I1201 00:03:43.383275 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0680971 (* 1 = 0.0680971 loss)
I1201 00:03:43.383288 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:03:43.383293 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:03:43.383298 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00168418 (* 1 = 0.00168418 loss)
I1201 00:03:43.383306 12698 sgd_solver.cpp:106] Iteration 79000, lr = 0.001
I1201 00:03:57.830628 12698 solver.cpp:228] Iteration 79500, loss = 0.0308312
I1201 00:03:57.830704 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00642113 (* 0.5 = 0.00321057 loss)
I1201 00:03:57.830713 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0194885 (* 1 = 0.0194885 loss)
I1201 00:03:57.830718 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:03:57.830724 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:03:57.830729 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00120159 (* 1 = 0.00120159 loss)
I1201 00:03:57.830734 12698 sgd_solver.cpp:106] Iteration 79500, lr = 0.001
I1201 00:04:12.385635 12698 solver.cpp:228] Iteration 80000, loss = 0.0464048
I1201 00:04:12.385709 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00504411 (* 0.5 = 0.00252206 loss)
I1201 00:04:12.385717 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0187384 (* 1 = 0.0187384 loss)
I1201 00:04:12.385722 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:04:12.385726 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:04:12.385731 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00124649 (* 1 = 0.00124649 loss)
I1201 00:04:12.385738 12698 sgd_solver.cpp:106] Iteration 80000, lr = 0.001
I1201 00:04:26.756023 12698 solver.cpp:228] Iteration 80500, loss = 0.037597
I1201 00:04:26.756101 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00488797 (* 0.5 = 0.00244399 loss)
I1201 00:04:26.756112 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0171388 (* 1 = 0.0171388 loss)
I1201 00:04:26.756117 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:04:26.756122 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:04:26.756127 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00797146 (* 1 = 0.00797146 loss)
I1201 00:04:26.756134 12698 sgd_solver.cpp:106] Iteration 80500, lr = 0.001
I1201 00:04:41.129029 12698 solver.cpp:228] Iteration 81000, loss = 0.0357737
I1201 00:04:41.129109 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00510805 (* 0.5 = 0.00255403 loss)
I1201 00:04:41.129117 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.031877 (* 1 = 0.031877 loss)
I1201 00:04:41.129122 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:04:41.129127 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:04:41.129132 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000762479 (* 1 = 0.000762479 loss)
I1201 00:04:41.129138 12698 sgd_solver.cpp:106] Iteration 81000, lr = 0.001
I1201 00:04:55.631338 12698 solver.cpp:228] Iteration 81500, loss = 0.0429039
I1201 00:04:55.631412 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00666907 (* 0.5 = 0.00333453 loss)
I1201 00:04:55.631422 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0498881 (* 1 = 0.0498881 loss)
I1201 00:04:55.631428 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:04:55.631431 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:04:55.631438 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.001373 (* 1 = 0.001373 loss)
I1201 00:04:55.631443 12698 sgd_solver.cpp:106] Iteration 81500, lr = 0.001
I1201 00:05:00.784337 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_81681.caffemodel
I1201 00:05:00.808046 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_81681.solverstate
I1201 00:05:00.810838 12698 solver.cpp:337] Iteration 81681, Testing net (#0)
I1201 00:05:25.321910 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00569363 (* 0.5 = 0.00284681 loss)
I1201 00:05:25.321967 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.060184 (* 1 = 0.060184 loss)
I1201 00:05:25.321974 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.984667
I1201 00:05:25.321979 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.912863
I1201 00:05:25.321985 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00138852 (* 1 = 0.00138852 loss)
I1201 00:05:34.452334 12698 solver.cpp:228] Iteration 82000, loss = 0.0296176
I1201 00:05:34.452400 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00437879 (* 0.5 = 0.0021894 loss)
I1201 00:05:34.452409 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0273925 (* 1 = 0.0273925 loss)
I1201 00:05:34.452414 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:05:34.452419 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:05:34.452424 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00131045 (* 1 = 0.00131045 loss)
I1201 00:05:34.452430 12698 sgd_solver.cpp:106] Iteration 82000, lr = 0.001
I1201 00:05:48.717566 12698 solver.cpp:228] Iteration 82500, loss = 0.0457942
I1201 00:05:48.717639 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00536492 (* 0.5 = 0.00268246 loss)
I1201 00:05:48.717648 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0431813 (* 1 = 0.0431813 loss)
I1201 00:05:48.717654 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:05:48.717659 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:05:48.717664 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00124477 (* 1 = 0.00124477 loss)
I1201 00:05:48.717671 12698 sgd_solver.cpp:106] Iteration 82500, lr = 0.001
I1201 00:06:02.974354 12698 solver.cpp:228] Iteration 83000, loss = 0.0371432
I1201 00:06:02.974426 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00498759 (* 0.5 = 0.0024938 loss)
I1201 00:06:02.974434 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0363996 (* 1 = 0.0363996 loss)
I1201 00:06:02.974439 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:06:02.974444 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:06:02.974449 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000867949 (* 1 = 0.000867949 loss)
I1201 00:06:02.974457 12698 sgd_solver.cpp:106] Iteration 83000, lr = 0.001
I1201 00:06:17.210881 12698 solver.cpp:228] Iteration 83500, loss = 0.0359986
I1201 00:06:17.210955 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00539834 (* 0.5 = 0.00269917 loss)
I1201 00:06:17.210964 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0403198 (* 1 = 0.0403198 loss)
I1201 00:06:17.210969 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:06:17.210974 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:06:17.210980 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00112954 (* 1 = 0.00112954 loss)
I1201 00:06:17.210988 12698 sgd_solver.cpp:106] Iteration 83500, lr = 0.001
I1201 00:06:31.452430 12698 solver.cpp:228] Iteration 84000, loss = 0.0426175
I1201 00:06:31.452498 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00599142 (* 0.5 = 0.00299571 loss)
I1201 00:06:31.452507 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0442608 (* 1 = 0.0442608 loss)
I1201 00:06:31.452512 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1201 00:06:31.452517 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:06:31.452522 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0010343 (* 1 = 0.0010343 loss)
I1201 00:06:31.452536 12698 sgd_solver.cpp:106] Iteration 84000, lr = 0.001
I1201 00:06:45.713577 12698 solver.cpp:228] Iteration 84500, loss = 0.0294217
I1201 00:06:45.713650 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00539661 (* 0.5 = 0.00269831 loss)
I1201 00:06:45.713660 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0349434 (* 1 = 0.0349434 loss)
I1201 00:06:45.713665 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:06:45.713668 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:06:45.713675 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00725204 (* 1 = 0.00725204 loss)
I1201 00:06:45.713680 12698 sgd_solver.cpp:106] Iteration 84500, lr = 0.001
I1201 00:06:59.958709 12698 solver.cpp:228] Iteration 85000, loss = 0.0461192
I1201 00:06:59.958783 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00632353 (* 0.5 = 0.00316176 loss)
I1201 00:06:59.958791 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0223291 (* 1 = 0.0223291 loss)
I1201 00:06:59.958796 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:06:59.958801 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:06:59.958806 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00195531 (* 1 = 0.00195531 loss)
I1201 00:06:59.958813 12698 sgd_solver.cpp:106] Iteration 85000, lr = 0.001
I1201 00:07:14.212438 12698 solver.cpp:228] Iteration 85500, loss = 0.0362898
I1201 00:07:14.212504 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00478219 (* 0.5 = 0.00239109 loss)
I1201 00:07:14.212513 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0276644 (* 1 = 0.0276644 loss)
I1201 00:07:14.212517 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:07:14.212522 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:07:14.212527 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000790051 (* 1 = 0.000790051 loss)
I1201 00:07:14.212534 12698 sgd_solver.cpp:106] Iteration 85500, lr = 0.001
I1201 00:07:27.870529 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_85980.caffemodel
I1201 00:07:27.893353 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_85980.solverstate
I1201 00:07:27.896150 12698 solver.cpp:337] Iteration 85980, Testing net (#0)
I1201 00:07:52.299141 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00571463 (* 0.5 = 0.00285731 loss)
I1201 00:07:52.299199 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0597201 (* 1 = 0.0597201 loss)
I1201 00:07:52.299206 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.972394
I1201 00:07:52.299211 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.941429
I1201 00:07:52.299216 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00132755 (* 1 = 0.00132755 loss)
I1201 00:07:52.898608 12698 solver.cpp:228] Iteration 86000, loss = 0.0361977
I1201 00:07:52.898674 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00524168 (* 0.5 = 0.00262084 loss)
I1201 00:07:52.898684 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0429485 (* 1 = 0.0429485 loss)
I1201 00:07:52.898687 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:07:52.898692 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:07:52.898697 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0019933 (* 1 = 0.0019933 loss)
I1201 00:07:52.898705 12698 sgd_solver.cpp:106] Iteration 86000, lr = 0.0001
I1201 00:08:07.262444 12698 solver.cpp:228] Iteration 86500, loss = 0.0430057
I1201 00:08:07.262517 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00459607 (* 0.5 = 0.00229803 loss)
I1201 00:08:07.262526 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0125862 (* 1 = 0.0125862 loss)
I1201 00:08:07.262544 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:08:07.262549 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:08:07.262554 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00148274 (* 1 = 0.00148274 loss)
I1201 00:08:07.262562 12698 sgd_solver.cpp:106] Iteration 86500, lr = 0.0001
I1201 00:08:21.639915 12698 solver.cpp:228] Iteration 87000, loss = 0.0299148
I1201 00:08:21.639994 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00481902 (* 0.5 = 0.00240951 loss)
I1201 00:08:21.640003 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0271919 (* 1 = 0.0271919 loss)
I1201 00:08:21.640008 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:08:21.640012 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:08:21.640018 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00123807 (* 1 = 0.00123807 loss)
I1201 00:08:21.640025 12698 sgd_solver.cpp:106] Iteration 87000, lr = 0.0001
I1201 00:08:36.010979 12698 solver.cpp:228] Iteration 87500, loss = 0.0458508
I1201 00:08:36.011051 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00487071 (* 0.5 = 0.00243536 loss)
I1201 00:08:36.011060 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0235367 (* 1 = 0.0235367 loss)
I1201 00:08:36.011065 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:08:36.011076 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:08:36.011083 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00106556 (* 1 = 0.00106556 loss)
I1201 00:08:36.011090 12698 sgd_solver.cpp:106] Iteration 87500, lr = 0.0001
I1201 00:08:50.379896 12698 solver.cpp:228] Iteration 88000, loss = 0.0356883
I1201 00:08:50.379969 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00440058 (* 0.5 = 0.00220029 loss)
I1201 00:08:50.379978 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0253554 (* 1 = 0.0253554 loss)
I1201 00:08:50.379983 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:08:50.379988 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:08:50.379993 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000849206 (* 1 = 0.000849206 loss)
I1201 00:08:50.380000 12698 sgd_solver.cpp:106] Iteration 88000, lr = 0.0001
I1201 00:09:04.736769 12698 solver.cpp:228] Iteration 88500, loss = 0.0368443
I1201 00:09:04.736843 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00498628 (* 0.5 = 0.00249314 loss)
I1201 00:09:04.736852 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0485185 (* 1 = 0.0485185 loss)
I1201 00:09:04.736857 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:09:04.736862 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:09:04.736867 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00101527 (* 1 = 0.00101527 loss)
I1201 00:09:04.736874 12698 sgd_solver.cpp:106] Iteration 88500, lr = 0.0001
I1201 00:09:19.121237 12698 solver.cpp:228] Iteration 89000, loss = 0.0416952
I1201 00:09:19.121314 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00563253 (* 0.5 = 0.00281627 loss)
I1201 00:09:19.121325 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0452247 (* 1 = 0.0452247 loss)
I1201 00:09:19.121330 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:09:19.121336 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:09:19.121343 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000886033 (* 1 = 0.000886033 loss)
I1201 00:09:19.121351 12698 sgd_solver.cpp:106] Iteration 89000, lr = 0.0001
I1201 00:09:33.490943 12698 solver.cpp:228] Iteration 89500, loss = 0.0298966
I1201 00:09:33.491034 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00460512 (* 0.5 = 0.00230256 loss)
I1201 00:09:33.491044 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0395941 (* 1 = 0.0395941 loss)
I1201 00:09:33.491049 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:09:33.491052 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:09:33.491058 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00107349 (* 1 = 0.00107349 loss)
I1201 00:09:33.491065 12698 sgd_solver.cpp:106] Iteration 89500, lr = 0.0001
I1201 00:09:47.868255 12698 solver.cpp:228] Iteration 90000, loss = 0.0451836
I1201 00:09:47.868330 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00484545 (* 0.5 = 0.00242273 loss)
I1201 00:09:47.868340 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0289729 (* 1 = 0.0289729 loss)
I1201 00:09:47.868345 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:09:47.868348 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:09:47.868355 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00141297 (* 1 = 0.00141297 loss)
I1201 00:09:47.868361 12698 sgd_solver.cpp:106] Iteration 90000, lr = 0.0001
I1201 00:09:55.855254 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_90279.caffemodel
I1201 00:09:55.879155 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_90279.solverstate
I1201 00:09:55.881947 12698 solver.cpp:337] Iteration 90279, Testing net (#0)
I1201 00:10:20.261353 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00566769 (* 0.5 = 0.00283384 loss)
I1201 00:10:20.261416 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0573804 (* 1 = 0.0573804 loss)
I1201 00:10:20.261423 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.97789
I1201 00:10:20.261427 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.934246
I1201 00:10:20.261433 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00140046 (* 1 = 0.00140046 loss)
I1201 00:10:26.655987 12698 solver.cpp:228] Iteration 90500, loss = 0.0353157
I1201 00:10:26.656054 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00514356 (* 0.5 = 0.00257178 loss)
I1201 00:10:26.656064 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0271835 (* 1 = 0.0271835 loss)
I1201 00:10:26.656075 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:10:26.656081 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:10:26.656086 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00078028 (* 1 = 0.00078028 loss)
I1201 00:10:26.656093 12698 sgd_solver.cpp:106] Iteration 90500, lr = 0.0001
I1201 00:10:41.045835 12698 solver.cpp:228] Iteration 91000, loss = 0.0375633
I1201 00:10:41.045912 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0046637 (* 0.5 = 0.00233185 loss)
I1201 00:10:41.045919 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0356793 (* 1 = 0.0356793 loss)
I1201 00:10:41.045924 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:10:41.045929 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:10:41.045934 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00104489 (* 1 = 0.00104489 loss)
I1201 00:10:41.045943 12698 sgd_solver.cpp:106] Iteration 91000, lr = 0.0001
I1201 00:10:55.450783 12698 solver.cpp:228] Iteration 91500, loss = 0.0407863
I1201 00:10:55.450860 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00423292 (* 0.5 = 0.00211646 loss)
I1201 00:10:55.450870 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0138757 (* 1 = 0.0138757 loss)
I1201 00:10:55.450875 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:10:55.450880 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:10:55.450893 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0012817 (* 1 = 0.0012817 loss)
I1201 00:10:55.450901 12698 sgd_solver.cpp:106] Iteration 91500, lr = 0.0001
I1201 00:11:09.862632 12698 solver.cpp:228] Iteration 92000, loss = 0.030557
I1201 00:11:09.862702 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00619651 (* 0.5 = 0.00309826 loss)
I1201 00:11:09.862711 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0669133 (* 1 = 0.0669133 loss)
I1201 00:11:09.862716 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1201 00:11:09.862721 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1201 00:11:09.862726 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000843239 (* 1 = 0.000843239 loss)
I1201 00:11:09.862733 12698 sgd_solver.cpp:106] Iteration 92000, lr = 0.0001
I1201 00:11:24.263819 12698 solver.cpp:228] Iteration 92500, loss = 0.0444241
I1201 00:11:24.263895 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00570485 (* 0.5 = 0.00285243 loss)
I1201 00:11:24.263906 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0313056 (* 1 = 0.0313056 loss)
I1201 00:11:24.263911 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:11:24.263914 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:11:24.263921 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000711862 (* 1 = 0.000711862 loss)
I1201 00:11:24.263927 12698 sgd_solver.cpp:106] Iteration 92500, lr = 0.0001
I1201 00:11:38.682654 12698 solver.cpp:228] Iteration 93000, loss = 0.034911
I1201 00:11:38.682732 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0041809 (* 0.5 = 0.00209045 loss)
I1201 00:11:38.682740 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0349999 (* 1 = 0.0349999 loss)
I1201 00:11:38.682745 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:11:38.682750 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:11:38.682755 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00330138 (* 1 = 0.00330138 loss)
I1201 00:11:38.682762 12698 sgd_solver.cpp:106] Iteration 93000, lr = 0.0001
I1201 00:11:53.073249 12698 solver.cpp:228] Iteration 93500, loss = 0.0382065
I1201 00:11:53.073318 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00630378 (* 0.5 = 0.00315189 loss)
I1201 00:11:53.073328 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0399336 (* 1 = 0.0399336 loss)
I1201 00:11:53.073333 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:11:53.073336 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:11:53.073343 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00157371 (* 1 = 0.00157371 loss)
I1201 00:11:53.073348 12698 sgd_solver.cpp:106] Iteration 93500, lr = 0.0001
I1201 00:12:07.466856 12698 solver.cpp:228] Iteration 94000, loss = 0.0401124
I1201 00:12:07.466929 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0054339 (* 0.5 = 0.00271695 loss)
I1201 00:12:07.466938 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0166074 (* 1 = 0.0166074 loss)
I1201 00:12:07.466943 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:12:07.466948 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:12:07.466953 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0011318 (* 1 = 0.0011318 loss)
I1201 00:12:07.466960 12698 sgd_solver.cpp:106] Iteration 94000, lr = 0.0001
I1201 00:12:21.873950 12698 solver.cpp:228] Iteration 94500, loss = 0.0325719
I1201 00:12:21.874027 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00734691 (* 0.5 = 0.00367346 loss)
I1201 00:12:21.874035 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0500882 (* 1 = 0.0500882 loss)
I1201 00:12:21.874048 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:12:21.874054 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:12:21.874059 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00418525 (* 1 = 0.00418525 loss)
I1201 00:12:21.874070 12698 sgd_solver.cpp:106] Iteration 94500, lr = 0.0001
I1201 00:12:24.087299 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_94578.caffemodel
I1201 00:12:24.110762 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_94578.solverstate
I1201 00:12:24.113549 12698 solver.cpp:337] Iteration 94578, Testing net (#0)
I1201 00:12:48.737921 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00563946 (* 0.5 = 0.00281973 loss)
I1201 00:12:48.737979 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0616063 (* 1 = 0.0616063 loss)
I1201 00:12:48.737987 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.966568
I1201 00:12:48.737992 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.949376
I1201 00:12:48.737998 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00135775 (* 1 = 0.00135775 loss)
I1201 00:13:00.908210 12698 solver.cpp:228] Iteration 95000, loss = 0.0427011
I1201 00:13:00.908283 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00542843 (* 0.5 = 0.00271421 loss)
I1201 00:13:00.908291 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.029217 (* 1 = 0.029217 loss)
I1201 00:13:00.908296 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:13:00.908301 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:13:00.908306 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00210804 (* 1 = 0.00210804 loss)
I1201 00:13:00.908313 12698 sgd_solver.cpp:106] Iteration 95000, lr = 0.0001
I1201 00:13:15.309468 12698 solver.cpp:228] Iteration 95500, loss = 0.0344004
I1201 00:13:15.309543 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00496319 (* 0.5 = 0.00248159 loss)
I1201 00:13:15.309552 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.013949 (* 1 = 0.013949 loss)
I1201 00:13:15.309557 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:13:15.309562 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:13:15.309568 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00106689 (* 1 = 0.00106689 loss)
I1201 00:13:15.309576 12698 sgd_solver.cpp:106] Iteration 95500, lr = 0.0001
I1201 00:13:29.700423 12698 solver.cpp:228] Iteration 96000, loss = 0.0391371
I1201 00:13:29.700495 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00575296 (* 0.5 = 0.00287648 loss)
I1201 00:13:29.700503 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0245636 (* 1 = 0.0245636 loss)
I1201 00:13:29.700507 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:13:29.700511 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:13:29.700517 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000631687 (* 1 = 0.000631687 loss)
I1201 00:13:29.700523 12698 sgd_solver.cpp:106] Iteration 96000, lr = 0.0001
I1201 00:13:44.113801 12698 solver.cpp:228] Iteration 96500, loss = 0.0391784
I1201 00:13:44.113883 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0050369 (* 0.5 = 0.00251845 loss)
I1201 00:13:44.113893 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.016663 (* 1 = 0.016663 loss)
I1201 00:13:44.113898 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:13:44.113901 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:13:44.113907 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0013948 (* 1 = 0.0013948 loss)
I1201 00:13:44.113914 12698 sgd_solver.cpp:106] Iteration 96500, lr = 0.0001
I1201 00:13:58.497925 12698 solver.cpp:228] Iteration 97000, loss = 0.0344895
I1201 00:13:58.498009 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00639374 (* 0.5 = 0.00319687 loss)
I1201 00:13:58.498018 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0266179 (* 1 = 0.0266179 loss)
I1201 00:13:58.498023 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:13:58.498028 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:13:58.498033 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00533117 (* 1 = 0.00533117 loss)
I1201 00:13:58.498039 12698 sgd_solver.cpp:106] Iteration 97000, lr = 0.0001
I1201 00:14:12.901820 12698 solver.cpp:228] Iteration 97500, loss = 0.0414455
I1201 00:14:12.901892 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00484551 (* 0.5 = 0.00242276 loss)
I1201 00:14:12.901901 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0319537 (* 1 = 0.0319537 loss)
I1201 00:14:12.901906 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:14:12.901911 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:14:12.901916 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000771984 (* 1 = 0.000771984 loss)
I1201 00:14:12.901922 12698 sgd_solver.cpp:106] Iteration 97500, lr = 0.0001
I1201 00:14:27.304154 12698 solver.cpp:228] Iteration 98000, loss = 0.0339822
I1201 00:14:27.304237 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00507787 (* 0.5 = 0.00253894 loss)
I1201 00:14:27.304247 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.014151 (* 1 = 0.014151 loss)
I1201 00:14:27.304253 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:14:27.304260 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:14:27.304266 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000887799 (* 1 = 0.000887799 loss)
I1201 00:14:27.304273 12698 sgd_solver.cpp:106] Iteration 98000, lr = 0.0001
I1201 00:14:41.699831 12698 solver.cpp:228] Iteration 98500, loss = 0.0393635
I1201 00:14:41.699910 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00601176 (* 0.5 = 0.00300588 loss)
I1201 00:14:41.699921 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0210514 (* 1 = 0.0210514 loss)
I1201 00:14:41.699926 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:14:41.699933 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:14:41.699939 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00105949 (* 1 = 0.00105949 loss)
I1201 00:14:41.699946 12698 sgd_solver.cpp:106] Iteration 98500, lr = 0.0001
I1201 00:14:52.532500 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_98877.caffemodel
I1201 00:14:52.556134 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_98877.solverstate
I1201 00:14:52.559028 12698 solver.cpp:337] Iteration 98877, Testing net (#0)
I1201 00:15:17.086187 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00568072 (* 0.5 = 0.00284036 loss)
I1201 00:15:17.086246 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0591422 (* 1 = 0.0591422 loss)
I1201 00:15:17.086252 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.971382
I1201 00:15:17.086257 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.944683
I1201 00:15:17.086262 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00131667 (* 1 = 0.00131667 loss)
I1201 00:15:20.643268 12698 solver.cpp:228] Iteration 99000, loss = 0.0376577
I1201 00:15:20.643338 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00532433 (* 0.5 = 0.00266217 loss)
I1201 00:15:20.643347 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0177936 (* 1 = 0.0177936 loss)
I1201 00:15:20.643352 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:15:20.643369 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:15:20.643375 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00092192 (* 1 = 0.00092192 loss)
I1201 00:15:20.643383 12698 sgd_solver.cpp:106] Iteration 99000, lr = 0.0001
I1201 00:15:35.006857 12698 solver.cpp:228] Iteration 99500, loss = 0.0364912
I1201 00:15:35.006927 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00510941 (* 0.5 = 0.0025547 loss)
I1201 00:15:35.006934 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0461545 (* 1 = 0.0461545 loss)
I1201 00:15:35.006939 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:15:35.006944 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:15:35.006950 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00145367 (* 1 = 0.00145367 loss)
I1201 00:15:35.006958 12698 sgd_solver.cpp:106] Iteration 99500, lr = 0.0001
I1201 00:15:49.368984 12698 solver.cpp:228] Iteration 100000, loss = 0.0408579
I1201 00:15:49.369058 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00527418 (* 0.5 = 0.00263709 loss)
I1201 00:15:49.369072 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0383752 (* 1 = 0.0383752 loss)
I1201 00:15:49.369079 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:15:49.369084 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:15:49.369091 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000964906 (* 1 = 0.000964906 loss)
I1201 00:15:49.369097 12698 sgd_solver.cpp:106] Iteration 100000, lr = 0.0001
I1201 00:16:03.730453 12698 solver.cpp:228] Iteration 100500, loss = 0.0334923
I1201 00:16:03.730525 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00494578 (* 0.5 = 0.00247289 loss)
I1201 00:16:03.730535 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0446663 (* 1 = 0.0446663 loss)
I1201 00:16:03.730538 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:16:03.730543 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:16:03.730548 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000937311 (* 1 = 0.000937311 loss)
I1201 00:16:03.730556 12698 sgd_solver.cpp:106] Iteration 100500, lr = 0.0001
I1201 00:16:18.094202 12698 solver.cpp:228] Iteration 101000, loss = 0.039954
I1201 00:16:18.094271 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00386445 (* 0.5 = 0.00193223 loss)
I1201 00:16:18.094280 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0309369 (* 1 = 0.0309369 loss)
I1201 00:16:18.094285 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:16:18.094290 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:16:18.094295 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00100029 (* 1 = 0.00100029 loss)
I1201 00:16:18.094301 12698 sgd_solver.cpp:106] Iteration 101000, lr = 0.0001
I1201 00:16:32.465900 12698 solver.cpp:228] Iteration 101500, loss = 0.0367786
I1201 00:16:32.465973 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00527849 (* 0.5 = 0.00263925 loss)
I1201 00:16:32.465984 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.00842877 (* 1 = 0.00842877 loss)
I1201 00:16:32.465991 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:16:32.465996 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:16:32.466002 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00114319 (* 1 = 0.00114319 loss)
I1201 00:16:32.466009 12698 sgd_solver.cpp:106] Iteration 101500, lr = 0.0001
I1201 00:16:46.848718 12698 solver.cpp:228] Iteration 102000, loss = 0.0380686
I1201 00:16:46.848793 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00615562 (* 0.5 = 0.00307781 loss)
I1201 00:16:46.848800 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0340832 (* 1 = 0.0340832 loss)
I1201 00:16:46.848814 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:16:46.848819 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:16:46.848825 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000776016 (* 1 = 0.000776016 loss)
I1201 00:16:46.848831 12698 sgd_solver.cpp:106] Iteration 102000, lr = 0.0001
I1201 00:17:01.236929 12698 solver.cpp:228] Iteration 102500, loss = 0.0402535
I1201 00:17:01.237006 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00510899 (* 0.5 = 0.00255449 loss)
I1201 00:17:01.237015 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0194827 (* 1 = 0.0194827 loss)
I1201 00:17:01.237021 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:17:01.237025 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:17:01.237031 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00150626 (* 1 = 0.00150626 loss)
I1201 00:17:01.237038 12698 sgd_solver.cpp:106] Iteration 102500, lr = 0.0001
I1201 00:17:15.588363 12698 solver.cpp:228] Iteration 103000, loss = 0.0331405
I1201 00:17:15.588438 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00555961 (* 0.5 = 0.00277981 loss)
I1201 00:17:15.588448 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0255156 (* 1 = 0.0255156 loss)
I1201 00:17:15.588452 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:17:15.588456 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:17:15.588462 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000918834 (* 1 = 0.000918834 loss)
I1201 00:17:15.588469 12698 sgd_solver.cpp:106] Iteration 103000, lr = 0.0001
I1201 00:17:20.611464 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_103176.caffemodel
I1201 00:17:20.634138 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_103176.solverstate
I1201 00:17:20.637002 12698 solver.cpp:337] Iteration 103176, Testing net (#0)
I1201 00:17:44.872647 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00564456 (* 0.5 = 0.00282228 loss)
I1201 00:17:44.872706 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0583358 (* 1 = 0.0583358 loss)
I1201 00:17:44.872714 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.976705
I1201 00:17:44.872719 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.935701
I1201 00:17:44.872723 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00139873 (* 1 = 0.00139873 loss)
I1201 00:17:54.141031 12698 solver.cpp:228] Iteration 103500, loss = 0.0400598
I1201 00:17:54.141105 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00462575 (* 0.5 = 0.00231287 loss)
I1201 00:17:54.141114 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0408325 (* 1 = 0.0408325 loss)
I1201 00:17:54.141120 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1201 00:17:54.141124 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:17:54.141130 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000656221 (* 1 = 0.000656221 loss)
I1201 00:17:54.141137 12698 sgd_solver.cpp:106] Iteration 103500, lr = 0.0001
I1201 00:18:08.395797 12698 solver.cpp:228] Iteration 104000, loss = 0.0355858
I1201 00:18:08.395869 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.005491 (* 0.5 = 0.0027455 loss)
I1201 00:18:08.395877 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0211738 (* 1 = 0.0211738 loss)
I1201 00:18:08.395882 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:18:08.395886 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:18:08.395892 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00120471 (* 1 = 0.00120471 loss)
I1201 00:18:08.395908 12698 sgd_solver.cpp:106] Iteration 104000, lr = 0.0001
I1201 00:18:22.670276 12698 solver.cpp:228] Iteration 104500, loss = 0.0395472
I1201 00:18:22.670351 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00683324 (* 0.5 = 0.00341662 loss)
I1201 00:18:22.670361 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0238845 (* 1 = 0.0238845 loss)
I1201 00:18:22.670366 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:18:22.670369 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:18:22.670375 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00111436 (* 1 = 0.00111436 loss)
I1201 00:18:22.670382 12698 sgd_solver.cpp:106] Iteration 104500, lr = 0.0001
I1201 00:18:36.936491 12698 solver.cpp:228] Iteration 105000, loss = 0.0397408
I1201 00:18:36.936568 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00407965 (* 0.5 = 0.00203982 loss)
I1201 00:18:36.936578 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0190825 (* 1 = 0.0190825 loss)
I1201 00:18:36.936583 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:18:36.936586 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:18:36.936592 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0011947 (* 1 = 0.0011947 loss)
I1201 00:18:36.936599 12698 sgd_solver.cpp:106] Iteration 105000, lr = 0.0001
I1201 00:18:51.206024 12698 solver.cpp:228] Iteration 105500, loss = 0.0333387
I1201 00:18:51.206101 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00580199 (* 0.5 = 0.00290099 loss)
I1201 00:18:51.206112 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0311837 (* 1 = 0.0311837 loss)
I1201 00:18:51.206117 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:18:51.206122 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:18:51.206127 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00218681 (* 1 = 0.00218681 loss)
I1201 00:18:51.206135 12698 sgd_solver.cpp:106] Iteration 105500, lr = 0.0001
I1201 00:19:05.461664 12698 solver.cpp:228] Iteration 106000, loss = 0.0401037
I1201 00:19:05.461740 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0053586 (* 0.5 = 0.0026793 loss)
I1201 00:19:05.461748 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0331273 (* 1 = 0.0331273 loss)
I1201 00:19:05.461753 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:19:05.461757 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:19:05.461762 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0011002 (* 1 = 0.0011002 loss)
I1201 00:19:05.461769 12698 sgd_solver.cpp:106] Iteration 106000, lr = 0.0001
I1201 00:19:19.731021 12698 solver.cpp:228] Iteration 106500, loss = 0.0337836
I1201 00:19:19.731099 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00634535 (* 0.5 = 0.00317267 loss)
I1201 00:19:19.731112 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0107137 (* 1 = 0.0107137 loss)
I1201 00:19:19.731117 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:19:19.731120 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:19:19.731127 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000601921 (* 1 = 0.000601921 loss)
I1201 00:19:19.731133 12698 sgd_solver.cpp:106] Iteration 106500, lr = 0.0001
I1201 00:19:34.000557 12698 solver.cpp:228] Iteration 107000, loss = 0.0409712
I1201 00:19:34.000627 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0055083 (* 0.5 = 0.00275415 loss)
I1201 00:19:34.000636 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0340265 (* 1 = 0.0340265 loss)
I1201 00:19:34.000640 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1201 00:19:34.000645 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:19:34.000669 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00165939 (* 1 = 0.00165939 loss)
I1201 00:19:34.000676 12698 sgd_solver.cpp:106] Iteration 107000, lr = 0.0001
I1201 00:19:47.544178 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_107475.caffemodel
I1201 00:19:47.567363 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_107475.solverstate
I1201 00:19:47.570521 12698 solver.cpp:337] Iteration 107475, Testing net (#0)
I1201 00:20:11.829114 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00564934 (* 0.5 = 0.00282467 loss)
I1201 00:20:11.829174 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0576868 (* 1 = 0.0576868 loss)
I1201 00:20:11.829181 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.976375
I1201 00:20:11.829187 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.93621
I1201 00:20:11.829192 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00135333 (* 1 = 0.00135333 loss)
I1201 00:20:12.575752 12698 solver.cpp:228] Iteration 107500, loss = 0.0385808
I1201 00:20:12.575824 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00529257 (* 0.5 = 0.00264628 loss)
I1201 00:20:12.575831 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0298672 (* 1 = 0.0298672 loss)
I1201 00:20:12.575836 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:20:12.575841 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:20:12.575846 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00116857 (* 1 = 0.00116857 loss)
I1201 00:20:12.575853 12698 sgd_solver.cpp:106] Iteration 107500, lr = 0.0001
I1201 00:20:26.943346 12698 solver.cpp:228] Iteration 108000, loss = 0.0336301
I1201 00:20:26.943419 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00582022 (* 0.5 = 0.00291011 loss)
I1201 00:20:26.943428 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0288558 (* 1 = 0.0288558 loss)
I1201 00:20:26.943433 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:20:26.943437 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:20:26.943442 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00127629 (* 1 = 0.00127629 loss)
I1201 00:20:26.943449 12698 sgd_solver.cpp:106] Iteration 108000, lr = 0.0001
I1201 00:20:41.316200 12698 solver.cpp:228] Iteration 108500, loss = 0.0410913
I1201 00:20:41.316277 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00539228 (* 0.5 = 0.00269614 loss)
I1201 00:20:41.316288 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0218211 (* 1 = 0.0218211 loss)
I1201 00:20:41.316293 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:20:41.316299 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:20:41.316305 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00173466 (* 1 = 0.00173466 loss)
I1201 00:20:41.316313 12698 sgd_solver.cpp:106] Iteration 108500, lr = 0.0001
I1201 00:20:55.695091 12698 solver.cpp:228] Iteration 109000, loss = 0.032096
I1201 00:20:55.695168 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0053306 (* 0.5 = 0.0026653 loss)
I1201 00:20:55.695178 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.00751913 (* 1 = 0.00751913 loss)
I1201 00:20:55.695183 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:20:55.695186 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:20:55.695191 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00142901 (* 1 = 0.00142901 loss)
I1201 00:20:55.695199 12698 sgd_solver.cpp:106] Iteration 109000, lr = 0.0001
I1201 00:21:10.059206 12698 solver.cpp:228] Iteration 109500, loss = 0.0431285
I1201 00:21:10.059273 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0059465 (* 0.5 = 0.00297325 loss)
I1201 00:21:10.059291 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.048006 (* 1 = 0.048006 loss)
I1201 00:21:10.059296 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:21:10.059301 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:21:10.059306 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00244016 (* 1 = 0.00244016 loss)
I1201 00:21:10.059314 12698 sgd_solver.cpp:106] Iteration 109500, lr = 0.0001
I1201 00:21:24.417049 12698 solver.cpp:228] Iteration 110000, loss = 0.0374054
I1201 00:21:24.417126 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00497551 (* 0.5 = 0.00248776 loss)
I1201 00:21:24.417135 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0228666 (* 1 = 0.0228666 loss)
I1201 00:21:24.417140 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:21:24.417145 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:21:24.417150 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000598316 (* 1 = 0.000598316 loss)
I1201 00:21:24.417157 12698 sgd_solver.cpp:106] Iteration 110000, lr = 0.0001
I1201 00:21:38.813210 12698 solver.cpp:228] Iteration 110500, loss = 0.0341623
I1201 00:21:38.813290 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00648927 (* 0.5 = 0.00324464 loss)
I1201 00:21:38.813299 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0411891 (* 1 = 0.0411891 loss)
I1201 00:21:38.813305 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1201 00:21:38.813309 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:21:38.813315 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00130132 (* 1 = 0.00130132 loss)
I1201 00:21:38.813323 12698 sgd_solver.cpp:106] Iteration 110500, lr = 0.0001
I1201 00:21:53.200657 12698 solver.cpp:228] Iteration 111000, loss = 0.0406212
I1201 00:21:53.200724 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0057979 (* 0.5 = 0.00289895 loss)
I1201 00:21:53.200733 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0359638 (* 1 = 0.0359638 loss)
I1201 00:21:53.200738 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:21:53.200743 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:21:53.200748 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00119101 (* 1 = 0.00119101 loss)
I1201 00:21:53.200755 12698 sgd_solver.cpp:106] Iteration 111000, lr = 0.0001
I1201 00:22:07.581841 12698 solver.cpp:228] Iteration 111500, loss = 0.0310636
I1201 00:22:07.581913 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0069106 (* 0.5 = 0.0034553 loss)
I1201 00:22:07.581923 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0217988 (* 1 = 0.0217988 loss)
I1201 00:22:07.581928 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:22:07.581931 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:22:07.581938 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00109776 (* 1 = 0.00109776 loss)
I1201 00:22:07.581944 12698 sgd_solver.cpp:106] Iteration 111500, lr = 0.0001
I1201 00:22:15.433498 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_111774.caffemodel
I1201 00:22:15.456392 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_111774.solverstate
I1201 00:22:15.459205 12698 solver.cpp:337] Iteration 111774, Testing net (#0)
I1201 00:22:39.917865 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00567474 (* 0.5 = 0.00283737 loss)
I1201 00:22:39.917927 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.06342 (* 1 = 0.06342 loss)
I1201 00:22:39.917933 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.962872
I1201 00:22:39.917938 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.952555
I1201 00:22:39.917953 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00132043 (* 1 = 0.00132043 loss)
I1201 00:22:46.467206 12698 solver.cpp:228] Iteration 112000, loss = 0.0443825
I1201 00:22:46.467274 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00395669 (* 0.5 = 0.00197835 loss)
I1201 00:22:46.467285 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0383174 (* 1 = 0.0383174 loss)
I1201 00:22:46.467290 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:22:46.467296 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:22:46.467303 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00117238 (* 1 = 0.00117238 loss)
I1201 00:22:46.467311 12698 sgd_solver.cpp:106] Iteration 112000, lr = 0.0001
I1201 00:23:00.869974 12698 solver.cpp:228] Iteration 112500, loss = 0.0362975
I1201 00:23:00.870051 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0041677 (* 0.5 = 0.00208385 loss)
I1201 00:23:00.870060 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0162305 (* 1 = 0.0162305 loss)
I1201 00:23:00.870065 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:23:00.870077 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:23:00.870084 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000684267 (* 1 = 0.000684267 loss)
I1201 00:23:00.870090 12698 sgd_solver.cpp:106] Iteration 112500, lr = 0.0001
I1201 00:23:15.260455 12698 solver.cpp:228] Iteration 113000, loss = 0.0349055
I1201 00:23:15.260527 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00404379 (* 0.5 = 0.00202189 loss)
I1201 00:23:15.260536 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0300258 (* 1 = 0.0300258 loss)
I1201 00:23:15.260540 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:23:15.260545 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:23:15.260550 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000614016 (* 1 = 0.000614016 loss)
I1201 00:23:15.260557 12698 sgd_solver.cpp:106] Iteration 113000, lr = 0.0001
I1201 00:23:29.668409 12698 solver.cpp:228] Iteration 113500, loss = 0.0413555
I1201 00:23:29.668483 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00618469 (* 0.5 = 0.00309234 loss)
I1201 00:23:29.668493 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0334699 (* 1 = 0.0334699 loss)
I1201 00:23:29.668496 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:23:29.668501 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:23:29.668506 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00118053 (* 1 = 0.00118053 loss)
I1201 00:23:29.668514 12698 sgd_solver.cpp:106] Iteration 113500, lr = 0.0001
I1201 00:23:44.078182 12698 solver.cpp:228] Iteration 114000, loss = 0.0296392
I1201 00:23:44.078259 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00449987 (* 0.5 = 0.00224993 loss)
I1201 00:23:44.078269 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0156653 (* 1 = 0.0156653 loss)
I1201 00:23:44.078274 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:23:44.078277 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:23:44.078284 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000738507 (* 1 = 0.000738507 loss)
I1201 00:23:44.078289 12698 sgd_solver.cpp:106] Iteration 114000, lr = 0.0001
I1201 00:23:58.477268 12698 solver.cpp:228] Iteration 114500, loss = 0.0454574
I1201 00:23:58.477346 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00441503 (* 0.5 = 0.00220752 loss)
I1201 00:23:58.477355 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0214158 (* 1 = 0.0214158 loss)
I1201 00:23:58.477360 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:23:58.477382 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:23:58.477388 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00229842 (* 1 = 0.00229842 loss)
I1201 00:23:58.477396 12698 sgd_solver.cpp:106] Iteration 114500, lr = 0.0001
I1201 00:24:12.898578 12698 solver.cpp:228] Iteration 115000, loss = 0.0356065
I1201 00:24:12.898648 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00403548 (* 0.5 = 0.00201774 loss)
I1201 00:24:12.898656 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0232955 (* 1 = 0.0232955 loss)
I1201 00:24:12.898661 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:24:12.898666 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:24:12.898671 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000937969 (* 1 = 0.000937969 loss)
I1201 00:24:12.898679 12698 sgd_solver.cpp:106] Iteration 115000, lr = 0.0001
I1201 00:24:27.306082 12698 solver.cpp:228] Iteration 115500, loss = 0.0353105
I1201 00:24:27.306157 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00383907 (* 0.5 = 0.00191954 loss)
I1201 00:24:27.306166 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0276693 (* 1 = 0.0276693 loss)
I1201 00:24:27.306171 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:24:27.306176 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:24:27.306181 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000995984 (* 1 = 0.000995984 loss)
I1201 00:24:27.306188 12698 sgd_solver.cpp:106] Iteration 115500, lr = 0.0001
I1201 00:24:41.712376 12698 solver.cpp:228] Iteration 116000, loss = 0.041443
I1201 00:24:41.712455 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00526768 (* 0.5 = 0.00263384 loss)
I1201 00:24:41.712465 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.040175 (* 1 = 0.040175 loss)
I1201 00:24:41.712468 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:24:41.712473 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:24:41.712478 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00199039 (* 1 = 0.00199039 loss)
I1201 00:24:41.712486 12698 sgd_solver.cpp:106] Iteration 116000, lr = 0.0001
I1201 00:24:43.790536 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_116073.caffemodel
I1201 00:24:43.814043 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_116073.solverstate
I1201 00:24:43.816884 12698 solver.cpp:337] Iteration 116073, Testing net (#0)
I1201 00:25:08.205138 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00563268 (* 0.5 = 0.00281634 loss)
I1201 00:25:08.205202 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0584442 (* 1 = 0.0584442 loss)
I1201 00:25:08.205209 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.975993
I1201 00:25:08.205214 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.93675
I1201 00:25:08.205219 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.0014087 (* 1 = 0.0014087 loss)
I1201 00:25:20.514122 12698 solver.cpp:228] Iteration 116500, loss = 0.0299737
I1201 00:25:20.514195 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00551509 (* 0.5 = 0.00275755 loss)
I1201 00:25:20.514204 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0412202 (* 1 = 0.0412202 loss)
I1201 00:25:20.514209 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:25:20.514214 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:25:20.514219 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00146869 (* 1 = 0.00146869 loss)
I1201 00:25:20.514226 12698 sgd_solver.cpp:106] Iteration 116500, lr = 0.0001
I1201 00:25:34.892768 12698 solver.cpp:228] Iteration 117000, loss = 0.045044
I1201 00:25:34.892846 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00478737 (* 0.5 = 0.00239369 loss)
I1201 00:25:34.892855 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0397632 (* 1 = 0.0397632 loss)
I1201 00:25:34.892860 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:25:34.892864 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:25:34.892870 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00245481 (* 1 = 0.00245481 loss)
I1201 00:25:34.892876 12698 sgd_solver.cpp:106] Iteration 117000, lr = 0.0001
I1201 00:25:49.273419 12698 solver.cpp:228] Iteration 117500, loss = 0.0358411
I1201 00:25:49.273495 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00452169 (* 0.5 = 0.00226085 loss)
I1201 00:25:49.273504 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0402438 (* 1 = 0.0402438 loss)
I1201 00:25:49.273509 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:25:49.273514 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:25:49.273519 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00139937 (* 1 = 0.00139937 loss)
I1201 00:25:49.273526 12698 sgd_solver.cpp:106] Iteration 117500, lr = 0.0001
I1201 00:26:03.663172 12698 solver.cpp:228] Iteration 118000, loss = 0.0352561
I1201 00:26:03.663247 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00598739 (* 0.5 = 0.00299369 loss)
I1201 00:26:03.663256 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.046898 (* 1 = 0.046898 loss)
I1201 00:26:03.663261 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:26:03.663265 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:26:03.663271 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00105184 (* 1 = 0.00105184 loss)
I1201 00:26:03.663278 12698 sgd_solver.cpp:106] Iteration 118000, lr = 0.0001
I1201 00:26:18.054365 12698 solver.cpp:228] Iteration 118500, loss = 0.0415127
I1201 00:26:18.054445 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00572286 (* 0.5 = 0.00286143 loss)
I1201 00:26:18.054453 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0221255 (* 1 = 0.0221255 loss)
I1201 00:26:18.054458 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:26:18.054462 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:26:18.054468 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00112762 (* 1 = 0.00112762 loss)
I1201 00:26:18.054476 12698 sgd_solver.cpp:106] Iteration 118500, lr = 0.0001
I1201 00:26:32.436863 12698 solver.cpp:228] Iteration 119000, loss = 0.0294679
I1201 00:26:32.436936 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00658596 (* 0.5 = 0.00329298 loss)
I1201 00:26:32.436945 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.039735 (* 1 = 0.039735 loss)
I1201 00:26:32.436950 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:26:32.436954 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:26:32.436960 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00164506 (* 1 = 0.00164506 loss)
I1201 00:26:32.436966 12698 sgd_solver.cpp:106] Iteration 119000, lr = 0.0001
I1201 00:26:46.839066 12698 solver.cpp:228] Iteration 119500, loss = 0.0447869
I1201 00:26:46.839145 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00564373 (* 0.5 = 0.00282186 loss)
I1201 00:26:46.839154 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0406251 (* 1 = 0.0406251 loss)
I1201 00:26:46.839159 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:26:46.839164 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:26:46.839169 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0011453 (* 1 = 0.0011453 loss)
I1201 00:26:46.839185 12698 sgd_solver.cpp:106] Iteration 119500, lr = 0.0001
I1201 00:27:01.246434 12698 solver.cpp:228] Iteration 120000, loss = 0.0357466
I1201 00:27:01.246510 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00434444 (* 0.5 = 0.00217222 loss)
I1201 00:27:01.246518 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0227949 (* 1 = 0.0227949 loss)
I1201 00:27:01.246523 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:27:01.246527 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:27:01.246533 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00268687 (* 1 = 0.00268687 loss)
I1201 00:27:01.246541 12698 sgd_solver.cpp:106] Iteration 120000, lr = 0.0001
I1201 00:27:11.916923 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_120372.caffemodel
I1201 00:27:11.940770 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_120372.solverstate
I1201 00:27:11.943678 12698 solver.cpp:337] Iteration 120372, Testing net (#0)
I1201 00:27:36.256835 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00564466 (* 0.5 = 0.00282233 loss)
I1201 00:27:36.256897 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0591587 (* 1 = 0.0591587 loss)
I1201 00:27:36.256906 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.973481
I1201 00:27:36.256911 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.939914
I1201 00:27:36.256916 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00134667 (* 1 = 0.00134667 loss)
I1201 00:27:39.959118 12698 solver.cpp:228] Iteration 120500, loss = 0.0353032
I1201 00:27:39.959177 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0058362 (* 0.5 = 0.0029181 loss)
I1201 00:27:39.959184 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0443066 (* 1 = 0.0443066 loss)
I1201 00:27:39.959188 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:27:39.959193 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:27:39.959198 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00132142 (* 1 = 0.00132142 loss)
I1201 00:27:39.959205 12698 sgd_solver.cpp:106] Iteration 120500, lr = 0.0001
I1201 00:27:54.314476 12698 solver.cpp:228] Iteration 121000, loss = 0.0414352
I1201 00:27:54.314543 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00516169 (* 0.5 = 0.00258085 loss)
I1201 00:27:54.314551 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.064655 (* 1 = 0.064655 loss)
I1201 00:27:54.314556 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1201 00:27:54.314560 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:27:54.314566 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.001674 (* 1 = 0.001674 loss)
I1201 00:27:54.314574 12698 sgd_solver.cpp:106] Iteration 121000, lr = 0.0001
I1201 00:28:08.692523 12698 solver.cpp:228] Iteration 121500, loss = 0.0297378
I1201 00:28:08.692595 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00661527 (* 0.5 = 0.00330763 loss)
I1201 00:28:08.692605 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0295546 (* 1 = 0.0295546 loss)
I1201 00:28:08.692610 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:28:08.692613 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:28:08.692620 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00110377 (* 1 = 0.00110377 loss)
I1201 00:28:08.692626 12698 sgd_solver.cpp:106] Iteration 121500, lr = 0.0001
I1201 00:28:23.028781 12698 solver.cpp:228] Iteration 122000, loss = 0.0442605
I1201 00:28:23.028856 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00584291 (* 0.5 = 0.00292145 loss)
I1201 00:28:23.028863 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0465712 (* 1 = 0.0465712 loss)
I1201 00:28:23.028878 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:28:23.028883 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:28:23.028888 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00200308 (* 1 = 0.00200308 loss)
I1201 00:28:23.028895 12698 sgd_solver.cpp:106] Iteration 122000, lr = 0.0001
I1201 00:28:37.389050 12698 solver.cpp:228] Iteration 122500, loss = 0.03586
I1201 00:28:37.389128 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0053656 (* 0.5 = 0.0026828 loss)
I1201 00:28:37.389137 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0144623 (* 1 = 0.0144623 loss)
I1201 00:28:37.389142 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:28:37.389147 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:28:37.389152 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00144411 (* 1 = 0.00144411 loss)
I1201 00:28:37.389158 12698 sgd_solver.cpp:106] Iteration 122500, lr = 0.0001
I1201 00:28:51.751519 12698 solver.cpp:228] Iteration 123000, loss = 0.0359929
I1201 00:28:51.751607 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00590114 (* 0.5 = 0.00295057 loss)
I1201 00:28:51.751616 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0487379 (* 1 = 0.0487379 loss)
I1201 00:28:51.751621 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:28:51.751626 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:28:51.751631 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000880853 (* 1 = 0.000880853 loss)
I1201 00:28:51.751639 12698 sgd_solver.cpp:106] Iteration 123000, lr = 0.0001
I1201 00:29:06.111634 12698 solver.cpp:228] Iteration 123500, loss = 0.0415397
I1201 00:29:06.111711 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00581597 (* 0.5 = 0.00290798 loss)
I1201 00:29:06.111719 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.058304 (* 1 = 0.058304 loss)
I1201 00:29:06.111724 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:29:06.111728 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:29:06.111734 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00147334 (* 1 = 0.00147334 loss)
I1201 00:29:06.111742 12698 sgd_solver.cpp:106] Iteration 123500, lr = 0.0001
I1201 00:29:20.483502 12698 solver.cpp:228] Iteration 124000, loss = 0.0290584
I1201 00:29:20.483574 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00397847 (* 0.5 = 0.00198923 loss)
I1201 00:29:20.483583 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0475693 (* 1 = 0.0475693 loss)
I1201 00:29:20.483588 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:29:20.483593 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:29:20.483598 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000758086 (* 1 = 0.000758086 loss)
I1201 00:29:20.483606 12698 sgd_solver.cpp:106] Iteration 124000, lr = 0.0001
I1201 00:29:34.847477 12698 solver.cpp:228] Iteration 124500, loss = 0.0442931
I1201 00:29:34.847548 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00665083 (* 0.5 = 0.00332541 loss)
I1201 00:29:34.847556 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0288809 (* 1 = 0.0288809 loss)
I1201 00:29:34.847561 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:29:34.847566 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:29:34.847571 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000929656 (* 1 = 0.000929656 loss)
I1201 00:29:34.847579 12698 sgd_solver.cpp:106] Iteration 124500, lr = 0.0001
I1201 00:29:39.731571 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_124671.caffemodel
I1201 00:29:39.754711 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_124671.solverstate
I1201 00:29:39.757732 12698 solver.cpp:337] Iteration 124671, Testing net (#0)
I1201 00:30:05.832041 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00567941 (* 0.5 = 0.0028397 loss)
I1201 00:30:05.832111 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0598659 (* 1 = 0.0598659 loss)
I1201 00:30:05.832119 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.970819
I1201 00:30:05.832126 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.945208
I1201 00:30:05.832134 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00130723 (* 1 = 0.00130723 loss)
I1201 00:30:15.261143 12698 solver.cpp:228] Iteration 125000, loss = 0.035699
I1201 00:30:15.261211 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0043366 (* 0.5 = 0.0021683 loss)
I1201 00:30:15.261219 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0180316 (* 1 = 0.0180316 loss)
I1201 00:30:15.261224 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:30:15.261229 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:30:15.261234 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00113453 (* 1 = 0.00113453 loss)
I1201 00:30:15.261241 12698 sgd_solver.cpp:106] Iteration 125000, lr = 0.0001
I1201 00:30:29.546597 12698 solver.cpp:228] Iteration 125500, loss = 0.0367275
I1201 00:30:29.546691 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00591133 (* 0.5 = 0.00295566 loss)
I1201 00:30:29.546700 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0540786 (* 1 = 0.0540786 loss)
I1201 00:30:29.546705 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:30:29.546710 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:30:29.546715 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00149918 (* 1 = 0.00149918 loss)
I1201 00:30:29.546725 12698 sgd_solver.cpp:106] Iteration 125500, lr = 0.0001
I1201 00:30:43.839838 12698 solver.cpp:228] Iteration 126000, loss = 0.0411347
I1201 00:30:43.839915 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00711885 (* 0.5 = 0.00355943 loss)
I1201 00:30:43.839923 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0473662 (* 1 = 0.0473662 loss)
I1201 00:30:43.839928 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:30:43.839933 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:30:43.839938 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000889693 (* 1 = 0.000889693 loss)
I1201 00:30:43.839946 12698 sgd_solver.cpp:106] Iteration 126000, lr = 0.0001
I1201 00:30:58.105553 12698 solver.cpp:228] Iteration 126500, loss = 0.0290324
I1201 00:30:58.105629 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00476613 (* 0.5 = 0.00238307 loss)
I1201 00:30:58.105638 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0390416 (* 1 = 0.0390416 loss)
I1201 00:30:58.105643 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:30:58.105648 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:30:58.105654 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000696169 (* 1 = 0.000696169 loss)
I1201 00:30:58.105660 12698 sgd_solver.cpp:106] Iteration 126500, lr = 0.0001
I1201 00:31:12.350028 12698 solver.cpp:228] Iteration 127000, loss = 0.0445344
I1201 00:31:12.350101 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0064434 (* 0.5 = 0.0032217 loss)
I1201 00:31:12.350111 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0336593 (* 1 = 0.0336593 loss)
I1201 00:31:12.350116 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:31:12.350119 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:31:12.350136 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000772172 (* 1 = 0.000772172 loss)
I1201 00:31:12.350142 12698 sgd_solver.cpp:106] Iteration 127000, lr = 0.0001
I1201 00:31:26.613168 12698 solver.cpp:228] Iteration 127500, loss = 0.0344847
I1201 00:31:26.613245 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00401293 (* 0.5 = 0.00200647 loss)
I1201 00:31:26.613253 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0220502 (* 1 = 0.0220502 loss)
I1201 00:31:26.613258 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:31:26.613262 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:31:26.613268 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000664836 (* 1 = 0.000664836 loss)
I1201 00:31:26.613276 12698 sgd_solver.cpp:106] Iteration 127500, lr = 0.0001
I1201 00:31:40.883605 12698 solver.cpp:228] Iteration 128000, loss = 0.037781
I1201 00:31:40.883683 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00432591 (* 0.5 = 0.00216295 loss)
I1201 00:31:40.883692 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0248196 (* 1 = 0.0248196 loss)
I1201 00:31:40.883697 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:31:40.883702 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:31:40.883708 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00106231 (* 1 = 0.00106231 loss)
I1201 00:31:40.883715 12698 sgd_solver.cpp:106] Iteration 128000, lr = 0.0001
I1201 00:31:55.168186 12698 solver.cpp:228] Iteration 128500, loss = 0.0398114
I1201 00:31:55.168252 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00813123 (* 0.5 = 0.00406562 loss)
I1201 00:31:55.168262 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0122149 (* 1 = 0.0122149 loss)
I1201 00:31:55.168267 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:31:55.168270 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:31:55.168277 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00175422 (* 1 = 0.00175422 loss)
I1201 00:31:55.168283 12698 sgd_solver.cpp:106] Iteration 128500, lr = 0.0001
I1201 00:32:08.555801 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_128970.caffemodel
I1201 00:32:08.578717 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_128970.solverstate
I1201 00:32:08.581506 12698 solver.cpp:337] Iteration 128970, Testing net (#0)
I1201 00:32:34.131881 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00560803 (* 0.5 = 0.00280401 loss)
I1201 00:32:34.131944 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0588887 (* 1 = 0.0588887 loss)
I1201 00:32:34.131952 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.973773
I1201 00:32:34.131956 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.941654
I1201 00:32:34.131963 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.0013913 (* 1 = 0.0013913 loss)
I1201 00:32:35.020015 12698 solver.cpp:228] Iteration 129000, loss = 0.0307784
I1201 00:32:35.020087 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0055926 (* 0.5 = 0.0027963 loss)
I1201 00:32:35.020098 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0495085 (* 1 = 0.0495085 loss)
I1201 00:32:35.020103 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:32:35.020108 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:32:35.020113 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00141294 (* 1 = 0.00141294 loss)
I1201 00:32:35.020123 12698 sgd_solver.cpp:106] Iteration 129000, lr = 1e-05
I1201 00:32:49.393213 12698 solver.cpp:228] Iteration 129500, loss = 0.044061
I1201 00:32:49.393285 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00628732 (* 0.5 = 0.00314366 loss)
I1201 00:32:49.393303 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0292903 (* 1 = 0.0292903 loss)
I1201 00:32:49.393308 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:32:49.393312 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:32:49.393318 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000987525 (* 1 = 0.000987525 loss)
I1201 00:32:49.393326 12698 sgd_solver.cpp:106] Iteration 129500, lr = 1e-05
I1201 00:33:03.759079 12698 solver.cpp:228] Iteration 130000, loss = 0.0341558
I1201 00:33:03.759155 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00522596 (* 0.5 = 0.00261298 loss)
I1201 00:33:03.759165 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0312707 (* 1 = 0.0312707 loss)
I1201 00:33:03.759169 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:33:03.759174 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:33:03.759179 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00104659 (* 1 = 0.00104659 loss)
I1201 00:33:03.759186 12698 sgd_solver.cpp:106] Iteration 130000, lr = 1e-05
I1201 00:33:18.138548 12698 solver.cpp:228] Iteration 130500, loss = 0.0390619
I1201 00:33:18.138622 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00491019 (* 0.5 = 0.00245509 loss)
I1201 00:33:18.138631 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.041824 (* 1 = 0.041824 loss)
I1201 00:33:18.138636 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:33:18.138641 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:33:18.138646 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00112062 (* 1 = 0.00112062 loss)
I1201 00:33:18.138653 12698 sgd_solver.cpp:106] Iteration 130500, lr = 1e-05
I1201 00:33:32.525360 12698 solver.cpp:228] Iteration 131000, loss = 0.0386183
I1201 00:33:32.525437 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00430286 (* 0.5 = 0.00215143 loss)
I1201 00:33:32.525447 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0163969 (* 1 = 0.0163969 loss)
I1201 00:33:32.525454 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1201 00:33:32.525460 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:33:32.525466 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000928005 (* 1 = 0.000928005 loss)
I1201 00:33:32.525475 12698 sgd_solver.cpp:106] Iteration 131000, lr = 1e-05
I1201 00:33:46.900387 12698 solver.cpp:228] Iteration 131500, loss = 0.0337254
I1201 00:33:46.900459 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00444792 (* 0.5 = 0.00222396 loss)
I1201 00:33:46.900467 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.058339 (* 1 = 0.058339 loss)
I1201 00:33:46.900471 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:33:46.900476 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:33:46.900482 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000923582 (* 1 = 0.000923582 loss)
I1201 00:33:46.900490 12698 sgd_solver.cpp:106] Iteration 131500, lr = 1e-05
I1201 00:34:01.281847 12698 solver.cpp:228] Iteration 132000, loss = 0.0419435
I1201 00:34:01.281920 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00681883 (* 0.5 = 0.00340942 loss)
I1201 00:34:01.281929 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0374405 (* 1 = 0.0374405 loss)
I1201 00:34:01.281934 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:34:01.281939 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:34:01.281944 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00081274 (* 1 = 0.00081274 loss)
I1201 00:34:01.281951 12698 sgd_solver.cpp:106] Iteration 132000, lr = 1e-05
I1201 00:34:15.648030 12698 solver.cpp:228] Iteration 132500, loss = 0.0334388
I1201 00:34:15.648108 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00551818 (* 0.5 = 0.00275909 loss)
I1201 00:34:15.648118 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0389083 (* 1 = 0.0389083 loss)
I1201 00:34:15.648123 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:34:15.648126 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:34:15.648133 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000666579 (* 1 = 0.000666579 loss)
I1201 00:34:15.648139 12698 sgd_solver.cpp:106] Iteration 132500, lr = 1e-05
I1201 00:34:30.025658 12698 solver.cpp:228] Iteration 133000, loss = 0.03956
I1201 00:34:30.025727 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00624809 (* 0.5 = 0.00312404 loss)
I1201 00:34:30.025735 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.052626 (* 1 = 0.052626 loss)
I1201 00:34:30.025739 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:34:30.025744 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:34:30.025750 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000884546 (* 1 = 0.000884546 loss)
I1201 00:34:30.025758 12698 sgd_solver.cpp:106] Iteration 133000, lr = 1e-05
I1201 00:34:37.734509 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_133269.caffemodel
I1201 00:34:37.757952 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_133269.solverstate
I1201 00:34:37.760793 12698 solver.cpp:337] Iteration 133269, Testing net (#0)
I1201 00:35:03.753144 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00565877 (* 0.5 = 0.00282938 loss)
I1201 00:35:03.753208 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0599561 (* 1 = 0.0599561 loss)
I1201 00:35:03.753216 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.971127
I1201 00:35:03.753221 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.944038
I1201 00:35:03.753227 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00136181 (* 1 = 0.00136181 loss)
I1201 00:35:10.437044 12698 solver.cpp:228] Iteration 133500, loss = 0.0375646
I1201 00:35:10.437119 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00432044 (* 0.5 = 0.00216022 loss)
I1201 00:35:10.437129 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0288584 (* 1 = 0.0288584 loss)
I1201 00:35:10.437134 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:35:10.437137 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:35:10.437144 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000999293 (* 1 = 0.000999293 loss)
I1201 00:35:10.437151 12698 sgd_solver.cpp:106] Iteration 133500, lr = 1e-05
I1201 00:35:24.846655 12698 solver.cpp:228] Iteration 134000, loss = 0.0362358
I1201 00:35:24.846729 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00658029 (* 0.5 = 0.00329015 loss)
I1201 00:35:24.846737 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0389538 (* 1 = 0.0389538 loss)
I1201 00:35:24.846742 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:35:24.846746 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:35:24.846752 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00107962 (* 1 = 0.00107962 loss)
I1201 00:35:24.846760 12698 sgd_solver.cpp:106] Iteration 134000, lr = 1e-05
I1201 00:35:39.267396 12698 solver.cpp:228] Iteration 134500, loss = 0.0406825
I1201 00:35:39.267472 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00632164 (* 0.5 = 0.00316082 loss)
I1201 00:35:39.267482 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0551978 (* 1 = 0.0551978 loss)
I1201 00:35:39.267487 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:35:39.267499 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1201 00:35:39.267505 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0012141 (* 1 = 0.0012141 loss)
I1201 00:35:39.267513 12698 sgd_solver.cpp:106] Iteration 134500, lr = 1e-05
I1201 00:35:53.684679 12698 solver.cpp:228] Iteration 135000, loss = 0.0336854
I1201 00:35:53.684747 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00548031 (* 0.5 = 0.00274016 loss)
I1201 00:35:53.684756 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0327254 (* 1 = 0.0327254 loss)
I1201 00:35:53.684761 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:35:53.684764 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:35:53.684770 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00118809 (* 1 = 0.00118809 loss)
I1201 00:35:53.684777 12698 sgd_solver.cpp:106] Iteration 135000, lr = 1e-05
I1201 00:36:08.110157 12698 solver.cpp:228] Iteration 135500, loss = 0.0402186
I1201 00:36:08.110230 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00544984 (* 0.5 = 0.00272492 loss)
I1201 00:36:08.110239 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0362568 (* 1 = 0.0362568 loss)
I1201 00:36:08.110244 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:36:08.110249 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:36:08.110255 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000962882 (* 1 = 0.000962882 loss)
I1201 00:36:08.110261 12698 sgd_solver.cpp:106] Iteration 135500, lr = 1e-05
I1201 00:36:22.529455 12698 solver.cpp:228] Iteration 136000, loss = 0.036555
I1201 00:36:22.529536 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00440103 (* 0.5 = 0.00220052 loss)
I1201 00:36:22.529546 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0259885 (* 1 = 0.0259885 loss)
I1201 00:36:22.529552 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:36:22.529558 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:36:22.529566 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00077978 (* 1 = 0.00077978 loss)
I1201 00:36:22.529573 12698 sgd_solver.cpp:106] Iteration 136000, lr = 1e-05
I1201 00:36:36.965811 12698 solver.cpp:228] Iteration 136500, loss = 0.0381426
I1201 00:36:36.965886 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00587226 (* 0.5 = 0.00293613 loss)
I1201 00:36:36.965894 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0285317 (* 1 = 0.0285317 loss)
I1201 00:36:36.965899 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:36:36.965903 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:36:36.965909 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00113299 (* 1 = 0.00113299 loss)
I1201 00:36:36.965916 12698 sgd_solver.cpp:106] Iteration 136500, lr = 1e-05
I1201 00:36:51.374217 12698 solver.cpp:228] Iteration 137000, loss = 0.0399548
I1201 00:36:51.374282 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0056355 (* 0.5 = 0.00281775 loss)
I1201 00:36:51.374291 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0346418 (* 1 = 0.0346418 loss)
I1201 00:36:51.374296 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:36:51.374301 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:36:51.374306 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000744332 (* 1 = 0.000744332 loss)
I1201 00:36:51.374315 12698 sgd_solver.cpp:106] Iteration 137000, lr = 1e-05
I1201 00:37:05.791980 12698 solver.cpp:228] Iteration 137500, loss = 0.0335582
I1201 00:37:05.792063 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00612494 (* 0.5 = 0.00306247 loss)
I1201 00:37:05.792091 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0317487 (* 1 = 0.0317487 loss)
I1201 00:37:05.792098 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:37:05.792103 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:37:05.792107 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00174259 (* 1 = 0.00174259 loss)
I1201 00:37:05.792115 12698 sgd_solver.cpp:106] Iteration 137500, lr = 1e-05
I1201 00:37:07.721058 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_137568.caffemodel
I1201 00:37:07.743896 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_137568.solverstate
I1201 00:37:07.746803 12698 solver.cpp:337] Iteration 137568, Testing net (#0)
I1201 00:37:33.432564 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00566382 (* 0.5 = 0.00283191 loss)
I1201 00:37:33.432624 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0584056 (* 1 = 0.0584056 loss)
I1201 00:37:33.432631 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.97522
I1201 00:37:33.432636 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.93822
I1201 00:37:33.432641 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00130048 (* 1 = 0.00130048 loss)
I1201 00:37:45.897493 12698 solver.cpp:228] Iteration 138000, loss = 0.0395083
I1201 00:37:45.897567 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00672401 (* 0.5 = 0.003362 loss)
I1201 00:37:45.897577 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0322072 (* 1 = 0.0322072 loss)
I1201 00:37:45.897581 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:37:45.897585 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:37:45.897591 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00108929 (* 1 = 0.00108929 loss)
I1201 00:37:45.897598 12698 sgd_solver.cpp:106] Iteration 138000, lr = 1e-05
I1201 00:38:00.292150 12698 solver.cpp:228] Iteration 138500, loss = 0.0361557
I1201 00:38:00.292223 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00521625 (* 0.5 = 0.00260812 loss)
I1201 00:38:00.292232 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0190336 (* 1 = 0.0190336 loss)
I1201 00:38:00.292237 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:38:00.292242 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:38:00.292248 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000609836 (* 1 = 0.000609836 loss)
I1201 00:38:00.292254 12698 sgd_solver.cpp:106] Iteration 138500, lr = 1e-05
I1201 00:38:14.682124 12698 solver.cpp:228] Iteration 139000, loss = 0.0394111
I1201 00:38:14.682194 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00554423 (* 0.5 = 0.00277212 loss)
I1201 00:38:14.682204 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0442158 (* 1 = 0.0442158 loss)
I1201 00:38:14.682207 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:38:14.682212 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:38:14.682217 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000759162 (* 1 = 0.000759162 loss)
I1201 00:38:14.682225 12698 sgd_solver.cpp:106] Iteration 139000, lr = 1e-05
I1201 00:38:29.075245 12698 solver.cpp:228] Iteration 139500, loss = 0.0389732
I1201 00:38:29.075322 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0061169 (* 0.5 = 0.00305845 loss)
I1201 00:38:29.075330 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0352409 (* 1 = 0.0352409 loss)
I1201 00:38:29.075336 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:38:29.075340 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:38:29.075346 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00241754 (* 1 = 0.00241754 loss)
I1201 00:38:29.075362 12698 sgd_solver.cpp:106] Iteration 139500, lr = 1e-05
I1201 00:38:43.470468 12698 solver.cpp:228] Iteration 140000, loss = 0.0340853
I1201 00:38:43.470543 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0041095 (* 0.5 = 0.00205475 loss)
I1201 00:38:43.470551 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0328075 (* 1 = 0.0328075 loss)
I1201 00:38:43.470556 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:38:43.470561 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:38:43.470566 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000997321 (* 1 = 0.000997321 loss)
I1201 00:38:43.470574 12698 sgd_solver.cpp:106] Iteration 140000, lr = 1e-05
I1201 00:38:57.871903 12698 solver.cpp:228] Iteration 140500, loss = 0.0394564
I1201 00:38:57.871979 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00479847 (* 0.5 = 0.00239923 loss)
I1201 00:38:57.871989 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0384982 (* 1 = 0.0384982 loss)
I1201 00:38:57.871994 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:38:57.871999 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:38:57.872004 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000751226 (* 1 = 0.000751226 loss)
I1201 00:38:57.872011 12698 sgd_solver.cpp:106] Iteration 140500, lr = 1e-05
I1201 00:39:12.273174 12698 solver.cpp:228] Iteration 141000, loss = 0.0348451
I1201 00:39:12.273242 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00512573 (* 0.5 = 0.00256287 loss)
I1201 00:39:12.273252 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0153997 (* 1 = 0.0153997 loss)
I1201 00:39:12.273257 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:39:12.273262 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:39:12.273267 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000996472 (* 1 = 0.000996472 loss)
I1201 00:39:12.273274 12698 sgd_solver.cpp:106] Iteration 141000, lr = 1e-05
I1201 00:39:26.673080 12698 solver.cpp:228] Iteration 141500, loss = 0.0406945
I1201 00:39:26.673156 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00641132 (* 0.5 = 0.00320566 loss)
I1201 00:39:26.673164 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0405715 (* 1 = 0.0405715 loss)
I1201 00:39:26.673169 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:39:26.673173 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:39:26.673179 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00153514 (* 1 = 0.00153514 loss)
I1201 00:39:26.673187 12698 sgd_solver.cpp:106] Iteration 141500, lr = 1e-05
I1201 00:39:37.197718 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_141867.caffemodel
I1201 00:39:37.221520 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_141867.solverstate
I1201 00:39:37.224386 12698 solver.cpp:337] Iteration 141867, Testing net (#0)
I1201 00:40:04.366439 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.0055911 (* 0.5 = 0.00279555 loss)
I1201 00:40:04.366498 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0578337 (* 1 = 0.0578337 loss)
I1201 00:40:04.366505 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.973451
I1201 00:40:04.366511 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.942658
I1201 00:40:04.366518 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00138859 (* 1 = 0.00138859 loss)
I1201 00:40:08.214347 12698 solver.cpp:228] Iteration 142000, loss = 0.0388765
I1201 00:40:08.214418 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00396217 (* 0.5 = 0.00198108 loss)
I1201 00:40:08.214427 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0391072 (* 1 = 0.0391072 loss)
I1201 00:40:08.214462 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:40:08.214468 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:40:08.214474 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00131815 (* 1 = 0.00131815 loss)
I1201 00:40:08.214481 12698 sgd_solver.cpp:106] Iteration 142000, lr = 1e-05
I1201 00:40:22.577904 12698 solver.cpp:228] Iteration 142500, loss = 0.0336063
I1201 00:40:22.577980 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0052599 (* 0.5 = 0.00262995 loss)
I1201 00:40:22.577989 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0311549 (* 1 = 0.0311549 loss)
I1201 00:40:22.577994 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:40:22.577998 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:40:22.578004 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00252169 (* 1 = 0.00252169 loss)
I1201 00:40:22.578012 12698 sgd_solver.cpp:106] Iteration 142500, lr = 1e-05
I1201 00:40:36.965059 12698 solver.cpp:228] Iteration 143000, loss = 0.0395526
I1201 00:40:36.965148 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00390855 (* 0.5 = 0.00195428 loss)
I1201 00:40:36.965158 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.062347 (* 1 = 0.062347 loss)
I1201 00:40:36.965162 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:40:36.965167 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:40:36.965173 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000896496 (* 1 = 0.000896496 loss)
I1201 00:40:36.965181 12698 sgd_solver.cpp:106] Iteration 143000, lr = 1e-05
I1201 00:40:51.329892 12698 solver.cpp:228] Iteration 143500, loss = 0.0338374
I1201 00:40:51.329962 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00319099 (* 0.5 = 0.00159549 loss)
I1201 00:40:51.329970 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0489691 (* 1 = 0.0489691 loss)
I1201 00:40:51.329975 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:40:51.329979 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:40:51.329985 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000878434 (* 1 = 0.000878434 loss)
I1201 00:40:51.329993 12698 sgd_solver.cpp:106] Iteration 143500, lr = 1e-05
I1201 00:41:05.691484 12698 solver.cpp:228] Iteration 144000, loss = 0.0419326
I1201 00:41:05.691556 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00637882 (* 0.5 = 0.00318941 loss)
I1201 00:41:05.691565 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0328079 (* 1 = 0.0328079 loss)
I1201 00:41:05.691570 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:41:05.691576 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:41:05.691581 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000970291 (* 1 = 0.000970291 loss)
I1201 00:41:05.691588 12698 sgd_solver.cpp:106] Iteration 144000, lr = 1e-05
I1201 00:41:20.049904 12698 solver.cpp:228] Iteration 144500, loss = 0.0379873
I1201 00:41:20.049983 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00554997 (* 0.5 = 0.00277498 loss)
I1201 00:41:20.049991 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0302652 (* 1 = 0.0302652 loss)
I1201 00:41:20.049995 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:41:20.050000 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:41:20.050006 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00135176 (* 1 = 0.00135176 loss)
I1201 00:41:20.050014 12698 sgd_solver.cpp:106] Iteration 144500, lr = 1e-05
I1201 00:41:34.403223 12698 solver.cpp:228] Iteration 145000, loss = 0.0342619
I1201 00:41:34.403301 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00711675 (* 0.5 = 0.00355837 loss)
I1201 00:41:34.403311 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.038152 (* 1 = 0.038152 loss)
I1201 00:41:34.403316 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:41:34.403319 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:41:34.403326 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00119906 (* 1 = 0.00119906 loss)
I1201 00:41:34.403332 12698 sgd_solver.cpp:106] Iteration 145000, lr = 1e-05
I1201 00:41:48.783274 12698 solver.cpp:228] Iteration 145500, loss = 0.0404037
I1201 00:41:48.783368 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00539751 (* 0.5 = 0.00269876 loss)
I1201 00:41:48.783377 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0388032 (* 1 = 0.0388032 loss)
I1201 00:41:48.783382 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:41:48.783387 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:41:48.783392 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000691926 (* 1 = 0.000691926 loss)
I1201 00:41:48.783402 12698 sgd_solver.cpp:106] Iteration 145500, lr = 1e-05
I1201 00:42:03.145453 12698 solver.cpp:228] Iteration 146000, loss = 0.0319453
I1201 00:42:03.145534 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00486862 (* 0.5 = 0.00243431 loss)
I1201 00:42:03.145542 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0206044 (* 1 = 0.0206044 loss)
I1201 00:42:03.145547 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:42:03.145551 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:42:03.145557 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00113758 (* 1 = 0.00113758 loss)
I1201 00:42:03.145565 12698 sgd_solver.cpp:106] Iteration 146000, lr = 1e-05
I1201 00:42:07.884351 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_146166.caffemodel
I1201 00:42:07.906992 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_146166.solverstate
I1201 00:42:07.909862 12698 solver.cpp:337] Iteration 146166, Testing net (#0)
I1201 00:42:33.756057 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00566362 (* 0.5 = 0.00283181 loss)
I1201 00:42:33.756136 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0582195 (* 1 = 0.0582195 loss)
I1201 00:42:33.756144 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.976757
I1201 00:42:33.756148 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.935986
I1201 00:42:33.756153 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00136504 (* 1 = 0.00136504 loss)
I1201 00:42:43.314750 12698 solver.cpp:228] Iteration 146500, loss = 0.0439872
I1201 00:42:43.314822 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00646469 (* 0.5 = 0.00323234 loss)
I1201 00:42:43.314831 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0539989 (* 1 = 0.0539989 loss)
I1201 00:42:43.314836 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:42:43.314841 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:42:43.314846 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00180205 (* 1 = 0.00180205 loss)
I1201 00:42:43.314853 12698 sgd_solver.cpp:106] Iteration 146500, lr = 1e-05
I1201 00:42:57.589613 12698 solver.cpp:228] Iteration 147000, loss = 0.0373762
I1201 00:42:57.589689 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00529347 (* 0.5 = 0.00264674 loss)
I1201 00:42:57.589699 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0324479 (* 1 = 0.0324479 loss)
I1201 00:42:57.589705 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:42:57.589711 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:42:57.589727 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000915703 (* 1 = 0.000915703 loss)
I1201 00:42:57.589736 12698 sgd_solver.cpp:106] Iteration 147000, lr = 1e-05
I1201 00:43:11.841246 12698 solver.cpp:228] Iteration 147500, loss = 0.0338972
I1201 00:43:11.841316 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00616043 (* 0.5 = 0.00308021 loss)
I1201 00:43:11.841325 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0321183 (* 1 = 0.0321183 loss)
I1201 00:43:11.841331 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:43:11.841334 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:43:11.841341 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00113426 (* 1 = 0.00113426 loss)
I1201 00:43:11.841347 12698 sgd_solver.cpp:106] Iteration 147500, lr = 1e-05
I1201 00:43:26.115033 12698 solver.cpp:228] Iteration 148000, loss = 0.0412361
I1201 00:43:26.115110 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00428446 (* 0.5 = 0.00214223 loss)
I1201 00:43:26.115119 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0471119 (* 1 = 0.0471119 loss)
I1201 00:43:26.115124 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:43:26.115128 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:43:26.115134 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00161958 (* 1 = 0.00161958 loss)
I1201 00:43:26.115142 12698 sgd_solver.cpp:106] Iteration 148000, lr = 1e-05
I1201 00:43:40.394582 12698 solver.cpp:228] Iteration 148500, loss = 0.030567
I1201 00:43:40.394659 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00631699 (* 0.5 = 0.0031585 loss)
I1201 00:43:40.394668 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.015366 (* 1 = 0.015366 loss)
I1201 00:43:40.394672 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:43:40.394677 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:43:40.394682 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00131822 (* 1 = 0.00131822 loss)
I1201 00:43:40.394690 12698 sgd_solver.cpp:106] Iteration 148500, lr = 1e-05
I1201 00:43:54.644165 12698 solver.cpp:228] Iteration 149000, loss = 0.0454991
I1201 00:43:54.644233 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00550815 (* 0.5 = 0.00275407 loss)
I1201 00:43:54.644243 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0326194 (* 1 = 0.0326194 loss)
I1201 00:43:54.644248 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:43:54.644253 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:43:54.644258 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00132678 (* 1 = 0.00132678 loss)
I1201 00:43:54.644265 12698 sgd_solver.cpp:106] Iteration 149000, lr = 1e-05
I1201 00:44:08.907835 12698 solver.cpp:228] Iteration 149500, loss = 0.0359334
I1201 00:44:08.907907 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0049662 (* 0.5 = 0.0024831 loss)
I1201 00:44:08.907917 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0162241 (* 1 = 0.0162241 loss)
I1201 00:44:08.907922 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:44:08.907925 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:44:08.907932 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00247866 (* 1 = 0.00247866 loss)
I1201 00:44:08.907938 12698 sgd_solver.cpp:106] Iteration 149500, lr = 1e-05
I1201 00:44:23.162293 12698 solver.cpp:228] Iteration 150000, loss = 0.034366
I1201 00:44:23.162370 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00579109 (* 0.5 = 0.00289554 loss)
I1201 00:44:23.162379 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0269459 (* 1 = 0.0269459 loss)
I1201 00:44:23.162402 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:44:23.162408 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:44:23.162413 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000831363 (* 1 = 0.000831363 loss)
I1201 00:44:23.162421 12698 sgd_solver.cpp:106] Iteration 150000, lr = 1e-05
I1201 00:44:36.387050 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_150465.caffemodel
I1201 00:44:36.410676 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_150465.solverstate
I1201 00:44:36.413477 12698 solver.cpp:337] Iteration 150465, Testing net (#0)
I1201 00:45:02.047897 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00566289 (* 0.5 = 0.00283144 loss)
I1201 00:45:02.047960 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0596881 (* 1 = 0.0596881 loss)
I1201 00:45:02.047967 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.971509
I1201 00:45:02.047971 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.942568
I1201 00:45:02.047977 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00131003 (* 1 = 0.00131003 loss)
I1201 00:45:03.085796 12698 solver.cpp:228] Iteration 150500, loss = 0.0415118
I1201 00:45:03.085868 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00733356 (* 0.5 = 0.00366678 loss)
I1201 00:45:03.085877 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0407273 (* 1 = 0.0407273 loss)
I1201 00:45:03.085881 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:45:03.085886 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:45:03.085892 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000912405 (* 1 = 0.000912405 loss)
I1201 00:45:03.085899 12698 sgd_solver.cpp:106] Iteration 150500, lr = 1e-05
I1201 00:45:17.469677 12698 solver.cpp:228] Iteration 151000, loss = 0.0292786
I1201 00:45:17.469763 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00718482 (* 0.5 = 0.00359241 loss)
I1201 00:45:17.469774 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0279532 (* 1 = 0.0279532 loss)
I1201 00:45:17.469779 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:45:17.469784 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:45:17.469791 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000812116 (* 1 = 0.000812116 loss)
I1201 00:45:17.469801 12698 sgd_solver.cpp:106] Iteration 151000, lr = 1e-05
I1201 00:45:31.846761 12698 solver.cpp:228] Iteration 151500, loss = 0.0463102
I1201 00:45:31.846835 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00506861 (* 0.5 = 0.00253431 loss)
I1201 00:45:31.846844 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.048392 (* 1 = 0.048392 loss)
I1201 00:45:31.846850 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:45:31.846854 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:45:31.846859 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00230165 (* 1 = 0.00230165 loss)
I1201 00:45:31.846868 12698 sgd_solver.cpp:106] Iteration 151500, lr = 1e-05
I1201 00:45:46.223280 12698 solver.cpp:228] Iteration 152000, loss = 0.035232
I1201 00:45:46.223362 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.004585 (* 0.5 = 0.0022925 loss)
I1201 00:45:46.223371 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0471293 (* 1 = 0.0471293 loss)
I1201 00:45:46.223376 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:45:46.223381 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:45:46.223387 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00131248 (* 1 = 0.00131248 loss)
I1201 00:45:46.223394 12698 sgd_solver.cpp:106] Iteration 152000, lr = 1e-05
I1201 00:46:00.607751 12698 solver.cpp:228] Iteration 152500, loss = 0.0353106
I1201 00:46:00.607827 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00554773 (* 0.5 = 0.00277387 loss)
I1201 00:46:00.607837 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0592751 (* 1 = 0.0592751 loss)
I1201 00:46:00.607841 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:46:00.607846 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:46:00.607852 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0034928 (* 1 = 0.0034928 loss)
I1201 00:46:00.607859 12698 sgd_solver.cpp:106] Iteration 152500, lr = 1e-05
I1201 00:46:14.988972 12698 solver.cpp:228] Iteration 153000, loss = 0.0415868
I1201 00:46:14.989043 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00549872 (* 0.5 = 0.00274936 loss)
I1201 00:46:14.989053 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0281905 (* 1 = 0.0281905 loss)
I1201 00:46:14.989056 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:46:14.989061 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:46:14.989071 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000805243 (* 1 = 0.000805243 loss)
I1201 00:46:14.989083 12698 sgd_solver.cpp:106] Iteration 153000, lr = 1e-05
I1201 00:46:29.358307 12698 solver.cpp:228] Iteration 153500, loss = 0.0294593
I1201 00:46:29.358387 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00602726 (* 0.5 = 0.00301363 loss)
I1201 00:46:29.358395 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0166856 (* 1 = 0.0166856 loss)
I1201 00:46:29.358400 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:46:29.358404 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:46:29.358410 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00157962 (* 1 = 0.00157962 loss)
I1201 00:46:29.358418 12698 sgd_solver.cpp:106] Iteration 153500, lr = 1e-05
I1201 00:46:43.743824 12698 solver.cpp:228] Iteration 154000, loss = 0.0458679
I1201 00:46:43.743898 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00490684 (* 0.5 = 0.00245342 loss)
I1201 00:46:43.743907 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0507745 (* 1 = 0.0507745 loss)
I1201 00:46:43.743912 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:46:43.743917 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:46:43.743922 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00164659 (* 1 = 0.00164659 loss)
I1201 00:46:43.743929 12698 sgd_solver.cpp:106] Iteration 154000, lr = 1e-05
I1201 00:46:58.119046 12698 solver.cpp:228] Iteration 154500, loss = 0.034968
I1201 00:46:58.119128 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00628043 (* 0.5 = 0.00314021 loss)
I1201 00:46:58.119138 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.00878641 (* 1 = 0.00878641 loss)
I1201 00:46:58.119143 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:46:58.119148 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:46:58.119153 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00343489 (* 1 = 0.00343489 loss)
I1201 00:46:58.119160 12698 sgd_solver.cpp:106] Iteration 154500, lr = 1e-05
I1201 00:47:05.682440 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_154764.caffemodel
I1201 00:47:05.706151 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_154764.solverstate
I1201 00:47:05.708991 12698 solver.cpp:337] Iteration 154764, Testing net (#0)
I1201 00:47:31.551318 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00559594 (* 0.5 = 0.00279797 loss)
I1201 00:47:31.551393 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0570856 (* 1 = 0.0570856 loss)
I1201 00:47:31.551416 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.97648
I1201 00:47:31.551422 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.938985
I1201 00:47:31.551429 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00137925 (* 1 = 0.00137925 loss)
I1201 00:47:38.384605 12698 solver.cpp:228] Iteration 155000, loss = 0.035711
I1201 00:47:38.384685 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00425136 (* 0.5 = 0.00212568 loss)
I1201 00:47:38.384694 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0267784 (* 1 = 0.0267784 loss)
I1201 00:47:38.384699 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:47:38.384703 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:47:38.384709 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000943082 (* 1 = 0.000943082 loss)
I1201 00:47:38.384717 12698 sgd_solver.cpp:106] Iteration 155000, lr = 1e-05
I1201 00:47:52.807277 12698 solver.cpp:228] Iteration 155500, loss = 0.0410779
I1201 00:47:52.807348 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00394714 (* 0.5 = 0.00197357 loss)
I1201 00:47:52.807358 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0478647 (* 1 = 0.0478647 loss)
I1201 00:47:52.807361 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1201 00:47:52.807366 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.9375
I1201 00:47:52.807373 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00110512 (* 1 = 0.00110512 loss)
I1201 00:47:52.807379 12698 sgd_solver.cpp:106] Iteration 155500, lr = 1e-05
I1201 00:48:07.243144 12698 solver.cpp:228] Iteration 156000, loss = 0.0299008
I1201 00:48:07.243217 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00510472 (* 0.5 = 0.00255236 loss)
I1201 00:48:07.243227 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0311087 (* 1 = 0.0311087 loss)
I1201 00:48:07.243232 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:48:07.243237 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:48:07.243242 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000655591 (* 1 = 0.000655591 loss)
I1201 00:48:07.243252 12698 sgd_solver.cpp:106] Iteration 156000, lr = 1e-05
I1201 00:48:21.660636 12698 solver.cpp:228] Iteration 156500, loss = 0.0450844
I1201 00:48:21.660712 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00472206 (* 0.5 = 0.00236103 loss)
I1201 00:48:21.660722 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0368152 (* 1 = 0.0368152 loss)
I1201 00:48:21.660727 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:48:21.660730 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:48:21.660737 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00128439 (* 1 = 0.00128439 loss)
I1201 00:48:21.660744 12698 sgd_solver.cpp:106] Iteration 156500, lr = 1e-05
I1201 00:48:36.057915 12698 solver.cpp:228] Iteration 157000, loss = 0.0351266
I1201 00:48:36.057991 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00504219 (* 0.5 = 0.00252109 loss)
I1201 00:48:36.057999 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.014136 (* 1 = 0.014136 loss)
I1201 00:48:36.058004 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:48:36.058008 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:48:36.058014 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000870755 (* 1 = 0.000870755 loss)
I1201 00:48:36.058022 12698 sgd_solver.cpp:106] Iteration 157000, lr = 1e-05
I1201 00:48:50.480892 12698 solver.cpp:228] Iteration 157500, loss = 0.0361674
I1201 00:48:50.480965 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00477687 (* 0.5 = 0.00238843 loss)
I1201 00:48:50.480983 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0473298 (* 1 = 0.0473298 loss)
I1201 00:48:50.480988 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:48:50.480993 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:48:50.480998 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00226484 (* 1 = 0.00226484 loss)
I1201 00:48:50.481004 12698 sgd_solver.cpp:106] Iteration 157500, lr = 1e-05
I1201 00:49:04.894762 12698 solver.cpp:228] Iteration 158000, loss = 0.0406797
I1201 00:49:04.894840 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00479103 (* 0.5 = 0.00239551 loss)
I1201 00:49:04.894848 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.056435 (* 1 = 0.056435 loss)
I1201 00:49:04.894853 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:49:04.894857 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:49:04.894865 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000740433 (* 1 = 0.000740433 loss)
I1201 00:49:04.894871 12698 sgd_solver.cpp:106] Iteration 158000, lr = 1e-05
I1201 00:49:19.295745 12698 solver.cpp:228] Iteration 158500, loss = 0.0300902
I1201 00:49:19.295816 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00348193 (* 0.5 = 0.00174096 loss)
I1201 00:49:19.295825 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.026378 (* 1 = 0.026378 loss)
I1201 00:49:19.295830 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:49:19.295835 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:49:19.295840 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00138122 (* 1 = 0.00138122 loss)
I1201 00:49:19.295847 12698 sgd_solver.cpp:106] Iteration 158500, lr = 1e-05
I1201 00:49:33.700922 12698 solver.cpp:228] Iteration 159000, loss = 0.0440365
I1201 00:49:33.701012 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00570679 (* 0.5 = 0.0028534 loss)
I1201 00:49:33.701021 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.024225 (* 1 = 0.024225 loss)
I1201 00:49:33.701026 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:49:33.701031 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:49:33.701037 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000930343 (* 1 = 0.000930343 loss)
I1201 00:49:33.701046 12698 sgd_solver.cpp:106] Iteration 159000, lr = 1e-05
I1201 00:49:35.491209 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_159063.caffemodel
I1201 00:49:35.513876 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_159063.solverstate
I1201 00:49:35.516712 12698 solver.cpp:337] Iteration 159063, Testing net (#0)
I1201 00:50:00.856994 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00566635 (* 0.5 = 0.00283317 loss)
I1201 00:50:00.857049 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0588811 (* 1 = 0.0588811 loss)
I1201 00:50:00.857055 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.973331
I1201 00:50:00.857061 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.941504
I1201 00:50:00.857072 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00137451 (* 1 = 0.00137451 loss)
I1201 00:50:13.475421 12698 solver.cpp:228] Iteration 159500, loss = 0.0359674
I1201 00:50:13.475493 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00511167 (* 0.5 = 0.00255583 loss)
I1201 00:50:13.475502 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0154245 (* 1 = 0.0154245 loss)
I1201 00:50:13.475507 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:50:13.475512 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:50:13.475517 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00233418 (* 1 = 0.00233418 loss)
I1201 00:50:13.475533 12698 sgd_solver.cpp:106] Iteration 159500, lr = 1e-05
I1201 00:50:27.882896 12698 solver.cpp:228] Iteration 160000, loss = 0.0364663
I1201 00:50:27.882975 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00544438 (* 0.5 = 0.00272219 loss)
I1201 00:50:27.882984 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0440252 (* 1 = 0.0440252 loss)
I1201 00:50:27.882989 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:50:27.882993 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:50:27.882999 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00164611 (* 1 = 0.00164611 loss)
I1201 00:50:27.883008 12698 sgd_solver.cpp:106] Iteration 160000, lr = 1e-05
I1201 00:50:42.285476 12698 solver.cpp:228] Iteration 160500, loss = 0.0411403
I1201 00:50:42.285550 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00596036 (* 0.5 = 0.00298018 loss)
I1201 00:50:42.285559 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0454618 (* 1 = 0.0454618 loss)
I1201 00:50:42.285564 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:50:42.285569 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:50:42.285574 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00132102 (* 1 = 0.00132102 loss)
I1201 00:50:42.285583 12698 sgd_solver.cpp:106] Iteration 160500, lr = 1e-05
I1201 00:50:56.681418 12698 solver.cpp:228] Iteration 161000, loss = 0.0295916
I1201 00:50:56.681491 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00524735 (* 0.5 = 0.00262367 loss)
I1201 00:50:56.681500 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0162713 (* 1 = 0.0162713 loss)
I1201 00:50:56.681504 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:50:56.681509 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:50:56.681515 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00100682 (* 1 = 0.00100682 loss)
I1201 00:50:56.681522 12698 sgd_solver.cpp:106] Iteration 161000, lr = 1e-05
I1201 00:51:11.058790 12698 solver.cpp:228] Iteration 161500, loss = 0.0446575
I1201 00:51:11.058862 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00615902 (* 0.5 = 0.00307951 loss)
I1201 00:51:11.058871 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0334159 (* 1 = 0.0334159 loss)
I1201 00:51:11.058876 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:51:11.058881 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:51:11.058887 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00162484 (* 1 = 0.00162484 loss)
I1201 00:51:11.058893 12698 sgd_solver.cpp:106] Iteration 161500, lr = 1e-05
I1201 00:51:25.469980 12698 solver.cpp:228] Iteration 162000, loss = 0.0352675
I1201 00:51:25.470055 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00541296 (* 0.5 = 0.00270648 loss)
I1201 00:51:25.470064 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0104817 (* 1 = 0.0104817 loss)
I1201 00:51:25.470077 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:51:25.470082 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 1
I1201 00:51:25.470088 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00153311 (* 1 = 0.00153311 loss)
I1201 00:51:25.470094 12698 sgd_solver.cpp:106] Iteration 162000, lr = 1e-05
I1201 00:51:39.875233 12698 solver.cpp:228] Iteration 162500, loss = 0.037032
I1201 00:51:39.875305 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00571883 (* 0.5 = 0.00285941 loss)
I1201 00:51:39.875315 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0454584 (* 1 = 0.0454584 loss)
I1201 00:51:39.875320 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.984375
I1201 00:51:39.875334 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:51:39.875339 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000765696 (* 1 = 0.000765696 loss)
I1201 00:51:39.875346 12698 sgd_solver.cpp:106] Iteration 162500, lr = 1e-05
I1201 00:51:54.266108 12698 solver.cpp:228] Iteration 163000, loss = 0.0408033
I1201 00:51:54.266178 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00560489 (* 0.5 = 0.00280244 loss)
I1201 00:51:54.266186 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0281454 (* 1 = 0.0281454 loss)
I1201 00:51:54.266191 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:51:54.266196 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:51:54.266201 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00100338 (* 1 = 0.00100338 loss)
I1201 00:51:54.266209 12698 sgd_solver.cpp:106] Iteration 163000, lr = 1e-05
I1201 00:52:04.664131 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_163362.caffemodel
I1201 00:52:04.687810 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_163362.solverstate
I1201 00:52:04.690635 12698 solver.cpp:337] Iteration 163362, Testing net (#0)
I1201 00:52:30.158998 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00564753 (* 0.5 = 0.00282377 loss)
I1201 00:52:30.159065 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0573455 (* 1 = 0.0573455 loss)
I1201 00:52:30.159078 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.9781
I1201 00:52:30.159083 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.933601
I1201 00:52:30.159090 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.0013077 (* 1 = 0.0013077 loss)
I1201 00:52:34.148871 12698 solver.cpp:228] Iteration 163500, loss = 0.030378
I1201 00:52:34.148939 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0039272 (* 0.5 = 0.0019636 loss)
I1201 00:52:34.148947 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0449716 (* 1 = 0.0449716 loss)
I1201 00:52:34.148952 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:52:34.148957 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.875
I1201 00:52:34.148962 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000748568 (* 1 = 0.000748568 loss)
I1201 00:52:34.148969 12698 sgd_solver.cpp:106] Iteration 163500, lr = 1e-05
I1201 00:52:48.524302 12698 solver.cpp:228] Iteration 164000, loss = 0.0441372
I1201 00:52:48.524377 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00483548 (* 0.5 = 0.00241774 loss)
I1201 00:52:48.524387 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0260391 (* 1 = 0.0260391 loss)
I1201 00:52:48.524391 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.976562
I1201 00:52:48.524396 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:52:48.524401 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00236742 (* 1 = 0.00236742 loss)
I1201 00:52:48.524410 12698 sgd_solver.cpp:106] Iteration 164000, lr = 1e-05
I1201 00:53:02.907495 12698 solver.cpp:228] Iteration 164500, loss = 0.0343154
I1201 00:53:02.907577 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00500131 (* 0.5 = 0.00250066 loss)
I1201 00:53:02.907588 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0297502 (* 1 = 0.0297502 loss)
I1201 00:53:02.907594 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:53:02.907599 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:53:02.907606 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00156574 (* 1 = 0.00156574 loss)
I1201 00:53:02.907614 12698 sgd_solver.cpp:106] Iteration 164500, lr = 1e-05
I1201 00:53:17.267081 12698 solver.cpp:228] Iteration 165000, loss = 0.0376683
I1201 00:53:17.267159 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00464726 (* 0.5 = 0.00232363 loss)
I1201 00:53:17.267179 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0211395 (* 1 = 0.0211395 loss)
I1201 00:53:17.267184 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:53:17.267187 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:53:17.267194 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.0023141 (* 1 = 0.0023141 loss)
I1201 00:53:17.267200 12698 sgd_solver.cpp:106] Iteration 165000, lr = 1e-05
I1201 00:53:31.626402 12698 solver.cpp:228] Iteration 165500, loss = 0.0399955
I1201 00:53:31.626474 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00533441 (* 0.5 = 0.0026672 loss)
I1201 00:53:31.626483 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0205426 (* 1 = 0.0205426 loss)
I1201 00:53:31.626487 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:53:31.626492 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:53:31.626497 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00115538 (* 1 = 0.00115538 loss)
I1201 00:53:31.626505 12698 sgd_solver.cpp:106] Iteration 165500, lr = 1e-05
I1201 00:53:45.996625 12698 solver.cpp:228] Iteration 166000, loss = 0.0325615
I1201 00:53:45.996704 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00531622 (* 0.5 = 0.00265811 loss)
I1201 00:53:45.996713 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0625764 (* 1 = 0.0625764 loss)
I1201 00:53:45.996718 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:53:45.996722 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:53:45.996728 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00106261 (* 1 = 0.00106261 loss)
I1201 00:53:45.996737 12698 sgd_solver.cpp:106] Iteration 166000, lr = 1e-05
I1201 00:54:00.370162 12698 solver.cpp:228] Iteration 166500, loss = 0.0430975
I1201 00:54:00.370241 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00455407 (* 0.5 = 0.00227704 loss)
I1201 00:54:00.370250 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0260749 (* 1 = 0.0260749 loss)
I1201 00:54:00.370255 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:54:00.370260 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:54:00.370265 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000991688 (* 1 = 0.000991688 loss)
I1201 00:54:00.370272 12698 sgd_solver.cpp:106] Iteration 166500, lr = 1e-05
I1201 00:54:14.720175 12698 solver.cpp:228] Iteration 167000, loss = 0.0334513
I1201 00:54:14.720245 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00418286 (* 0.5 = 0.00209143 loss)
I1201 00:54:14.720253 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0207293 (* 1 = 0.0207293 loss)
I1201 00:54:14.720258 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:54:14.720263 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:54:14.720268 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000819798 (* 1 = 0.000819798 loss)
I1201 00:54:14.720275 12698 sgd_solver.cpp:106] Iteration 167000, lr = 1e-05
I1201 00:54:29.082312 12698 solver.cpp:228] Iteration 167500, loss = 0.0390773
I1201 00:54:29.082391 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0060302 (* 0.5 = 0.0030151 loss)
I1201 00:54:29.082401 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0263165 (* 1 = 0.0263165 loss)
I1201 00:54:29.082406 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:54:29.082409 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.96875
I1201 00:54:29.082415 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00100879 (* 1 = 0.00100879 loss)
I1201 00:54:29.082422 12698 sgd_solver.cpp:106] Iteration 167500, lr = 1e-05
I1201 00:54:33.683670 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_167661.caffemodel
I1201 00:54:33.707375 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_167661.solverstate
I1201 00:54:33.710181 12698 solver.cpp:337] Iteration 167661, Testing net (#0)
I1201 00:54:59.012559 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00560472 (* 0.5 = 0.00280236 loss)
I1201 00:54:59.012617 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0595127 (* 1 = 0.0595127 loss)
I1201 00:54:59.012625 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.971884
I1201 00:54:59.012630 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.943438
I1201 00:54:59.012636 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00137783 (* 1 = 0.00137783 loss)
I1201 00:55:08.719363 12698 solver.cpp:228] Iteration 168000, loss = 0.0382174
I1201 00:55:08.719432 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00462037 (* 0.5 = 0.00231018 loss)
I1201 00:55:08.719444 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0152878 (* 1 = 0.0152878 loss)
I1201 00:55:08.719449 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:55:08.719455 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:55:08.719461 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000957153 (* 1 = 0.000957153 loss)
I1201 00:55:08.719470 12698 sgd_solver.cpp:106] Iteration 168000, lr = 1e-05
I1201 00:55:22.983722 12698 solver.cpp:228] Iteration 168500, loss = 0.0350247
I1201 00:55:22.983793 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.0040733 (* 0.5 = 0.00203665 loss)
I1201 00:55:22.983801 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0665098 (* 1 = 0.0665098 loss)
I1201 00:55:22.983806 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.96875
I1201 00:55:22.983811 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:55:22.983816 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00693519 (* 1 = 0.00693519 loss)
I1201 00:55:22.983824 12698 sgd_solver.cpp:106] Iteration 168500, lr = 1e-05
I1201 00:55:37.255017 12698 solver.cpp:228] Iteration 169000, loss = 0.0416076
I1201 00:55:37.255100 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00679863 (* 0.5 = 0.00339932 loss)
I1201 00:55:37.255111 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0554894 (* 1 = 0.0554894 loss)
I1201 00:55:37.255116 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:55:37.255121 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:55:37.255126 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00194987 (* 1 = 0.00194987 loss)
I1201 00:55:37.255133 12698 sgd_solver.cpp:106] Iteration 169000, lr = 1e-05
I1201 00:55:51.543944 12698 solver.cpp:228] Iteration 169500, loss = 0.0327526
I1201 00:55:51.544013 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00538711 (* 0.5 = 0.00269356 loss)
I1201 00:55:51.544023 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0478362 (* 1 = 0.0478362 loss)
I1201 00:55:51.544026 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:55:51.544031 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.921875
I1201 00:55:51.544036 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00112172 (* 1 = 0.00112172 loss)
I1201 00:55:51.544044 12698 sgd_solver.cpp:106] Iteration 169500, lr = 1e-05
I1201 00:56:05.810396 12698 solver.cpp:228] Iteration 170000, loss = 0.0401547
I1201 00:56:05.810470 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00568555 (* 0.5 = 0.00284277 loss)
I1201 00:56:05.810479 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0401181 (* 1 = 0.0401181 loss)
I1201 00:56:05.810494 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:56:05.810499 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.90625
I1201 00:56:05.810505 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000861546 (* 1 = 0.000861546 loss)
I1201 00:56:05.810513 12698 sgd_solver.cpp:106] Iteration 170000, lr = 1e-05
I1201 00:56:20.075044 12698 solver.cpp:228] Iteration 170500, loss = 0.0367149
I1201 00:56:20.075125 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00498273 (* 0.5 = 0.00249137 loss)
I1201 00:56:20.075134 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0380453 (* 1 = 0.0380453 loss)
I1201 00:56:20.075139 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:56:20.075145 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.953125
I1201 00:56:20.075150 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00109842 (* 1 = 0.00109842 loss)
I1201 00:56:20.075157 12698 sgd_solver.cpp:106] Iteration 170500, lr = 1e-05
I1201 00:56:34.339135 12698 solver.cpp:228] Iteration 171000, loss = 0.0374007
I1201 00:56:34.339203 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00758379 (* 0.5 = 0.00379189 loss)
I1201 00:56:34.339211 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0709343 (* 1 = 0.0709343 loss)
I1201 00:56:34.339216 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 0.992188
I1201 00:56:34.339221 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.890625
I1201 00:56:34.339226 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.000947401 (* 1 = 0.000947401 loss)
I1201 00:56:34.339234 12698 sgd_solver.cpp:106] Iteration 171000, lr = 1e-05
I1201 00:56:48.602249 12698 solver.cpp:228] Iteration 171500, loss = 0.0404333
I1201 00:56:48.602319 12698 solver.cpp:244]     Train net output #0: bbox_reg_loss = 0.00463587 (* 0.5 = 0.00231793 loss)
I1201 00:56:48.602329 12698 solver.cpp:244]     Train net output #1: face_cls_loss = 0.0165771 (* 1 = 0.0165771 loss)
I1201 00:56:48.602334 12698 solver.cpp:244]     Train net output #2: face_cls_neg_acc = 1
I1201 00:56:48.602339 12698 solver.cpp:244]     Train net output #3: face_cls_pos_acc = 0.984375
I1201 00:56:48.602344 12698 solver.cpp:244]     Train net output #4: landmark_reg_loss = 0.00171681 (* 1 = 0.00171681 loss)
I1201 00:56:48.602351 12698 sgd_solver.cpp:106] Iteration 171500, lr = 1e-05
I1201 00:57:01.688356 12698 solver.cpp:454] Snapshotting to binary proto file tmp/onet_iter_171960.caffemodel
I1201 00:57:01.710989 12698 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/onet_iter_171960.solverstate
I1201 00:57:01.713709 12698 solver.cpp:337] Iteration 171960, Testing net (#0)
I1201 00:57:27.383432 12698 solver.cpp:404]     Test net output #0: bbox_reg_loss = 0.00565168 (* 0.5 = 0.00282584 loss)
I1201 00:57:27.383491 12698 solver.cpp:404]     Test net output #1: face_cls_loss = 0.0569045 (* 1 = 0.0569045 loss)
I1201 00:57:27.383497 12698 solver.cpp:404]     Test net output #2: face_cls_neg_acc = 0.976772
I1201 00:57:27.383502 12698 solver.cpp:404]     Test net output #3: face_cls_pos_acc = 0.937635
I1201 00:57:27.383507 12698 solver.cpp:404]     Test net output #4: landmark_reg_loss = 0.00137772 (* 1 = 0.00137772 loss)
I1201 00:57:27.383512 12698 solver.cpp:322] Optimization Done.
Generate Data for lNet
[2016-12-01 00:57:30,276][INFO] loading CelebA
[2016-12-01 00:57:36,594][INFO] writing train data
Namespace(epoch=20, gpu=0, lr=0.01, lrp=2, lrw=0.1, prepare=True, snapshot=None, train=False, worker=8)
[2016-12-01 00:57:40,709][INFO] writes 10000 landmark data
[2016-12-01 00:57:44,138][INFO] writes 20000 landmark data
[2016-12-01 00:57:47,587][INFO] writes 30000 landmark data
[2016-12-01 00:57:50,722][INFO] writes 40000 landmark data
[2016-12-01 00:57:53,880][INFO] writes 50000 landmark data
[2016-12-01 00:57:57,311][INFO] writes 60000 landmark data
[2016-12-01 00:58:00,885][INFO] writes 70000 landmark data
[2016-12-01 00:58:03,973][INFO] writes 80000 landmark data
[2016-12-01 00:58:07,137][INFO] writes 90000 landmark data
[2016-12-01 00:58:10,371][INFO] writes 100000 landmark data
[2016-12-01 00:58:21,077][INFO] write to data/lnet_train_001.h5
[2016-12-01 00:58:59,429][INFO] writes 110000 landmark data
[2016-12-01 00:59:28,602][INFO] writes 120000 landmark data
[2016-12-01 00:59:43,733][INFO] writes 130000 landmark data
[2016-12-01 01:00:00,099][INFO] writes 140000 landmark data
[2016-12-01 01:00:13,399][INFO] writes 150000 landmark data
[2016-12-01 01:00:25,141][INFO] writes 160000 landmark data
[2016-12-01 01:00:36,831][INFO] writes 170000 landmark data
[2016-12-01 01:00:45,963][INFO] writes 180000 landmark data
[2016-12-01 01:00:50,352][INFO] writes 190000 landmark data
[2016-12-01 01:00:54,665][INFO] writes 200000 landmark data
[2016-12-01 01:01:04,783][INFO] write to data/lnet_train_002.h5
[2016-12-01 01:01:45,108][INFO] writes 210000 landmark data
[2016-12-01 01:02:16,497][INFO] writes 220000 landmark data
[2016-12-01 01:02:28,227][INFO] Process-7 reads 10000
[2016-12-01 01:02:33,203][INFO] Process-8 reads 10000
[2016-12-01 01:02:37,543][INFO] writes 230000 landmark data
[2016-12-01 01:02:41,714][INFO] Process-3 reads 10000
[2016-12-01 01:02:57,775][INFO] Process-4 reads 10000
[2016-12-01 01:02:58,477][INFO] writes 240000 landmark data
[2016-12-01 01:03:04,281][INFO] Process-5 reads 10000
[2016-12-01 01:03:09,017][INFO] Process-1 reads 10000
[2016-12-01 01:03:12,006][INFO] Process-6 reads 10000
[2016-12-01 01:03:18,454][INFO] writes 250000 landmark data
[2016-12-01 01:03:36,539][INFO] writes 260000 landmark data
[2016-12-01 01:03:41,609][INFO] Process-2 reads 10000
[2016-12-01 01:03:55,216][INFO] writes 270000 landmark data
[2016-12-01 01:04:15,587][INFO] writes 280000 landmark data
[2016-12-01 01:04:33,337][INFO] writes 290000 landmark data
[2016-12-01 01:04:53,104][INFO] writes 300000 landmark data
[2016-12-01 01:05:02,014][INFO] write to data/lnet_train_003.h5
[2016-12-01 01:05:46,079][INFO] writes 310000 landmark data
[2016-12-01 01:06:15,208][INFO] writes 320000 landmark data
[2016-12-01 01:06:36,734][INFO] writes 330000 landmark data
[2016-12-01 01:06:58,275][INFO] writes 340000 landmark data
[2016-12-01 01:07:20,391][INFO] writes 350000 landmark data
[2016-12-01 01:07:41,098][INFO] writes 360000 landmark data
[2016-12-01 01:08:01,777][INFO] writes 370000 landmark data
[2016-12-01 01:08:22,230][INFO] writes 380000 landmark data
[2016-12-01 01:08:42,561][INFO] writes 390000 landmark data
[2016-12-01 01:09:02,462][INFO] writes 400000 landmark data
[2016-12-01 01:09:09,678][INFO] write to data/lnet_train_004.h5
[2016-12-01 01:09:48,042][INFO] writes 410000 landmark data
[2016-12-01 01:10:19,905][INFO] writes 420000 landmark data
[2016-12-01 01:10:39,286][INFO] writes 430000 landmark data
[2016-12-01 01:10:55,502][INFO] writes 440000 landmark data
[2016-12-01 01:11:15,304][INFO] writes 450000 landmark data
[2016-12-01 01:11:28,860][INFO] Process-8 reads 20000
[2016-12-01 01:11:36,465][INFO] writes 460000 landmark data
[2016-12-01 01:11:47,909][INFO] Process-4 reads 20000
[2016-12-01 01:11:52,135][INFO] Process-3 reads 20000
[2016-12-01 01:11:58,830][INFO] writes 470000 landmark data
[2016-12-01 01:12:00,458][INFO] Process-7 reads 20000
[2016-12-01 01:12:02,817][INFO] Process-6 reads 20000
[2016-12-01 01:12:20,279][INFO] Process-5 reads 20000
[2016-12-01 01:12:22,409][INFO] writes 480000 landmark data
[2016-12-01 01:12:27,180][INFO] Process-1 reads 20000
[2016-12-01 01:12:37,430][INFO] Process-2 reads 20000
[2016-12-01 01:12:44,671][INFO] write to data/lnet_train_005.h5
[2016-12-01 01:12:46,689][INFO] Finish
[2016-12-01 01:12:46,826][INFO] writing val data
[2016-12-01 01:13:16,914][INFO] writes 10000 landmark data
[2016-12-01 01:13:43,669][INFO] writes 20000 landmark data
[2016-12-01 01:14:01,599][INFO] writes 30000 landmark data
[2016-12-01 01:14:18,653][INFO] writes 40000 landmark data
[2016-12-01 01:14:38,578][INFO] writes 50000 landmark data
[2016-12-01 01:14:58,141][INFO] writes 60000 landmark data
[2016-12-01 01:15:17,928][INFO] writes 70000 landmark data
[2016-12-01 01:15:41,015][INFO] writes 80000 landmark data
[2016-12-01 01:16:03,984][INFO] writes 90000 landmark data
[2016-12-01 01:16:29,152][INFO] writes 100000 landmark data
[2016-12-01 01:16:37,518][INFO] write to data/lnet_val_001.h5
[2016-12-01 01:17:28,202][INFO] writes 110000 landmark data
[2016-12-01 01:17:53,728][INFO] writes 120000 landmark data
[2016-12-01 01:17:58,875][INFO] write to data/lnet_val_002.h5
[2016-12-01 01:17:59,305][INFO] Finish
Train lNet
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1201 01:18:09.883888 13889 solver.cpp:48] Initializing solver from parameters: 
test_iter: 949
test_interval: 3798
base_lr: 0.1
display: 500
max_iter: 37980
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 7596
snapshot: 3798
snapshot_prefix: "tmp/lnet"
solver_mode: GPU
net: "proto/l_train_val.prototxt"
test_initialization: false
average_loss: 500
I1201 01:18:09.928676 13889 solver.cpp:91] Creating training net from net file: proto/l_train_val.prototxt
I1201 01:18:09.948930 13889 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1201 01:18:09.949759 13889 net.cpp:58] Initializing net from parameters: 
name: "lNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "target"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "data/lnet_train.txt"
    batch_size: 128
  }
}
layer {
  name: "slicer_data"
  type: "Slice"
  bottom: "data"
  top: "data_1"
  top: "data_2"
  top: "data_3"
  top: "data_4"
  top: "data_5"
  slice_param {
    slice_point: 3
    slice_point: 6
    slice_point: 9
    slice_point: 12
    axis: 1
  }
}
layer {
  name: "slicer_target"
  type: "Slice"
  bottom: "target"
  top: "target_1"
  top: "target_2"
  top: "target_3"
  top: "target_4"
  top: "target_5"
  slice_param {
    slice_point: 2
    slice_point: 4
    slice_point: 6
    slice_point: 8
    axis: 1
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1_1"
  type: "PReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "pool1_1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1_1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2_1"
  type: "PReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3_1"
  type: "PReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "data_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1_2"
  type: "PReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1_2"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1_2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool1_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2_2"
  type: "PReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "pool2_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3_2"
  type: "PReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv1_3"
  type: "Convolution"
  bottom: "data_3"
  top: "conv1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1_3"
  type: "PReLU"
  bottom: "conv1_3"
  top: "conv1_3"
}
layer {
  name: "pool1_3"
  type: "Pooling"
  bottom: "conv1_3"
  top: "pool1_3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_3"
  type: "Convolution"
  bottom: "pool1_3"
  top: "conv2_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2_3"
  type: "PReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "pool2_3"
  type: "Pooling"
  bottom: "conv2_3"
  top: "pool2_3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "pool2_3"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3_3"
  type: "PReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv1_4"
  type: "Convolution"
  bottom: "data_4"
  top: "conv1_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1_4"
  type: "PReLU"
  bottom: "conv1_4"
  top: "conv1_4"
}
layer {
  name: "pool1_4"
  type: "Pooling"
  bottom: "conv1_4"
  top: "pool1_4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_4"
  type: "Convolution"
  bottom: "pool1_4"
  top: "conv2_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2_4"
  type: "PReLU"
  bottom: "conv2_4"
  top: "conv2_4"
}
layer {
  name: "pool2_4"
  type: "Pooling"
  bottom: "conv2_4"
  top: "pool2_4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_4"
  type: "Convolution"
  bottom: "pool2_4"
  top: "conv3_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3_4"
  type: "PReLU"
  bottom: "conv3_4"
  top: "conv3_4"
}
layer {
  name: "conv1_5"
  type: "Convolution"
  bottom: "data_5"
  top: "conv1_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1_5"
  type: "PReLU"
  bottom: "conv1_5"
  top: "conv1_5"
}
layer {
  name: "pool1_5"
  type: "Pooling"
  bottom: "conv1_5"
  top: "pool1_5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_5"
  type: "Convolution"
  bottom: "pool1_5"
  top: "conv2_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2_5"
  type: "PReLU"
  bottom: "conv2_5"
  top: "conv2_5"
}
layer {
  name: "pool2_5"
  type: "Pooling"
  bottom: "conv2_5"
  top: "pool2_5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_5"
  type: "Convolution"
  bottom: "pool2_5"
  top: "conv3_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3_5"
  type: "PReLU"
  bottom: "conv3_5"
  top: "conv3_5"
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "conv3_1"
  bottom: "conv3_2"
  bottom: "conv3_3"
  bottom: "conv3_4"
  bottom: "conv3_5"
  top: "concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "fc4"
  type: "InnerProduct"
  bottom: "concat"
  top: "fc4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "fc4"
  top: "fc4"
}
layer {
  name: "fc5_1"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu5_1"
  type: "PReLU"
  bottom: "fc5_1"
  top: "fc5_1"
}
layer {
  name: "fc6_1"
  type: "InnerProduct"
  bottom: "fc5_1"
  top: "fc6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss_1"
  type: "EuclideanLoss"
  bottom: "fc6_1"
  bottom: "target_1"
  top: "loss_1"
}
layer {
  name: "fc5_2"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu5_2"
  type: "PReLU"
  bottom: "fc5_2"
  top: "fc5_2"
}
layer {
  name: "fc6_2"
  type: "InnerProduct"
  bottom: "fc5_2"
  top: "fc6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss_2"
  type: "EuclideanLoss"
  bottom: "fc6_2"
  bottom: "target_2"
  top: "loss_2"
}
layer {
  name: "fc5_3"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu5_3"
  type: "PReLU"
  bottom: "fc5_3"
  top: "fc5_3"
}
layer {
  name: "fc6_3"
  type: "InnerProduct"
  bottom: "fc5_3"
  top: "fc6_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss_3"
  type: "EuclideanLoss"
  bottom: "fc6_3"
  bottom: "target_3"
  top: "loss_3"
}
layer {
  name: "fc5_4"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu5_4"
  type: "PReLU"
  bottom: "fc5_4"
  top: "fc5_4"
}
layer {
  name: "fc6_4"
  type: "InnerProduct"
  bottom: "fc5_4"
  top: "fc6_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss_4"
  type: "EuclideanLoss"
  bottom: "fc6_4"
  bottom: "target_4"
  top: "loss_4"
}
layer {
  name: "fc5_5"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu5_5"
  type: "PReLU"
  bottom: "fc5_5"
  top: "fc5_5"
}
layer {
  name: "fc6_5"
  type: "InnerProduct"
  bottom: "fc5_5"
  top: "fc6_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss_5"
  type: "EuclideanLoss"
  bottom: "fc6_5"
  bottom: "target_5"
  top: "loss_5"
}
I1201 01:18:09.962822 13889 layer_factory.hpp:77] Creating layer data
I1201 01:18:09.969449 13889 net.cpp:100] Creating Layer data
I1201 01:18:09.969496 13889 net.cpp:408] data -> data
I1201 01:18:09.969532 13889 net.cpp:408] data -> target
I1201 01:18:09.969560 13889 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: data/lnet_train.txt
I1201 01:18:09.969616 13889 hdf5_data_layer.cpp:93] Number of HDF5 files: 5
I1201 01:18:10.075857 13889 hdf5.cpp:32] Datatype class: H5T_FLOAT
I1201 01:18:37.322778 13889 net.cpp:150] Setting up data
I1201 01:18:37.322868 13889 net.cpp:157] Top shape: 128 15 24 24 (1105920)
I1201 01:18:37.322882 13889 net.cpp:157] Top shape: 128 10 (1280)
I1201 01:18:37.322890 13889 net.cpp:165] Memory required for data: 4428800
I1201 01:18:37.322911 13889 layer_factory.hpp:77] Creating layer slicer_data
I1201 01:18:37.367084 13889 net.cpp:100] Creating Layer slicer_data
I1201 01:18:37.367112 13889 net.cpp:434] slicer_data <- data
I1201 01:18:37.367136 13889 net.cpp:408] slicer_data -> data_1
I1201 01:18:37.367164 13889 net.cpp:408] slicer_data -> data_2
I1201 01:18:37.367179 13889 net.cpp:408] slicer_data -> data_3
I1201 01:18:37.367194 13889 net.cpp:408] slicer_data -> data_4
I1201 01:18:37.367208 13889 net.cpp:408] slicer_data -> data_5
I1201 01:18:37.367367 13889 net.cpp:150] Setting up slicer_data
I1201 01:18:37.367384 13889 net.cpp:157] Top shape: 128 3 24 24 (221184)
I1201 01:18:37.367395 13889 net.cpp:157] Top shape: 128 3 24 24 (221184)
I1201 01:18:37.367404 13889 net.cpp:157] Top shape: 128 3 24 24 (221184)
I1201 01:18:37.367413 13889 net.cpp:157] Top shape: 128 3 24 24 (221184)
I1201 01:18:37.367422 13889 net.cpp:157] Top shape: 128 3 24 24 (221184)
I1201 01:18:37.367441 13889 net.cpp:165] Memory required for data: 8852480
I1201 01:18:37.367451 13889 layer_factory.hpp:77] Creating layer slicer_target
I1201 01:18:37.367470 13889 net.cpp:100] Creating Layer slicer_target
I1201 01:18:37.367480 13889 net.cpp:434] slicer_target <- target
I1201 01:18:37.367492 13889 net.cpp:408] slicer_target -> target_1
I1201 01:18:37.367511 13889 net.cpp:408] slicer_target -> target_2
I1201 01:18:37.367527 13889 net.cpp:408] slicer_target -> target_3
I1201 01:18:37.367540 13889 net.cpp:408] slicer_target -> target_4
I1201 01:18:37.367552 13889 net.cpp:408] slicer_target -> target_5
I1201 01:18:37.367681 13889 net.cpp:150] Setting up slicer_target
I1201 01:18:37.367696 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:37.367705 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:37.367715 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:37.367723 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:37.367733 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:37.367739 13889 net.cpp:165] Memory required for data: 8857600
I1201 01:18:37.367748 13889 layer_factory.hpp:77] Creating layer conv1_1
I1201 01:18:37.367781 13889 net.cpp:100] Creating Layer conv1_1
I1201 01:18:37.367791 13889 net.cpp:434] conv1_1 <- data_1
I1201 01:18:37.367808 13889 net.cpp:408] conv1_1 -> conv1_1
I1201 01:18:39.196588 13889 net.cpp:150] Setting up conv1_1
I1201 01:18:39.196687 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:39.196699 13889 net.cpp:165] Memory required for data: 15796224
I1201 01:18:39.196756 13889 layer_factory.hpp:77] Creating layer prelu1_1
I1201 01:18:39.215855 13889 net.cpp:100] Creating Layer prelu1_1
I1201 01:18:39.215885 13889 net.cpp:434] prelu1_1 <- conv1_1
I1201 01:18:39.215903 13889 net.cpp:395] prelu1_1 -> conv1_1 (in-place)
I1201 01:18:39.218386 13889 net.cpp:150] Setting up prelu1_1
I1201 01:18:39.218426 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:39.218437 13889 net.cpp:165] Memory required for data: 22734848
I1201 01:18:39.218457 13889 layer_factory.hpp:77] Creating layer pool1_1
I1201 01:18:39.218497 13889 net.cpp:100] Creating Layer pool1_1
I1201 01:18:39.218510 13889 net.cpp:434] pool1_1 <- conv1_1
I1201 01:18:39.218535 13889 net.cpp:408] pool1_1 -> pool1_1
I1201 01:18:39.218626 13889 net.cpp:150] Setting up pool1_1
I1201 01:18:39.218642 13889 net.cpp:157] Top shape: 128 28 11 11 (433664)
I1201 01:18:39.218650 13889 net.cpp:165] Memory required for data: 24469504
I1201 01:18:39.218658 13889 layer_factory.hpp:77] Creating layer conv2_1
I1201 01:18:39.218708 13889 net.cpp:100] Creating Layer conv2_1
I1201 01:18:39.218719 13889 net.cpp:434] conv2_1 <- pool1_1
I1201 01:18:39.218732 13889 net.cpp:408] conv2_1 -> conv2_1
I1201 01:18:39.222906 13889 net.cpp:150] Setting up conv2_1
I1201 01:18:39.222949 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:39.222960 13889 net.cpp:165] Memory required for data: 26460160
I1201 01:18:39.223001 13889 layer_factory.hpp:77] Creating layer prelu2_1
I1201 01:18:39.223019 13889 net.cpp:100] Creating Layer prelu2_1
I1201 01:18:39.223029 13889 net.cpp:434] prelu2_1 <- conv2_1
I1201 01:18:39.223042 13889 net.cpp:395] prelu2_1 -> conv2_1 (in-place)
I1201 01:18:39.225414 13889 net.cpp:150] Setting up prelu2_1
I1201 01:18:39.225452 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:39.225463 13889 net.cpp:165] Memory required for data: 28450816
I1201 01:18:39.225477 13889 layer_factory.hpp:77] Creating layer pool2_1
I1201 01:18:39.225528 13889 net.cpp:100] Creating Layer pool2_1
I1201 01:18:39.225540 13889 net.cpp:434] pool2_1 <- conv2_1
I1201 01:18:39.225554 13889 net.cpp:408] pool2_1 -> pool2_1
I1201 01:18:39.225639 13889 net.cpp:150] Setting up pool2_1
I1201 01:18:39.225654 13889 net.cpp:157] Top shape: 128 48 4 4 (98304)
I1201 01:18:39.225662 13889 net.cpp:165] Memory required for data: 28844032
I1201 01:18:39.225670 13889 layer_factory.hpp:77] Creating layer conv3_1
I1201 01:18:39.225720 13889 net.cpp:100] Creating Layer conv3_1
I1201 01:18:39.225742 13889 net.cpp:434] conv3_1 <- pool2_1
I1201 01:18:39.225757 13889 net.cpp:408] conv3_1 -> conv3_1
I1201 01:18:39.228132 13889 net.cpp:150] Setting up conv3_1
I1201 01:18:39.228170 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:39.228181 13889 net.cpp:165] Memory required for data: 29138944
I1201 01:18:39.228196 13889 layer_factory.hpp:77] Creating layer prelu3_1
I1201 01:18:39.228226 13889 net.cpp:100] Creating Layer prelu3_1
I1201 01:18:39.228236 13889 net.cpp:434] prelu3_1 <- conv3_1
I1201 01:18:39.228250 13889 net.cpp:395] prelu3_1 -> conv3_1 (in-place)
I1201 01:18:39.228430 13889 net.cpp:150] Setting up prelu3_1
I1201 01:18:39.228446 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:39.228452 13889 net.cpp:165] Memory required for data: 29433856
I1201 01:18:39.228469 13889 layer_factory.hpp:77] Creating layer conv1_2
I1201 01:18:39.228502 13889 net.cpp:100] Creating Layer conv1_2
I1201 01:18:39.228513 13889 net.cpp:434] conv1_2 <- data_2
I1201 01:18:39.228533 13889 net.cpp:408] conv1_2 -> conv1_2
I1201 01:18:39.230595 13889 net.cpp:150] Setting up conv1_2
I1201 01:18:39.230633 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:39.230643 13889 net.cpp:165] Memory required for data: 36372480
I1201 01:18:39.230659 13889 layer_factory.hpp:77] Creating layer prelu1_2
I1201 01:18:39.230690 13889 net.cpp:100] Creating Layer prelu1_2
I1201 01:18:39.230700 13889 net.cpp:434] prelu1_2 <- conv1_2
I1201 01:18:39.230712 13889 net.cpp:395] prelu1_2 -> conv1_2 (in-place)
I1201 01:18:39.230896 13889 net.cpp:150] Setting up prelu1_2
I1201 01:18:39.230912 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:39.230919 13889 net.cpp:165] Memory required for data: 43311104
I1201 01:18:39.230942 13889 layer_factory.hpp:77] Creating layer pool1_2
I1201 01:18:39.230957 13889 net.cpp:100] Creating Layer pool1_2
I1201 01:18:39.230964 13889 net.cpp:434] pool1_2 <- conv1_2
I1201 01:18:39.230976 13889 net.cpp:408] pool1_2 -> pool1_2
I1201 01:18:39.231046 13889 net.cpp:150] Setting up pool1_2
I1201 01:18:39.231060 13889 net.cpp:157] Top shape: 128 28 11 11 (433664)
I1201 01:18:39.231077 13889 net.cpp:165] Memory required for data: 45045760
I1201 01:18:39.231092 13889 layer_factory.hpp:77] Creating layer conv2_2
I1201 01:18:39.231111 13889 net.cpp:100] Creating Layer conv2_2
I1201 01:18:39.231119 13889 net.cpp:434] conv2_2 <- pool1_2
I1201 01:18:39.231132 13889 net.cpp:408] conv2_2 -> conv2_2
I1201 01:18:39.233309 13889 net.cpp:150] Setting up conv2_2
I1201 01:18:39.233346 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:39.233356 13889 net.cpp:165] Memory required for data: 47036416
I1201 01:18:39.233372 13889 layer_factory.hpp:77] Creating layer prelu2_2
I1201 01:18:39.233386 13889 net.cpp:100] Creating Layer prelu2_2
I1201 01:18:39.233395 13889 net.cpp:434] prelu2_2 <- conv2_2
I1201 01:18:39.233407 13889 net.cpp:395] prelu2_2 -> conv2_2 (in-place)
I1201 01:18:39.233587 13889 net.cpp:150] Setting up prelu2_2
I1201 01:18:39.233602 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:39.233608 13889 net.cpp:165] Memory required for data: 49027072
I1201 01:18:39.233618 13889 layer_factory.hpp:77] Creating layer pool2_2
I1201 01:18:39.233650 13889 net.cpp:100] Creating Layer pool2_2
I1201 01:18:39.233660 13889 net.cpp:434] pool2_2 <- conv2_2
I1201 01:18:39.233672 13889 net.cpp:408] pool2_2 -> pool2_2
I1201 01:18:39.233743 13889 net.cpp:150] Setting up pool2_2
I1201 01:18:39.233757 13889 net.cpp:157] Top shape: 128 48 4 4 (98304)
I1201 01:18:39.233764 13889 net.cpp:165] Memory required for data: 49420288
I1201 01:18:39.233772 13889 layer_factory.hpp:77] Creating layer conv3_2
I1201 01:18:39.233789 13889 net.cpp:100] Creating Layer conv3_2
I1201 01:18:39.233798 13889 net.cpp:434] conv3_2 <- pool2_2
I1201 01:18:39.233809 13889 net.cpp:408] conv3_2 -> conv3_2
I1201 01:18:39.235954 13889 net.cpp:150] Setting up conv3_2
I1201 01:18:39.235992 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:39.236002 13889 net.cpp:165] Memory required for data: 49715200
I1201 01:18:39.236032 13889 layer_factory.hpp:77] Creating layer prelu3_2
I1201 01:18:39.236048 13889 net.cpp:100] Creating Layer prelu3_2
I1201 01:18:39.236057 13889 net.cpp:434] prelu3_2 <- conv3_2
I1201 01:18:39.236090 13889 net.cpp:395] prelu3_2 -> conv3_2 (in-place)
I1201 01:18:39.236279 13889 net.cpp:150] Setting up prelu3_2
I1201 01:18:39.236295 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:39.236304 13889 net.cpp:165] Memory required for data: 50010112
I1201 01:18:39.236315 13889 layer_factory.hpp:77] Creating layer conv1_3
I1201 01:18:39.236349 13889 net.cpp:100] Creating Layer conv1_3
I1201 01:18:39.236359 13889 net.cpp:434] conv1_3 <- data_3
I1201 01:18:39.236372 13889 net.cpp:408] conv1_3 -> conv1_3
I1201 01:18:39.237735 13889 net.cpp:150] Setting up conv1_3
I1201 01:18:39.237766 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:39.237774 13889 net.cpp:165] Memory required for data: 56948736
I1201 01:18:39.237802 13889 layer_factory.hpp:77] Creating layer prelu1_3
I1201 01:18:39.237815 13889 net.cpp:100] Creating Layer prelu1_3
I1201 01:18:39.237824 13889 net.cpp:434] prelu1_3 <- conv1_3
I1201 01:18:39.237835 13889 net.cpp:395] prelu1_3 -> conv1_3 (in-place)
I1201 01:18:39.238006 13889 net.cpp:150] Setting up prelu1_3
I1201 01:18:39.238020 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:39.238026 13889 net.cpp:165] Memory required for data: 63887360
I1201 01:18:39.238037 13889 layer_factory.hpp:77] Creating layer pool1_3
I1201 01:18:39.238059 13889 net.cpp:100] Creating Layer pool1_3
I1201 01:18:39.238077 13889 net.cpp:434] pool1_3 <- conv1_3
I1201 01:18:39.238095 13889 net.cpp:408] pool1_3 -> pool1_3
I1201 01:18:39.238167 13889 net.cpp:150] Setting up pool1_3
I1201 01:18:39.238179 13889 net.cpp:157] Top shape: 128 28 11 11 (433664)
I1201 01:18:39.238185 13889 net.cpp:165] Memory required for data: 65622016
I1201 01:18:39.238193 13889 layer_factory.hpp:77] Creating layer conv2_3
I1201 01:18:39.238209 13889 net.cpp:100] Creating Layer conv2_3
I1201 01:18:39.238215 13889 net.cpp:434] conv2_3 <- pool1_3
I1201 01:18:39.238227 13889 net.cpp:408] conv2_3 -> conv2_3
I1201 01:18:39.240252 13889 net.cpp:150] Setting up conv2_3
I1201 01:18:39.240288 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:39.240296 13889 net.cpp:165] Memory required for data: 67612672
I1201 01:18:39.240312 13889 layer_factory.hpp:77] Creating layer prelu2_3
I1201 01:18:39.240325 13889 net.cpp:100] Creating Layer prelu2_3
I1201 01:18:39.240334 13889 net.cpp:434] prelu2_3 <- conv2_3
I1201 01:18:39.240361 13889 net.cpp:395] prelu2_3 -> conv2_3 (in-place)
I1201 01:18:39.240538 13889 net.cpp:150] Setting up prelu2_3
I1201 01:18:39.240553 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:39.240561 13889 net.cpp:165] Memory required for data: 69603328
I1201 01:18:39.240571 13889 layer_factory.hpp:77] Creating layer pool2_3
I1201 01:18:39.240582 13889 net.cpp:100] Creating Layer pool2_3
I1201 01:18:39.240589 13889 net.cpp:434] pool2_3 <- conv2_3
I1201 01:18:39.240602 13889 net.cpp:408] pool2_3 -> pool2_3
I1201 01:18:39.240666 13889 net.cpp:150] Setting up pool2_3
I1201 01:18:39.240677 13889 net.cpp:157] Top shape: 128 48 4 4 (98304)
I1201 01:18:39.240684 13889 net.cpp:165] Memory required for data: 69996544
I1201 01:18:39.240702 13889 layer_factory.hpp:77] Creating layer conv3_3
I1201 01:18:39.240727 13889 net.cpp:100] Creating Layer conv3_3
I1201 01:18:39.240736 13889 net.cpp:434] conv3_3 <- pool2_3
I1201 01:18:39.240747 13889 net.cpp:408] conv3_3 -> conv3_3
I1201 01:18:39.242841 13889 net.cpp:150] Setting up conv3_3
I1201 01:18:39.242877 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:39.242887 13889 net.cpp:165] Memory required for data: 70291456
I1201 01:18:39.242900 13889 layer_factory.hpp:77] Creating layer prelu3_3
I1201 01:18:39.242920 13889 net.cpp:100] Creating Layer prelu3_3
I1201 01:18:39.242929 13889 net.cpp:434] prelu3_3 <- conv3_3
I1201 01:18:39.242940 13889 net.cpp:395] prelu3_3 -> conv3_3 (in-place)
I1201 01:18:39.243136 13889 net.cpp:150] Setting up prelu3_3
I1201 01:18:39.243165 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:39.243173 13889 net.cpp:165] Memory required for data: 70586368
I1201 01:18:39.243183 13889 layer_factory.hpp:77] Creating layer conv1_4
I1201 01:18:39.243216 13889 net.cpp:100] Creating Layer conv1_4
I1201 01:18:39.243226 13889 net.cpp:434] conv1_4 <- data_4
I1201 01:18:39.243240 13889 net.cpp:408] conv1_4 -> conv1_4
I1201 01:18:39.245262 13889 net.cpp:150] Setting up conv1_4
I1201 01:18:39.245301 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:39.245309 13889 net.cpp:165] Memory required for data: 77524992
I1201 01:18:39.245324 13889 layer_factory.hpp:77] Creating layer prelu1_4
I1201 01:18:39.245350 13889 net.cpp:100] Creating Layer prelu1_4
I1201 01:18:39.245360 13889 net.cpp:434] prelu1_4 <- conv1_4
I1201 01:18:39.245370 13889 net.cpp:395] prelu1_4 -> conv1_4 (in-place)
I1201 01:18:39.245563 13889 net.cpp:150] Setting up prelu1_4
I1201 01:18:39.245578 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:39.245584 13889 net.cpp:165] Memory required for data: 84463616
I1201 01:18:39.245594 13889 layer_factory.hpp:77] Creating layer pool1_4
I1201 01:18:39.245609 13889 net.cpp:100] Creating Layer pool1_4
I1201 01:18:39.245616 13889 net.cpp:434] pool1_4 <- conv1_4
I1201 01:18:39.245627 13889 net.cpp:408] pool1_4 -> pool1_4
I1201 01:18:39.245700 13889 net.cpp:150] Setting up pool1_4
I1201 01:18:39.245713 13889 net.cpp:157] Top shape: 128 28 11 11 (433664)
I1201 01:18:39.245719 13889 net.cpp:165] Memory required for data: 86198272
I1201 01:18:39.245725 13889 layer_factory.hpp:77] Creating layer conv2_4
I1201 01:18:39.245748 13889 net.cpp:100] Creating Layer conv2_4
I1201 01:18:39.245756 13889 net.cpp:434] conv2_4 <- pool1_4
I1201 01:18:39.245771 13889 net.cpp:408] conv2_4 -> conv2_4
I1201 01:18:39.247859 13889 net.cpp:150] Setting up conv2_4
I1201 01:18:39.247891 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:39.247900 13889 net.cpp:165] Memory required for data: 88188928
I1201 01:18:39.247915 13889 layer_factory.hpp:77] Creating layer prelu2_4
I1201 01:18:39.247926 13889 net.cpp:100] Creating Layer prelu2_4
I1201 01:18:39.247938 13889 net.cpp:434] prelu2_4 <- conv2_4
I1201 01:18:39.247949 13889 net.cpp:395] prelu2_4 -> conv2_4 (in-place)
I1201 01:18:39.248142 13889 net.cpp:150] Setting up prelu2_4
I1201 01:18:39.248162 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:39.248168 13889 net.cpp:165] Memory required for data: 90179584
I1201 01:18:39.248189 13889 layer_factory.hpp:77] Creating layer pool2_4
I1201 01:18:39.248222 13889 net.cpp:100] Creating Layer pool2_4
I1201 01:18:39.248231 13889 net.cpp:434] pool2_4 <- conv2_4
I1201 01:18:39.248242 13889 net.cpp:408] pool2_4 -> pool2_4
I1201 01:18:39.248316 13889 net.cpp:150] Setting up pool2_4
I1201 01:18:39.248328 13889 net.cpp:157] Top shape: 128 48 4 4 (98304)
I1201 01:18:39.248333 13889 net.cpp:165] Memory required for data: 90572800
I1201 01:18:39.248340 13889 layer_factory.hpp:77] Creating layer conv3_4
I1201 01:18:39.248358 13889 net.cpp:100] Creating Layer conv3_4
I1201 01:18:39.248366 13889 net.cpp:434] conv3_4 <- pool2_4
I1201 01:18:39.248376 13889 net.cpp:408] conv3_4 -> conv3_4
I1201 01:18:39.250442 13889 net.cpp:150] Setting up conv3_4
I1201 01:18:39.250476 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:39.250484 13889 net.cpp:165] Memory required for data: 90867712
I1201 01:18:39.250497 13889 layer_factory.hpp:77] Creating layer prelu3_4
I1201 01:18:39.250512 13889 net.cpp:100] Creating Layer prelu3_4
I1201 01:18:39.250521 13889 net.cpp:434] prelu3_4 <- conv3_4
I1201 01:18:39.250531 13889 net.cpp:395] prelu3_4 -> conv3_4 (in-place)
I1201 01:18:39.250705 13889 net.cpp:150] Setting up prelu3_4
I1201 01:18:39.250720 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:39.250725 13889 net.cpp:165] Memory required for data: 91162624
I1201 01:18:39.250735 13889 layer_factory.hpp:77] Creating layer conv1_5
I1201 01:18:39.250752 13889 net.cpp:100] Creating Layer conv1_5
I1201 01:18:39.250759 13889 net.cpp:434] conv1_5 <- data_5
I1201 01:18:39.250782 13889 net.cpp:408] conv1_5 -> conv1_5
I1201 01:18:39.252720 13889 net.cpp:150] Setting up conv1_5
I1201 01:18:39.252753 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:39.252761 13889 net.cpp:165] Memory required for data: 98101248
I1201 01:18:39.252787 13889 layer_factory.hpp:77] Creating layer prelu1_5
I1201 01:18:39.252804 13889 net.cpp:100] Creating Layer prelu1_5
I1201 01:18:39.252812 13889 net.cpp:434] prelu1_5 <- conv1_5
I1201 01:18:39.252822 13889 net.cpp:395] prelu1_5 -> conv1_5 (in-place)
I1201 01:18:39.253007 13889 net.cpp:150] Setting up prelu1_5
I1201 01:18:39.253022 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:39.253027 13889 net.cpp:165] Memory required for data: 105039872
I1201 01:18:39.253037 13889 layer_factory.hpp:77] Creating layer pool1_5
I1201 01:18:39.253048 13889 net.cpp:100] Creating Layer pool1_5
I1201 01:18:39.253056 13889 net.cpp:434] pool1_5 <- conv1_5
I1201 01:18:39.253077 13889 net.cpp:408] pool1_5 -> pool1_5
I1201 01:18:39.253155 13889 net.cpp:150] Setting up pool1_5
I1201 01:18:39.253168 13889 net.cpp:157] Top shape: 128 28 11 11 (433664)
I1201 01:18:39.253175 13889 net.cpp:165] Memory required for data: 106774528
I1201 01:18:39.253180 13889 layer_factory.hpp:77] Creating layer conv2_5
I1201 01:18:39.253201 13889 net.cpp:100] Creating Layer conv2_5
I1201 01:18:39.253209 13889 net.cpp:434] conv2_5 <- pool1_5
I1201 01:18:39.253221 13889 net.cpp:408] conv2_5 -> conv2_5
I1201 01:18:39.255297 13889 net.cpp:150] Setting up conv2_5
I1201 01:18:39.255334 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:39.255342 13889 net.cpp:165] Memory required for data: 108765184
I1201 01:18:39.255357 13889 layer_factory.hpp:77] Creating layer prelu2_5
I1201 01:18:39.255369 13889 net.cpp:100] Creating Layer prelu2_5
I1201 01:18:39.255378 13889 net.cpp:434] prelu2_5 <- conv2_5
I1201 01:18:39.255388 13889 net.cpp:395] prelu2_5 -> conv2_5 (in-place)
I1201 01:18:39.255568 13889 net.cpp:150] Setting up prelu2_5
I1201 01:18:39.255585 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:39.255592 13889 net.cpp:165] Memory required for data: 110755840
I1201 01:18:39.255614 13889 layer_factory.hpp:77] Creating layer pool2_5
I1201 01:18:39.255632 13889 net.cpp:100] Creating Layer pool2_5
I1201 01:18:39.255640 13889 net.cpp:434] pool2_5 <- conv2_5
I1201 01:18:39.255650 13889 net.cpp:408] pool2_5 -> pool2_5
I1201 01:18:39.255719 13889 net.cpp:150] Setting up pool2_5
I1201 01:18:39.255731 13889 net.cpp:157] Top shape: 128 48 4 4 (98304)
I1201 01:18:39.255738 13889 net.cpp:165] Memory required for data: 111149056
I1201 01:18:39.255743 13889 layer_factory.hpp:77] Creating layer conv3_5
I1201 01:18:39.255760 13889 net.cpp:100] Creating Layer conv3_5
I1201 01:18:39.255769 13889 net.cpp:434] conv3_5 <- pool2_5
I1201 01:18:39.255782 13889 net.cpp:408] conv3_5 -> conv3_5
I1201 01:18:39.257786 13889 net.cpp:150] Setting up conv3_5
I1201 01:18:39.257818 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:39.257827 13889 net.cpp:165] Memory required for data: 111443968
I1201 01:18:39.257839 13889 layer_factory.hpp:77] Creating layer prelu3_5
I1201 01:18:39.257854 13889 net.cpp:100] Creating Layer prelu3_5
I1201 01:18:39.257863 13889 net.cpp:434] prelu3_5 <- conv3_5
I1201 01:18:39.257872 13889 net.cpp:395] prelu3_5 -> conv3_5 (in-place)
I1201 01:18:39.258062 13889 net.cpp:150] Setting up prelu3_5
I1201 01:18:39.258093 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:39.258100 13889 net.cpp:165] Memory required for data: 111738880
I1201 01:18:39.258110 13889 layer_factory.hpp:77] Creating layer concat
I1201 01:18:39.258141 13889 net.cpp:100] Creating Layer concat
I1201 01:18:39.258149 13889 net.cpp:434] concat <- conv3_1
I1201 01:18:39.258158 13889 net.cpp:434] concat <- conv3_2
I1201 01:18:39.258165 13889 net.cpp:434] concat <- conv3_3
I1201 01:18:39.258172 13889 net.cpp:434] concat <- conv3_4
I1201 01:18:39.258177 13889 net.cpp:434] concat <- conv3_5
I1201 01:18:39.258186 13889 net.cpp:408] concat -> concat
I1201 01:18:39.329780 13889 net.cpp:150] Setting up concat
I1201 01:18:39.329824 13889 net.cpp:157] Top shape: 128 320 3 3 (368640)
I1201 01:18:39.329830 13889 net.cpp:165] Memory required for data: 113213440
I1201 01:18:39.329838 13889 layer_factory.hpp:77] Creating layer fc4
I1201 01:18:39.329859 13889 net.cpp:100] Creating Layer fc4
I1201 01:18:39.329867 13889 net.cpp:434] fc4 <- concat
I1201 01:18:39.329877 13889 net.cpp:408] fc4 -> fc4
I1201 01:18:39.344451 13889 net.cpp:150] Setting up fc4
I1201 01:18:39.344486 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:39.344496 13889 net.cpp:165] Memory required for data: 113344512
I1201 01:18:39.344509 13889 layer_factory.hpp:77] Creating layer prelu4
I1201 01:18:39.344522 13889 net.cpp:100] Creating Layer prelu4
I1201 01:18:39.344530 13889 net.cpp:434] prelu4 <- fc4
I1201 01:18:39.344545 13889 net.cpp:395] prelu4 -> fc4 (in-place)
I1201 01:18:39.344697 13889 net.cpp:150] Setting up prelu4
I1201 01:18:39.344712 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:39.344717 13889 net.cpp:165] Memory required for data: 113475584
I1201 01:18:39.344728 13889 layer_factory.hpp:77] Creating layer fc4_prelu4_0_split
I1201 01:18:39.344748 13889 net.cpp:100] Creating Layer fc4_prelu4_0_split
I1201 01:18:39.344756 13889 net.cpp:434] fc4_prelu4_0_split <- fc4
I1201 01:18:39.344766 13889 net.cpp:408] fc4_prelu4_0_split -> fc4_prelu4_0_split_0
I1201 01:18:39.344780 13889 net.cpp:408] fc4_prelu4_0_split -> fc4_prelu4_0_split_1
I1201 01:18:39.344794 13889 net.cpp:408] fc4_prelu4_0_split -> fc4_prelu4_0_split_2
I1201 01:18:39.344805 13889 net.cpp:408] fc4_prelu4_0_split -> fc4_prelu4_0_split_3
I1201 01:18:39.344816 13889 net.cpp:408] fc4_prelu4_0_split -> fc4_prelu4_0_split_4
I1201 01:18:39.344955 13889 net.cpp:150] Setting up fc4_prelu4_0_split
I1201 01:18:39.344969 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:39.344977 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:39.344985 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:39.344992 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:39.345000 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:39.345006 13889 net.cpp:165] Memory required for data: 114130944
I1201 01:18:39.345016 13889 layer_factory.hpp:77] Creating layer fc5_1
I1201 01:18:39.345034 13889 net.cpp:100] Creating Layer fc5_1
I1201 01:18:39.345062 13889 net.cpp:434] fc5_1 <- fc4_prelu4_0_split_0
I1201 01:18:39.345087 13889 net.cpp:408] fc5_1 -> fc5_1
I1201 01:18:39.345530 13889 net.cpp:150] Setting up fc5_1
I1201 01:18:39.345547 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:39.345554 13889 net.cpp:165] Memory required for data: 114163712
I1201 01:18:39.345567 13889 layer_factory.hpp:77] Creating layer prelu5_1
I1201 01:18:39.345582 13889 net.cpp:100] Creating Layer prelu5_1
I1201 01:18:39.345590 13889 net.cpp:434] prelu5_1 <- fc5_1
I1201 01:18:39.345600 13889 net.cpp:395] prelu5_1 -> fc5_1 (in-place)
I1201 01:18:39.345762 13889 net.cpp:150] Setting up prelu5_1
I1201 01:18:39.345774 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:39.345782 13889 net.cpp:165] Memory required for data: 114196480
I1201 01:18:39.345791 13889 layer_factory.hpp:77] Creating layer fc6_1
I1201 01:18:39.345806 13889 net.cpp:100] Creating Layer fc6_1
I1201 01:18:39.345814 13889 net.cpp:434] fc6_1 <- fc5_1
I1201 01:18:39.345824 13889 net.cpp:408] fc6_1 -> fc6_1
I1201 01:18:39.346009 13889 net.cpp:150] Setting up fc6_1
I1201 01:18:39.346022 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:39.346029 13889 net.cpp:165] Memory required for data: 114197504
I1201 01:18:39.346040 13889 layer_factory.hpp:77] Creating layer loss_1
I1201 01:18:39.346518 13889 net.cpp:100] Creating Layer loss_1
I1201 01:18:39.346557 13889 net.cpp:434] loss_1 <- fc6_1
I1201 01:18:39.346573 13889 net.cpp:434] loss_1 <- target_1
I1201 01:18:39.346595 13889 net.cpp:408] loss_1 -> loss_1
I1201 01:18:39.346698 13889 net.cpp:150] Setting up loss_1
I1201 01:18:39.346714 13889 net.cpp:157] Top shape: (1)
I1201 01:18:39.346721 13889 net.cpp:160]     with loss weight 1
I1201 01:18:39.346760 13889 net.cpp:165] Memory required for data: 114197508
I1201 01:18:39.346773 13889 layer_factory.hpp:77] Creating layer fc5_2
I1201 01:18:39.346793 13889 net.cpp:100] Creating Layer fc5_2
I1201 01:18:39.346803 13889 net.cpp:434] fc5_2 <- fc4_prelu4_0_split_1
I1201 01:18:39.346819 13889 net.cpp:408] fc5_2 -> fc5_2
I1201 01:18:39.347301 13889 net.cpp:150] Setting up fc5_2
I1201 01:18:39.347323 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:39.347331 13889 net.cpp:165] Memory required for data: 114230276
I1201 01:18:39.347345 13889 layer_factory.hpp:77] Creating layer prelu5_2
I1201 01:18:39.347362 13889 net.cpp:100] Creating Layer prelu5_2
I1201 01:18:39.347371 13889 net.cpp:434] prelu5_2 <- fc5_2
I1201 01:18:39.347381 13889 net.cpp:395] prelu5_2 -> fc5_2 (in-place)
I1201 01:18:39.347546 13889 net.cpp:150] Setting up prelu5_2
I1201 01:18:39.347560 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:39.347568 13889 net.cpp:165] Memory required for data: 114263044
I1201 01:18:39.347578 13889 layer_factory.hpp:77] Creating layer fc6_2
I1201 01:18:39.347594 13889 net.cpp:100] Creating Layer fc6_2
I1201 01:18:39.347602 13889 net.cpp:434] fc6_2 <- fc5_2
I1201 01:18:39.347614 13889 net.cpp:408] fc6_2 -> fc6_2
I1201 01:18:39.347800 13889 net.cpp:150] Setting up fc6_2
I1201 01:18:39.347812 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:39.347820 13889 net.cpp:165] Memory required for data: 114264068
I1201 01:18:39.347831 13889 layer_factory.hpp:77] Creating layer loss_2
I1201 01:18:39.347843 13889 net.cpp:100] Creating Layer loss_2
I1201 01:18:39.347851 13889 net.cpp:434] loss_2 <- fc6_2
I1201 01:18:39.347861 13889 net.cpp:434] loss_2 <- target_2
I1201 01:18:39.347870 13889 net.cpp:408] loss_2 -> loss_2
I1201 01:18:39.347930 13889 net.cpp:150] Setting up loss_2
I1201 01:18:39.347942 13889 net.cpp:157] Top shape: (1)
I1201 01:18:39.347949 13889 net.cpp:160]     with loss weight 1
I1201 01:18:39.347960 13889 net.cpp:165] Memory required for data: 114264072
I1201 01:18:39.347970 13889 layer_factory.hpp:77] Creating layer fc5_3
I1201 01:18:39.347982 13889 net.cpp:100] Creating Layer fc5_3
I1201 01:18:39.347990 13889 net.cpp:434] fc5_3 <- fc4_prelu4_0_split_2
I1201 01:18:39.348006 13889 net.cpp:408] fc5_3 -> fc5_3
I1201 01:18:39.348448 13889 net.cpp:150] Setting up fc5_3
I1201 01:18:39.348469 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:39.348476 13889 net.cpp:165] Memory required for data: 114296840
I1201 01:18:39.348489 13889 layer_factory.hpp:77] Creating layer prelu5_3
I1201 01:18:39.348505 13889 net.cpp:100] Creating Layer prelu5_3
I1201 01:18:39.348512 13889 net.cpp:434] prelu5_3 <- fc5_3
I1201 01:18:39.348526 13889 net.cpp:395] prelu5_3 -> fc5_3 (in-place)
I1201 01:18:39.348682 13889 net.cpp:150] Setting up prelu5_3
I1201 01:18:39.348695 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:39.348702 13889 net.cpp:165] Memory required for data: 114329608
I1201 01:18:39.348712 13889 layer_factory.hpp:77] Creating layer fc6_3
I1201 01:18:39.348731 13889 net.cpp:100] Creating Layer fc6_3
I1201 01:18:39.348738 13889 net.cpp:434] fc6_3 <- fc5_3
I1201 01:18:39.348749 13889 net.cpp:408] fc6_3 -> fc6_3
I1201 01:18:39.348924 13889 net.cpp:150] Setting up fc6_3
I1201 01:18:39.348937 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:39.348944 13889 net.cpp:165] Memory required for data: 114330632
I1201 01:18:39.348955 13889 layer_factory.hpp:77] Creating layer loss_3
I1201 01:18:39.348966 13889 net.cpp:100] Creating Layer loss_3
I1201 01:18:39.348974 13889 net.cpp:434] loss_3 <- fc6_3
I1201 01:18:39.348984 13889 net.cpp:434] loss_3 <- target_3
I1201 01:18:39.348994 13889 net.cpp:408] loss_3 -> loss_3
I1201 01:18:39.349053 13889 net.cpp:150] Setting up loss_3
I1201 01:18:39.349066 13889 net.cpp:157] Top shape: (1)
I1201 01:18:39.349086 13889 net.cpp:160]     with loss weight 1
I1201 01:18:39.349097 13889 net.cpp:165] Memory required for data: 114330636
I1201 01:18:39.349107 13889 layer_factory.hpp:77] Creating layer fc5_4
I1201 01:18:39.349119 13889 net.cpp:100] Creating Layer fc5_4
I1201 01:18:39.349134 13889 net.cpp:434] fc5_4 <- fc4_prelu4_0_split_3
I1201 01:18:39.349150 13889 net.cpp:408] fc5_4 -> fc5_4
I1201 01:18:39.349580 13889 net.cpp:150] Setting up fc5_4
I1201 01:18:39.349594 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:39.349601 13889 net.cpp:165] Memory required for data: 114363404
I1201 01:18:39.349642 13889 layer_factory.hpp:77] Creating layer prelu5_4
I1201 01:18:39.349658 13889 net.cpp:100] Creating Layer prelu5_4
I1201 01:18:39.349668 13889 net.cpp:434] prelu5_4 <- fc5_4
I1201 01:18:39.349678 13889 net.cpp:395] prelu5_4 -> fc5_4 (in-place)
I1201 01:18:39.349843 13889 net.cpp:150] Setting up prelu5_4
I1201 01:18:39.349856 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:39.349862 13889 net.cpp:165] Memory required for data: 114396172
I1201 01:18:39.349874 13889 layer_factory.hpp:77] Creating layer fc6_4
I1201 01:18:39.349889 13889 net.cpp:100] Creating Layer fc6_4
I1201 01:18:39.349896 13889 net.cpp:434] fc6_4 <- fc5_4
I1201 01:18:39.349911 13889 net.cpp:408] fc6_4 -> fc6_4
I1201 01:18:39.350106 13889 net.cpp:150] Setting up fc6_4
I1201 01:18:39.350127 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:39.350134 13889 net.cpp:165] Memory required for data: 114397196
I1201 01:18:39.350147 13889 layer_factory.hpp:77] Creating layer loss_4
I1201 01:18:39.350162 13889 net.cpp:100] Creating Layer loss_4
I1201 01:18:39.350169 13889 net.cpp:434] loss_4 <- fc6_4
I1201 01:18:39.350179 13889 net.cpp:434] loss_4 <- target_4
I1201 01:18:39.350190 13889 net.cpp:408] loss_4 -> loss_4
I1201 01:18:39.350250 13889 net.cpp:150] Setting up loss_4
I1201 01:18:39.350260 13889 net.cpp:157] Top shape: (1)
I1201 01:18:39.350267 13889 net.cpp:160]     with loss weight 1
I1201 01:18:39.350278 13889 net.cpp:165] Memory required for data: 114397200
I1201 01:18:39.350286 13889 layer_factory.hpp:77] Creating layer fc5_5
I1201 01:18:39.350302 13889 net.cpp:100] Creating Layer fc5_5
I1201 01:18:39.350311 13889 net.cpp:434] fc5_5 <- fc4_prelu4_0_split_4
I1201 01:18:39.350322 13889 net.cpp:408] fc5_5 -> fc5_5
I1201 01:18:39.350756 13889 net.cpp:150] Setting up fc5_5
I1201 01:18:39.350771 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:39.350777 13889 net.cpp:165] Memory required for data: 114429968
I1201 01:18:39.350790 13889 layer_factory.hpp:77] Creating layer prelu5_5
I1201 01:18:39.350811 13889 net.cpp:100] Creating Layer prelu5_5
I1201 01:18:39.350821 13889 net.cpp:434] prelu5_5 <- fc5_5
I1201 01:18:39.350831 13889 net.cpp:395] prelu5_5 -> fc5_5 (in-place)
I1201 01:18:39.350991 13889 net.cpp:150] Setting up prelu5_5
I1201 01:18:39.351004 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:39.351011 13889 net.cpp:165] Memory required for data: 114462736
I1201 01:18:39.351022 13889 layer_factory.hpp:77] Creating layer fc6_5
I1201 01:18:39.351035 13889 net.cpp:100] Creating Layer fc6_5
I1201 01:18:39.351043 13889 net.cpp:434] fc6_5 <- fc5_5
I1201 01:18:39.351058 13889 net.cpp:408] fc6_5 -> fc6_5
I1201 01:18:39.351253 13889 net.cpp:150] Setting up fc6_5
I1201 01:18:39.351272 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:39.351279 13889 net.cpp:165] Memory required for data: 114463760
I1201 01:18:39.351291 13889 layer_factory.hpp:77] Creating layer loss_5
I1201 01:18:39.351302 13889 net.cpp:100] Creating Layer loss_5
I1201 01:18:39.351310 13889 net.cpp:434] loss_5 <- fc6_5
I1201 01:18:39.351320 13889 net.cpp:434] loss_5 <- target_5
I1201 01:18:39.351330 13889 net.cpp:408] loss_5 -> loss_5
I1201 01:18:39.351390 13889 net.cpp:150] Setting up loss_5
I1201 01:18:39.351402 13889 net.cpp:157] Top shape: (1)
I1201 01:18:39.351409 13889 net.cpp:160]     with loss weight 1
I1201 01:18:39.351419 13889 net.cpp:165] Memory required for data: 114463764
I1201 01:18:39.351428 13889 net.cpp:226] loss_5 needs backward computation.
I1201 01:18:39.351435 13889 net.cpp:226] fc6_5 needs backward computation.
I1201 01:18:39.351442 13889 net.cpp:226] prelu5_5 needs backward computation.
I1201 01:18:39.351449 13889 net.cpp:226] fc5_5 needs backward computation.
I1201 01:18:39.351455 13889 net.cpp:226] loss_4 needs backward computation.
I1201 01:18:39.351471 13889 net.cpp:226] fc6_4 needs backward computation.
I1201 01:18:39.351478 13889 net.cpp:226] prelu5_4 needs backward computation.
I1201 01:18:39.351485 13889 net.cpp:226] fc5_4 needs backward computation.
I1201 01:18:39.351492 13889 net.cpp:226] loss_3 needs backward computation.
I1201 01:18:39.351501 13889 net.cpp:226] fc6_3 needs backward computation.
I1201 01:18:39.351508 13889 net.cpp:226] prelu5_3 needs backward computation.
I1201 01:18:39.351516 13889 net.cpp:226] fc5_3 needs backward computation.
I1201 01:18:39.351521 13889 net.cpp:226] loss_2 needs backward computation.
I1201 01:18:39.351531 13889 net.cpp:226] fc6_2 needs backward computation.
I1201 01:18:39.351537 13889 net.cpp:226] prelu5_2 needs backward computation.
I1201 01:18:39.351543 13889 net.cpp:226] fc5_2 needs backward computation.
I1201 01:18:39.351550 13889 net.cpp:226] loss_1 needs backward computation.
I1201 01:18:39.351558 13889 net.cpp:226] fc6_1 needs backward computation.
I1201 01:18:39.351565 13889 net.cpp:226] prelu5_1 needs backward computation.
I1201 01:18:39.351572 13889 net.cpp:226] fc5_1 needs backward computation.
I1201 01:18:39.351579 13889 net.cpp:226] fc4_prelu4_0_split needs backward computation.
I1201 01:18:39.351586 13889 net.cpp:226] prelu4 needs backward computation.
I1201 01:18:39.351593 13889 net.cpp:226] fc4 needs backward computation.
I1201 01:18:39.351601 13889 net.cpp:226] concat needs backward computation.
I1201 01:18:39.351611 13889 net.cpp:226] prelu3_5 needs backward computation.
I1201 01:18:39.351619 13889 net.cpp:226] conv3_5 needs backward computation.
I1201 01:18:39.351626 13889 net.cpp:226] pool2_5 needs backward computation.
I1201 01:18:39.351634 13889 net.cpp:226] prelu2_5 needs backward computation.
I1201 01:18:39.351640 13889 net.cpp:226] conv2_5 needs backward computation.
I1201 01:18:39.351647 13889 net.cpp:226] pool1_5 needs backward computation.
I1201 01:18:39.351655 13889 net.cpp:226] prelu1_5 needs backward computation.
I1201 01:18:39.351662 13889 net.cpp:226] conv1_5 needs backward computation.
I1201 01:18:39.351670 13889 net.cpp:226] prelu3_4 needs backward computation.
I1201 01:18:39.351677 13889 net.cpp:226] conv3_4 needs backward computation.
I1201 01:18:39.351685 13889 net.cpp:226] pool2_4 needs backward computation.
I1201 01:18:39.351692 13889 net.cpp:226] prelu2_4 needs backward computation.
I1201 01:18:39.351699 13889 net.cpp:226] conv2_4 needs backward computation.
I1201 01:18:39.351707 13889 net.cpp:226] pool1_4 needs backward computation.
I1201 01:18:39.351714 13889 net.cpp:226] prelu1_4 needs backward computation.
I1201 01:18:39.351722 13889 net.cpp:226] conv1_4 needs backward computation.
I1201 01:18:39.351729 13889 net.cpp:226] prelu3_3 needs backward computation.
I1201 01:18:39.351737 13889 net.cpp:226] conv3_3 needs backward computation.
I1201 01:18:39.351743 13889 net.cpp:226] pool2_3 needs backward computation.
I1201 01:18:39.351752 13889 net.cpp:226] prelu2_3 needs backward computation.
I1201 01:18:39.351758 13889 net.cpp:226] conv2_3 needs backward computation.
I1201 01:18:39.351765 13889 net.cpp:226] pool1_3 needs backward computation.
I1201 01:18:39.351773 13889 net.cpp:226] prelu1_3 needs backward computation.
I1201 01:18:39.351779 13889 net.cpp:226] conv1_3 needs backward computation.
I1201 01:18:39.351788 13889 net.cpp:226] prelu3_2 needs backward computation.
I1201 01:18:39.351794 13889 net.cpp:226] conv3_2 needs backward computation.
I1201 01:18:39.351801 13889 net.cpp:226] pool2_2 needs backward computation.
I1201 01:18:39.351809 13889 net.cpp:226] prelu2_2 needs backward computation.
I1201 01:18:39.351816 13889 net.cpp:226] conv2_2 needs backward computation.
I1201 01:18:39.351824 13889 net.cpp:226] pool1_2 needs backward computation.
I1201 01:18:39.351830 13889 net.cpp:226] prelu1_2 needs backward computation.
I1201 01:18:39.351837 13889 net.cpp:226] conv1_2 needs backward computation.
I1201 01:18:39.351845 13889 net.cpp:226] prelu3_1 needs backward computation.
I1201 01:18:39.351852 13889 net.cpp:226] conv3_1 needs backward computation.
I1201 01:18:39.351864 13889 net.cpp:226] pool2_1 needs backward computation.
I1201 01:18:39.351872 13889 net.cpp:226] prelu2_1 needs backward computation.
I1201 01:18:39.351878 13889 net.cpp:226] conv2_1 needs backward computation.
I1201 01:18:39.351886 13889 net.cpp:226] pool1_1 needs backward computation.
I1201 01:18:39.351893 13889 net.cpp:226] prelu1_1 needs backward computation.
I1201 01:18:39.351900 13889 net.cpp:226] conv1_1 needs backward computation.
I1201 01:18:39.351912 13889 net.cpp:228] slicer_target does not need backward computation.
I1201 01:18:39.351922 13889 net.cpp:228] slicer_data does not need backward computation.
I1201 01:18:39.351930 13889 net.cpp:228] data does not need backward computation.
I1201 01:18:39.351938 13889 net.cpp:270] This network produces output loss_1
I1201 01:18:39.351944 13889 net.cpp:270] This network produces output loss_2
I1201 01:18:39.351953 13889 net.cpp:270] This network produces output loss_3
I1201 01:18:39.351960 13889 net.cpp:270] This network produces output loss_4
I1201 01:18:39.351966 13889 net.cpp:270] This network produces output loss_5
I1201 01:18:39.352048 13889 net.cpp:283] Network initialization done.
I1201 01:18:39.354948 13889 solver.cpp:181] Creating test net (#0) specified by net file: proto/l_train_val.prototxt
I1201 01:18:39.355132 13889 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1201 01:18:39.355918 13889 net.cpp:58] Initializing net from parameters: 
name: "lNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "target"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "data/lnet_val.txt"
    batch_size: 128
  }
}
layer {
  name: "slicer_data"
  type: "Slice"
  bottom: "data"
  top: "data_1"
  top: "data_2"
  top: "data_3"
  top: "data_4"
  top: "data_5"
  slice_param {
    slice_point: 3
    slice_point: 6
    slice_point: 9
    slice_point: 12
    axis: 1
  }
}
layer {
  name: "slicer_target"
  type: "Slice"
  bottom: "target"
  top: "target_1"
  top: "target_2"
  top: "target_3"
  top: "target_4"
  top: "target_5"
  slice_param {
    slice_point: 2
    slice_point: 4
    slice_point: 6
    slice_point: 8
    axis: 1
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1_1"
  type: "PReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "pool1_1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1_1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2_1"
  type: "PReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3_1"
  type: "PReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "data_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1_2"
  type: "PReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1_2"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1_2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool1_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2_2"
  type: "PReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "pool2_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3_2"
  type: "PReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv1_3"
  type: "Convolution"
  bottom: "data_3"
  top: "conv1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1_3"
  type: "PReLU"
  bottom: "conv1_3"
  top: "conv1_3"
}
layer {
  name: "pool1_3"
  type: "Pooling"
  bottom: "conv1_3"
  top: "pool1_3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_3"
  type: "Convolution"
  bottom: "pool1_3"
  top: "conv2_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2_3"
  type: "PReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "pool2_3"
  type: "Pooling"
  bottom: "conv2_3"
  top: "pool2_3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "pool2_3"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3_3"
  type: "PReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv1_4"
  type: "Convolution"
  bottom: "data_4"
  top: "conv1_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1_4"
  type: "PReLU"
  bottom: "conv1_4"
  top: "conv1_4"
}
layer {
  name: "pool1_4"
  type: "Pooling"
  bottom: "conv1_4"
  top: "pool1_4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_4"
  type: "Convolution"
  bottom: "pool1_4"
  top: "conv2_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2_4"
  type: "PReLU"
  bottom: "conv2_4"
  top: "conv2_4"
}
layer {
  name: "pool2_4"
  type: "Pooling"
  bottom: "conv2_4"
  top: "pool2_4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_4"
  type: "Convolution"
  bottom: "pool2_4"
  top: "conv3_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3_4"
  type: "PReLU"
  bottom: "conv3_4"
  top: "conv3_4"
}
layer {
  name: "conv1_5"
  type: "Convolution"
  bottom: "data_5"
  top: "conv1_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu1_5"
  type: "PReLU"
  bottom: "conv1_5"
  top: "conv1_5"
}
layer {
  name: "pool1_5"
  type: "Pooling"
  bottom: "conv1_5"
  top: "pool1_5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_5"
  type: "Convolution"
  bottom: "pool1_5"
  top: "conv2_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu2_5"
  type: "PReLU"
  bottom: "conv2_5"
  top: "conv2_5"
}
layer {
  name: "pool2_5"
  type: "Pooling"
  bottom: "conv2_5"
  top: "pool2_5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_5"
  type: "Convolution"
  bottom: "pool2_5"
  top: "conv3_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu3_5"
  type: "PReLU"
  bottom: "conv3_5"
  top: "conv3_5"
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "conv3_1"
  bottom: "conv3_2"
  bottom: "conv3_3"
  bottom: "conv3_4"
  bottom: "conv3_5"
  top: "concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "fc4"
  type: "InnerProduct"
  bottom: "concat"
  top: "fc4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "fc4"
  top: "fc4"
}
layer {
  name: "fc5_1"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu5_1"
  type: "PReLU"
  bottom: "fc5_1"
  top: "fc5_1"
}
layer {
  name: "fc6_1"
  type: "InnerProduct"
  bottom: "fc5_1"
  top: "fc6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss_1"
  type: "EuclideanLoss"
  bottom: "fc6_1"
  bottom: "target_1"
  top: "loss_1"
}
layer {
  name: "fc5_2"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu5_2"
  type: "PReLU"
  bottom: "fc5_2"
  top: "fc5_2"
}
layer {
  name: "fc6_2"
  type: "InnerProduct"
  bottom: "fc5_2"
  top: "fc6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss_2"
  type: "EuclideanLoss"
  bottom: "fc6_2"
  bottom: "target_2"
  top: "loss_2"
}
layer {
  name: "fc5_3"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu5_3"
  type: "PReLU"
  bottom: "fc5_3"
  top: "fc5_3"
}
layer {
  name: "fc6_3"
  type: "InnerProduct"
  bottom: "fc5_3"
  top: "fc6_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss_3"
  type: "EuclideanLoss"
  bottom: "fc6_3"
  bottom: "target_3"
  top: "loss_3"
}
layer {
  name: "fc5_4"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu5_4"
  type: "PReLU"
  bottom: "fc5_4"
  top: "fc5_4"
}
layer {
  name: "fc6_4"
  type: "InnerProduct"
  bottom: "fc5_4"
  top: "fc6_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss_4"
  type: "EuclideanLoss"
  bottom: "fc6_4"
  bottom: "target_4"
  top: "loss_4"
}
layer {
  name: "fc5_5"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "prelu5_5"
  type: "PReLU"
  bottom: "fc5_5"
  top: "fc5_5"
}
layer {
  name: "fc6_5"
  type: "InnerProduct"
  bottom: "fc5_5"
  top: "fc6_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss_5"
  type: "EuclideanLoss"
  bottom: "fc6_5"
  bottom: "target_5"
  top: "loss_5"
}
I1201 01:18:39.356402 13889 layer_factory.hpp:77] Creating layer data
I1201 01:18:39.356431 13889 net.cpp:100] Creating Layer data
I1201 01:18:39.356442 13889 net.cpp:408] data -> data
I1201 01:18:39.356459 13889 net.cpp:408] data -> target
I1201 01:18:39.356473 13889 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: data/lnet_val.txt
I1201 01:18:39.356515 13889 hdf5_data_layer.cpp:93] Number of HDF5 files: 2
I1201 01:18:42.289049 13889 net.cpp:150] Setting up data
I1201 01:18:42.289099 13889 net.cpp:157] Top shape: 128 15 24 24 (1105920)
I1201 01:18:42.289105 13889 net.cpp:157] Top shape: 128 10 (1280)
I1201 01:18:42.289108 13889 net.cpp:165] Memory required for data: 4428800
I1201 01:18:42.289118 13889 layer_factory.hpp:77] Creating layer slicer_data
I1201 01:18:42.289137 13889 net.cpp:100] Creating Layer slicer_data
I1201 01:18:42.289142 13889 net.cpp:434] slicer_data <- data
I1201 01:18:42.289150 13889 net.cpp:408] slicer_data -> data_1
I1201 01:18:42.289161 13889 net.cpp:408] slicer_data -> data_2
I1201 01:18:42.289166 13889 net.cpp:408] slicer_data -> data_3
I1201 01:18:42.289171 13889 net.cpp:408] slicer_data -> data_4
I1201 01:18:42.289175 13889 net.cpp:408] slicer_data -> data_5
I1201 01:18:42.289233 13889 net.cpp:150] Setting up slicer_data
I1201 01:18:42.289239 13889 net.cpp:157] Top shape: 128 3 24 24 (221184)
I1201 01:18:42.289242 13889 net.cpp:157] Top shape: 128 3 24 24 (221184)
I1201 01:18:42.289253 13889 net.cpp:157] Top shape: 128 3 24 24 (221184)
I1201 01:18:42.289257 13889 net.cpp:157] Top shape: 128 3 24 24 (221184)
I1201 01:18:42.289259 13889 net.cpp:157] Top shape: 128 3 24 24 (221184)
I1201 01:18:42.289263 13889 net.cpp:165] Memory required for data: 8852480
I1201 01:18:42.289264 13889 layer_factory.hpp:77] Creating layer slicer_target
I1201 01:18:42.289273 13889 net.cpp:100] Creating Layer slicer_target
I1201 01:18:42.289275 13889 net.cpp:434] slicer_target <- target
I1201 01:18:42.289280 13889 net.cpp:408] slicer_target -> target_1
I1201 01:18:42.289285 13889 net.cpp:408] slicer_target -> target_2
I1201 01:18:42.289290 13889 net.cpp:408] slicer_target -> target_3
I1201 01:18:42.289295 13889 net.cpp:408] slicer_target -> target_4
I1201 01:18:42.289299 13889 net.cpp:408] slicer_target -> target_5
I1201 01:18:42.289351 13889 net.cpp:150] Setting up slicer_target
I1201 01:18:42.289356 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:42.289360 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:42.289362 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:42.289366 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:42.289368 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:42.289371 13889 net.cpp:165] Memory required for data: 8857600
I1201 01:18:42.289373 13889 layer_factory.hpp:77] Creating layer conv1_1
I1201 01:18:42.289386 13889 net.cpp:100] Creating Layer conv1_1
I1201 01:18:42.289389 13889 net.cpp:434] conv1_1 <- data_1
I1201 01:18:42.289393 13889 net.cpp:408] conv1_1 -> conv1_1
I1201 01:18:42.290438 13889 net.cpp:150] Setting up conv1_1
I1201 01:18:42.290453 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:42.290457 13889 net.cpp:165] Memory required for data: 15796224
I1201 01:18:42.290468 13889 layer_factory.hpp:77] Creating layer prelu1_1
I1201 01:18:42.290479 13889 net.cpp:100] Creating Layer prelu1_1
I1201 01:18:42.290482 13889 net.cpp:434] prelu1_1 <- conv1_1
I1201 01:18:42.290489 13889 net.cpp:395] prelu1_1 -> conv1_1 (in-place)
I1201 01:18:42.290580 13889 net.cpp:150] Setting up prelu1_1
I1201 01:18:42.290585 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:42.290587 13889 net.cpp:165] Memory required for data: 22734848
I1201 01:18:42.290593 13889 layer_factory.hpp:77] Creating layer pool1_1
I1201 01:18:42.290603 13889 net.cpp:100] Creating Layer pool1_1
I1201 01:18:42.290606 13889 net.cpp:434] pool1_1 <- conv1_1
I1201 01:18:42.290611 13889 net.cpp:408] pool1_1 -> pool1_1
I1201 01:18:42.290645 13889 net.cpp:150] Setting up pool1_1
I1201 01:18:42.290650 13889 net.cpp:157] Top shape: 128 28 11 11 (433664)
I1201 01:18:42.290653 13889 net.cpp:165] Memory required for data: 24469504
I1201 01:18:42.290657 13889 layer_factory.hpp:77] Creating layer conv2_1
I1201 01:18:42.290665 13889 net.cpp:100] Creating Layer conv2_1
I1201 01:18:42.290668 13889 net.cpp:434] conv2_1 <- pool1_1
I1201 01:18:42.290674 13889 net.cpp:408] conv2_1 -> conv2_1
I1201 01:18:42.291431 13889 net.cpp:150] Setting up conv2_1
I1201 01:18:42.291445 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:42.291447 13889 net.cpp:165] Memory required for data: 26460160
I1201 01:18:42.291456 13889 layer_factory.hpp:77] Creating layer prelu2_1
I1201 01:18:42.291462 13889 net.cpp:100] Creating Layer prelu2_1
I1201 01:18:42.291465 13889 net.cpp:434] prelu2_1 <- conv2_1
I1201 01:18:42.291476 13889 net.cpp:395] prelu2_1 -> conv2_1 (in-place)
I1201 01:18:42.291563 13889 net.cpp:150] Setting up prelu2_1
I1201 01:18:42.291569 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:42.291571 13889 net.cpp:165] Memory required for data: 28450816
I1201 01:18:42.291576 13889 layer_factory.hpp:77] Creating layer pool2_1
I1201 01:18:42.291589 13889 net.cpp:100] Creating Layer pool2_1
I1201 01:18:42.291591 13889 net.cpp:434] pool2_1 <- conv2_1
I1201 01:18:42.291599 13889 net.cpp:408] pool2_1 -> pool2_1
I1201 01:18:42.291630 13889 net.cpp:150] Setting up pool2_1
I1201 01:18:42.291636 13889 net.cpp:157] Top shape: 128 48 4 4 (98304)
I1201 01:18:42.291640 13889 net.cpp:165] Memory required for data: 28844032
I1201 01:18:42.291646 13889 layer_factory.hpp:77] Creating layer conv3_1
I1201 01:18:42.291654 13889 net.cpp:100] Creating Layer conv3_1
I1201 01:18:42.291658 13889 net.cpp:434] conv3_1 <- pool2_1
I1201 01:18:42.291663 13889 net.cpp:408] conv3_1 -> conv3_1
I1201 01:18:42.292650 13889 net.cpp:150] Setting up conv3_1
I1201 01:18:42.292665 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:42.292668 13889 net.cpp:165] Memory required for data: 29138944
I1201 01:18:42.292675 13889 layer_factory.hpp:77] Creating layer prelu3_1
I1201 01:18:42.292682 13889 net.cpp:100] Creating Layer prelu3_1
I1201 01:18:42.292686 13889 net.cpp:434] prelu3_1 <- conv3_1
I1201 01:18:42.292691 13889 net.cpp:395] prelu3_1 -> conv3_1 (in-place)
I1201 01:18:42.292775 13889 net.cpp:150] Setting up prelu3_1
I1201 01:18:42.292781 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:42.292783 13889 net.cpp:165] Memory required for data: 29433856
I1201 01:18:42.292790 13889 layer_factory.hpp:77] Creating layer conv1_2
I1201 01:18:42.292803 13889 net.cpp:100] Creating Layer conv1_2
I1201 01:18:42.292805 13889 net.cpp:434] conv1_2 <- data_2
I1201 01:18:42.292810 13889 net.cpp:408] conv1_2 -> conv1_2
I1201 01:18:42.293709 13889 net.cpp:150] Setting up conv1_2
I1201 01:18:42.293723 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:42.293726 13889 net.cpp:165] Memory required for data: 36372480
I1201 01:18:42.293732 13889 layer_factory.hpp:77] Creating layer prelu1_2
I1201 01:18:42.293741 13889 net.cpp:100] Creating Layer prelu1_2
I1201 01:18:42.293745 13889 net.cpp:434] prelu1_2 <- conv1_2
I1201 01:18:42.293750 13889 net.cpp:395] prelu1_2 -> conv1_2 (in-place)
I1201 01:18:42.293835 13889 net.cpp:150] Setting up prelu1_2
I1201 01:18:42.293841 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:42.293843 13889 net.cpp:165] Memory required for data: 43311104
I1201 01:18:42.293848 13889 layer_factory.hpp:77] Creating layer pool1_2
I1201 01:18:42.293853 13889 net.cpp:100] Creating Layer pool1_2
I1201 01:18:42.293856 13889 net.cpp:434] pool1_2 <- conv1_2
I1201 01:18:42.293862 13889 net.cpp:408] pool1_2 -> pool1_2
I1201 01:18:42.293891 13889 net.cpp:150] Setting up pool1_2
I1201 01:18:42.293902 13889 net.cpp:157] Top shape: 128 28 11 11 (433664)
I1201 01:18:42.293905 13889 net.cpp:165] Memory required for data: 45045760
I1201 01:18:42.293907 13889 layer_factory.hpp:77] Creating layer conv2_2
I1201 01:18:42.293916 13889 net.cpp:100] Creating Layer conv2_2
I1201 01:18:42.293920 13889 net.cpp:434] conv2_2 <- pool1_2
I1201 01:18:42.293925 13889 net.cpp:408] conv2_2 -> conv2_2
I1201 01:18:42.295110 13889 net.cpp:150] Setting up conv2_2
I1201 01:18:42.295125 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:42.295128 13889 net.cpp:165] Memory required for data: 47036416
I1201 01:18:42.295135 13889 layer_factory.hpp:77] Creating layer prelu2_2
I1201 01:18:42.295143 13889 net.cpp:100] Creating Layer prelu2_2
I1201 01:18:42.295147 13889 net.cpp:434] prelu2_2 <- conv2_2
I1201 01:18:42.295151 13889 net.cpp:395] prelu2_2 -> conv2_2 (in-place)
I1201 01:18:42.295235 13889 net.cpp:150] Setting up prelu2_2
I1201 01:18:42.295241 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:42.295243 13889 net.cpp:165] Memory required for data: 49027072
I1201 01:18:42.295248 13889 layer_factory.hpp:77] Creating layer pool2_2
I1201 01:18:42.295255 13889 net.cpp:100] Creating Layer pool2_2
I1201 01:18:42.295259 13889 net.cpp:434] pool2_2 <- conv2_2
I1201 01:18:42.295264 13889 net.cpp:408] pool2_2 -> pool2_2
I1201 01:18:42.295295 13889 net.cpp:150] Setting up pool2_2
I1201 01:18:42.295300 13889 net.cpp:157] Top shape: 128 48 4 4 (98304)
I1201 01:18:42.295303 13889 net.cpp:165] Memory required for data: 49420288
I1201 01:18:42.295306 13889 layer_factory.hpp:77] Creating layer conv3_2
I1201 01:18:42.295315 13889 net.cpp:100] Creating Layer conv3_2
I1201 01:18:42.295318 13889 net.cpp:434] conv3_2 <- pool2_2
I1201 01:18:42.295325 13889 net.cpp:408] conv3_2 -> conv3_2
I1201 01:18:42.296291 13889 net.cpp:150] Setting up conv3_2
I1201 01:18:42.296309 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:42.296314 13889 net.cpp:165] Memory required for data: 49715200
I1201 01:18:42.296322 13889 layer_factory.hpp:77] Creating layer prelu3_2
I1201 01:18:42.296330 13889 net.cpp:100] Creating Layer prelu3_2
I1201 01:18:42.296334 13889 net.cpp:434] prelu3_2 <- conv3_2
I1201 01:18:42.296339 13889 net.cpp:395] prelu3_2 -> conv3_2 (in-place)
I1201 01:18:42.296422 13889 net.cpp:150] Setting up prelu3_2
I1201 01:18:42.296427 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:42.296430 13889 net.cpp:165] Memory required for data: 50010112
I1201 01:18:42.296434 13889 layer_factory.hpp:77] Creating layer conv1_3
I1201 01:18:42.296445 13889 net.cpp:100] Creating Layer conv1_3
I1201 01:18:42.296449 13889 net.cpp:434] conv1_3 <- data_3
I1201 01:18:42.296455 13889 net.cpp:408] conv1_3 -> conv1_3
I1201 01:18:42.297344 13889 net.cpp:150] Setting up conv1_3
I1201 01:18:42.297358 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:42.297363 13889 net.cpp:165] Memory required for data: 56948736
I1201 01:18:42.297369 13889 layer_factory.hpp:77] Creating layer prelu1_3
I1201 01:18:42.297374 13889 net.cpp:100] Creating Layer prelu1_3
I1201 01:18:42.297376 13889 net.cpp:434] prelu1_3 <- conv1_3
I1201 01:18:42.297384 13889 net.cpp:395] prelu1_3 -> conv1_3 (in-place)
I1201 01:18:42.297469 13889 net.cpp:150] Setting up prelu1_3
I1201 01:18:42.297480 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:42.297482 13889 net.cpp:165] Memory required for data: 63887360
I1201 01:18:42.297487 13889 layer_factory.hpp:77] Creating layer pool1_3
I1201 01:18:42.297492 13889 net.cpp:100] Creating Layer pool1_3
I1201 01:18:42.297495 13889 net.cpp:434] pool1_3 <- conv1_3
I1201 01:18:42.297499 13889 net.cpp:408] pool1_3 -> pool1_3
I1201 01:18:42.297531 13889 net.cpp:150] Setting up pool1_3
I1201 01:18:42.297536 13889 net.cpp:157] Top shape: 128 28 11 11 (433664)
I1201 01:18:42.297539 13889 net.cpp:165] Memory required for data: 65622016
I1201 01:18:42.297544 13889 layer_factory.hpp:77] Creating layer conv2_3
I1201 01:18:42.297554 13889 net.cpp:100] Creating Layer conv2_3
I1201 01:18:42.297556 13889 net.cpp:434] conv2_3 <- pool1_3
I1201 01:18:42.297562 13889 net.cpp:408] conv2_3 -> conv2_3
I1201 01:18:42.298516 13889 net.cpp:150] Setting up conv2_3
I1201 01:18:42.298532 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:42.298535 13889 net.cpp:165] Memory required for data: 67612672
I1201 01:18:42.298542 13889 layer_factory.hpp:77] Creating layer prelu2_3
I1201 01:18:42.298547 13889 net.cpp:100] Creating Layer prelu2_3
I1201 01:18:42.298552 13889 net.cpp:434] prelu2_3 <- conv2_3
I1201 01:18:42.298557 13889 net.cpp:395] prelu2_3 -> conv2_3 (in-place)
I1201 01:18:42.298641 13889 net.cpp:150] Setting up prelu2_3
I1201 01:18:42.298647 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:42.298650 13889 net.cpp:165] Memory required for data: 69603328
I1201 01:18:42.298655 13889 layer_factory.hpp:77] Creating layer pool2_3
I1201 01:18:42.298662 13889 net.cpp:100] Creating Layer pool2_3
I1201 01:18:42.298666 13889 net.cpp:434] pool2_3 <- conv2_3
I1201 01:18:42.298671 13889 net.cpp:408] pool2_3 -> pool2_3
I1201 01:18:42.298702 13889 net.cpp:150] Setting up pool2_3
I1201 01:18:42.298708 13889 net.cpp:157] Top shape: 128 48 4 4 (98304)
I1201 01:18:42.298712 13889 net.cpp:165] Memory required for data: 69996544
I1201 01:18:42.298713 13889 layer_factory.hpp:77] Creating layer conv3_3
I1201 01:18:42.298724 13889 net.cpp:100] Creating Layer conv3_3
I1201 01:18:42.298727 13889 net.cpp:434] conv3_3 <- pool2_3
I1201 01:18:42.298732 13889 net.cpp:408] conv3_3 -> conv3_3
I1201 01:18:42.299688 13889 net.cpp:150] Setting up conv3_3
I1201 01:18:42.299702 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:42.299706 13889 net.cpp:165] Memory required for data: 70291456
I1201 01:18:42.299712 13889 layer_factory.hpp:77] Creating layer prelu3_3
I1201 01:18:42.299721 13889 net.cpp:100] Creating Layer prelu3_3
I1201 01:18:42.299728 13889 net.cpp:434] prelu3_3 <- conv3_3
I1201 01:18:42.299733 13889 net.cpp:395] prelu3_3 -> conv3_3 (in-place)
I1201 01:18:42.299818 13889 net.cpp:150] Setting up prelu3_3
I1201 01:18:42.299824 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:42.299826 13889 net.cpp:165] Memory required for data: 70586368
I1201 01:18:42.299831 13889 layer_factory.hpp:77] Creating layer conv1_4
I1201 01:18:42.299840 13889 net.cpp:100] Creating Layer conv1_4
I1201 01:18:42.299844 13889 net.cpp:434] conv1_4 <- data_4
I1201 01:18:42.299850 13889 net.cpp:408] conv1_4 -> conv1_4
I1201 01:18:42.300737 13889 net.cpp:150] Setting up conv1_4
I1201 01:18:42.300751 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:42.300755 13889 net.cpp:165] Memory required for data: 77524992
I1201 01:18:42.300761 13889 layer_factory.hpp:77] Creating layer prelu1_4
I1201 01:18:42.300770 13889 net.cpp:100] Creating Layer prelu1_4
I1201 01:18:42.300772 13889 net.cpp:434] prelu1_4 <- conv1_4
I1201 01:18:42.300777 13889 net.cpp:395] prelu1_4 -> conv1_4 (in-place)
I1201 01:18:42.300869 13889 net.cpp:150] Setting up prelu1_4
I1201 01:18:42.300875 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:42.300879 13889 net.cpp:165] Memory required for data: 84463616
I1201 01:18:42.300884 13889 layer_factory.hpp:77] Creating layer pool1_4
I1201 01:18:42.300890 13889 net.cpp:100] Creating Layer pool1_4
I1201 01:18:42.300894 13889 net.cpp:434] pool1_4 <- conv1_4
I1201 01:18:42.300899 13889 net.cpp:408] pool1_4 -> pool1_4
I1201 01:18:42.300930 13889 net.cpp:150] Setting up pool1_4
I1201 01:18:42.300935 13889 net.cpp:157] Top shape: 128 28 11 11 (433664)
I1201 01:18:42.300938 13889 net.cpp:165] Memory required for data: 86198272
I1201 01:18:42.300941 13889 layer_factory.hpp:77] Creating layer conv2_4
I1201 01:18:42.300951 13889 net.cpp:100] Creating Layer conv2_4
I1201 01:18:42.300956 13889 net.cpp:434] conv2_4 <- pool1_4
I1201 01:18:42.300959 13889 net.cpp:408] conv2_4 -> conv2_4
I1201 01:18:42.301914 13889 net.cpp:150] Setting up conv2_4
I1201 01:18:42.301928 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:42.301933 13889 net.cpp:165] Memory required for data: 88188928
I1201 01:18:42.301939 13889 layer_factory.hpp:77] Creating layer prelu2_4
I1201 01:18:42.301944 13889 net.cpp:100] Creating Layer prelu2_4
I1201 01:18:42.301947 13889 net.cpp:434] prelu2_4 <- conv2_4
I1201 01:18:42.301952 13889 net.cpp:395] prelu2_4 -> conv2_4 (in-place)
I1201 01:18:42.302037 13889 net.cpp:150] Setting up prelu2_4
I1201 01:18:42.302043 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:42.302047 13889 net.cpp:165] Memory required for data: 90179584
I1201 01:18:42.302055 13889 layer_factory.hpp:77] Creating layer pool2_4
I1201 01:18:42.302064 13889 net.cpp:100] Creating Layer pool2_4
I1201 01:18:42.302075 13889 net.cpp:434] pool2_4 <- conv2_4
I1201 01:18:42.302081 13889 net.cpp:408] pool2_4 -> pool2_4
I1201 01:18:42.302116 13889 net.cpp:150] Setting up pool2_4
I1201 01:18:42.302124 13889 net.cpp:157] Top shape: 128 48 4 4 (98304)
I1201 01:18:42.302126 13889 net.cpp:165] Memory required for data: 90572800
I1201 01:18:42.302130 13889 layer_factory.hpp:77] Creating layer conv3_4
I1201 01:18:42.302140 13889 net.cpp:100] Creating Layer conv3_4
I1201 01:18:42.302145 13889 net.cpp:434] conv3_4 <- pool2_4
I1201 01:18:42.302148 13889 net.cpp:408] conv3_4 -> conv3_4
I1201 01:18:42.302848 13889 net.cpp:150] Setting up conv3_4
I1201 01:18:42.302860 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:42.302862 13889 net.cpp:165] Memory required for data: 90867712
I1201 01:18:42.302867 13889 layer_factory.hpp:77] Creating layer prelu3_4
I1201 01:18:42.302875 13889 net.cpp:100] Creating Layer prelu3_4
I1201 01:18:42.302878 13889 net.cpp:434] prelu3_4 <- conv3_4
I1201 01:18:42.302882 13889 net.cpp:395] prelu3_4 -> conv3_4 (in-place)
I1201 01:18:42.302963 13889 net.cpp:150] Setting up prelu3_4
I1201 01:18:42.302969 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:42.302971 13889 net.cpp:165] Memory required for data: 91162624
I1201 01:18:42.302980 13889 layer_factory.hpp:77] Creating layer conv1_5
I1201 01:18:42.302990 13889 net.cpp:100] Creating Layer conv1_5
I1201 01:18:42.302994 13889 net.cpp:434] conv1_5 <- data_5
I1201 01:18:42.303000 13889 net.cpp:408] conv1_5 -> conv1_5
I1201 01:18:42.303903 13889 net.cpp:150] Setting up conv1_5
I1201 01:18:42.303917 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:42.303921 13889 net.cpp:165] Memory required for data: 98101248
I1201 01:18:42.303928 13889 layer_factory.hpp:77] Creating layer prelu1_5
I1201 01:18:42.303935 13889 net.cpp:100] Creating Layer prelu1_5
I1201 01:18:42.303937 13889 net.cpp:434] prelu1_5 <- conv1_5
I1201 01:18:42.303947 13889 net.cpp:395] prelu1_5 -> conv1_5 (in-place)
I1201 01:18:42.304034 13889 net.cpp:150] Setting up prelu1_5
I1201 01:18:42.304040 13889 net.cpp:157] Top shape: 128 28 22 22 (1734656)
I1201 01:18:42.304044 13889 net.cpp:165] Memory required for data: 105039872
I1201 01:18:42.304047 13889 layer_factory.hpp:77] Creating layer pool1_5
I1201 01:18:42.304054 13889 net.cpp:100] Creating Layer pool1_5
I1201 01:18:42.304056 13889 net.cpp:434] pool1_5 <- conv1_5
I1201 01:18:42.304060 13889 net.cpp:408] pool1_5 -> pool1_5
I1201 01:18:42.304098 13889 net.cpp:150] Setting up pool1_5
I1201 01:18:42.304107 13889 net.cpp:157] Top shape: 128 28 11 11 (433664)
I1201 01:18:42.304111 13889 net.cpp:165] Memory required for data: 106774528
I1201 01:18:42.304113 13889 layer_factory.hpp:77] Creating layer conv2_5
I1201 01:18:42.304126 13889 net.cpp:100] Creating Layer conv2_5
I1201 01:18:42.304128 13889 net.cpp:434] conv2_5 <- pool1_5
I1201 01:18:42.304133 13889 net.cpp:408] conv2_5 -> conv2_5
I1201 01:18:42.305094 13889 net.cpp:150] Setting up conv2_5
I1201 01:18:42.305109 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:42.305111 13889 net.cpp:165] Memory required for data: 108765184
I1201 01:18:42.305117 13889 layer_factory.hpp:77] Creating layer prelu2_5
I1201 01:18:42.305125 13889 net.cpp:100] Creating Layer prelu2_5
I1201 01:18:42.305130 13889 net.cpp:434] prelu2_5 <- conv2_5
I1201 01:18:42.305133 13889 net.cpp:395] prelu2_5 -> conv2_5 (in-place)
I1201 01:18:42.305218 13889 net.cpp:150] Setting up prelu2_5
I1201 01:18:42.305224 13889 net.cpp:157] Top shape: 128 48 9 9 (497664)
I1201 01:18:42.305227 13889 net.cpp:165] Memory required for data: 110755840
I1201 01:18:42.305233 13889 layer_factory.hpp:77] Creating layer pool2_5
I1201 01:18:42.305239 13889 net.cpp:100] Creating Layer pool2_5
I1201 01:18:42.305243 13889 net.cpp:434] pool2_5 <- conv2_5
I1201 01:18:42.305248 13889 net.cpp:408] pool2_5 -> pool2_5
I1201 01:18:42.305279 13889 net.cpp:150] Setting up pool2_5
I1201 01:18:42.305284 13889 net.cpp:157] Top shape: 128 48 4 4 (98304)
I1201 01:18:42.305286 13889 net.cpp:165] Memory required for data: 111149056
I1201 01:18:42.305289 13889 layer_factory.hpp:77] Creating layer conv3_5
I1201 01:18:42.305299 13889 net.cpp:100] Creating Layer conv3_5
I1201 01:18:42.305304 13889 net.cpp:434] conv3_5 <- pool2_5
I1201 01:18:42.305310 13889 net.cpp:408] conv3_5 -> conv3_5
I1201 01:18:42.306269 13889 net.cpp:150] Setting up conv3_5
I1201 01:18:42.306283 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:42.306288 13889 net.cpp:165] Memory required for data: 111443968
I1201 01:18:42.306293 13889 layer_factory.hpp:77] Creating layer prelu3_5
I1201 01:18:42.306301 13889 net.cpp:100] Creating Layer prelu3_5
I1201 01:18:42.306305 13889 net.cpp:434] prelu3_5 <- conv3_5
I1201 01:18:42.306311 13889 net.cpp:395] prelu3_5 -> conv3_5 (in-place)
I1201 01:18:42.306394 13889 net.cpp:150] Setting up prelu3_5
I1201 01:18:42.306401 13889 net.cpp:157] Top shape: 128 64 3 3 (73728)
I1201 01:18:42.306403 13889 net.cpp:165] Memory required for data: 111738880
I1201 01:18:42.306408 13889 layer_factory.hpp:77] Creating layer concat
I1201 01:18:42.306416 13889 net.cpp:100] Creating Layer concat
I1201 01:18:42.306421 13889 net.cpp:434] concat <- conv3_1
I1201 01:18:42.306424 13889 net.cpp:434] concat <- conv3_2
I1201 01:18:42.306427 13889 net.cpp:434] concat <- conv3_3
I1201 01:18:42.306434 13889 net.cpp:434] concat <- conv3_4
I1201 01:18:42.306437 13889 net.cpp:434] concat <- conv3_5
I1201 01:18:42.306442 13889 net.cpp:408] concat -> concat
I1201 01:18:42.306465 13889 net.cpp:150] Setting up concat
I1201 01:18:42.306470 13889 net.cpp:157] Top shape: 128 320 3 3 (368640)
I1201 01:18:42.306473 13889 net.cpp:165] Memory required for data: 113213440
I1201 01:18:42.306476 13889 layer_factory.hpp:77] Creating layer fc4
I1201 01:18:42.306485 13889 net.cpp:100] Creating Layer fc4
I1201 01:18:42.306489 13889 net.cpp:434] fc4 <- concat
I1201 01:18:42.306493 13889 net.cpp:408] fc4 -> fc4
I1201 01:18:42.312212 13889 net.cpp:150] Setting up fc4
I1201 01:18:42.312227 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:42.312230 13889 net.cpp:165] Memory required for data: 113344512
I1201 01:18:42.312237 13889 layer_factory.hpp:77] Creating layer prelu4
I1201 01:18:42.312242 13889 net.cpp:100] Creating Layer prelu4
I1201 01:18:42.312244 13889 net.cpp:434] prelu4 <- fc4
I1201 01:18:42.312250 13889 net.cpp:395] prelu4 -> fc4 (in-place)
I1201 01:18:42.312314 13889 net.cpp:150] Setting up prelu4
I1201 01:18:42.312319 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:42.312321 13889 net.cpp:165] Memory required for data: 113475584
I1201 01:18:42.312325 13889 layer_factory.hpp:77] Creating layer fc4_prelu4_0_split
I1201 01:18:42.312330 13889 net.cpp:100] Creating Layer fc4_prelu4_0_split
I1201 01:18:42.312333 13889 net.cpp:434] fc4_prelu4_0_split <- fc4
I1201 01:18:42.312337 13889 net.cpp:408] fc4_prelu4_0_split -> fc4_prelu4_0_split_0
I1201 01:18:42.312343 13889 net.cpp:408] fc4_prelu4_0_split -> fc4_prelu4_0_split_1
I1201 01:18:42.312347 13889 net.cpp:408] fc4_prelu4_0_split -> fc4_prelu4_0_split_2
I1201 01:18:42.312352 13889 net.cpp:408] fc4_prelu4_0_split -> fc4_prelu4_0_split_3
I1201 01:18:42.312356 13889 net.cpp:408] fc4_prelu4_0_split -> fc4_prelu4_0_split_4
I1201 01:18:42.312412 13889 net.cpp:150] Setting up fc4_prelu4_0_split
I1201 01:18:42.312419 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:42.312422 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:42.312425 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:42.312428 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:42.312432 13889 net.cpp:157] Top shape: 128 256 (32768)
I1201 01:18:42.312433 13889 net.cpp:165] Memory required for data: 114130944
I1201 01:18:42.312436 13889 layer_factory.hpp:77] Creating layer fc5_1
I1201 01:18:42.312443 13889 net.cpp:100] Creating Layer fc5_1
I1201 01:18:42.312446 13889 net.cpp:434] fc5_1 <- fc4_prelu4_0_split_0
I1201 01:18:42.312454 13889 net.cpp:408] fc5_1 -> fc5_1
I1201 01:18:42.312629 13889 net.cpp:150] Setting up fc5_1
I1201 01:18:42.312635 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:42.312638 13889 net.cpp:165] Memory required for data: 114163712
I1201 01:18:42.312644 13889 layer_factory.hpp:77] Creating layer prelu5_1
I1201 01:18:42.312649 13889 net.cpp:100] Creating Layer prelu5_1
I1201 01:18:42.312651 13889 net.cpp:434] prelu5_1 <- fc5_1
I1201 01:18:42.312655 13889 net.cpp:395] prelu5_1 -> fc5_1 (in-place)
I1201 01:18:42.312721 13889 net.cpp:150] Setting up prelu5_1
I1201 01:18:42.312726 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:42.312728 13889 net.cpp:165] Memory required for data: 114196480
I1201 01:18:42.312732 13889 layer_factory.hpp:77] Creating layer fc6_1
I1201 01:18:42.312737 13889 net.cpp:100] Creating Layer fc6_1
I1201 01:18:42.312741 13889 net.cpp:434] fc6_1 <- fc5_1
I1201 01:18:42.312744 13889 net.cpp:408] fc6_1 -> fc6_1
I1201 01:18:42.312821 13889 net.cpp:150] Setting up fc6_1
I1201 01:18:42.312826 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:42.312829 13889 net.cpp:165] Memory required for data: 114197504
I1201 01:18:42.312834 13889 layer_factory.hpp:77] Creating layer loss_1
I1201 01:18:42.312839 13889 net.cpp:100] Creating Layer loss_1
I1201 01:18:42.312841 13889 net.cpp:434] loss_1 <- fc6_1
I1201 01:18:42.312845 13889 net.cpp:434] loss_1 <- target_1
I1201 01:18:42.312851 13889 net.cpp:408] loss_1 -> loss_1
I1201 01:18:42.312880 13889 net.cpp:150] Setting up loss_1
I1201 01:18:42.312885 13889 net.cpp:157] Top shape: (1)
I1201 01:18:42.312887 13889 net.cpp:160]     with loss weight 1
I1201 01:18:42.312896 13889 net.cpp:165] Memory required for data: 114197508
I1201 01:18:42.312899 13889 layer_factory.hpp:77] Creating layer fc5_2
I1201 01:18:42.312906 13889 net.cpp:100] Creating Layer fc5_2
I1201 01:18:42.312909 13889 net.cpp:434] fc5_2 <- fc4_prelu4_0_split_1
I1201 01:18:42.312916 13889 net.cpp:408] fc5_2 -> fc5_2
I1201 01:18:42.313096 13889 net.cpp:150] Setting up fc5_2
I1201 01:18:42.313104 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:42.313107 13889 net.cpp:165] Memory required for data: 114230276
I1201 01:18:42.313112 13889 layer_factory.hpp:77] Creating layer prelu5_2
I1201 01:18:42.313119 13889 net.cpp:100] Creating Layer prelu5_2
I1201 01:18:42.313122 13889 net.cpp:434] prelu5_2 <- fc5_2
I1201 01:18:42.313127 13889 net.cpp:395] prelu5_2 -> fc5_2 (in-place)
I1201 01:18:42.313197 13889 net.cpp:150] Setting up prelu5_2
I1201 01:18:42.313204 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:42.313205 13889 net.cpp:165] Memory required for data: 114263044
I1201 01:18:42.313210 13889 layer_factory.hpp:77] Creating layer fc6_2
I1201 01:18:42.313215 13889 net.cpp:100] Creating Layer fc6_2
I1201 01:18:42.313217 13889 net.cpp:434] fc6_2 <- fc5_2
I1201 01:18:42.313222 13889 net.cpp:408] fc6_2 -> fc6_2
I1201 01:18:42.313302 13889 net.cpp:150] Setting up fc6_2
I1201 01:18:42.313308 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:42.313309 13889 net.cpp:165] Memory required for data: 114264068
I1201 01:18:42.313314 13889 layer_factory.hpp:77] Creating layer loss_2
I1201 01:18:42.313319 13889 net.cpp:100] Creating Layer loss_2
I1201 01:18:42.313323 13889 net.cpp:434] loss_2 <- fc6_2
I1201 01:18:42.313325 13889 net.cpp:434] loss_2 <- target_2
I1201 01:18:42.313329 13889 net.cpp:408] loss_2 -> loss_2
I1201 01:18:42.313355 13889 net.cpp:150] Setting up loss_2
I1201 01:18:42.313360 13889 net.cpp:157] Top shape: (1)
I1201 01:18:42.313364 13889 net.cpp:160]     with loss weight 1
I1201 01:18:42.313367 13889 net.cpp:165] Memory required for data: 114264072
I1201 01:18:42.313370 13889 layer_factory.hpp:77] Creating layer fc5_3
I1201 01:18:42.313375 13889 net.cpp:100] Creating Layer fc5_3
I1201 01:18:42.313379 13889 net.cpp:434] fc5_3 <- fc4_prelu4_0_split_2
I1201 01:18:42.313385 13889 net.cpp:408] fc5_3 -> fc5_3
I1201 01:18:42.313561 13889 net.cpp:150] Setting up fc5_3
I1201 01:18:42.313566 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:42.313570 13889 net.cpp:165] Memory required for data: 114296840
I1201 01:18:42.313575 13889 layer_factory.hpp:77] Creating layer prelu5_3
I1201 01:18:42.313580 13889 net.cpp:100] Creating Layer prelu5_3
I1201 01:18:42.313581 13889 net.cpp:434] prelu5_3 <- fc5_3
I1201 01:18:42.313587 13889 net.cpp:395] prelu5_3 -> fc5_3 (in-place)
I1201 01:18:42.313652 13889 net.cpp:150] Setting up prelu5_3
I1201 01:18:42.313657 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:42.313659 13889 net.cpp:165] Memory required for data: 114329608
I1201 01:18:42.313663 13889 layer_factory.hpp:77] Creating layer fc6_3
I1201 01:18:42.313670 13889 net.cpp:100] Creating Layer fc6_3
I1201 01:18:42.313673 13889 net.cpp:434] fc6_3 <- fc5_3
I1201 01:18:42.313678 13889 net.cpp:408] fc6_3 -> fc6_3
I1201 01:18:42.313751 13889 net.cpp:150] Setting up fc6_3
I1201 01:18:42.313756 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:42.313758 13889 net.cpp:165] Memory required for data: 114330632
I1201 01:18:42.313763 13889 layer_factory.hpp:77] Creating layer loss_3
I1201 01:18:42.313768 13889 net.cpp:100] Creating Layer loss_3
I1201 01:18:42.313771 13889 net.cpp:434] loss_3 <- fc6_3
I1201 01:18:42.313774 13889 net.cpp:434] loss_3 <- target_3
I1201 01:18:42.313778 13889 net.cpp:408] loss_3 -> loss_3
I1201 01:18:42.313804 13889 net.cpp:150] Setting up loss_3
I1201 01:18:42.313808 13889 net.cpp:157] Top shape: (1)
I1201 01:18:42.313812 13889 net.cpp:160]     with loss weight 1
I1201 01:18:42.313815 13889 net.cpp:165] Memory required for data: 114330636
I1201 01:18:42.313820 13889 layer_factory.hpp:77] Creating layer fc5_4
I1201 01:18:42.313827 13889 net.cpp:100] Creating Layer fc5_4
I1201 01:18:42.313829 13889 net.cpp:434] fc5_4 <- fc4_prelu4_0_split_3
I1201 01:18:42.313835 13889 net.cpp:408] fc5_4 -> fc5_4
I1201 01:18:42.315035 13889 net.cpp:150] Setting up fc5_4
I1201 01:18:42.315049 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:42.315052 13889 net.cpp:165] Memory required for data: 114363404
I1201 01:18:42.315070 13889 layer_factory.hpp:77] Creating layer prelu5_4
I1201 01:18:42.315078 13889 net.cpp:100] Creating Layer prelu5_4
I1201 01:18:42.315083 13889 net.cpp:434] prelu5_4 <- fc5_4
I1201 01:18:42.315086 13889 net.cpp:395] prelu5_4 -> fc5_4 (in-place)
I1201 01:18:42.315157 13889 net.cpp:150] Setting up prelu5_4
I1201 01:18:42.315163 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:42.315165 13889 net.cpp:165] Memory required for data: 114396172
I1201 01:18:42.315171 13889 layer_factory.hpp:77] Creating layer fc6_4
I1201 01:18:42.315176 13889 net.cpp:100] Creating Layer fc6_4
I1201 01:18:42.315178 13889 net.cpp:434] fc6_4 <- fc5_4
I1201 01:18:42.315183 13889 net.cpp:408] fc6_4 -> fc6_4
I1201 01:18:42.315264 13889 net.cpp:150] Setting up fc6_4
I1201 01:18:42.315269 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:42.315273 13889 net.cpp:165] Memory required for data: 114397196
I1201 01:18:42.315276 13889 layer_factory.hpp:77] Creating layer loss_4
I1201 01:18:42.315281 13889 net.cpp:100] Creating Layer loss_4
I1201 01:18:42.315284 13889 net.cpp:434] loss_4 <- fc6_4
I1201 01:18:42.315289 13889 net.cpp:434] loss_4 <- target_4
I1201 01:18:42.315294 13889 net.cpp:408] loss_4 -> loss_4
I1201 01:18:42.315318 13889 net.cpp:150] Setting up loss_4
I1201 01:18:42.315323 13889 net.cpp:157] Top shape: (1)
I1201 01:18:42.315325 13889 net.cpp:160]     with loss weight 1
I1201 01:18:42.315330 13889 net.cpp:165] Memory required for data: 114397200
I1201 01:18:42.315333 13889 layer_factory.hpp:77] Creating layer fc5_5
I1201 01:18:42.315340 13889 net.cpp:100] Creating Layer fc5_5
I1201 01:18:42.315343 13889 net.cpp:434] fc5_5 <- fc4_prelu4_0_split_4
I1201 01:18:42.315347 13889 net.cpp:408] fc5_5 -> fc5_5
I1201 01:18:42.315518 13889 net.cpp:150] Setting up fc5_5
I1201 01:18:42.315524 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:42.315526 13889 net.cpp:165] Memory required for data: 114429968
I1201 01:18:42.315531 13889 layer_factory.hpp:77] Creating layer prelu5_5
I1201 01:18:42.315541 13889 net.cpp:100] Creating Layer prelu5_5
I1201 01:18:42.315544 13889 net.cpp:434] prelu5_5 <- fc5_5
I1201 01:18:42.315551 13889 net.cpp:395] prelu5_5 -> fc5_5 (in-place)
I1201 01:18:42.315616 13889 net.cpp:150] Setting up prelu5_5
I1201 01:18:42.315621 13889 net.cpp:157] Top shape: 128 64 (8192)
I1201 01:18:42.315623 13889 net.cpp:165] Memory required for data: 114462736
I1201 01:18:42.315628 13889 layer_factory.hpp:77] Creating layer fc6_5
I1201 01:18:42.315632 13889 net.cpp:100] Creating Layer fc6_5
I1201 01:18:42.315635 13889 net.cpp:434] fc6_5 <- fc5_5
I1201 01:18:42.315641 13889 net.cpp:408] fc6_5 -> fc6_5
I1201 01:18:42.315721 13889 net.cpp:150] Setting up fc6_5
I1201 01:18:42.315726 13889 net.cpp:157] Top shape: 128 2 (256)
I1201 01:18:42.315728 13889 net.cpp:165] Memory required for data: 114463760
I1201 01:18:42.315733 13889 layer_factory.hpp:77] Creating layer loss_5
I1201 01:18:42.315738 13889 net.cpp:100] Creating Layer loss_5
I1201 01:18:42.315742 13889 net.cpp:434] loss_5 <- fc6_5
I1201 01:18:42.315747 13889 net.cpp:434] loss_5 <- target_5
I1201 01:18:42.315750 13889 net.cpp:408] loss_5 -> loss_5
I1201 01:18:42.315775 13889 net.cpp:150] Setting up loss_5
I1201 01:18:42.315779 13889 net.cpp:157] Top shape: (1)
I1201 01:18:42.315783 13889 net.cpp:160]     with loss weight 1
I1201 01:18:42.315786 13889 net.cpp:165] Memory required for data: 114463764
I1201 01:18:42.315788 13889 net.cpp:226] loss_5 needs backward computation.
I1201 01:18:42.315791 13889 net.cpp:226] fc6_5 needs backward computation.
I1201 01:18:42.315798 13889 net.cpp:226] prelu5_5 needs backward computation.
I1201 01:18:42.315800 13889 net.cpp:226] fc5_5 needs backward computation.
I1201 01:18:42.315804 13889 net.cpp:226] loss_4 needs backward computation.
I1201 01:18:42.315806 13889 net.cpp:226] fc6_4 needs backward computation.
I1201 01:18:42.315809 13889 net.cpp:226] prelu5_4 needs backward computation.
I1201 01:18:42.315811 13889 net.cpp:226] fc5_4 needs backward computation.
I1201 01:18:42.315814 13889 net.cpp:226] loss_3 needs backward computation.
I1201 01:18:42.315817 13889 net.cpp:226] fc6_3 needs backward computation.
I1201 01:18:42.315822 13889 net.cpp:226] prelu5_3 needs backward computation.
I1201 01:18:42.315824 13889 net.cpp:226] fc5_3 needs backward computation.
I1201 01:18:42.315827 13889 net.cpp:226] loss_2 needs backward computation.
I1201 01:18:42.315830 13889 net.cpp:226] fc6_2 needs backward computation.
I1201 01:18:42.315834 13889 net.cpp:226] prelu5_2 needs backward computation.
I1201 01:18:42.315835 13889 net.cpp:226] fc5_2 needs backward computation.
I1201 01:18:42.315839 13889 net.cpp:226] loss_1 needs backward computation.
I1201 01:18:42.315841 13889 net.cpp:226] fc6_1 needs backward computation.
I1201 01:18:42.315843 13889 net.cpp:226] prelu5_1 needs backward computation.
I1201 01:18:42.315846 13889 net.cpp:226] fc5_1 needs backward computation.
I1201 01:18:42.315850 13889 net.cpp:226] fc4_prelu4_0_split needs backward computation.
I1201 01:18:42.315851 13889 net.cpp:226] prelu4 needs backward computation.
I1201 01:18:42.315855 13889 net.cpp:226] fc4 needs backward computation.
I1201 01:18:42.315857 13889 net.cpp:226] concat needs backward computation.
I1201 01:18:42.315861 13889 net.cpp:226] prelu3_5 needs backward computation.
I1201 01:18:42.315865 13889 net.cpp:226] conv3_5 needs backward computation.
I1201 01:18:42.315866 13889 net.cpp:226] pool2_5 needs backward computation.
I1201 01:18:42.315870 13889 net.cpp:226] prelu2_5 needs backward computation.
I1201 01:18:42.315872 13889 net.cpp:226] conv2_5 needs backward computation.
I1201 01:18:42.315876 13889 net.cpp:226] pool1_5 needs backward computation.
I1201 01:18:42.315877 13889 net.cpp:226] prelu1_5 needs backward computation.
I1201 01:18:42.315881 13889 net.cpp:226] conv1_5 needs backward computation.
I1201 01:18:42.315883 13889 net.cpp:226] prelu3_4 needs backward computation.
I1201 01:18:42.315886 13889 net.cpp:226] conv3_4 needs backward computation.
I1201 01:18:42.315889 13889 net.cpp:226] pool2_4 needs backward computation.
I1201 01:18:42.315891 13889 net.cpp:226] prelu2_4 needs backward computation.
I1201 01:18:42.315894 13889 net.cpp:226] conv2_4 needs backward computation.
I1201 01:18:42.315897 13889 net.cpp:226] pool1_4 needs backward computation.
I1201 01:18:42.315899 13889 net.cpp:226] prelu1_4 needs backward computation.
I1201 01:18:42.315902 13889 net.cpp:226] conv1_4 needs backward computation.
I1201 01:18:42.315906 13889 net.cpp:226] prelu3_3 needs backward computation.
I1201 01:18:42.315908 13889 net.cpp:226] conv3_3 needs backward computation.
I1201 01:18:42.315910 13889 net.cpp:226] pool2_3 needs backward computation.
I1201 01:18:42.315913 13889 net.cpp:226] prelu2_3 needs backward computation.
I1201 01:18:42.315917 13889 net.cpp:226] conv2_3 needs backward computation.
I1201 01:18:42.315918 13889 net.cpp:226] pool1_3 needs backward computation.
I1201 01:18:42.315922 13889 net.cpp:226] prelu1_3 needs backward computation.
I1201 01:18:42.315924 13889 net.cpp:226] conv1_3 needs backward computation.
I1201 01:18:42.315927 13889 net.cpp:226] prelu3_2 needs backward computation.
I1201 01:18:42.315929 13889 net.cpp:226] conv3_2 needs backward computation.
I1201 01:18:42.315932 13889 net.cpp:226] pool2_2 needs backward computation.
I1201 01:18:42.315935 13889 net.cpp:226] prelu2_2 needs backward computation.
I1201 01:18:42.315937 13889 net.cpp:226] conv2_2 needs backward computation.
I1201 01:18:42.315940 13889 net.cpp:226] pool1_2 needs backward computation.
I1201 01:18:42.315943 13889 net.cpp:226] prelu1_2 needs backward computation.
I1201 01:18:42.315948 13889 net.cpp:226] conv1_2 needs backward computation.
I1201 01:18:42.315951 13889 net.cpp:226] prelu3_1 needs backward computation.
I1201 01:18:42.315953 13889 net.cpp:226] conv3_1 needs backward computation.
I1201 01:18:42.315956 13889 net.cpp:226] pool2_1 needs backward computation.
I1201 01:18:42.315959 13889 net.cpp:226] prelu2_1 needs backward computation.
I1201 01:18:42.315961 13889 net.cpp:226] conv2_1 needs backward computation.
I1201 01:18:42.315964 13889 net.cpp:226] pool1_1 needs backward computation.
I1201 01:18:42.315966 13889 net.cpp:226] prelu1_1 needs backward computation.
I1201 01:18:42.315969 13889 net.cpp:226] conv1_1 needs backward computation.
I1201 01:18:42.315973 13889 net.cpp:228] slicer_target does not need backward computation.
I1201 01:18:42.315978 13889 net.cpp:228] slicer_data does not need backward computation.
I1201 01:18:42.315980 13889 net.cpp:228] data does not need backward computation.
I1201 01:18:42.315982 13889 net.cpp:270] This network produces output loss_1
I1201 01:18:42.315985 13889 net.cpp:270] This network produces output loss_2
I1201 01:18:42.315989 13889 net.cpp:270] This network produces output loss_3
I1201 01:18:42.315991 13889 net.cpp:270] This network produces output loss_4
I1201 01:18:42.315994 13889 net.cpp:270] This network produces output loss_5
I1201 01:18:42.316030 13889 net.cpp:283] Network initialization done.
I1201 01:18:42.316241 13889 solver.cpp:60] Solver scaffolding done.
I1201 01:18:42.330603 13889 solver.cpp:279] Solving lNet
I1201 01:18:42.330660 13889 solver.cpp:280] Learning Rate Policy: step
I1201 01:18:42.407791 13889 solver.cpp:228] Iteration 0, loss = 0.253994
I1201 01:18:42.407821 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.050541 (* 1 = 0.050541 loss)
I1201 01:18:42.407832 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.0372553 (* 1 = 0.0372553 loss)
I1201 01:18:42.407840 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.0456784 (* 1 = 0.0456784 loss)
I1201 01:18:42.407846 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.0491776 (* 1 = 0.0491776 loss)
I1201 01:18:42.407853 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.0713413 (* 1 = 0.0713413 loss)
I1201 01:18:42.407866 13889 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I1201 01:18:50.557131 13889 solver.cpp:228] Iteration 500, loss = 0.073117
I1201 01:18:50.557183 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00568851 (* 1 = 0.00568851 loss)
I1201 01:18:50.557190 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.0045904 (* 1 = 0.0045904 loss)
I1201 01:18:50.557194 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00889825 (* 1 = 0.00889825 loss)
I1201 01:18:50.557199 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00473854 (* 1 = 0.00473854 loss)
I1201 01:18:50.557204 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00593179 (* 1 = 0.00593179 loss)
I1201 01:18:50.557207 13889 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I1201 01:19:19.125751 13889 solver.cpp:228] Iteration 1000, loss = 0.0302909
I1201 01:19:19.125815 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00449098 (* 1 = 0.00449098 loss)
I1201 01:19:19.125823 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00393493 (* 1 = 0.00393493 loss)
I1201 01:19:19.125828 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00704729 (* 1 = 0.00704729 loss)
I1201 01:19:19.125839 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00417885 (* 1 = 0.00417885 loss)
I1201 01:19:19.125844 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00542844 (* 1 = 0.00542844 loss)
I1201 01:19:19.125849 13889 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I1201 01:19:27.349714 13889 solver.cpp:228] Iteration 1500, loss = 0.0257424
I1201 01:19:27.349755 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00437214 (* 1 = 0.00437214 loss)
I1201 01:19:27.349761 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00463672 (* 1 = 0.00463672 loss)
I1201 01:19:27.349766 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00543843 (* 1 = 0.00543843 loss)
I1201 01:19:27.349778 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00556078 (* 1 = 0.00556078 loss)
I1201 01:19:27.349783 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00473081 (* 1 = 0.00473081 loss)
I1201 01:19:27.349787 13889 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I1201 01:19:38.899833 13889 solver.cpp:228] Iteration 2000, loss = 0.0231191
I1201 01:19:38.899888 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00370342 (* 1 = 0.00370342 loss)
I1201 01:19:38.899895 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00422968 (* 1 = 0.00422968 loss)
I1201 01:19:38.899907 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00569455 (* 1 = 0.00569455 loss)
I1201 01:19:38.899912 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00403437 (* 1 = 0.00403437 loss)
I1201 01:19:38.899916 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00521609 (* 1 = 0.00521609 loss)
I1201 01:19:38.899921 13889 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I1201 01:19:50.449053 13889 solver.cpp:228] Iteration 2500, loss = 0.0219879
I1201 01:19:50.449123 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00309666 (* 1 = 0.00309666 loss)
I1201 01:19:50.449131 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00293051 (* 1 = 0.00293051 loss)
I1201 01:19:50.449136 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00393801 (* 1 = 0.00393801 loss)
I1201 01:19:50.449141 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00365142 (* 1 = 0.00365142 loss)
I1201 01:19:50.449146 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00302098 (* 1 = 0.00302098 loss)
I1201 01:19:50.449151 13889 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I1201 01:19:58.556351 13889 solver.cpp:228] Iteration 3000, loss = 0.0215406
I1201 01:19:58.556399 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00386079 (* 1 = 0.00386079 loss)
I1201 01:19:58.556408 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.004347 (* 1 = 0.004347 loss)
I1201 01:19:58.556413 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.0055649 (* 1 = 0.0055649 loss)
I1201 01:19:58.556419 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00331464 (* 1 = 0.00331464 loss)
I1201 01:19:58.556424 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00496765 (* 1 = 0.00496765 loss)
I1201 01:19:58.556428 13889 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I1201 01:20:09.265763 13889 solver.cpp:228] Iteration 3500, loss = 0.0208731
I1201 01:20:09.265822 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00333856 (* 1 = 0.00333856 loss)
I1201 01:20:09.265831 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.0033199 (* 1 = 0.0033199 loss)
I1201 01:20:09.265843 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00402281 (* 1 = 0.00402281 loss)
I1201 01:20:09.265849 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00286761 (* 1 = 0.00286761 loss)
I1201 01:20:09.265854 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00348196 (* 1 = 0.00348196 loss)
I1201 01:20:09.265858 13889 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I1201 01:20:14.158432 13889 solver.cpp:454] Snapshotting to binary proto file tmp/lnet_iter_3798.caffemodel
I1201 01:20:14.197989 13889 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/lnet_iter_3798.solverstate
I1201 01:20:14.203451 13889 solver.cpp:337] Iteration 3798, Testing net (#0)
I1201 01:20:22.221614 13889 solver.cpp:404]     Test net output #0: loss_1 = 0.00335166 (* 1 = 0.00335166 loss)
I1201 01:20:22.221654 13889 solver.cpp:404]     Test net output #1: loss_2 = 0.00328669 (* 1 = 0.00328669 loss)
I1201 01:20:22.221662 13889 solver.cpp:404]     Test net output #2: loss_3 = 0.00454026 (* 1 = 0.00454026 loss)
I1201 01:20:22.221671 13889 solver.cpp:404]     Test net output #3: loss_4 = 0.00389722 (* 1 = 0.00389722 loss)
I1201 01:20:22.221676 13889 solver.cpp:404]     Test net output #4: loss_5 = 0.00425611 (* 1 = 0.00425611 loss)
I1201 01:20:28.155016 13889 solver.cpp:228] Iteration 4000, loss = 0.0204525
I1201 01:20:28.155098 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00544646 (* 1 = 0.00544646 loss)
I1201 01:20:28.155109 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00392852 (* 1 = 0.00392852 loss)
I1201 01:20:28.155114 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00504255 (* 1 = 0.00504255 loss)
I1201 01:20:28.155120 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00574578 (* 1 = 0.00574578 loss)
I1201 01:20:28.155125 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00327278 (* 1 = 0.00327278 loss)
I1201 01:20:28.155130 13889 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I1201 01:20:36.308149 13889 solver.cpp:228] Iteration 4500, loss = 0.0199908
I1201 01:20:36.308185 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00352753 (* 1 = 0.00352753 loss)
I1201 01:20:36.308194 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00282262 (* 1 = 0.00282262 loss)
I1201 01:20:36.308200 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00550405 (* 1 = 0.00550405 loss)
I1201 01:20:36.308205 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00367441 (* 1 = 0.00367441 loss)
I1201 01:20:36.308210 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00407751 (* 1 = 0.00407751 loss)
I1201 01:20:36.308215 13889 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I1201 01:20:47.091998 13889 solver.cpp:228] Iteration 5000, loss = 0.0196626
I1201 01:20:47.092054 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00429242 (* 1 = 0.00429242 loss)
I1201 01:20:47.092063 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.0042725 (* 1 = 0.0042725 loss)
I1201 01:20:47.092073 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00442192 (* 1 = 0.00442192 loss)
I1201 01:20:47.092082 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00422553 (* 1 = 0.00422553 loss)
I1201 01:20:47.092087 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00555783 (* 1 = 0.00555783 loss)
I1201 01:20:47.092092 13889 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I1201 01:20:58.419911 13889 solver.cpp:228] Iteration 5500, loss = 0.0192128
I1201 01:20:58.419972 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00254502 (* 1 = 0.00254502 loss)
I1201 01:20:58.419981 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00212194 (* 1 = 0.00212194 loss)
I1201 01:20:58.419986 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.0039479 (* 1 = 0.0039479 loss)
I1201 01:20:58.419991 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00313588 (* 1 = 0.00313588 loss)
I1201 01:20:58.419996 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00269292 (* 1 = 0.00269292 loss)
I1201 01:20:58.420001 13889 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I1201 01:21:06.400230 13889 solver.cpp:228] Iteration 6000, loss = 0.0187441
I1201 01:21:06.400274 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00224513 (* 1 = 0.00224513 loss)
I1201 01:21:06.400284 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00294964 (* 1 = 0.00294964 loss)
I1201 01:21:06.400288 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00407302 (* 1 = 0.00407302 loss)
I1201 01:21:06.400295 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00511907 (* 1 = 0.00511907 loss)
I1201 01:21:06.400300 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00347439 (* 1 = 0.00347439 loss)
I1201 01:21:06.400305 13889 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I1201 01:21:17.692718 13889 solver.cpp:228] Iteration 6500, loss = 0.0189203
I1201 01:21:17.692780 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00314659 (* 1 = 0.00314659 loss)
I1201 01:21:17.692788 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00360103 (* 1 = 0.00360103 loss)
I1201 01:21:17.692793 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00388635 (* 1 = 0.00388635 loss)
I1201 01:21:17.692806 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00394674 (* 1 = 0.00394674 loss)
I1201 01:21:17.692811 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00411208 (* 1 = 0.00411208 loss)
I1201 01:21:17.692822 13889 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I1201 01:21:28.516865 13889 solver.cpp:228] Iteration 7000, loss = 0.0187108
I1201 01:21:28.516912 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00292064 (* 1 = 0.00292064 loss)
I1201 01:21:28.516921 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00304496 (* 1 = 0.00304496 loss)
I1201 01:21:28.516926 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00390628 (* 1 = 0.00390628 loss)
I1201 01:21:28.516932 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00489012 (* 1 = 0.00489012 loss)
I1201 01:21:28.516935 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00285344 (* 1 = 0.00285344 loss)
I1201 01:21:28.516939 13889 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I1201 01:21:36.799599 13889 solver.cpp:228] Iteration 7500, loss = 0.0186771
I1201 01:21:36.799646 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00378252 (* 1 = 0.00378252 loss)
I1201 01:21:36.799654 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00357448 (* 1 = 0.00357448 loss)
I1201 01:21:36.799659 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00307915 (* 1 = 0.00307915 loss)
I1201 01:21:36.799665 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00502053 (* 1 = 0.00502053 loss)
I1201 01:21:36.799670 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00432137 (* 1 = 0.00432137 loss)
I1201 01:21:36.799674 13889 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I1201 01:21:38.377290 13889 solver.cpp:454] Snapshotting to binary proto file tmp/lnet_iter_7596.caffemodel
I1201 01:21:38.398725 13889 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/lnet_iter_7596.solverstate
I1201 01:21:38.403221 13889 solver.cpp:337] Iteration 7596, Testing net (#0)
I1201 01:21:49.198211 13889 solver.cpp:404]     Test net output #0: loss_1 = 0.00306395 (* 1 = 0.00306395 loss)
I1201 01:21:49.198246 13889 solver.cpp:404]     Test net output #1: loss_2 = 0.00293984 (* 1 = 0.00293984 loss)
I1201 01:21:49.198252 13889 solver.cpp:404]     Test net output #2: loss_3 = 0.00453918 (* 1 = 0.00453918 loss)
I1201 01:21:49.198257 13889 solver.cpp:404]     Test net output #3: loss_4 = 0.00351021 (* 1 = 0.00351021 loss)
I1201 01:21:49.198261 13889 solver.cpp:404]     Test net output #4: loss_5 = 0.0035061 (* 1 = 0.0035061 loss)
I1201 01:21:58.483723 13889 solver.cpp:228] Iteration 8000, loss = 0.0171931
I1201 01:21:58.483778 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00235247 (* 1 = 0.00235247 loss)
I1201 01:21:58.483786 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00331027 (* 1 = 0.00331027 loss)
I1201 01:21:58.483790 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00372463 (* 1 = 0.00372463 loss)
I1201 01:21:58.483795 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.0041507 (* 1 = 0.0041507 loss)
I1201 01:21:58.483800 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.0035825 (* 1 = 0.0035825 loss)
I1201 01:21:58.483804 13889 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I1201 01:22:09.359684 13889 solver.cpp:228] Iteration 8500, loss = 0.0165271
I1201 01:22:09.359733 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00281449 (* 1 = 0.00281449 loss)
I1201 01:22:09.359742 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00318071 (* 1 = 0.00318071 loss)
I1201 01:22:09.359747 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00388661 (* 1 = 0.00388661 loss)
I1201 01:22:09.359752 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00306306 (* 1 = 0.00306306 loss)
I1201 01:22:09.359757 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00282481 (* 1 = 0.00282481 loss)
I1201 01:22:09.359761 13889 sgd_solver.cpp:106] Iteration 8500, lr = 0.01
I1201 01:22:17.604048 13889 solver.cpp:228] Iteration 9000, loss = 0.0163876
I1201 01:22:17.604084 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00261479 (* 1 = 0.00261479 loss)
I1201 01:22:17.604092 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00213925 (* 1 = 0.00213925 loss)
I1201 01:22:17.604104 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00318818 (* 1 = 0.00318818 loss)
I1201 01:22:17.604110 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00315801 (* 1 = 0.00315801 loss)
I1201 01:22:17.604115 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00283154 (* 1 = 0.00283154 loss)
I1201 01:22:17.604120 13889 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I1201 01:22:28.680220 13889 solver.cpp:228] Iteration 9500, loss = 0.0161691
I1201 01:22:28.680281 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.0022668 (* 1 = 0.0022668 loss)
I1201 01:22:28.680289 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00203646 (* 1 = 0.00203646 loss)
I1201 01:22:28.680296 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00394031 (* 1 = 0.00394031 loss)
I1201 01:22:28.680301 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00270199 (* 1 = 0.00270199 loss)
I1201 01:22:28.680307 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00327934 (* 1 = 0.00327934 loss)
I1201 01:22:28.680312 13889 sgd_solver.cpp:106] Iteration 9500, lr = 0.01
I1201 01:22:39.779376 13889 solver.cpp:228] Iteration 10000, loss = 0.0161661
I1201 01:22:39.779441 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00357463 (* 1 = 0.00357463 loss)
I1201 01:22:39.779449 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00195093 (* 1 = 0.00195093 loss)
I1201 01:22:39.779454 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00395326 (* 1 = 0.00395326 loss)
I1201 01:22:39.779460 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00461781 (* 1 = 0.00461781 loss)
I1201 01:22:39.779464 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.0035535 (* 1 = 0.0035535 loss)
I1201 01:22:39.779469 13889 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I1201 01:22:47.755043 13889 solver.cpp:228] Iteration 10500, loss = 0.0163313
I1201 01:22:47.755138 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00315553 (* 1 = 0.00315553 loss)
I1201 01:22:47.755161 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00233766 (* 1 = 0.00233766 loss)
I1201 01:22:47.755170 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.0037502 (* 1 = 0.0037502 loss)
I1201 01:22:47.755175 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00291373 (* 1 = 0.00291373 loss)
I1201 01:22:47.755180 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00542525 (* 1 = 0.00542525 loss)
I1201 01:22:47.755185 13889 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I1201 01:22:58.540278 13889 solver.cpp:228] Iteration 11000, loss = 0.0162648
I1201 01:22:58.540341 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00289411 (* 1 = 0.00289411 loss)
I1201 01:22:58.540349 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00336389 (* 1 = 0.00336389 loss)
I1201 01:22:58.540355 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00297955 (* 1 = 0.00297955 loss)
I1201 01:22:58.540360 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00257894 (* 1 = 0.00257894 loss)
I1201 01:22:58.540365 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00287253 (* 1 = 0.00287253 loss)
I1201 01:22:58.540369 13889 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I1201 01:23:04.857266 13889 solver.cpp:454] Snapshotting to binary proto file tmp/lnet_iter_11394.caffemodel
I1201 01:23:04.883014 13889 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/lnet_iter_11394.solverstate
I1201 01:23:04.887832 13889 solver.cpp:337] Iteration 11394, Testing net (#0)
I1201 01:23:16.248997 13889 solver.cpp:404]     Test net output #0: loss_1 = 0.00288795 (* 1 = 0.00288795 loss)
I1201 01:23:16.249039 13889 solver.cpp:404]     Test net output #1: loss_2 = 0.00274911 (* 1 = 0.00274911 loss)
I1201 01:23:16.249045 13889 solver.cpp:404]     Test net output #2: loss_3 = 0.00372276 (* 1 = 0.00372276 loss)
I1201 01:23:16.249050 13889 solver.cpp:404]     Test net output #3: loss_4 = 0.00333149 (* 1 = 0.00333149 loss)
I1201 01:23:16.249064 13889 solver.cpp:404]     Test net output #4: loss_5 = 0.00323813 (* 1 = 0.00323813 loss)
I1201 01:23:21.049931 13889 solver.cpp:228] Iteration 11500, loss = 0.0162354
I1201 01:23:21.049989 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00225315 (* 1 = 0.00225315 loss)
I1201 01:23:21.049998 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00283493 (* 1 = 0.00283493 loss)
I1201 01:23:21.050004 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.0024444 (* 1 = 0.0024444 loss)
I1201 01:23:21.050009 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00217586 (* 1 = 0.00217586 loss)
I1201 01:23:21.050014 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00437392 (* 1 = 0.00437392 loss)
I1201 01:23:21.050017 13889 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I1201 01:23:29.035156 13889 solver.cpp:228] Iteration 12000, loss = 0.016268
I1201 01:23:29.035218 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00269556 (* 1 = 0.00269556 loss)
I1201 01:23:29.035225 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00340008 (* 1 = 0.00340008 loss)
I1201 01:23:29.035231 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00318753 (* 1 = 0.00318753 loss)
I1201 01:23:29.035236 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00217107 (* 1 = 0.00217107 loss)
I1201 01:23:29.035243 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00293848 (* 1 = 0.00293848 loss)
I1201 01:23:29.035246 13889 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I1201 01:23:40.397996 13889 solver.cpp:228] Iteration 12500, loss = 0.0162381
I1201 01:23:40.398047 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00299271 (* 1 = 0.00299271 loss)
I1201 01:23:40.398056 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00221438 (* 1 = 0.00221438 loss)
I1201 01:23:40.398061 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00273352 (* 1 = 0.00273352 loss)
I1201 01:23:40.398066 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00244575 (* 1 = 0.00244575 loss)
I1201 01:23:40.398077 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00226354 (* 1 = 0.00226354 loss)
I1201 01:23:40.398082 13889 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I1201 01:23:51.651432 13889 solver.cpp:228] Iteration 13000, loss = 0.0162567
I1201 01:23:51.651504 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.0028757 (* 1 = 0.0028757 loss)
I1201 01:23:51.651513 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00206775 (* 1 = 0.00206775 loss)
I1201 01:23:51.651520 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00494971 (* 1 = 0.00494971 loss)
I1201 01:23:51.651525 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00368384 (* 1 = 0.00368384 loss)
I1201 01:23:51.651530 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00501316 (* 1 = 0.00501316 loss)
I1201 01:23:51.651535 13889 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I1201 01:23:59.656445 13889 solver.cpp:228] Iteration 13500, loss = 0.0159939
I1201 01:23:59.656507 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00171914 (* 1 = 0.00171914 loss)
I1201 01:23:59.656514 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00349543 (* 1 = 0.00349543 loss)
I1201 01:23:59.656519 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00318666 (* 1 = 0.00318666 loss)
I1201 01:23:59.656524 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00240498 (* 1 = 0.00240498 loss)
I1201 01:23:59.656530 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00466073 (* 1 = 0.00466073 loss)
I1201 01:23:59.656535 13889 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I1201 01:24:10.841874 13889 solver.cpp:228] Iteration 14000, loss = 0.01611
I1201 01:24:10.841934 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00278035 (* 1 = 0.00278035 loss)
I1201 01:24:10.841943 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00206427 (* 1 = 0.00206427 loss)
I1201 01:24:10.841948 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00401873 (* 1 = 0.00401873 loss)
I1201 01:24:10.841962 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00301269 (* 1 = 0.00301269 loss)
I1201 01:24:10.841969 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00248857 (* 1 = 0.00248857 loss)
I1201 01:24:10.841972 13889 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I1201 01:24:18.857280 13889 solver.cpp:228] Iteration 14500, loss = 0.0162818
I1201 01:24:18.857342 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00295742 (* 1 = 0.00295742 loss)
I1201 01:24:18.857349 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00182244 (* 1 = 0.00182244 loss)
I1201 01:24:18.857354 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00287818 (* 1 = 0.00287818 loss)
I1201 01:24:18.857359 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00405652 (* 1 = 0.00405652 loss)
I1201 01:24:18.857364 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00304124 (* 1 = 0.00304124 loss)
I1201 01:24:18.857368 13889 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I1201 01:24:30.043174 13889 solver.cpp:228] Iteration 15000, loss = 0.0161674
I1201 01:24:30.043233 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.0029544 (* 1 = 0.0029544 loss)
I1201 01:24:30.043242 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.002608 (* 1 = 0.002608 loss)
I1201 01:24:30.043248 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00302143 (* 1 = 0.00302143 loss)
I1201 01:24:30.043254 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00375621 (* 1 = 0.00375621 loss)
I1201 01:24:30.043259 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00210728 (* 1 = 0.00210728 loss)
I1201 01:24:30.043263 13889 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I1201 01:24:33.113126 13889 solver.cpp:454] Snapshotting to binary proto file tmp/lnet_iter_15192.caffemodel
I1201 01:24:33.130820 13889 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/lnet_iter_15192.solverstate
I1201 01:24:33.135408 13889 solver.cpp:337] Iteration 15192, Testing net (#0)
I1201 01:24:43.797652 13889 solver.cpp:404]     Test net output #0: loss_1 = 0.00286611 (* 1 = 0.00286611 loss)
I1201 01:24:43.797683 13889 solver.cpp:404]     Test net output #1: loss_2 = 0.00272936 (* 1 = 0.00272936 loss)
I1201 01:24:43.797690 13889 solver.cpp:404]     Test net output #2: loss_3 = 0.00371428 (* 1 = 0.00371428 loss)
I1201 01:24:43.797695 13889 solver.cpp:404]     Test net output #3: loss_4 = 0.00330926 (* 1 = 0.00330926 loss)
I1201 01:24:43.797699 13889 solver.cpp:404]     Test net output #4: loss_5 = 0.00318664 (* 1 = 0.00318664 loss)
I1201 01:24:51.700584 13889 solver.cpp:228] Iteration 15500, loss = 0.0160505
I1201 01:24:51.700645 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00447169 (* 1 = 0.00447169 loss)
I1201 01:24:51.700654 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00340166 (* 1 = 0.00340166 loss)
I1201 01:24:51.700659 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00329706 (* 1 = 0.00329706 loss)
I1201 01:24:51.700664 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00401142 (* 1 = 0.00401142 loss)
I1201 01:24:51.700667 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00406151 (* 1 = 0.00406151 loss)
I1201 01:24:51.700672 13889 sgd_solver.cpp:106] Iteration 15500, lr = 0.001
I1201 01:25:02.614078 13889 solver.cpp:228] Iteration 16000, loss = 0.0160365
I1201 01:25:02.614132 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00251014 (* 1 = 0.00251014 loss)
I1201 01:25:02.614140 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00287727 (* 1 = 0.00287727 loss)
I1201 01:25:02.614145 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00318524 (* 1 = 0.00318524 loss)
I1201 01:25:02.614151 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00328734 (* 1 = 0.00328734 loss)
I1201 01:25:02.614156 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.0030176 (* 1 = 0.0030176 loss)
I1201 01:25:02.614161 13889 sgd_solver.cpp:106] Iteration 16000, lr = 0.001
I1201 01:25:10.889914 13889 solver.cpp:228] Iteration 16500, loss = 0.015945
I1201 01:25:10.889943 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00382431 (* 1 = 0.00382431 loss)
I1201 01:25:10.889950 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00307363 (* 1 = 0.00307363 loss)
I1201 01:25:10.889955 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00525672 (* 1 = 0.00525672 loss)
I1201 01:25:10.889961 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00274396 (* 1 = 0.00274396 loss)
I1201 01:25:10.889964 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00445582 (* 1 = 0.00445582 loss)
I1201 01:25:10.889968 13889 sgd_solver.cpp:106] Iteration 16500, lr = 0.001
I1201 01:25:21.891321 13889 solver.cpp:228] Iteration 17000, loss = 0.0158427
I1201 01:25:21.891366 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00250363 (* 1 = 0.00250363 loss)
I1201 01:25:21.891372 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00355327 (* 1 = 0.00355327 loss)
I1201 01:25:21.891378 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00282756 (* 1 = 0.00282756 loss)
I1201 01:25:21.891383 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00405116 (* 1 = 0.00405116 loss)
I1201 01:25:21.891388 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00363036 (* 1 = 0.00363036 loss)
I1201 01:25:21.891392 13889 sgd_solver.cpp:106] Iteration 17000, lr = 0.001
I1201 01:25:30.177759 13889 solver.cpp:228] Iteration 17500, loss = 0.0157876
I1201 01:25:30.177784 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00293989 (* 1 = 0.00293989 loss)
I1201 01:25:30.177791 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00168447 (* 1 = 0.00168447 loss)
I1201 01:25:30.177796 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00372882 (* 1 = 0.00372882 loss)
I1201 01:25:30.177800 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00369098 (* 1 = 0.00369098 loss)
I1201 01:25:30.177805 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00319732 (* 1 = 0.00319732 loss)
I1201 01:25:30.177810 13889 sgd_solver.cpp:106] Iteration 17500, lr = 0.001
I1201 01:25:41.572302 13889 solver.cpp:228] Iteration 18000, loss = 0.0159542
I1201 01:25:41.572366 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00407635 (* 1 = 0.00407635 loss)
I1201 01:25:41.572376 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00232725 (* 1 = 0.00232725 loss)
I1201 01:25:41.572381 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00402464 (* 1 = 0.00402464 loss)
I1201 01:25:41.572386 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00359838 (* 1 = 0.00359838 loss)
I1201 01:25:41.572391 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00273071 (* 1 = 0.00273071 loss)
I1201 01:25:41.572396 13889 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I1201 01:25:52.273763 13889 solver.cpp:228] Iteration 18500, loss = 0.0158963
I1201 01:25:52.273844 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00227308 (* 1 = 0.00227308 loss)
I1201 01:25:52.273851 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00241376 (* 1 = 0.00241376 loss)
I1201 01:25:52.273857 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00344193 (* 1 = 0.00344193 loss)
I1201 01:25:52.273864 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00359312 (* 1 = 0.00359312 loss)
I1201 01:25:52.273867 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00258085 (* 1 = 0.00258085 loss)
I1201 01:25:52.273872 13889 sgd_solver.cpp:106] Iteration 18500, lr = 0.001
I1201 01:26:00.085115 13889 solver.cpp:454] Snapshotting to binary proto file tmp/lnet_iter_18990.caffemodel
I1201 01:26:00.102434 13889 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/lnet_iter_18990.solverstate
I1201 01:26:00.107306 13889 solver.cpp:337] Iteration 18990, Testing net (#0)
I1201 01:26:11.225370 13889 solver.cpp:404]     Test net output #0: loss_1 = 0.00283088 (* 1 = 0.00283088 loss)
I1201 01:26:11.225411 13889 solver.cpp:404]     Test net output #1: loss_2 = 0.00269652 (* 1 = 0.00269652 loss)
I1201 01:26:11.225425 13889 solver.cpp:404]     Test net output #2: loss_3 = 0.00357872 (* 1 = 0.00357872 loss)
I1201 01:26:11.225430 13889 solver.cpp:404]     Test net output #3: loss_4 = 0.00327113 (* 1 = 0.00327113 loss)
I1201 01:26:11.225435 13889 solver.cpp:404]     Test net output #4: loss_5 = 0.00312724 (* 1 = 0.00312724 loss)
I1201 01:26:14.485425 13889 solver.cpp:228] Iteration 19000, loss = 0.0158422
I1201 01:26:14.485493 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00312178 (* 1 = 0.00312178 loss)
I1201 01:26:14.485502 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00215979 (* 1 = 0.00215979 loss)
I1201 01:26:14.485507 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.0031274 (* 1 = 0.0031274 loss)
I1201 01:26:14.485512 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00251122 (* 1 = 0.00251122 loss)
I1201 01:26:14.485517 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00270821 (* 1 = 0.00270821 loss)
I1201 01:26:14.485522 13889 sgd_solver.cpp:106] Iteration 19000, lr = 0.001
I1201 01:26:22.376014 13889 solver.cpp:228] Iteration 19500, loss = 0.0159834
I1201 01:26:22.376044 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00328801 (* 1 = 0.00328801 loss)
I1201 01:26:22.376052 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00306829 (* 1 = 0.00306829 loss)
I1201 01:26:22.376057 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00473463 (* 1 = 0.00473463 loss)
I1201 01:26:22.376062 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00313684 (* 1 = 0.00313684 loss)
I1201 01:26:22.376071 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00422361 (* 1 = 0.00422361 loss)
I1201 01:26:22.376078 13889 sgd_solver.cpp:106] Iteration 19500, lr = 0.001
I1201 01:26:33.690744 13889 solver.cpp:228] Iteration 20000, loss = 0.0159634
I1201 01:26:33.690800 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00344023 (* 1 = 0.00344023 loss)
I1201 01:26:33.690810 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.0024795 (* 1 = 0.0024795 loss)
I1201 01:26:33.690815 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00241054 (* 1 = 0.00241054 loss)
I1201 01:26:33.690821 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00389777 (* 1 = 0.00389777 loss)
I1201 01:26:33.690826 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00208993 (* 1 = 0.00208993 loss)
I1201 01:26:33.690830 13889 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I1201 01:26:41.699523 13889 solver.cpp:228] Iteration 20500, loss = 0.0160034
I1201 01:26:41.699558 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00360282 (* 1 = 0.00360282 loss)
I1201 01:26:41.699565 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00277889 (* 1 = 0.00277889 loss)
I1201 01:26:41.699571 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.0029705 (* 1 = 0.0029705 loss)
I1201 01:26:41.699576 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00258962 (* 1 = 0.00258962 loss)
I1201 01:26:41.699581 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00254138 (* 1 = 0.00254138 loss)
I1201 01:26:41.699585 13889 sgd_solver.cpp:106] Iteration 20500, lr = 0.001
I1201 01:26:52.796972 13889 solver.cpp:228] Iteration 21000, loss = 0.0157241
I1201 01:26:52.797030 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.0039544 (* 1 = 0.0039544 loss)
I1201 01:26:52.797039 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00257364 (* 1 = 0.00257364 loss)
I1201 01:26:52.797044 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00261963 (* 1 = 0.00261963 loss)
I1201 01:26:52.797049 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00221658 (* 1 = 0.00221658 loss)
I1201 01:26:52.797055 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00369677 (* 1 = 0.00369677 loss)
I1201 01:26:52.797058 13889 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I1201 01:27:03.928114 13889 solver.cpp:228] Iteration 21500, loss = 0.0157425
I1201 01:27:03.928167 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00331556 (* 1 = 0.00331556 loss)
I1201 01:27:03.928185 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00177503 (* 1 = 0.00177503 loss)
I1201 01:27:03.928190 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00307003 (* 1 = 0.00307003 loss)
I1201 01:27:03.928196 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00289085 (* 1 = 0.00289085 loss)
I1201 01:27:03.928201 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00339555 (* 1 = 0.00339555 loss)
I1201 01:27:03.928206 13889 sgd_solver.cpp:106] Iteration 21500, lr = 0.001
I1201 01:27:11.885077 13889 solver.cpp:228] Iteration 22000, loss = 0.0160007
I1201 01:27:11.885107 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00301184 (* 1 = 0.00301184 loss)
I1201 01:27:11.885113 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00344118 (* 1 = 0.00344118 loss)
I1201 01:27:11.885118 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00346187 (* 1 = 0.00346187 loss)
I1201 01:27:11.885123 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00262631 (* 1 = 0.00262631 loss)
I1201 01:27:11.885128 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00236867 (* 1 = 0.00236867 loss)
I1201 01:27:11.885133 13889 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I1201 01:27:22.659423 13889 solver.cpp:228] Iteration 22500, loss = 0.0158299
I1201 01:27:22.659482 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.0045378 (* 1 = 0.0045378 loss)
I1201 01:27:22.659489 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00256225 (* 1 = 0.00256225 loss)
I1201 01:27:22.659494 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00400552 (* 1 = 0.00400552 loss)
I1201 01:27:22.659499 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00227833 (* 1 = 0.00227833 loss)
I1201 01:27:22.659505 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00284971 (* 1 = 0.00284971 loss)
I1201 01:27:22.659509 13889 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I1201 01:27:27.289752 13889 solver.cpp:454] Snapshotting to binary proto file tmp/lnet_iter_22788.caffemodel
I1201 01:27:27.307672 13889 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/lnet_iter_22788.solverstate
I1201 01:27:27.312543 13889 solver.cpp:337] Iteration 22788, Testing net (#0)
I1201 01:27:38.572363 13889 solver.cpp:404]     Test net output #0: loss_1 = 0.00282906 (* 1 = 0.00282906 loss)
I1201 01:27:38.572402 13889 solver.cpp:404]     Test net output #1: loss_2 = 0.00269382 (* 1 = 0.00269382 loss)
I1201 01:27:38.572409 13889 solver.cpp:404]     Test net output #2: loss_3 = 0.00357724 (* 1 = 0.00357724 loss)
I1201 01:27:38.572414 13889 solver.cpp:404]     Test net output #3: loss_4 = 0.00326956 (* 1 = 0.00326956 loss)
I1201 01:27:38.572418 13889 solver.cpp:404]     Test net output #4: loss_5 = 0.00312356 (* 1 = 0.00312356 loss)
I1201 01:27:45.049232 13889 solver.cpp:228] Iteration 23000, loss = 0.015917
I1201 01:27:45.049284 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00338213 (* 1 = 0.00338213 loss)
I1201 01:27:45.049291 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00335747 (* 1 = 0.00335747 loss)
I1201 01:27:45.049296 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00275616 (* 1 = 0.00275616 loss)
I1201 01:27:45.049301 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.0037573 (* 1 = 0.0037573 loss)
I1201 01:27:45.049306 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00264363 (* 1 = 0.00264363 loss)
I1201 01:27:45.049311 13889 sgd_solver.cpp:106] Iteration 23000, lr = 0.0001
I1201 01:27:53.046164 13889 solver.cpp:228] Iteration 23500, loss = 0.0159254
I1201 01:27:53.046193 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00231421 (* 1 = 0.00231421 loss)
I1201 01:27:53.046200 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00201511 (* 1 = 0.00201511 loss)
I1201 01:27:53.046205 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00446428 (* 1 = 0.00446428 loss)
I1201 01:27:53.046210 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00418008 (* 1 = 0.00418008 loss)
I1201 01:27:53.046223 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00294609 (* 1 = 0.00294609 loss)
I1201 01:27:53.046228 13889 sgd_solver.cpp:106] Iteration 23500, lr = 0.0001
I1201 01:28:04.307548 13889 solver.cpp:228] Iteration 24000, loss = 0.0158902
I1201 01:28:04.307595 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00352244 (* 1 = 0.00352244 loss)
I1201 01:28:04.307602 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00229231 (* 1 = 0.00229231 loss)
I1201 01:28:04.307608 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00394078 (* 1 = 0.00394078 loss)
I1201 01:28:04.307613 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00233423 (* 1 = 0.00233423 loss)
I1201 01:28:04.307618 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00304635 (* 1 = 0.00304635 loss)
I1201 01:28:04.307622 13889 sgd_solver.cpp:106] Iteration 24000, lr = 0.0001
I1201 01:28:15.476827 13889 solver.cpp:228] Iteration 24500, loss = 0.0158455
I1201 01:28:15.476887 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00262101 (* 1 = 0.00262101 loss)
I1201 01:28:15.476896 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00268535 (* 1 = 0.00268535 loss)
I1201 01:28:15.476900 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.0034086 (* 1 = 0.0034086 loss)
I1201 01:28:15.476905 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00173262 (* 1 = 0.00173262 loss)
I1201 01:28:15.476910 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00198608 (* 1 = 0.00198608 loss)
I1201 01:28:15.476915 13889 sgd_solver.cpp:106] Iteration 24500, lr = 0.0001
I1201 01:28:23.426853 13889 solver.cpp:228] Iteration 25000, loss = 0.0157081
I1201 01:28:23.426883 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00273635 (* 1 = 0.00273635 loss)
I1201 01:28:23.426892 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00200355 (* 1 = 0.00200355 loss)
I1201 01:28:23.426898 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00429665 (* 1 = 0.00429665 loss)
I1201 01:28:23.426903 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00334162 (* 1 = 0.00334162 loss)
I1201 01:28:23.426906 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00385287 (* 1 = 0.00385287 loss)
I1201 01:28:23.426911 13889 sgd_solver.cpp:106] Iteration 25000, lr = 0.0001
I1201 01:28:34.506984 13889 solver.cpp:228] Iteration 25500, loss = 0.0159006
I1201 01:28:34.507043 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00290785 (* 1 = 0.00290785 loss)
I1201 01:28:34.507051 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00331995 (* 1 = 0.00331995 loss)
I1201 01:28:34.507056 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00480536 (* 1 = 0.00480536 loss)
I1201 01:28:34.507062 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.0051691 (* 1 = 0.0051691 loss)
I1201 01:28:34.507071 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00383768 (* 1 = 0.00383768 loss)
I1201 01:28:34.507077 13889 sgd_solver.cpp:106] Iteration 25500, lr = 0.0001
I1201 01:28:45.269372 13889 solver.cpp:228] Iteration 26000, loss = 0.0158615
I1201 01:28:45.269433 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.0019955 (* 1 = 0.0019955 loss)
I1201 01:28:45.269443 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00221096 (* 1 = 0.00221096 loss)
I1201 01:28:45.269448 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00273243 (* 1 = 0.00273243 loss)
I1201 01:28:45.269453 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00367208 (* 1 = 0.00367208 loss)
I1201 01:28:45.269457 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00306161 (* 1 = 0.00306161 loss)
I1201 01:28:45.269462 13889 sgd_solver.cpp:106] Iteration 26000, lr = 0.0001
I1201 01:28:53.205037 13889 solver.cpp:228] Iteration 26500, loss = 0.0158344
I1201 01:28:53.205073 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00425526 (* 1 = 0.00425526 loss)
I1201 01:28:53.205083 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00291855 (* 1 = 0.00291855 loss)
I1201 01:28:53.205098 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00585893 (* 1 = 0.00585893 loss)
I1201 01:28:53.205103 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00507643 (* 1 = 0.00507643 loss)
I1201 01:28:53.205108 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00352053 (* 1 = 0.00352053 loss)
I1201 01:28:53.205112 13889 sgd_solver.cpp:106] Iteration 26500, lr = 0.0001
I1201 01:28:54.571749 13889 solver.cpp:454] Snapshotting to binary proto file tmp/lnet_iter_26586.caffemodel
I1201 01:28:54.589095 13889 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/lnet_iter_26586.solverstate
I1201 01:28:54.593952 13889 solver.cpp:337] Iteration 26586, Testing net (#0)
I1201 01:29:05.846704 13889 solver.cpp:404]     Test net output #0: loss_1 = 0.00282679 (* 1 = 0.00282679 loss)
I1201 01:29:05.846748 13889 solver.cpp:404]     Test net output #1: loss_2 = 0.00269316 (* 1 = 0.00269316 loss)
I1201 01:29:05.846755 13889 solver.cpp:404]     Test net output #2: loss_3 = 0.00357383 (* 1 = 0.00357383 loss)
I1201 01:29:05.846760 13889 solver.cpp:404]     Test net output #3: loss_4 = 0.0032621 (* 1 = 0.0032621 loss)
I1201 01:29:05.846765 13889 solver.cpp:404]     Test net output #4: loss_5 = 0.00311879 (* 1 = 0.00311879 loss)
I1201 01:29:15.754319 13889 solver.cpp:228] Iteration 27000, loss = 0.0158613
I1201 01:29:15.754367 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00253382 (* 1 = 0.00253382 loss)
I1201 01:29:15.754375 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00378086 (* 1 = 0.00378086 loss)
I1201 01:29:15.754380 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.0027606 (* 1 = 0.0027606 loss)
I1201 01:29:15.754386 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.0030602 (* 1 = 0.0030602 loss)
I1201 01:29:15.754390 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00339195 (* 1 = 0.00339195 loss)
I1201 01:29:15.754395 13889 sgd_solver.cpp:106] Iteration 27000, lr = 0.0001
I1201 01:29:26.784533 13889 solver.cpp:228] Iteration 27500, loss = 0.0160132
I1201 01:29:26.784597 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00260418 (* 1 = 0.00260418 loss)
I1201 01:29:26.784605 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00227174 (* 1 = 0.00227174 loss)
I1201 01:29:26.784610 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00485485 (* 1 = 0.00485485 loss)
I1201 01:29:26.784620 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00213984 (* 1 = 0.00213984 loss)
I1201 01:29:26.784624 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00200902 (* 1 = 0.00200902 loss)
I1201 01:29:26.784628 13889 sgd_solver.cpp:106] Iteration 27500, lr = 0.0001
I1201 01:29:34.997745 13889 solver.cpp:228] Iteration 28000, loss = 0.0159104
I1201 01:29:34.997782 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00385662 (* 1 = 0.00385662 loss)
I1201 01:29:34.997789 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00300132 (* 1 = 0.00300132 loss)
I1201 01:29:34.997794 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00478025 (* 1 = 0.00478025 loss)
I1201 01:29:34.997799 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00264861 (* 1 = 0.00264861 loss)
I1201 01:29:34.997804 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00223745 (* 1 = 0.00223745 loss)
I1201 01:29:34.997808 13889 sgd_solver.cpp:106] Iteration 28000, lr = 0.0001
I1201 01:29:45.956255 13889 solver.cpp:228] Iteration 28500, loss = 0.0157164
I1201 01:29:45.956302 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00147654 (* 1 = 0.00147654 loss)
I1201 01:29:45.956310 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00332098 (* 1 = 0.00332098 loss)
I1201 01:29:45.956315 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00294858 (* 1 = 0.00294858 loss)
I1201 01:29:45.956318 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00242073 (* 1 = 0.00242073 loss)
I1201 01:29:45.956323 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00274193 (* 1 = 0.00274193 loss)
I1201 01:29:45.956341 13889 sgd_solver.cpp:106] Iteration 28500, lr = 0.0001
I1201 01:29:56.903491 13889 solver.cpp:228] Iteration 29000, loss = 0.0157294
I1201 01:29:56.903544 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00244447 (* 1 = 0.00244447 loss)
I1201 01:29:56.903553 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00292659 (* 1 = 0.00292659 loss)
I1201 01:29:56.903558 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00372676 (* 1 = 0.00372676 loss)
I1201 01:29:56.903563 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.0029532 (* 1 = 0.0029532 loss)
I1201 01:29:56.903568 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00256468 (* 1 = 0.00256468 loss)
I1201 01:29:56.903580 13889 sgd_solver.cpp:106] Iteration 29000, lr = 0.0001
I1201 01:30:05.124603 13889 solver.cpp:228] Iteration 29500, loss = 0.0159297
I1201 01:30:05.124629 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00237631 (* 1 = 0.00237631 loss)
I1201 01:30:05.124635 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00371773 (* 1 = 0.00371773 loss)
I1201 01:30:05.124640 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00341247 (* 1 = 0.00341247 loss)
I1201 01:30:05.124645 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00316825 (* 1 = 0.00316825 loss)
I1201 01:30:05.124650 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00438915 (* 1 = 0.00438915 loss)
I1201 01:30:05.124653 13889 sgd_solver.cpp:106] Iteration 29500, lr = 0.0001
I1201 01:30:15.746513 13889 solver.cpp:228] Iteration 30000, loss = 0.0158402
I1201 01:30:15.746557 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00399585 (* 1 = 0.00399585 loss)
I1201 01:30:15.746565 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00479458 (* 1 = 0.00479458 loss)
I1201 01:30:15.746570 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00360437 (* 1 = 0.00360437 loss)
I1201 01:30:15.746574 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00240354 (* 1 = 0.00240354 loss)
I1201 01:30:15.746579 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00433849 (* 1 = 0.00433849 loss)
I1201 01:30:15.746584 13889 sgd_solver.cpp:106] Iteration 30000, lr = 0.0001
I1201 01:30:22.040917 13889 solver.cpp:454] Snapshotting to binary proto file tmp/lnet_iter_30384.caffemodel
I1201 01:30:22.057526 13889 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/lnet_iter_30384.solverstate
I1201 01:30:22.069106 13889 solver.cpp:337] Iteration 30384, Testing net (#0)
I1201 01:30:33.101972 13889 solver.cpp:404]     Test net output #0: loss_1 = 0.00282676 (* 1 = 0.00282676 loss)
I1201 01:30:33.102006 13889 solver.cpp:404]     Test net output #1: loss_2 = 0.00269376 (* 1 = 0.00269376 loss)
I1201 01:30:33.102012 13889 solver.cpp:404]     Test net output #2: loss_3 = 0.00357388 (* 1 = 0.00357388 loss)
I1201 01:30:33.102016 13889 solver.cpp:404]     Test net output #3: loss_4 = 0.00326323 (* 1 = 0.00326323 loss)
I1201 01:30:33.102021 13889 solver.cpp:404]     Test net output #4: loss_5 = 0.00311986 (* 1 = 0.00311986 loss)
I1201 01:30:37.666543 13889 solver.cpp:228] Iteration 30500, loss = 0.0158473
I1201 01:30:37.666586 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00341632 (* 1 = 0.00341632 loss)
I1201 01:30:37.666594 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00306771 (* 1 = 0.00306771 loss)
I1201 01:30:37.666599 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00234419 (* 1 = 0.00234419 loss)
I1201 01:30:37.666604 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00261458 (* 1 = 0.00261458 loss)
I1201 01:30:37.666609 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00188275 (* 1 = 0.00188275 loss)
I1201 01:30:37.666613 13889 sgd_solver.cpp:106] Iteration 30500, lr = 1e-05
I1201 01:30:45.966298 13889 solver.cpp:228] Iteration 31000, loss = 0.0159243
I1201 01:30:45.966323 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00220912 (* 1 = 0.00220912 loss)
I1201 01:30:45.966331 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00260809 (* 1 = 0.00260809 loss)
I1201 01:30:45.966343 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00412651 (* 1 = 0.00412651 loss)
I1201 01:30:45.966348 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00272464 (* 1 = 0.00272464 loss)
I1201 01:30:45.966354 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.0039682 (* 1 = 0.0039682 loss)
I1201 01:30:45.966358 13889 sgd_solver.cpp:106] Iteration 31000, lr = 1e-05
I1201 01:30:56.917176 13889 solver.cpp:228] Iteration 31500, loss = 0.0159103
I1201 01:30:56.917222 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00353029 (* 1 = 0.00353029 loss)
I1201 01:30:56.917229 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00231998 (* 1 = 0.00231998 loss)
I1201 01:30:56.917234 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00313769 (* 1 = 0.00313769 loss)
I1201 01:30:56.917240 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00460284 (* 1 = 0.00460284 loss)
I1201 01:30:56.917244 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00350144 (* 1 = 0.00350144 loss)
I1201 01:30:56.917248 13889 sgd_solver.cpp:106] Iteration 31500, lr = 1e-05
I1201 01:31:07.941689 13889 solver.cpp:228] Iteration 32000, loss = 0.0159128
I1201 01:31:07.941745 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.0027557 (* 1 = 0.0027557 loss)
I1201 01:31:07.941752 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00276907 (* 1 = 0.00276907 loss)
I1201 01:31:07.941758 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00442097 (* 1 = 0.00442097 loss)
I1201 01:31:07.941763 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00304415 (* 1 = 0.00304415 loss)
I1201 01:31:07.941768 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00229492 (* 1 = 0.00229492 loss)
I1201 01:31:07.941772 13889 sgd_solver.cpp:106] Iteration 32000, lr = 1e-05
I1201 01:31:16.243415 13889 solver.cpp:228] Iteration 32500, loss = 0.0156894
I1201 01:31:16.243439 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00330697 (* 1 = 0.00330697 loss)
I1201 01:31:16.243446 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.0032345 (* 1 = 0.0032345 loss)
I1201 01:31:16.243451 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00283167 (* 1 = 0.00283167 loss)
I1201 01:31:16.243455 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00304617 (* 1 = 0.00304617 loss)
I1201 01:31:16.243460 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00291058 (* 1 = 0.00291058 loss)
I1201 01:31:16.243464 13889 sgd_solver.cpp:106] Iteration 32500, lr = 1e-05
I1201 01:31:27.227424 13889 solver.cpp:228] Iteration 33000, loss = 0.0158038
I1201 01:31:27.227478 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00213034 (* 1 = 0.00213034 loss)
I1201 01:31:27.227486 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00218143 (* 1 = 0.00218143 loss)
I1201 01:31:27.227491 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00340769 (* 1 = 0.00340769 loss)
I1201 01:31:27.227495 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00326777 (* 1 = 0.00326777 loss)
I1201 01:31:27.227500 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00303109 (* 1 = 0.00303109 loss)
I1201 01:31:27.227505 13889 sgd_solver.cpp:106] Iteration 33000, lr = 1e-05
I1201 01:31:35.511201 13889 solver.cpp:228] Iteration 33500, loss = 0.0159413
I1201 01:31:35.511231 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00337768 (* 1 = 0.00337768 loss)
I1201 01:31:35.511240 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00317568 (* 1 = 0.00317568 loss)
I1201 01:31:35.511245 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00337785 (* 1 = 0.00337785 loss)
I1201 01:31:35.511248 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00372783 (* 1 = 0.00372783 loss)
I1201 01:31:35.511253 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.0028972 (* 1 = 0.0028972 loss)
I1201 01:31:35.511257 13889 sgd_solver.cpp:106] Iteration 33500, lr = 1e-05
I1201 01:31:46.196252 13889 solver.cpp:228] Iteration 34000, loss = 0.0158429
I1201 01:31:46.196313 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00288444 (* 1 = 0.00288444 loss)
I1201 01:31:46.196322 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00289736 (* 1 = 0.00289736 loss)
I1201 01:31:46.196327 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00375077 (* 1 = 0.00375077 loss)
I1201 01:31:46.196331 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00254636 (* 1 = 0.00254636 loss)
I1201 01:31:46.196336 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00284014 (* 1 = 0.00284014 loss)
I1201 01:31:46.196341 13889 sgd_solver.cpp:106] Iteration 34000, lr = 1e-05
I1201 01:31:49.196399 13889 solver.cpp:454] Snapshotting to binary proto file tmp/lnet_iter_34182.caffemodel
I1201 01:31:49.213356 13889 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/lnet_iter_34182.solverstate
I1201 01:31:49.217846 13889 solver.cpp:337] Iteration 34182, Testing net (#0)
I1201 01:32:00.054277 13889 solver.cpp:404]     Test net output #0: loss_1 = 0.00282802 (* 1 = 0.00282802 loss)
I1201 01:32:00.054316 13889 solver.cpp:404]     Test net output #1: loss_2 = 0.00269246 (* 1 = 0.00269246 loss)
I1201 01:32:00.054322 13889 solver.cpp:404]     Test net output #2: loss_3 = 0.00357471 (* 1 = 0.00357471 loss)
I1201 01:32:00.054327 13889 solver.cpp:404]     Test net output #3: loss_4 = 0.00326204 (* 1 = 0.00326204 loss)
I1201 01:32:00.054332 13889 solver.cpp:404]     Test net output #4: loss_5 = 0.00311888 (* 1 = 0.00311888 loss)
I1201 01:32:07.951179 13889 solver.cpp:228] Iteration 34500, loss = 0.0158395
I1201 01:32:07.951221 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00272502 (* 1 = 0.00272502 loss)
I1201 01:32:07.951230 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00277531 (* 1 = 0.00277531 loss)
I1201 01:32:07.951234 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00423829 (* 1 = 0.00423829 loss)
I1201 01:32:07.951238 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00425718 (* 1 = 0.00425718 loss)
I1201 01:32:07.951252 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00549304 (* 1 = 0.00549304 loss)
I1201 01:32:07.951256 13889 sgd_solver.cpp:106] Iteration 34500, lr = 1e-05
I1201 01:32:18.862428 13889 solver.cpp:228] Iteration 35000, loss = 0.0159731
I1201 01:32:18.862493 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00406547 (* 1 = 0.00406547 loss)
I1201 01:32:18.862500 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00330818 (* 1 = 0.00330818 loss)
I1201 01:32:18.862506 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00336859 (* 1 = 0.00336859 loss)
I1201 01:32:18.862510 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.0046986 (* 1 = 0.0046986 loss)
I1201 01:32:18.862515 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00296603 (* 1 = 0.00296603 loss)
I1201 01:32:18.862519 13889 sgd_solver.cpp:106] Iteration 35000, lr = 1e-05
I1201 01:32:27.148128 13889 solver.cpp:228] Iteration 35500, loss = 0.0158633
I1201 01:32:27.148154 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.0028479 (* 1 = 0.0028479 loss)
I1201 01:32:27.148160 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.0036354 (* 1 = 0.0036354 loss)
I1201 01:32:27.148165 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00455515 (* 1 = 0.00455515 loss)
I1201 01:32:27.148170 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00321873 (* 1 = 0.00321873 loss)
I1201 01:32:27.148175 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00272223 (* 1 = 0.00272223 loss)
I1201 01:32:27.148180 13889 sgd_solver.cpp:106] Iteration 35500, lr = 1e-05
I1201 01:32:38.139999 13889 solver.cpp:228] Iteration 36000, loss = 0.0157824
I1201 01:32:38.140054 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.0019606 (* 1 = 0.0019606 loss)
I1201 01:32:38.140063 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00178087 (* 1 = 0.00178087 loss)
I1201 01:32:38.140071 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00418201 (* 1 = 0.00418201 loss)
I1201 01:32:38.140085 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00265819 (* 1 = 0.00265819 loss)
I1201 01:32:38.140090 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00236953 (* 1 = 0.00236953 loss)
I1201 01:32:38.140095 13889 sgd_solver.cpp:106] Iteration 36000, lr = 1e-05
I1201 01:32:46.421237 13889 solver.cpp:228] Iteration 36500, loss = 0.0157449
I1201 01:32:46.421272 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00365393 (* 1 = 0.00365393 loss)
I1201 01:32:46.421278 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.0027845 (* 1 = 0.0027845 loss)
I1201 01:32:46.421283 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00351242 (* 1 = 0.00351242 loss)
I1201 01:32:46.421288 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.003818 (* 1 = 0.003818 loss)
I1201 01:32:46.421293 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00350349 (* 1 = 0.00350349 loss)
I1201 01:32:46.421296 13889 sgd_solver.cpp:106] Iteration 36500, lr = 1e-05
I1201 01:32:57.448791 13889 solver.cpp:228] Iteration 37000, loss = 0.0158806
I1201 01:32:57.448834 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.0028987 (* 1 = 0.0028987 loss)
I1201 01:32:57.448842 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00211196 (* 1 = 0.00211196 loss)
I1201 01:32:57.448854 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00310602 (* 1 = 0.00310602 loss)
I1201 01:32:57.448859 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00263913 (* 1 = 0.00263913 loss)
I1201 01:32:57.448864 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00266437 (* 1 = 0.00266437 loss)
I1201 01:32:57.448868 13889 sgd_solver.cpp:106] Iteration 37000, lr = 1e-05
I1201 01:33:08.121635 13889 solver.cpp:228] Iteration 37500, loss = 0.0158755
I1201 01:33:08.121680 13889 solver.cpp:244]     Train net output #0: loss_1 = 0.00395069 (* 1 = 0.00395069 loss)
I1201 01:33:08.121687 13889 solver.cpp:244]     Train net output #1: loss_2 = 0.00295051 (* 1 = 0.00295051 loss)
I1201 01:33:08.121692 13889 solver.cpp:244]     Train net output #2: loss_3 = 0.00367437 (* 1 = 0.00367437 loss)
I1201 01:33:08.121698 13889 solver.cpp:244]     Train net output #3: loss_4 = 0.00375615 (* 1 = 0.00375615 loss)
I1201 01:33:08.121703 13889 solver.cpp:244]     Train net output #4: loss_5 = 0.00270969 (* 1 = 0.00270969 loss)
I1201 01:33:08.121707 13889 sgd_solver.cpp:106] Iteration 37500, lr = 1e-05
I1201 01:33:16.066676 13889 solver.cpp:454] Snapshotting to binary proto file tmp/lnet_iter_37980.caffemodel
I1201 01:33:16.083464 13889 sgd_solver.cpp:273] Snapshotting solver state to binary proto file tmp/lnet_iter_37980.solverstate
I1201 01:33:16.087605 13889 solver.cpp:337] Iteration 37980, Testing net (#0)
I1201 01:33:26.934618 13889 solver.cpp:404]     Test net output #0: loss_1 = 0.00282708 (* 1 = 0.00282708 loss)
I1201 01:33:26.934654 13889 solver.cpp:404]     Test net output #1: loss_2 = 0.0026928 (* 1 = 0.0026928 loss)
I1201 01:33:26.934660 13889 solver.cpp:404]     Test net output #2: loss_3 = 0.00357466 (* 1 = 0.00357466 loss)
I1201 01:33:26.934665 13889 solver.cpp:404]     Test net output #3: loss_4 = 0.00326313 (* 1 = 0.00326313 loss)
I1201 01:33:26.934669 13889 solver.cpp:404]     Test net output #4: loss_5 = 0.00311863 (* 1 = 0.00311863 loss)
I1201 01:33:26.934674 13889 solver.cpp:322] Optimization Done.
Namespace(epoch=10, gpu=0, lr=0.1, lrp=2, lrw=0.1, prepare=False, snapshot=None, train=True, worker=8)
